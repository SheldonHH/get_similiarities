v68 = ( tree_node *)global_trees; 
( save_level)( x_block_stack->next == 0LL), 
rtx v23; // r15 
rtx nonnote_insn; // rax 
timevar_push( TV_CFG_0); 
v23 = f; 
if ( control_flow_insn_p( v23) ) 
v37 = ( __int64)v23[2]; 
v39 = find_label_refs( *( rtx *)( *( _QWORD *)&v23[2] + 16LL), label_refs); 
v22 = find_label_refs( *( rtx *)( *( _QWORD *)&v23[2] + 24LL), v39); 
v40 = *(  struct rtx_def **)( *( _QWORD *)&v23[2] + 32LL); 
if ( v23[2].fld[0].rtint == -80 ) 
f = delete_insn( v23); 
if ( ( sch_istable[*( ( unsigned __int8 *)pfile->buffer->cur - 1)] & 0x400) != 0 ) 
v27 = ( ( unsigned int)( mode_class_0[BYTE2( v8)] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[( unsigned int)v7] - 5) < 2) + 1; 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
result = gen_rtx_fmt_i0( REG, ( machine_mode)v7, v15); 
if ( base_alias_check( rtx, mem_addr, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), mem_mode) ) 
if ( ( i - 1 < 0) ^ __OFADD__( -1LL, i) | ( i == 1) ) 
tree v50; // [rsp+48h] [rbp-1A8h] 
tree qual_type; // [rsp+D8h] [rbp-118h] 
tree type_1; // [rsp+E8h] [rbp-108h] 
tree val_1; // [rsp+F0h] [rbp-100h] 
tree type_0; // [rsp+108h] [rbp-E8h] 
tree val_0; // [rsp+110h] [rbp-E0h] 
v2 = ( tree_node *)*( &global_trees + 16); 
v2 = ( tree_node *)*( &global_trees + 15); 
return &arg0; 
p_time = ( cpp_token_0 *)v15; 
*( _OWORD *)&u.i[1] = *( _OWORD *)( *( _QWORD *)data + 24LL); 
*( _OWORD *)&u.i[1] = *( _OWORD *)( *( _QWORD *)data + 24LL); 
*( _OWORD *)d1.r = *( _OWORD *)( v1 + 16); 
*( _OWORD *)x.r = *( _OWORD *)u.d.r; 
*( _OWORD *)xa.r = *( _OWORD *)u.d.r; 
*( _OWORD *)xb.r = *( _OWORD *)u.d.r; 
*( _OWORD *)y.r = *( _OWORD *)u.d.r; 
fatal_insn_not_found( insn, "insn-attrtab.c", 19810, "get_attr_pent_prefix"); 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
v3 = !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0; 
&& ( ( pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * insn->fld[0].rtint) & 0x3F)) & 1) == 0 ) 
&& ( ( pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * insn->fld[0].rtint) & 0x3F)) & 1) == 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 0x10) != 0 ) 
|| operator+=<char [3], QByteArray>( val, mem_base) ) 
fancy_abort( &off_723588[4], 1599, "count_pseudo"); 
v5 = ( ( unsigned int)( mode_class_0[v3] - 5) < 2) + 1; 
v16 = ( _DWORD *)( ( char *)&unk_A1C34C + 4 * v9 + 4 * v2); 
fatal_insn_not_found( insn, "insn-attrtab.c", 15861, "get_attr_memory"); 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
LODWORD( v3) = 2 * ( memory_operand( recog_data_0.operand[0], VOIDmode) != 0) + 1; 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
LODWORD( v3) = 2 * ( memory_operand( recog_data_0.operand[0], VOIDmode) != 0); 
|| ( LODWORD( v3) = 0, !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) 
|| ( LODWORD( v3) = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) 
|| !symbolic_operand( recog_data_0.operand[1], SImode) 
|| !memory_operand( recog_data_0.operand[2], VOIDmode)) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_EXPAND_0); 
timevar_push( TV_EXPAND_0); 
timevar_pop( TV_EXPAND_0); 
rtx v38; // rax 
rtx v39; // rcx 
rtx v42; // rcx 
rtx v54; // rcx 
rtx *datum; // [rsp+8h] [rbp-60h] 
rtx datuma; // [rsp+8h] [rbp-60h] 
rtx v60; // [rsp+10h] [rbp-58h] 
v60 = insn; 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)nodes[v30] + 2)); 
immediate_operand( recog_data_0.operand[1], VOIDmode); 
v9 = immediate_operand( recog_data_0.operand[1], VOIDmode); 
v20 = general_operand( recog_data_0.operand[0], QImode); 
v11 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v17] - 5) < 2) + 1; 
v21 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v25] - 5) < 2) + 1; 
hitrate = 10000 - predictor_info_0[predictor].hitrate; 
hitrate = predictor_info_0[predictor].hitrate; 
fatal_insn( "VOIDmode on an output", insn, &off_88ECD0[4], 6651, "emit_output_reload_insns"); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)real_old->fld[0].rtwint), 
v5 = insn_data_0[tertiary_icode].genfun( real_old, reloadreg, third_reloadreg); 
v4 = insn_data_0[rl->secondary_out_icode].genfun( real_old, second_reloadreg, reloadreg); 
low = *( _OWORD *)&c->block.vars; 
recog_data_0.insn = 0LL; 
*( _WORD *)&recog_data_0.n_operands = 0; 
recog_data_0.n_alternatives = 0; 
recog_data_0.n_operands = n_operands; 
fatal_insn_not_found( insn, "recog.c", 2139, "extract_insn"); 
recog_data_0.operand, 
recog_data_0.operand_loc, 
recog_data_0.constraints, 
recog_data_0.operand_mode); 
recog_data_0.n_alternatives = 1; 
v10 = *recog_data_0.constraints[0]; 
if ( !*recog_data_0.constraints[0] ) 
v11 = recog_data_0.constraints[0] + 1; 
recog_data_0.n_alternatives = v12; 
v14 = *recog_data_0.constraints[v13]; 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 1; 
spelling_0->u.s = string; 
++spelling_0; 
for ( du_ptr = ( def_use_0 *)def_use_chain->data.l[0]; ; du_ptr = ( def_use_0 *)def_use_chain->data.l[v0] ) 
for ( du_ptr = ( def_use_0 *)def_use_chain->data.l[0]; ; du_ptr = ( def_use_0 *)def_use_chain->data.l[v0] ) 
*( _OWORD *)&v42[v43].const_rtx = 0LL; 
reg_eqv_table[v5] = ( reg_eqv_elem)-1LL; 
v50 = *( ( _DWORD *)uid_cuid_0 + v49[1]); 
if ( ( v50 > cse_basic_block_end || *( ( _DWORD *)uid_cuid_0 + *v49) < cse_basic_block_start) 
&& v50 > *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[first_reg] + 4)) ) 
&& ( operand = insn_data_0[insn_code].operand, operand->predicate( 
( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)iterations), 
emit_cmp_and_jump_insns( extra, v8, v9, 0LL, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)extra), 0, label); 
handlers = optab_table[37]->handlers; 
handlers[mode_for_size( 0x20u, MODE_INT, 0)].libfunc = inited; 
if ( reg_pref_0 ) 
return reg_pref_0[regno].altclass; 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2), operands[2]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2)); 
error( "invalid operands to binary %s", off_695CB8); 
rtx v9; // rax 
rtx top; // rbx 
rtx v12; // r8 
rtx end; // rcx 
rtx exit_labels; // rcx 
rtx cont; // r8 
rtx v27; // rdx 
v9 = fncall( loop, rtx, v8, v35); 
v10 = ( unsigned __int16 *)v9; 
if ( *( _WORD *)v9 != 36 ) 
top = v9[1].fld[0].rtx; 
top = v9[1].fld[0].rtx; 
p->prev = constructor_range_stack_0; 
p->stack = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
constructor_range_stack_0->next = p; 
constructor_range_stack_0 = p; 
*( _OWORD *)( object_base + 40) = 0LL; 
*( _OWORD *)&v2->loads = 0LL; 
disabled_builtin_0 *v1; // rax 
disabled_builtin_0 *v1; // rax 
v1 = ( disabled_builtin_0 *)xmalloc( 0x10uLL); 
v1 = ( disabled_builtin_0 *)xmalloc( 0x10uLL); 
v1->name = name; 
v1->next = disabled_builtins; 
disabled_builtins = v1; 
rtx compound_operation; // rax 
rtx v27; // rbp 
rtx v28; // rax 
rtx *rtwint; // rcx 
rtx v56; // rax 
rtx *v62; // rbp 
rtx *intoa; // [rsp+8h] [rbp-40h] 
if ( rtuint <= 0x34 && !ix86_hard_regno_mode_ok( rtuint, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)i)) ) 
operand = insn_data_0[icode].operand; 
if ( !operand->predicate( v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)) ) 
v11 = gen_reg_rtx( ( machine_mode)BYTE2( v13)); 
v14 = insn_data_0[icode].genfun( v11, v10); 
pfilea->opts.user_label_prefix = &arg0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 13072, "get_attr_imm_disp"); 
v18 = recog_data_0.operand[1]; 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
v18 = recog_data_0.operand[1]; 
if ( memory_displacement_operand( recog_data_0.operand[0], VOIDmode) ) 
v4 = recog_data_0.operand[1]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
if ( !_bittest( &v20, ix86_cpu) || const1_operand( recog_data_0.operand[2], VOIDmode) || !_bittest( &v20, ix86_cpu) ) 
v5 = &arg0; 
v4 = &arg0; 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE && ( ( *( _DWORD *)&containing_scope[1] >> 14) & 1) == 0 ) 
v1 = mode_class_0[mode]; 
expr->reaching_reg = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2->fld[0].rtwint)); 
v0 = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6; 
pre_redundant_insns->elms[v0] |= 1LL << ( *( ( _BYTE *)uid_cuid_1 + 4 * insn->fld[0].rtint) & 0x3F); 
if ( !gen_aux_info_record_compiled_from_record++ ) 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x3w; 
recog_data_0.operand[2] = x2f; 
recog_data_0.operand[1] = x3x; 
recog_data_0.operand[2] = x2h; 
|| !ix86_binary_operator_ok( XOR, SImode, recog_data_0.operand) 
recog_data_0.operand[1] = x4n; 
|| !ix86_unary_operator_ok( NEG, SImode, recog_data_0.operand) 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x2a; 
recog_data_0.operand[1] = x3g; 
*( _OWORD *)( ( char *)&x->block + 88) = *( _OWORD *)( ( char *)&oldglobal->block + 88); 
*( _OWORD *)( ( char *)&x->block + 88) = *( _OWORD *)( ( char *)&oldglobal->block + 88); 
v5 = *( tree_node **)( low + 128); 
if ( v5 == ( tree_node *)*( &global_trees + 24) ) 
v2 = safe_hash( subexp, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)subexp)); 
relt = lookup( subexp, v2 & 0x1F, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)subexp)); 
v13 = ( tree_node *)*( &global_trees + 27); 
v31 = ( tree_node *)v40; 
u = *( real_extract *)( *( _QWORD *)p + 16LL); 
u_0 = *( real_extract *)( *( ( _QWORD *)p + 1) + 16LL); 
real_value_truncate( &v5, *( ( machine_mode *)p + 7), u.d); 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, 1); 
|| ( *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > cse_basic_block_end 
|| *( ( _DWORD *)uid_cuid_0 + *( int *)reg_n_info->data.l[a1]) < cse_basic_block_start) 
&& *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > *( ( _DWORD *)uid_cuid_0 
&& *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > *( ( _DWORD *)uid_cuid_0 
rtx v940; // rcx 
rtx v1003; // rcx 
recog_data_0.operand[0] = v5; 
recog_data_0.operand[1] = ( rtx)v8; 
v11 = rtx_equal_p( *( rtx *)( v10 + 16), recog_data_0.operand[0]); 
recog_data_0.operand[1] = v190; 
recog_data_0.operand[2] = v191; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)v191 == 66 ) 
recog_data_0.operand[1] = v196; 
recog_data_0.operand[2] = v197; 
recog_data_0.operand[1] = v201; 
recog_data_0.operand[2] = v202; 
recog_data_0.operand[0] = ( rtx)v6; 
recog_data_0.operand[1] = v85; 
recog_data_0.operand[2] = v86; 
recog_data_0.operand[3] = v88; 
if ( rtx_equal_p( *( rtx *)( v89 + 8), recog_data_0.operand[1]) ) 
v90 = rtx_equal_p( *( rtx *)( v89 + 16), recog_data_0.operand[2]); 
return gen_split_1003( recog_data_0.operand); 
recog_data_0.operand[1] = v10; 
recog_data_0.operand[2] = v11; 
recog_data_0.operand[3] = v14; 
if ( rtx_equal_p( *( rtx *)( v15 + 8), recog_data_0.operand[1]) ) 
v16 = rtx_equal_p( *( rtx *)( v15 + 16), recog_data_0.operand[2]); 
return gen_split_1005( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v6; 
recog_data_0.operand[1] = v55; 
recog_data_0.operand[2] = v60; 
if ( dead_or_set_p( insn, recog_data_0.operand[1]) 
&& !reg_mentioned_p( recog_data_0.operand[1], recog_data_0.operand[0]) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 9252, "pent_mul_unit_blockage_range"); 
if ( general_operand( v2, ( machine_mode)*( unsigned __int8 *)( a2 + 2)) ) 
if ( hex_value[( unsigned __int8)c] == 99 ) 
return hex_value[( unsigned __int8)c]; 
if ( ( sch_istable[( unsigned __int8)v17] & 0x88) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v17] & 0x88) == 0 ) 
color = &arg0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 4467, "k6_store_unit_ready_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 
|| !memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 
|| !symbolic_operand( recog_data_0.operand[1], SImode) 
|| !symbolic_operand( recog_data_0.operand[1], SImode)) 
&& ( memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 
|| !memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) 
|| !symbolic_operand( recog_data_0.operand[1], DImode)) 
&& ( memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 
|| !memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6) ) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode)) 
&& !pic_symbolic_operand( recog_data_0.operand[2], DImode) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
&& !pic_symbolic_operand( recog_data_0.operand[2], SImode) 
if ( ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, &now); 
rtx v21; // rax 
rtx v29; // rax 
rtx last_insn; // r15 
rtx v40; // rbp 
reg_set_0 **v20; // r15 
reg_set_0 **v20; // r15 
rtx v27; // r11 
reg_set_0 *v33; // rsi 
reg_set_0 *v33; // rsi 
reg_set_0 *v44; // rdi 
reg_set_0 *v44; // rdi 
reg_set_0 *v49; // rsi 
reg_set_0 *v49; // rsi 
rtx v116; // rcx 
rtx v118; // rbp 
rtx *fld; // rbp 
rtx v125; // r14 
genfun = insn_data_0[insn_code].genfun; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
lang_hooks_0.finish( ); 
insn_mode = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
diagnostic_for_asm( insn, msgid, ( va_list_0 *)ap, 1); 
v1 = constructor_stack_0; 
v1 = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
v10 = spelling_0; 
v11 = ( unsigned __int64)( ( char *)spelling_0 - ( char *)spelling_base) >> 4; 
spelling_0 = v10; 
spelling_0 = v10 + 1; 
spelling_0 = &spelling_base[constructor_depth]; 
constructor_range_stack_0 = v1->range_stack; 
spelling_0 = &spelling_base[depth]; 
constructor_stack_0 = v1->next; 
if ( constructor_stack_0 ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v16 = ( ( unsigned int)( mode_class_0[v14] - 5) < 2) + 1; 
v22 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v20), 80), ( __m128i)xmm*(short *)0x65AE30); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v27 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
v39 = ( ( unsigned int)( mode_class_0[v37] - 5) < 2) + 1; 
v44 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v39), 80), ( __m128i)xmm*(short *)0x65AE30); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( sizetype_tab[0]->block.abstract_origin)) >> 1), 
if ( this_insn_1[2].fld[0].rtint != -1 ) 
for ( ic = 1; ic < insn_data_0[this_insn_1[2].fld[0].rtint].n_operands; ++ic ) 
for ( ic = 1; ic < insn_data_0[this_insn_1[2].fld[0].rtint].n_operands; ++ic ) 
if ( *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 61 
if ( *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 61 
|| *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 43 ) 
|| *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 43 ) 
for ( note = this_insn_1[3].fld[0].rtx; note; note = ( rtx)note[1] ) 
if ( mode_class_0[rld[output_reload].outmode] != MODE_COMPLEX_INT ) 
v23 = mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)note->fld[0].rtwint)] != MODE_COMPLEX_INT ) 
v19 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)note->fld[0].rtwint)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[rld[ib].inmode] != MODE_COMPLEX_INT ) 
v29 = mode_class_0[rld[ib].inmode] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[rld[output_reload].outmode] != MODE_COMPLEX_INT ) 
v26 = mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_FLOAT; 
*( _OWORD *)( v7 + 9) = 0LL; 
v16 = ( tree_node *)v7; 
if ( !debug_no_type_hash ) 
v16 = ( tree_node *)v7; 
if ( !debug_no_type_hash ) 
if ( !v17 || ( v16 = ( tree_node *)*( ( _QWORD *)v17 + 1)) == 0LL ) 
v16 = ( tree_node *)v7; 
fn = ( tree_node *)*( ( _QWORD *)&id->fns->name + id->fns->elements_used); 
if ( !lang_hooks_0.tree_inlining.auto_var_in_fn_p( decl, fn) ) 
if ( !t->decl.name && t->common.type && lang_hooks_0.tree_inlining.anon_aggr_type_p( t->common.type) ) 
( *direction)[13 * loop_ptr->depth + sub] = independent; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[1])] == MODE_INT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[2])] == MODE_INT ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[1])] == MODE_INT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[2])] == MODE_INT ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[1])] == MODE_INT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[2])] == MODE_INT ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[1])] == MODE_INT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[2])] == MODE_INT ) 
strcpy( output_387_binary_op_buf, ssep); 
strcat( output_387_binary_op_buf, "ss\t{%2, %0|%0, %2}"); 
strcat( output_387_binary_op_buf, "sd\t{%2, %0|%0, %2}"); 
strcpy( output_387_binary_op_buf, p); 
strcat( output_387_binary_op_buf, "p\t{%0, %2|%2, %0}"); 
strcat( output_387_binary_op_buf, "p\t{%2, %0|%0, %2}"); 
return output_387_binary_op_buf; 
strcat( output_387_binary_op_buf, "\t{%2, %0|%0, %2}"); 
return output_387_binary_op_buf; 
strcat( output_387_binary_op_buf, "r%z1\t%1"); 
strcat( output_387_binary_op_buf, "%z2\t%2"); 
costs_0 = v4; 
memset( costs_0, 0, n); 
reg_pref_0 = reg_pref_buffer; 
fprintf( dump, " %s:%i", dump_regclass_reg_class_names[j], ( unsigned int)costs_0[v17].cost[j]); 
fprintf( dump, " %s:%i", dump_regclass_reg_class_names[j], ( unsigned int)costs_0[v17].cost[j]); 
fprintf( dump, " MEM:%i\n", ( unsigned int)costs_0[v16].mem_cost); 
v27 = costs_0[v20].cost[v26 + 23]; 
mem_cost = costs_0[v22].mem_cost; 
if ( costs_0[v22].cost[v32] < mem_cost ) 
if ( costs_0[v22].cost[v32 + 1] < mem_cost ) 
if ( dump && ( v25 != reg_pref_0[v20].prefclass || v28 != reg_pref_0[v20].altclass) ) 
if ( dump && ( v25 != reg_pref_0[v20].prefclass || v28 != reg_pref_0[v20].altclass) ) 
fprintf( dump, " pref %s\n", dump_regclass_reg_class_names[v25]); 
v30 = dump_regclass_reg_class_names[v25]; 
fprintf( dump, " pref %s, else %s\n", v30, dump_regclass_reg_class_names[v28]); 
v21 = reg_pref_0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 7005, "pent_v_unit_ready_cost"); 
if ( QTextBlock::operator<( op0a, op1a) ) 
warning( ( &off_71CE90)[code - 1], v3); 
_OWORD *v13; // rax 
_OWORD *v13; // rax 
__m256i arg0; // [rsp+0h] [rbp-58h] BYREF 
arg0.m256i_i64[0] = *v5; 
memset( &arg0.m256i_u64[1], 0, 24); 
arg0.m256i_i64[0] = v7; 
slot_with_hash = htab_find_slot_with_hash( const_int_htab, &arg0, v7, INSERT); 
mode_alignment = get_mode_alignment( ( machine_mode)v4); 
v8 = gen_rtx_fmt_w( CONST_INT, VOIDmode, arg0.m256i_i64[0]); 
mode_alignment = get_mode_alignment( ( machine_mode)v4); 
mode_alignment = get_mode_alignment( ( machine_mode)v4); 
arg0.m256i_i64[0] = v6; 
*( _OWORD *)&arg0.m256i_u64[1] = 0LL; 
*( _OWORD *)&arg0.m256i_u64[1] = 0LL; 
arg0.m256i_i64[3] = ( __int64)v8; 
slot = htab_find_slot( mem_attrs_htab, &arg0, INSERT); 
rtx *v11; // rax 
v11 = phi_alternative( *( rtx *)&rtx[2], bb->index); 
if ( v11 ) 
v12 = fn( rtx, *( _DWORD *)( *( _QWORD *)( v10 + 8) + 8LL), ( *v11)->fld[0].rtint, data); 
splay_tree_value v19; // rax 
splay_tree_value v42; // r14 
if ( v17 != ( tree_node *)global_trees ) 
v19 = global_trees; 
if ( v18 && v18 != ( tree_node *)global_trees || dont_output_data || decl->decl.section_name ) 
v19 = global_trees; 
if ( v18 == ( tree_node *)v19 ) 
if ( in_section_0 == in_text ) 
fprintf( ( FILE *)asm_out_file, off_73AB94, "object"); 
v42 = global_trees; 
if ( !v41 || v41 == ( tree_node *)v42 ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 4153, "k6_fpu_unit_blockage_range"); 
if ( memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest), global_rtl[2]) ) 
if ( ( tree_node *)global_trees != elements ) 
if ( !genrtl_case_label_explained ) 
genrtl_case_label_explained = 1; 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v30[2 * v31 + 2] + 2LL), 
v11 = v4 + hash_expr_1( v43[1], ( machine_mode)*( ( unsigned __int8 *)v43[1] + 2), do_not_record_p); 
v49 = hash_expr_1( ( rtx)v48, ( machine_mode)*( unsigned __int8 *)( v48 + 2), do_not_record_p); 
tree v33; // rbx 
tree v37; // rax 
tree v38; // rax 
mode_alignment = get_mode_alignment( ( machine_mode)BYTE2( v2)); 
htab_empty( hash_table_0); 
htab_delete( hash_table_0); 
if ( ( sch_istable[( unsigned __int8)i] & 0x8C) != 0 ) 
else if ( ( sch_istable[( unsigned __int8)i] & 0x20) != 0 ) 
else if ( ( sch_istable[( unsigned __int8)i] & 2) != 0 ) 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&min_ascii->block.vars 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&min_ascii->block.vars 
|| *( _OWORD *)&max_ascii->block.vars < *( _OWORD *)&n->high->block.vars ) 
|| *( _OWORD *)&max_ascii->block.vars < *( _OWORD *)&n->high->block.vars ) 
rtx nonnote_insn; // rax 
nonnote_insn = next_nonnote_insn( ( rtx)v5); 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( **( _DWORD **)&nonnote_insn[2] & 0xFFFE) == 44 ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( **( _DWORD **)&nonnote_insn[2] & 0xFFFE) == 44 ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( **( _DWORD **)&nonnote_insn[2] & 0xFFFE) == 44 ) 
delete_related_insns( nonnote_insn); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2c; 
recog_data_0.operand[2] = x2d; 
&& ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand) 
|| !ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand) 
recog_data_0.operand[1] = x2e; 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v12] - 5) < 2) + 1; 
result = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)result + 2), result, *( rtx *)&base[1]); 
result = gen_rtx_fmt_e( CONST, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)result), result); 
if ( ( ( unsigned int)( mode_class_0[v2] - 5) < 2) + 1 == nregs && ix86_hard_regno_mode_ok( regno, v2) ) 
if ( ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1 == nregs && ix86_hard_regno_mode_ok( regno, v7) ) 
if ( ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1 == nregs && ix86_hard_regno_mode_ok( regno, v11) ) 
if ( ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1 == nregs && ix86_hard_regno_mode_ok( regno, v15) ) 
if ( ( ( unsigned int)( mode_class_0[52] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[53] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[54] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[55] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[56] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[57] - 5) < 2) + 1 == nregs ) 
if ( ( ( unsigned int)( mode_class_0[58] - 5) < 2) + 1 != nregs ) 
*( _OWORD *)&v26->parm_flag = 0LL; 
*( _OWORD *)&v26->this_block = 0LL; 
*( _OWORD *)&v26->shadowed = 0LL; 
*( _OWORD *)&v26->names = 0LL; 
v13 = immed_double_const( cnst1, v12, ( machine_mode)v10); 
v16 = convert_to_mode( ( machine_mode)v10, op0, unsignedp); 
v17 = expand_mult( ( machine_mode)v10, v16, v13, 0LL, 0); 
v19 = expand_shift( RSHIFT_EXPR, ( machine_mode)v10, v17, v18, 0LL, 1); 
return convert_modes( mode, ( machine_mode)v10, v19, unsignedp); 
v46 = expand_shift( RSHIFT_EXPR, ( machine_mode)oldmode, v44, v45, 0LL, 1); 
v47 = convert_modes( mode, ( machine_mode)oldmode, v46, v42); 
v36 = expand_binop( ( machine_mode)v30, v32, op0, v57, 0LL, v35, OPTAB_WIDEN); 
v49 = expand_shift( RSHIFT_EXPR, ( machine_mode)oldmode, v37, v48, 0LL, 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtl = gen_rtx_MEM( ( machine_mode)v13, v14); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
rtx v24; // rax 
rtx v25; // r12 
rtx v27; // rax 
rtx *v40; // rbp 
rtx result; // rax 
rtx v49; // rax 
sprintf( xstrerror_buf, aUndocumentedEr, ( unsigned int)errnum); 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
arg0 = ( tree_node *)*( &global_trees + 16); 
element_size = ( tree_node *)*( &global_trees + 12); 
return force_reg( ( machine_mode)BYTE2( v1), x); 
( rtx_code)*( _WORD *)x, 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
return force_reg( ( machine_mode)BYTE2( v1), x); 
rtx v28; // rbx 
rtx *v43; // rax 
rtx *v50; // rax 
rtx v51; // r12 
rtx tmp_rtx; // [rsp+40h] [rbp-30h] 
tmp_rtx = rtx_first; 
if ( tmp_rtx ) 
rtx = tmp_rtx[1].fld[0].rtx; 
tmp_rtx = rtx; 
if ( end[rtint] < 0 && ( *( _WORD *)tmp_rtx == 35 || *( _WORD *)tmp_rtx == 37) ) 
if ( end[rtint] < 0 && ( *( _WORD *)tmp_rtx == 35 || *( _WORD *)tmp_rtx == 37) ) 
tmp_rtx->fld[0].rtuint, 
v28 = tmp_rtx; 
v28 = tmp_rtx; 
if ( !*( _QWORD *)&tmp_rtx[1] && graph_dump_format == vcg ) 
if ( reg_note ) 
v10 = *( _QWORD *)( reg_note->fld[0].rtwint + 8); 
if ( reg_classes_intersect_p( ( reg_class)i, GENERAL_REGS) ) 
if ( mode_class_0[m] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[m] == MODE_COMPLEX_FLOAT; 
&& ix86_hard_regno_mode_ok( j, ( machine_mode)m) ) 
cost = ix86_register_move_cost( ( machine_mode)m, ( reg_class)i, ( reg_class)j); 
cost = ix86_register_move_cost( ( machine_mode)m, ( reg_class)i, ( reg_class)j); 
if ( reg_class_subset_p( ( reg_class)i, ( reg_class)j) ) 
if ( reg_class_subset_p( ( reg_class)j, ( reg_class)i) ) 
targeta = force_reg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)targeta), targeta); 
rtx_c = expand_expr( c, 0LL, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)targeta), EXPAND_NORMAL); 
endlink = ( tree_node *)*( &global_trees + 32); 
value_type = ( tree_node *)*( &global_trees + 28); 
if ( check_mode && !ix86_hard_regno_mode_ok( v5, ( machine_mode)( unsigned __int8)BYTE2( *rtwint)) ) 
v3 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[regno])] - 5) < 2) 
if ( v13 || constructor_range_stack_0 ) 
v14->prev = constructor_range_stack_0; 
v14->stack = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
constructor_range_stack_0->next = v14; 
constructor_range_stack_0 = v14; 
if ( !reg_class_subset_p( ( reg_class)class0, ( reg_class)class1) 
if ( reg_class_subset_p( ( reg_class)class1, ( reg_class)class0) ) 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
fprintf( di_0->stream, "%*s", 15 - extra, &arg0); 
*( _OWORD *)&b->aux = 0LL; 
*( _OWORD *)&b->count = 0LL; 
*( _OWORD *)&b->global_live_at_start = 0LL; 
*( _OWORD *)&b->local_set = 0LL; 
*( _OWORD *)&b->pred = 0LL; 
*( _OWORD *)&b->head_tree = 0LL; 
*( _OWORD *)&b->head = 0LL; 
( machine_mode)v20, 
( machine_mode)v21, 
emit_cmp_and_jump_insns( v17, v23, GTU, 0LL, ( machine_mode)v20, 1, default_label); 
v17 = convert_modes( ( machine_mode)v25, VOIDmode, v17, 1); 
v28 = gen_rtx_fmt_ee( MULT, ( machine_mode)v26, v17, v27); 
v29 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), table_label); 
v30 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v26, v28, v29); 
v31 = memory_address_noforce( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v30); 
v32 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5)); 
v33 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v31); 
if ( ( sch_istable[v3] & 4) == 0 ) 
else if ( !strcmp( v1, off_73A990) ) 
else if ( !strcmp( v1, &off_73A990[4]) ) 
else if ( !strcmp( v1, off_73A998) ) 
else if ( !strcmp( v1, &off_73A998[4]) ) 
else if ( !strcmp( v1, off_70CC2B) ) 
else if ( !strcmp( v1, off_70B70B) ) 
else if ( !strcmp( v1, off_73A9AC) ) 
else if ( !strcmp( v1, off_73A9B0) ) 
else if ( !strcmp( v1, ( const char *)&off_695638 + 4) ) 
else if ( !strcmp( v1, ( const char *)&off_695638 + 7) ) 
LODWORD( i) = decode_reg_name_table[v8].number; 
recog_data_0.operand[1] = x2; 
|| !rtx_equal_p( x1bd->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x1bd[1], recog_data_0.operand[0]) 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[2] = x3b; 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 66 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = x4x; 
recog_data_0.operand[2] = x4z; 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 66 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = x4w; 
recog_data_0.operand[2] = x4y; 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 66 
fatal_insn_not_found( insn, "insn-attrtab.c", 3426, "athlon_ieu_unit_ready_cost"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
|| q_regs_operand( recog_data_0.operand[0], QImode) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) 
|| ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode)) 
if ( incdec_operand( recog_data_0.operand[2], DImode) && ix86_cpu == PROCESSOR_ATHLON 
|| !incdec_operand( recog_data_0.operand[2], DImode) && ix86_cpu == PROCESSOR_ATHLON ) 
|| ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
|| ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode)) && ix86_cpu == PROCESSOR_ATHLON 
if ( incdec_operand( recog_data_0.operand[2], SImode) && ix86_cpu == PROCESSOR_ATHLON 
|| !incdec_operand( recog_data_0.operand[2], SImode) && ix86_cpu == PROCESSOR_ATHLON ) 
if ( which_alternative != 2 && incdec_operand( recog_data_0.operand[2], HImode) && ix86_cpu == PROCESSOR_ATHLON 
|| which_alternative != 2 && !incdec_operand( recog_data_0.operand[2], HImode) && ix86_cpu == PROCESSOR_ATHLON ) 
if ( incdec_operand( recog_data_0.operand[2], HImode) && ix86_cpu == PROCESSOR_ATHLON 
v15 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)if_info->cond + 2), cmp_a, cmp_b); 
v16 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v15, vtrue, vfalse); 
if ( !general_operand( cmp_a, ( machine_mode)*( ( unsigned __int8 *)cmp_a + 2)) 
|| !general_operand( cmp_b, ( machine_mode)*( ( unsigned __int8 *)cmp_b + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v4, v5); 
fatal_insn_not_found( insn, "insn-attrtab.c", 5796, "k6_alu_unit_blockage_range"); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( args[i].tree_value->common.type->block.abstract_origin)) >> 1), 
v2 = &arg0; 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
reg_dead_regno = v33; 
reg_dead_endregno = v33 + 1; 
reg_dead_flag = 0; 
if ( reg_dead_flag ) 
if ( reg_dead_flag != 1 ) 
if ( find_regno_note( nonnote_insn, REG_DEAD, reg_dead_regno) ) 
v41 = reg_dead_regno; 
if ( reg_dead_regno < reg_dead_endregno ) 
if ( reg_dead_regno < reg_dead_endregno ) 
if ( ++v41 >= reg_dead_endregno ) 
v35 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v34] - 5) < 2) + 1; 
reg_dead_endregno = v40 + v33; 
reg_dead_flag = 0; 
diddle_return_value( ( void ( *)( rtx, void *))mark_reg_0, set); 
v5 = gen_lowpart_for_combine( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), x); 
v7 = gen_lowpart_for_combine( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v6), y); 
induction_1 *v; // [rsp+40h] [rbp-20h] 
induction_1 *v; // [rsp+40h] [rbp-20h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( v->same && ( ( *( ( _WORD *)v->same + 50) >> 2) & 1) != 0 ) 
if ( v->same && ( ( *( ( _WORD *)v->same + 50) >> 2) & 1) != 0 ) 
*( ( _WORD *)v + 50) = *( ( _WORD *)v + 50) & 0xFFFB | 4; 
*( ( _WORD *)v + 50) = *( ( _WORD *)v + 50) & 0xFFFB | 4; 
if ( ( ( *( ( _WORD *)v + 50) >> 2) & 1) == 0 ) 
if ( v->same ) 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
if ( ( unsigned __int16)*( _DWORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( _DWORD *)v->dest_reg < 0 ) 
if ( ( unsigned __int16)*( _DWORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( _DWORD *)v->dest_reg < 0 ) 
if ( ( unsigned __int16)*( _DWORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( _DWORD *)v->dest_reg < 0 ) 
rtx nonnote_insn; // rax 
rtx v6; // rdi 
rtx v7; // rax 
rtx *v18; // rbx 
rtx v21; // r15 
rtx v23; // rax 
rtx v30; // rax 
rtx v44; // rax 
rtx v45; // r15 
rtx m; // rax 
rtx v42; // r14 
rtx new_sp_equiv_reg; // rbp 
rtx v53; // rbp 
rtx v75; // rdi 
rtx v76; // rax 
rtx v92; // rax 
rtx v100; // rax 
rtx to; // [rsp+0h] [rbp-A8h] 
u = *( real_extract *)( *( _QWORD *)p + 16LL); 
v13 = gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), v12); 
v23 = gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v22 + 2), v22); 
v28 = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v27 + 2), v27); 
fatal_insn_not_found( insn, "insn-attrtab.c", 9235, "pent_mul_unit_ready_cost"); 
if ( !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( which_alternative != 2 && mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], DFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
&& mult_operator( recog_data_0.operand[3], DFmode) 
*( _OWORD *)&v7.first = 0LL; 
*( _OWORD *)&v2->loads = 0LL; 
if ( in_section_0 != in_data ) 
if ( in_section_0 == in_const ) 
in_section_0 = in_const; 
if ( in_section_0 != in_const ) 
if ( in_section_0 == in_data ) 
in_section_0 = in_data; 
( machine_mode)BYTE2( v3), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
v7 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v5] - 5) < 2) + 1; 
v20 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, &value); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&x[1], &v2); 
( va_list_0 *)va, 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rtl)] != MODE_FLOAT ) 
fprintf( di_0->stream, asc_737CC5, 25LL, 6657907LL); 
fprintf( di_0->stream, off_737CC6, v15, 6657907LL); 
run->next = ( tokenrun_0 *)xmalloc( 0x20uLL); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] != MODE_COMPLEX_INT ) 
v61 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] != MODE_COMPLEX_INT ) 
v55 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] != MODE_COMPLEX_INT ) 
v48 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].reg_rtx)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].out)] != MODE_COMPLEX_INT ) 
v36 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rld[r].out)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[rld[r].mode] != MODE_COMPLEX_INT ) 
v40 = mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT; 
sprintf( v18, "*.%s%u", ( const char *)&off_66511C, stmt->identifier.id.len >> 2); 
add_dependence_list_and_free( insn, &deps->pending_write_insns, ( reg_note)( ( for_read == 0) | 0xE)); 
add_dependence_list_and_free( insn, &deps->last_pending_memory_flush, ( reg_note)( ( for_read == 0) | 0xE)); 
v16 = build( ( tree_code)v10, tta, v29, v34, v18); 
v16 = build( ( tree_code)v10, tt, v21, new0, v9); 
v16 = build( ( tree_code)v10, ttb, v25, v26, v27); 
v16 = build1( ( tree_code)v10, type, v15); 
if ( !expand_builtin_va_arg_gave_help ) 
expand_builtin_va_arg_gave_help = 1; 
v16 = gen_rtx_MEM( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1), v14); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
v4 = &arg0; 
lang_hooks_0.name, 
v11 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v10] - 5) < 2) + 1; 
v18 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
v30 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v29] - 5) < 2) + 1; 
v32 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v31] - 5) < 2) + 1; 
if ( constructor_range_stack_0 ) 
while ( constructor_stack_0->implicit ) 
fwrite( &unk_661077, 0x11uLL, 1uLL, outf); 
return force_reg( ( machine_mode)v3, exp); 
v5 = gen_reg_rtx( ( machine_mode)v3); 
v14 = expand_mult_add( v9, reg, v12, v13, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
*( _OWORD *)&reload_inherited[160] = 0LL; 
*( _OWORD *)&reload_inherited[144] = 0LL; 
*( _OWORD *)&reload_inherited[128] = 0LL; 
*( _OWORD *)&reload_inherited[112] = 0LL; 
*( _OWORD *)&reload_inherited[96] = 0LL; 
*( _OWORD *)&reload_inherited[80] = 0LL; 
*( _OWORD *)&reload_inherited[64] = 0LL; 
*( _OWORD *)&reload_inherited[48] = 0LL; 
*( _OWORD *)&reload_inherited[32] = 0LL; 
rtx base_term; // rax 
base_term = find_base_term( rtx); 
|| ( v25 = *( _DWORD *)base_term, ( _WORD)v25 != 67) && ( ( _WORD)v25 != 68 || ( v25 & 0x4000000) == 0) ) 
if ( !base_term 
if ( base_alias_check( rtx, v18, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v5) ) 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v13] - 5) < 2) + 1; 
v33 = ( v14 - 1 < 0) ^ __OFADD__( -1, v14) | ( v14 == 1); 
v33 = ( v14 - 1 < 0) ^ __OFADD__( -1, v14) | ( v14 == 1); 
cselib_lookup( rtwint->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 1); 
if ( reg_note ) 
v5.rtwint = ( __int64)reg_note->fld[0]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 6971, "ppro_p0_unit_ready_cost"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode)) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
if ( ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
if ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
else if ( mult_operator( recog_data_0.operand[3], SFmode) || ix86_cpu != PROCESSOR_PENTIUMPRO ) 
if ( !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
else if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) || ix86_cpu != PROCESSOR_PENTIUMPRO ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) || ix86_cpu != PROCESSOR_PENTIUMPRO ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
else if ( mult_operator( recog_data_0.operand[3], TFmode) || ix86_cpu != PROCESSOR_PENTIUMPRO ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
if ( which_alternative != 2 && mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_PENTIUMPRO ) 
v17 = ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
v22 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v17), 80), ( __m128i)xmm*(short *)0x65AE30); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v27 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
*( _OWORD *)v15.r = a7; 
*( _OWORD *)a1 = *( _OWORD *)v8->r; 
return ( const char *)&unk_87EC4B; 
*( _OWORD *)&v0->x_nonlocal_labels = 0LL; 
*( _OWORD *)&v0->x_nonlocal_goto_handler_labels = 0LL; 
*( _OWORD *)&v1->original_arg_vector = 0LL; 
*( _OWORD *)&v1->x_temp_slots = 0LL; 
*( _OWORD *)&v1->x_rtl_expr_chain = 0LL; 
restype = ( tree_node *)*( &global_trees + 30); 
con0 = ( tree_node *)low; 
con0 = *( tree_node **)( low + 32); 
v6 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v7 = ( cpp_token_0 *)xmalloc( 0x1770uLL); 
if ( !cpp_trigraph_map[*( ( unsigned __int8 *)pfile->buffer->cur + 1)] ) 
cpp_trigraph_map[from_char]); 
if ( ( unsigned int)v1 <= 0xFF && ( sch_istable[( unsigned __int8)v1] & 0xAC) != 0 ) 
*( _OWORD *)( v2 + 88) = 0LL; 
constructor_stack_0 = (  struct constructor_stack *)v2; 
constructor_depth = ( unsigned __int64)( ( char *)spelling_0 - ( char *)spelling_base) >> 4; 
rttree = ( tree_node *)*( &global_trees + 11); 
v5 = gen_rtx_MEM( ( machine_mode)( ( ( v3 & 0x2000000 | 0x500000000uLL) - 1) >> 32), pointer); 
v6 = adjust_address_1( v5, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), offset, 1, 1); 
v7 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
v6 = ( &off_6C5190)[v3]; 
return ( alias_set_entry_0)sn->value; 
v8 = *( const char *const *)( ( char *)resolve_unique_section_prefixes[v4] 
*( _OWORD *)&element->next = 0LL; 
else if ( mode_class_0[BYTE2( v5)] == MODE_INT && !can_compare_p( NE, ( machine_mode)BYTE2( v5), ccp_jump) ) 
else if ( mode_class_0[BYTE2( v5)] == MODE_INT && !can_compare_p( NE, ( machine_mode)BYTE2( v5), ccp_jump) ) 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
rtx v40; // rcx 
rtx v68; // rax 
rtx v78; // rbp 
rtx v81; // rax 
rtx v82; // rbx 
rtx insn_after_basic_block_note; // rax 
rtx v87; // rbx 
rtx v90; // rax 
rtx mm; // rax 
for ( cur = pfile->buffer->cur; ( sch_istable[*cur] & 0x204) != 0; ++cur ) 
result = ( cpp_hashnode_0 *)ht_lookup( 
rtx v26; // rax 
rtx mem_set_list; // rbx 
rtx v30; // r15 
rtx *p_mem_set_list; // rax 
rtx *v34; // r14 
rtx v35; // r15 
rtx v37; // rbp 
rtx *v39; // rax 
rtx v42; // rax 
rtx v43; // r14 
return copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), x); 
char_mode = *( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
if ( !insn_data_0[icode].operand[2].predicate( 
genfun = insn_data_0[icode].genfun; 
return convert_to_mode( ( machine_mode)value_mode, result, 0); 
rtx v275; // rax 
rtx v338; // rax 
rtx v339; // rax 
rtx v350; // rax 
rtx v351; // rax 
rtx v376; // rax 
rtx v385; // rax 
*( _OWORD *)&v24[v25].defs = 0LL; 
return ( cpp_token_0 *)&cur[24 * count]; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v18 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v22 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
*( _OWORD *)d.r = *( _OWORD *)&exp->block.vars; 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( exp->common.type->block.abstract_origin)) >> 1), 
v19 = costs_0; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v7 = mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtl)); 
rtx v36; // [rsp+0h] [rbp-48h] 
v36 = r; 
r = v36; 
v3 = v36[1].fld[0].rtx; 
r = v36; 
r = v36; 
if ( ( sch_istable[v11] & 4) != 0 && !*( ( _BYTE *)v9 + 1) ) 
rtx i; // r13 
rtx v9; // rbp 
rtx v12; // rax 
rtx regno_note; // rax 
rtx ( *v38)[59]; // rcx 
for ( i = pat + 1; ; i = ( rtx)( v6 + 2) ) 
for ( i = pat + 1; ; i = ( rtx)( v6 + 2) ) 
v6 = *( int **)i; 
v7 = **( _DWORD **)i; 
( machine_mode)( unsigned __int8)BYTE2( *v8), 
( machine_mode)BYTE2( v7))] 
*( _QWORD *)i = v6; 
v9 = rtx; 
undo->next = undobuf_0.frees; 
undobuf_0.frees = undo; 
undobuf_0.undos = 0LL; 
v17 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
v35 = *( _OWORD *)&rtwint[2 * v33 + 6]; 
*( _OWORD *)v25[v33 / 2 + 1].elem = v35; 
v36 = *( _OWORD *)&rtwint[2 * v33 + 14]; 
*( _OWORD *)v25[v33 / 2 + 3].elem = v36; 
v37 = *( _OWORD *)&rtwint[2 * v33 + 22]; 
*( _OWORD *)v25[v33 / 2 + 5].elem = v37; 
v38 = *( _OWORD *)&rtwint[2 * v33 + 30]; 
*( _OWORD *)v25[v33 / 2 + 7].elem = v38; 
p_int_cst = &low->int_cst.int_cst; 
low = ( tree)p_int_cst->low; 
p_int_cst = &low->int_cst.int_cst; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&low->block.subblocks; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&low->block.subblocks; 
fatal_insn_not_found( insn, "insn-attrtab.c", 13438, "get_attr_i387"); 
v5 = recog_data_0.operand[3]; 
v5 = recog_data_0.operand[3]; 
v5 = recog_data_0.operand[3]; 
if ( get_attr_type( insn) == TYPE_FOP || mult_operator( recog_data_0.operand[3], TFmode) ) 
v7 = reverse_condition_maybe_unordered( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op0); 
v7 = reverse_condition( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op0); 
fprintf( v1, "%s, ", reg_class_names_0[*( ( int *)v2 - 20)]); 
fprintf( v1, "%ssecondary_in_icode = %s", "\n\t", insn_data_0[v8].name); 
fprintf( v1, "%ssecondary_out_icode = %s", v9, insn_data_0[v10].name); 
v1 = if_stack_0; 
if ( if_stack_0[( unsigned int)v0].compstmt_count == if_stack_0[v2].compstmt_count ) 
if ( if_stack_0[( unsigned int)v0].compstmt_count == if_stack_0[v2].compstmt_count ) 
if_stack_0[v2].needs_warning = 1; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
*( _OWORD *)&loc->offset = 0LL; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)var), 
rtx v12; // rax 
rtx x; // [rsp+0h] [rbp-68h] BYREF 
rtx v30[2]; // [rsp+8h] [rbp-60h] BYREF 
rtx parts; // [rsp+18h] [rbp-50h] BYREF 
v12 = copy_rtx( *operands); 
*operands = v12; 
*( ( _BYTE *)v12 + 2) = 5 - ( ( target_flags & 0x2000000) == 0); 
v5 = ix86_split_to_parts( operands[1], &parts, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v5 = ix86_split_to_parts( operands[1], &parts, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, &x, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, &x, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
compiler_params = ( param_info_0 *)xrealloc( compiler_params, 24 * ( n + num_compiler_params)); 
pfile->opts.in_fname = &arg0; 
pfile->opts.out_fname = &arg0; 
pfile->opts.user_label_prefix = &arg0; 
v51 = ( v84 - 1 < 0) ^ __OFADD__( -1LL, v84) | ( v84 == 1); 
v77 = __CFADD__( lnum_orig, *lrem); 
v77 = __CFADD__( ( *v17)++, 1LL); 
v77 = __CFADD__( lnum_orig, *lrem); 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&minval->block.vars ) 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x3e; 
|| !ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x3d; 
|| !ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3f; 
recog_data_0.operand[2] = x4c; 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[2] = x3g; 
if ( !general_operand( x, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)) ) 
v5 = want_to_gcse_p_test_insn; 
if ( !want_to_gcse_p_test_insn ) 
want_to_gcse_p_test_insn = make_insn_raw( v7); 
want_to_gcse_p_test_insn[1] = 0LL; 
ggc_add_rtx_root( &want_to_gcse_p_test_insn, 1); 
v5 = want_to_gcse_p_test_insn; 
v8 = want_to_gcse_p_test_insn; 
*( _QWORD *)( *( _QWORD *)&want_to_gcse_p_test_insn[2] + 16LL) = x; 
if ( code1 || mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)exp->fld[0].rtwint)] != MODE_CC ) 
return reversed_comparison_code_parts( ( rtx_code)( unsigned __int16)*( _DWORD *)exp, x->fld[0].rtx, *( rtx *)&x[1], 0LL); 
&& memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)g2->mem), ret) ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x->fld[0].rtwint)) == x[1]; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v11 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
*( _OWORD *)v27 = 0LL; 
*( _OWORD *)v25 = 0LL; 
rtx v11; // rbx 
induction_1 *v28; // rbx 
induction_1 *v28; // rbx 
induction_1 *v34; // rsi 
induction_1 *v34; // rsi 
rtx add_val; // [rsp+10h] [rbp-68h] BYREF 
rtx v38; // [rsp+18h] [rbp-60h] BYREF 
rtx v39; // [rsp+20h] [rbp-58h] BYREF 
rtx ext_val; // [rsp+28h] [rbp-50h] BYREF 
rtx v42; // [rsp+38h] [rbp-40h] 
v15 = convert_modes( v9, ( machine_mode)v11, v12, v10); 
v13 = ( tree_node *)i[4]; 
rtx *v9; // rsi 
rtx v10; // rdx 
rtx *p_old; // rdx 
if ( !legitimate_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)object), rtx, 0) ) 
v9 = ( rtx *)&object[2]; 
v10 = ( rtx)*( ( _QWORD *)v7 + 1); 
v10 = gen_rtx_fmt_E( PARALLEL, VOIDmode, v11); 
rtwint = ( int *)v10->fld[0].rtwint; 
rtwint = ( int *)v10->fld[0].rtwint; 
v9 = ( rtx *)&object[2]; 
validate_change( object, v9, v10, 1); 
validate_change( object, v9, v10, 1); 
|| ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_VECTOR_FLOAT) 
v19 = ( tree_node *)j[4]; 
aka = ( tree_node *)prev_try->aka; 
v16 = ( tree_node *)v13->aka; 
fprintf( file, ( const char *)&off_8A2198 + 4, "\t.zero\t", v7); 
table_0 = (  struct bucket **)permalloc( 296); 
memset( table_0, 0, 0x128uLL); 
print_node( stderr, &arg0, node, 0); 
table_0 = 0LL; 
v10 = *( tree_node **)( low + 40); 
v3 = spelling_0; 
if ( spelling_base < spelling_0 ) 
v3 = spelling_0; 
if ( !append_random_chars_value ) 
append_random_chars_value = st.st_mtim.tv_sec ^ st.st_ino ^ st.st_dev; 
append_random_chars_value = 1LL; 
v = append_random_chars_value; 
*templatea = append_random_chars_letters[append_random_chars_value % 0x3E]; 
*templatea = append_random_chars_letters[append_random_chars_value % 0x3E]; 
templatea[1] = append_random_chars_letters[v % 0x3E]; 
templatea[2] = append_random_chars_letters[v % 0x3E]; 
templatea[3] = append_random_chars_letters[v % 0x3E]; 
templatea[4] = append_random_chars_letters[v % 0x3E]; 
templatea[5] = append_random_chars_letters[v % 0x3E]; 
rtx epilogue_delay_list; // rbx 
epilogue_delay_list = cfun->epilogue_delay_list; 
if ( epilogue_delay_list ) 
while ( !can_throw_external( epilogue_delay_list) ) 
epilogue_delay_list = ( rtx)epilogue_delay_list[1]; 
if ( !epilogue_delay_list ) 
return ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, str, len, HT_ALLOC); 
args[i].value = convert_modes( args[i].mode, ( machine_mode)mode, args[i].value, args[i].unsignedp); 
bitmap_print( file, bb_info->rd_in, &arg0, "\n"); 
bitmap_print( file, bb_info->rd_gen, &arg0, "\n"); 
bitmap_print( file, bb_info->rd_kill, &arg0, "\n"); 
bitmap_print( file, bb_info->rd_out, &arg0, "\n"); 
bitmap_print( file, bb_info_0->ru_in, &arg0, "\n"); 
bitmap_print( file, bb_info_0->ru_gen, &arg0, "\n"); 
bitmap_print( file, bb_info_0->ru_kill, &arg0, "\n"); 
bitmap_print( file, bb_info_0->ru_out, &arg0, "\n"); 
bitmap_print( file, bb_info_1->lr_in, &arg0, "\n"); 
bitmap_print( file, bb_info_1->lr_use, &arg0, "\n"); 
bitmap_print( file, bb_info_1->lr_def, &arg0, "\n"); 
bitmap_print( file, bb_info_1->lr_out, &arg0, "\n"); 
expand_mult( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)aa), aa, ba, 0LL, 1); 
timevar_push( TV_CPP_0); 
timevar_pop( TV_CPP_0); 
if ( ( sch_istable[v3->val.c] & 0xAC) == 0 ) 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v11 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v11 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, j, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, j, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
if ( v3 == reverse_condition( ( rtx_code)( unsigned __int16)*( _DWORD *)cond2) 
v12 = gen_rtx( v10, ( machine_mode)v7, v11, v5); 
v8 = v7 + hash_rtx( rtwint[1], ( machine_mode)*( ( unsigned __int8 *)rtwint[1] + 2), 0); 
v8 += hash_rtx( ( rtx)v36, ( machine_mode)*( unsigned __int8 *)( v36 + 2), 0); 
u_buff = ( _cpp_buff_0 *)&result[v10]; 
rtx *fld; // rcx 
rtx memrefloc[8]; // [rsp+8h] [rbp-40h] BYREF 
v18 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)v12 + 2), *( rtx *)&v12[1]); 
memrefloc[1] = ( rtx)loc; 
memrefloc[0] = v18; 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), v12->fld[0].rtx, v18); 
fld = ( rtx *)v19->fld; 
find_reloads_address( mode, memrefloc, rtx, fld, ( rtx *)( unsigned int)opnum, type, ind_levels, 0LL); 
find_reloads_address( mode, memrefloc, rtx, fld, ( rtx *)( unsigned int)opnum, type, ind_levels, 0LL); 
if ( mode_class_0[v16] != MODE_INT || ( v19 = mode_bitsize[v16], v19 > 0x40) || ( _DWORD)v19 != 1 ) 
&& ( mode_class_0[*( unsigned __int8 *)( v14->fld[0].rtwint + 2)] == MODE_CC) == ( mode_class_0[( _QWORD)v31] != MODE_CC) ) 
&& ( mode_class_0[*( unsigned __int8 *)( v14->fld[0].rtwint + 2)] == MODE_CC) == ( mode_class_0[( _QWORD)v31] != MODE_CC) ) 
|| mode_class_0[*( unsigned __int8 *)( v14->fld[0].rtwint + 2)] != MODE_INT 
LOBYTE( v21) = mode_class_0[( _QWORD)v31] != MODE_CC; 
LOBYTE( v22) = mode_class_0[v22] == MODE_CC; 
if ( mode_class_0[v26] != MODE_CC ) 
if ( mode_class_0[BYTE2( v23)] == MODE_CC ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v11 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
rtx v4; // r14 
if ( reg_note && x ) 
v4 = reg_note; 
v4 = reg_note; 
rtx[3].fld[0].rtwint = ( __int64)gen_rtx_fmt_ee( EXPR_LIST, XCmode, v4->fld[0].rtx, rtx[3].fld[0].rtx); 
v39 = &off_71A8C0 + ( char)v38; 
v39 = &off_71A8D8 + ( char)v49; 
v39 = &off_71A8F0 + ( char)v47; 
v39 = &off_71A908 + ( char)v48; 
( machine_mode)*( ( unsigned __int8 *)v19 + 2), 
v53 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)v19 + 2), v37); 
if ( significand_size( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v19)) + 1 < *( const unsigned __int16 *)( ( char *)mode_bitsize + ( ( *( _DWORD *)v21 >> 15) & 0x1FE)) ) 
emit_cmp_and_jump_insns( v21, const_int_rtx[64], GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v21 + 2), 0, v18); 
rtx *v27; // rax 
result = ( _cpp_buff_0 *)&v1[lenb]; 
return ( _cpp_buff_0 *)&v1[lenb]; 
return gen_rtx_fmt_ee( ( rtx_code)( unsigned __int16)*( _DWORD *)x, v1, op0, op1); 
lang_hooks_0.init_options( ); 
set_target_switch( &arg0); 
lang_processed = lang_hooks_0.decode_option( argc - ia, &argv[ia]); 
lang_hooks_0.post_options( ); 
tmpcount = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)variable)); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)variable), 
allocno_0[( __int64)ialloc].hard_reg_conflicts |= hard_regs_live; 
allocno_0[( __int64)j].hard_reg_conflicts |= 1LL << regno; 
if ( recog_data_0.n_operands > 0 ) 
v4 = recog_data_0.operand_loc[v1]; 
if ( ( unsigned __int16)( *( _WORD *)recog_data_0.operand[v1] - 66) > 0xCu 
|| !_bittest( &v2, *( _DWORD *)recog_data_0.operand[v1] - 66) ) 
recog_data_0.operand[v1] = v3; 
while ( v1 < recog_data_0.n_operands ); 
if ( recog_data_0.n_dups > 0 ) 
v7 = recog_data_0.dup_loc[v5]; 
*recog_data_0.dup_loc[v5] = v6; 
while ( v5 < recog_data_0.n_dups ); 
mark_reg_live_nc( aa, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[i])); 
pri1 = ( int)( ( double)( allocno_0[( __int64)v1].freq * floor_log2_wide( allocno_0[( __int64)*( int *)v1p].n_refs)) 
pri1 = ( int)( ( double)( allocno_0[( __int64)v1].freq * floor_log2_wide( allocno_0[( __int64)*( int *)v1p].n_refs)) 
/ ( double)allocno_0[( __int64)v1].live_length 
* ( double)allocno_0[( __int64)v1].size); 
pri2 = ( int)( ( double)( allocno_0[( __int64)v2].freq * floor_log2_wide( allocno_0[( __int64)v2].n_refs)) 
pri2 = ( int)( ( double)( allocno_0[( __int64)v2].freq * floor_log2_wide( allocno_0[( __int64)v2].n_refs)) 
/ ( double)allocno_0[( __int64)v2].live_length 
* ( double)allocno_0[( __int64)v2].size); 
recog_data_0.insn = 0LL; 
result = gen_peephole2_1291( insn, recog_data_0.operand); 
result = gen_peephole2_1290( insn, recog_data_0.operand); 
result = gen_peephole2_1295( insn, recog_data_0.operand); 
result = gen_peephole2_1296( insn, recog_data_0.operand); 
result = gen_peephole2_1297( insn, recog_data_0.operand); 
result = gen_peephole2_1276( insn, recog_data_0.operand); 
result = gen_peephole2_1275( insn, recog_data_0.operand); 
result = gen_peephole2_1280( insn, recog_data_0.operand); 
result = gen_peephole2_1281( insn, recog_data_0.operand); 
result = gen_peephole2_1282( insn, recog_data_0.operand); 
recog_data_0.operand[0] = v63; 
recog_data_0.operand[3] = ( rtx)v232; 
if ( rtx_equal_p( v233, recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = v234; 
rtx result; // rax 
result = 0LL; 
return result; 
fprintf( asm_out_file, ( const char *)&off_8A2198 + 4, "\t.zero\t", ( unsigned int)size); 
name = ( unsigned __int8 *)&arg0; 
space = ( unsigned __int8 *)&arg0; 
rtx *v11; // r10 
rtx *v16; // rax 
rtx *v20; // r8 
rtx *v24; // rdi 
v10 = v7 + ( ( unsigned int)( mode_class_0[( unsigned __int8)v9] - 5) < 2) + 1; 
v11 = reg_last_death; 
v16 = &reg_last_death[v7 + 14]; 
*( __m128i *)&( &v11[v7])[v15] = si128; 
*( __m128i *)&v16[v15 - 12] = si128; 
*( __m128i *)&v16[v15 - 10] = si128; 
*( __m128i *)&v16[v15 - 8] = si128; 
*( __m128i *)&v16[v15 - 6] = si128; 
*( __m128i *)&v16[v15 - 4] = si128; 
*( __m128i *)&v16[v15 - 2] = si128; 
if ( v3 == ( tree_node *)global_trees ) 
rtx v34; // rax 
rtx result; // rax 
tree v47; // rax 
tree v49; // r12 
tree chain; // rbx 
tree rttree; // r13 
predictor_info_0[predictor].name, 
tmode = *( ( unsigned __int16 *)insn_data_0[icode].operand + 8); 
HIDWORD( mode1) = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
LODWORD( mode1) = *( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8); 
if ( mode_class_0[*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)] == MODE_VECTOR_INT 
if ( mode_class_0[*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)] == MODE_VECTOR_INT 
|| mode_class_0[*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)] == MODE_VECTOR_FLOAT ) 
|| mode_class_0[*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[( int)mode1] == MODE_VECTOR_INT || mode_class_0[( int)mode1] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[( int)mode1] == MODE_VECTOR_INT || mode_class_0[( int)mode1] == MODE_VECTOR_FLOAT ) 
op1 = safe_vector_operand( op1, ( machine_mode)mode1); 
|| !insn_data_0[icode].operand->predicate( target, tmode) ) 
if ( !insn_data_0[icode].operand[1].predicate( op0, ( machine_mode)HIDWORD( mode1)) ) 
if ( !insn_data_0[icode].operand[1].predicate( op0, ( machine_mode)HIDWORD( mode1)) ) 
if ( !insn_data_0[icode].operand[2].predicate( op1, ( machine_mode)mode1) ) 
if ( !insn_data_0[icode].operand[2].predicate( op1, ( machine_mode)mode1) ) 
v9 = gen_rtx_fmt_s( SYMBOL_REF, v7, off_88ECD0); 
rtx v12; // rax 
rtx operands; // [rsp+18h] [rbp-70h] BYREF 
operands = operand; 
operands = pool_constant; 
split_di( &operands, 1, parts, parts + 1); 
operands = v13; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v8 = fold_rtx_mult_add( v8, v11, *( rtx *)( i + 72), ( machine_mode)*( _DWORD *)( i + 48)); 
( machine_mode)*( ( unsigned __int8 *)v6 + 2), 
i += subreg_regno_offset( i, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)last_reg), byte, mode); 
need_mode = byte ? smallest_mode_for_size( byte + mode_size[mode], mode_class_0[mode]) : mode; 
if ( mode_class_0[rld[r].mode] != MODE_COMPLEX_INT ) 
v43 = mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT; 
fancy_abort( &off_88ECD0[4], 5670, "choose_reload_regs"); 
if ( mode_class_0[rld[r].mode] != MODE_COMPLEX_INT ) 
v34 = mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT; 
if ( warningp && !count_error_warning_message ) 
count_error_warning_message = 1; 
if ( ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)if_infoa->x)] == MODE_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)if_infoa->x)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)if_infoa->x)] == MODE_VECTOR_FLOAT) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_infoa->x), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
hash_table_0 = v3; 
v16 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1; 
rtx v30; // rax 
rtx memloc; // rbx 
rtx *fld; // r14 
rtx v37; // rax 
rtx v45; // rax 
v8 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v12] - 5) < 2) + 1; 
if ( reg_class_subset_p( rclass, qty_0[qtyno].min_class) ) 
qty_0[qtyno].min_class = rclass; 
if ( reg_class_subset_p( rclassa, qty_0[qtyno].alternate_class) ) 
qty_0[qtyno].alternate_class = rclassa; 
qty_0[qtyno].changes_mode = 1; 
set_value_regno( x->fld[0].rtuint, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), (  struct value_data *)data); 
( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), 
( machine_mode)BYTE2( v4)); 
v11 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1; 
if ( x_block_stack && *( _OWORD *)&x_block_stack->data.case_stmt.nominal_type != 0LL ) 
v10 = *( _OWORD *)&cum->words; 
*( _OWORD *)&v41.sse_words = *( _OWORD *)&cum->sse_words; 
*( _OWORD *)&v41.sse_words = *( _OWORD *)&cum->sse_words; 
*( _OWORD *)&v41.words = v10; 
v12 = *( _OWORD *)&cum->words; 
*( _OWORD *)&v41.sse_words = *( _OWORD *)&cum->sse_words; 
*( _OWORD *)&v41.sse_words = *( _OWORD *)&cum->sse_words; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
fatal_insn_not_found( insn, "insn-attrtab.c", 46, "insn_variable_length_p"); 
*( _OWORD *)&cfa->offset = 0LL; 
fatal_insn_not_found( insn, "insn-attrtab.c", 8333, "pent_u_unit_blockage_range"); 
o = *( optab_0 *)arg; 
if ( in_section_0 != in_named || strcmp( name, in_named_name) ) 
in_section_0 = v6; 
return mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)op)] == MODE_FLOAT; 
*( _OWORD *)( p_chain + 9) = 0LL; 
v8 = ( change_t_0 *)xrealloc( changes, 32LL * v9); 
rtx last_insn; // rbp 
rtx v12; // rax 
rtx v16; // r12 
rtx v20; // rax 
rtx v25; // rax 
rtx secondary_mem; // r14 
rtx v31; // r14 
last_insn = get_last_insn( ); 
&& ( v10 = gen_lowpart_common( ( machine_mode)v9, out)) != 0LL ) 
v4 = regno + ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v21 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *val_rtx)] - 5) < 2) + 1; 
rtx insn; // [rsp+28h] [rbp-18h] 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
if ( insn ) 
v3 = insn != bb->end[1].fld[0].rtx; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
for ( link = df_0->insns[insn->fld[0].rtuint].uses; link; link = link->next ) 
v4 = gen_rtx( ( rtx_code)( unsigned __int16)*( _DWORD *)operand3, V4SImode, operand1, operand2); 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[i])] != MODE_COMPLEX_INT ) 
v32 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[i])] == MODE_COMPLEX_FLOAT; 
rtx v24; // rsi 
rtx v25; // rax 
rtx v27; // [rsp+10h] [rbp-38h] 
v24 = ( rtx)i1[2]; 
if ( *( _WORD *)v24 != 47 ) 
v24 = single_set_2( i1, v24); 
v24 = single_set_2( i1, v24); 
v24 = 0LL; 
v25 = ( rtx)i2[2]; 
if ( *( _WORD *)v25 != 47 ) 
rtx v103; // rax 
rtx v119; // rax 
rtx v130; // [rsp+0h] [rbp-78h] 
rtx v132; // [rsp+8h] [rbp-70h] 
rtx v67; // rax 
rtx v69; // rax 
rtx v72; // rax 
rtx v76; // r14 
rtx v78; // r12 
rtx v82; // rax 
rtx v84; // rax 
do_compare_rtx_and_jump( op0, op1, v6, unsignedp, ( machine_mode)mode, size, if_false_label, if_true_label); 
&& ( _DWORD)v10 == reverse_condition( ( rtx_code)v11) 
v3 = ( machine_mode)rtl[3]; 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 2; 
spelling_0->u.s = low; 
++spelling_0; 
rtx v53; // rax 
rtx v54; // rsi 
rtx v62; // rax 
rtx v64; // rax 
rtx regno_note; // rax 
rtx real_insn; // r12 
rtx v84; // rax 
rtx v95; // rax 
rtx v99; // rax 
return in_section_0 == in_text; 
sprintf( &v8[v9], " %-33s", &unk_72B187); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest_reg), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x->fld[0].rtwint), 
fatal_insn_not_found( insn, "insn-attrtab.c", 6988, "ppro_p0_unit_blockage_range"); 
v6 = lang_hooks_0.expand_constant( exp); 
if ( in_section_0 == in_text ) 
fprintf( ( FILE *)asm_out_file, ( const char *)&off_73AB98 + 4, "\t.zero\t", ( unsigned int)v5); 
if ( in_section_0 != in_text ) 
result = simplify_subreg( v3, v2.rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2.rtwint), *( _DWORD *)&v1[1]); 
fprintf( outfile, off_690140, name->int_cst.int_cst.low); 
v8 = ( const char *)&unk_71B966; 
*( _OWORD *)&cum->sse_words = 0LL; 
*( _OWORD *)&cum->words = 0LL; 
if ( !insn_data_0[1159].operand->predicate( loc, ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32) ) 
v1 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), loc); 
u_buff = ( _cpp_buff_0 *)&cur[v13]; 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v12 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
free_buffs = ( _cpp_buff_0 *)&v18[v17]; 
v20 = ( _cpp_buff_0 *)&v29[v28]; 
while ( v4 == 46 || ( sch_istable[v4] & 0x204) != 0 ); 
if ( ( _DWORD)v4 != 46 && ( sch_istable[( unsigned __int8)v4] & 0x204) == 0 ) 
sprintf( digit_buffer, off_67FAE6, *v51); 
sprintf( digit_buffer, &off_685EAB[1], *v22); 
sprintf( digit_buffer, off_684DDF, *v40); 
if ( section_name == ( tree_node *)*( &global_trees + 5) ) 
if ( section_name == ( tree_node *)*( &global_trees + 4) ) 
if ( section_name == ( tree_node *)*( &global_trees + 3) ) 
if ( section_name == ( tree_node *)*( &global_trees + 2) ) 
if ( section_name == ( tree_node *)*( &global_trees + 1) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 2169, "athlon_fp_muladd_unit_ready_cost"); 
v15 = ( ( unsigned int)( mode_class_0[v13] - 5) < 2) + 1; 
v28 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v25 >> 14) & 0x3FC)) - 5) < 2) + 1; 
rtx v7; // r12 
rtx pending_read_insns; // rbp 
rtx *v9; // rbx 
rtx v10; // rbx 
rtx pending_write_insns; // rbp 
rtx *v12; // rbx 
rtx v13; // rbx 
rtx i; // rbx 
rtx v18; // rax 
rtx v19; // rbx 
sprintf( temp, "*.%s%u", "LM", ( unsigned int)dbxout_source_line_sym_lineno); 
fprintf( asmfile, ".%s%u:\n", "LM", ( unsigned int)dbxout_source_line_sym_lineno); 
++dbxout_source_line_sym_lineno; 
rtx v20; // [rsp+0h] [rbp-38h] BYREF 
v20 = v3; 
v20 = y; 
if ( ( unsigned __int16)v6 == 75 && ( constant_term_loc = find_constant_term_loc( &v20)) != 0LL ) 
v20 = *constant_term_loc; 
*v15 = v20; 
v0 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 2); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 29844, "ppro_p0_unit_conflict_cost"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
free( reg_pref_0); 
if ( reg_pref_0 ) 
reg_pref_0 = reg_pref_buffer; 
_OWORD *v16; // rax 
_OWORD *v16; // rax 
v16 = ggc_alloc( 0x28uLL); 
*slot = v16; 
*( ( _QWORD *)v16 + 4) = v20; 
v17 = *( _OWORD *)arg0; 
v16[1] = v19; 
*v16 = v17; 
if ( **( _WORD **)( v4.rtwint + 16) == 54 && !memory_address_p( ( machine_mode)BYTE2( v3), x->fld[0].rtx) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 6331, "ppro_p01_unit_ready_cost"); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65ADF0); 
v5 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE00); 
v6 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v7 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE20); 
v11 = ( ( unsigned int)( mode_class_0[v10] - 5) < 2) + 1; 
page_group_0 *v6; // rbx 
page_group_0 *v6; // rbx 
v0 = _mm_sub_pd( ( __m128d)_mm_unpacklo_ps( ( __m128)G.allocated, ( __m128)xmm*(short *)0x68F950), ( __m128d)xmm*(short *)0x68F960); 
fputs( dump_edge_info_bitnames[i], file); 
if ( ( tree_node *)v18 == elements ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
predicate = insn_data_0[( _QWORD)insn_code].operand->predicate; 
v14 = insn_data_0[v12].genfun( x, insn_code); 
induction_1 *biv1; // [rsp+148h] [rbp-1648h] 
induction_1 *biv1; // [rsp+148h] [rbp-1648h] 
induction_1 *biv; // [rsp+150h] [rbp-1640h] 
induction_1 *biv; // [rsp+150h] [rbp-1640h] 
induction_1 *iv; // [rsp+1748h] [rbp-48h] 
induction_1 *iv; // [rsp+1748h] [rbp-48h] 
biv = bl_0->biv; 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
if ( ( unsigned __int16)*( _DWORD *)biv->add_val != 54 ) 
biv->src_reg->fld[0].rtuint, 
rtx *v15; // r15 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v13] - 5) < 2) + 1; 
v15 = loc; 
v15 = loc; 
v15 = loc; 
v15 = loc; 
df_ref_record_1( df_0, v17, v15, insn, ref_type, ref_flags); 
v13 = *( tree_node **)( high + 40); 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v6; 
|| ( recog_data_0.operand[0] = v9, !ix86_match_ccmode( insn, CCGCmode)) 
|| ( result = 213LL, recog_data_0.operand[2]->fld[0].rtint == 0x80000000) ) 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = ( rtx)v12; 
&& rtx_equal_p( *( rtx *)( v182 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v182 + 16), recog_data_0.operand[2]) 
v15 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v12; 
&& rtx_equal_p( *( rtx *)( v14 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v14 + 16), recog_data_0.operand[2]) 
v15 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v16; 
recog_data_0.operand[2] = v17; 
recog_data_0.operand[0] = v186; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 ) 
v187 = recog_data_0.operand[2]; 
v10 = ( tree_node *)p_chain[4]; 
sprintf( v10, &off_6474F4[1], v7); 
formal_list = ( char *)&arg0; 
this_type = gen_type( &arg0, *( tree *)&formal_type[2], ansi); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] != MODE_COMPLEX_INT ) 
v12 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] == MODE_COMPLEX_FLOAT; 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v20 = mode_class_0[mode]; 
operand = insn_data_0[insn_code].operand; 
v18 = insn_data_0[v12].genfun( v15, v16); 
v20 = mode_class_0[mode]; 
( machine_mode)i, 
v25 = expand_unop( ( machine_mode)v23, v7, v24, 0LL, unsignedp); 
( machine_mode)v51, 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
if ( rtx_class[code] == 99 && QTextBlock::operator<( op0, op1) ) 
rtx opc; // [rsp+8h] [rbp-40h] 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v6; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v8; 
recog_data_0.operand[1] = v8; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v22; 
v23 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v22 >> 14) & 0x3FC)); 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[1] = v11; 
if ( generating_concat_p && ( v2 = mode_class_0[mode], ( unsigned int)( v2 - 5) <= 1) ) 
v13 = mode_class_0[mode]; 
v2 = ( tree_node *)ggc_alloc( v1); 
invalidate( v2->fld[0].rtx, ( machine_mode)BYTE2( v3)); 
if ( v23 != ( tree_node *)global_trees ) 
v2 = ix86_expand_compare( ( rtx_code)*( _WORD *)operand0, 0LL, 0LL); 
fatal_insn_not_found( insn, "insn-attrtab.c", 8316, "pent_u_unit_ready_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_PENTIUM ) 
|| !memory_operand( recog_data_0.operand[1], VOIDmode) 
&& ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
&& ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
&& ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
|| ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
&& incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
|| !incdec_operand( recog_data_0.operand[2], HImode) 
|| ( incdec_operand( recog_data_0.operand[2], HImode) 
&& ( !incdec_operand( recog_data_0.operand[2], HImode) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode)) 
if ( reg_note ) 
v10 = *( _QWORD *)( reg_note->fld[0].rtwint + 8); 
if ( recog_data_0.n_operands > 0 ) 
n_alternatives = recog_data_0.n_alternatives; 
v3 = recog_data_0.constraints[v2]; 
v8 = ( reg_class *)( v6 + v5 + 10106744); 
n_alternatives = recog_data_0.n_alternatives; 
while ( v4 < recog_data_0.n_alternatives ); 
while ( v2 < recog_data_0.n_operands ); 
*( _OWORD *)a1 = *( _OWORD *)p_e; 
v6 = mode_class_0[mode]; 
buffer->state.format_args = ( va_list_0 *)ap; 
v19 = *( _OWORD *)&v9[v18]; 
v20 = *( _OWORD *)&v9[v18 + 16]; 
v21 = *( _OWORD *)&base[v18 + 16]; 
*( _OWORD *)&v9[v18] = *( _OWORD *)&base[v18]; 
*( _OWORD *)&v9[v18] = *( _OWORD *)&base[v18]; 
*( _OWORD *)&v9[v18 + 16] = v21; 
*( _OWORD *)&base[v18] = v19; 
*( _OWORD *)&base[v18 + 16] = v20; 
v22 = *( _OWORD *)&v9[v18 + 32]; 
if ( !count_error_warning_message ) 
count_error_warning_message = 1; 
v30 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v31 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v32 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v33 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v34 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
if ( ( sch_istable[v28] & 0x88) != 0 ) 
htab_traverse( hash_table_0, ( htab_trav)cselib_invalidate_mem_1, mem_rtx); 
mode_alignment = get_mode_alignment( ( machine_mode)BYTE2( v12)); 
if ( QTextBlock::operator<( op0, op1) ) 
free_buffs = ( _cpp_buff_0 *)&v12[v11]; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 32215, "fpu_unit_blockage"); 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUM && mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( ix86_cpu != PROCESSOR_PENTIUMPRO || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUM && !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) ) 
|| mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || mult_operator( recog_data_0.operand[3], XFmode) ) 
data = &insn_data_0[1112]; 
data = &insn_data_0[1113]; 
data = &insn_data_0[1114]; 
sprintf( v6, "*.%s%u", ( const char *)&off_624A4C, stmt->identifier.id.len >> 2); 
reg_set_table = ( reg_set_0 **)gmalloc( n); 
( machine_mode)*( ( unsigned __int8 *)v73 + 2), 
( machine_mode)*( ( unsigned __int8 *)v76 + 2), 
rtx i; // r12 
rtx v44; // rbx 
rtx v48; // r15 
rtx v49; // rax 
rtx *v51; // rsi 
rtx reg_equal_equiv_note; // r15 
rtx v63; // rax 
rtx v88; // rbx 
rtx nonnote_insn; // rax 
v48 = pc_set( src->end); 
rtx *v31; // rbx 
rtx last_value; // rax 
v10 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x >> 14) & 0x3FC)); 
v12 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)val >> 14) & 0x3FC)); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
( machine_mode)BYTE2( v24)); 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
( machine_mode)BYTE2( v16), 
rtx v8; // rbx 
rtx v13; // rbx 
rtx v17; // rax 
rtx v21; // rax 
rtx v24; // rax 
reg_last_set_mode = ( machine_mode *)xmalloc( 4LL * nregs); 
v8 = f; 
*( ( _DWORD *)uid_cuid + v8->fld[0].rtint) = v7; 
subst_insn = v8; 
v9 = *( _WORD *)v8; 
v16 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v15] - 5) < 2) + 1; 
v22 = _mm_add_epi64( _mm_shuffle_epi32( ( __m128i)v1->fld[0].rtuint, 68), ( __m128i)xmm*(short *)0x65ADF0); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE00); 
v28 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v29 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE20); 
v30 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x668290); 
v31 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x6682A0); 
*( _OWORD *)&result->left = 0LL; 
result = construct_container( ( machine_mode)v2, valtype, 1, 6, 8, x86_64_int_return_registers, 0); 
return gen_rtx_REG( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( valtype->block.abstract_origin)) >> 1), 0); 
v3 = mode_class_0[v2]; 
return gen_rtx_REG( ( machine_mode)v2, v4); 
if ( ( sch_istable[v3] & 4) != 0 ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8)) ) 
if ( !insn_data_0[icode].operand[opnum].predicate( 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8), xa); 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8), xa); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)old), 
fancy_abort( &off_88ECD0[4], 6967, "do_output_reload"); 
v37 = expand_shift( ( tree_code)( v39 ^ 0x53), mode, v36, exp, target, 1); 
v38 = expand_shift( ( tree_code)( v39 | 0x52), mode, v36, v35, 0LL, 1); 
if ( mode_class_0[v3] == MODE_FLOAT ) 
if ( ( mode_class_0[mode] | 2) != 3 ) 
*( _OWORD *)&e->flags = 0LL; 
*( _OWORD *)&e->insns = 0LL; 
*( _OWORD *)&e->src = 0LL; 
*( _OWORD *)&e->pred_next = 0LL; 
v68 = *( _OWORD *)&x->fld[0].rtwint; 
v68 = *( _OWORD *)&x->fld[0].rtwint; 
v68 = *( _OWORD *)&x->fld[0].rtwint; 
v14 = ( char *)off_709FBB; 
v68 = *( _OWORD *)&x->fld[0].rtwint; 
v68 = *( _OWORD *)&x->fld[0].rtwint; 
for ( b = table_0[hash]; b; b = b->next ) 
b->next = table_0[hash]; 
table_0[hash] = b; 
first_rtl = first_rtl_op( ( tree_code)( unsigned __int8)*( ( _DWORD *)&nodea->common + 4)); 
lang_hooks_0.print_identifier( filea, nodea, indenta); 
if ( *( _OWORD *)&nodea->block.vars <= __PAIR128__( -1LL, 0LL) ) 
lang_hooks_0.print_xnode( filea, nodea, indenta); 
lang_hooks_0.print_decl( filea, nodea, indenta); 
lang_hooks_0.print_type( filea, nodea, indenta); 
rgn_print_insn_tmp, 
sprintf( rgn_print_insn_tmp, "%d", insn->fld[0].rtuint); 
rgn_print_insn_tmp, 
return rgn_print_insn_tmp; 
v11 = ( tree_node *)*( &global_trees + 16); 
v4 = *( tree_node **)( *( _QWORD *)( low + 8) + 8LL); 
v4 = *( tree_node **)( *( _QWORD *)( low + 8) + 8LL); 
rtx v16; // rsi 
v16 = reg_map[v15]; 
if ( !v16 || *( _WORD *)v16 != 63 ) 
if ( !v16 || *( _WORD *)v16 != 63 ) 
return simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
return simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
return simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
v8 = v52 == swap_condition( ( rtx_code)v46) 
destination = asm_dest_local; 
destination = asm_dest_local; 
destination = ( ( ( unsigned __int64)decl->real_cst.real_cst.r[2] >> 17) & 1) == 0; 
if ( destination == asm_dest_bss ) 
if ( destination == asm_dest_bss ) 
if ( destination ) 
if ( destination == asm_dest_bss ) 
if ( destination == asm_dest_bss ) 
if ( destination != asm_dest_local ) 
if ( destination != asm_dest_local ) 
k = hex_value[( unsigned __int8)*s]; 
v6 = sch_istable[( unsigned __int8)*sp_0] & 4; 
v14 = ( sch_istable[( unsigned __int8)*sp_0] & 0x100) != 0; 
if ( ( sch_istable[( unsigned __int8)*s] & 4) == 0 ) 
rtx v21; // rax 
rtx v27; // rax 
rtx v33; // rsi 
rtx v37; // rcx 
rtx *clobber_reg; // [rsp+A0h] [rbp-50h] 
rtx v55; // [rsp+B0h] [rbp-40h] 
n_operands = recog_data_0.n_operands; 
v51 = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
v3.rtwint = ( __int64)recog_data_0.operand[v8]; 
recog_data_0.operand[v8] = v3.rtx; 
clobber_reg = ( rtx *)v3.rtwint; 
return object_size_table[( *( page_entry_0 ***)( ( char *)G.lookup + ( ( ( unsigned __int64)p >> 21) & 0x7F8)))[( ( unsigned __int64)p >> SLOBYTE( G.lg_pagesize)) & ~( -1 << ( 24 - LOBYTE( G.lg_pagesize)))]->order]; 
if ( *( _OWORD *)&v13->data.case_stmt.nominal_type == 0LL ) 
v21 = canon_hash( v10, ( machine_mode)BYTE2( v11)); 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2x; 
|| ( unsigned __int8)recog_data_0.operand[2]->fld[0].rtwint == 128LL 
recog_data_0.operand[1] = x3bh; 
recog_data_0.operand[2] = x3bi; 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 66 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[2] = x3bg; 
recog_data_0.operand[1] = x2y; 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 66 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[0] = x3bj; 
recog_data_0.operand[1] = x3bk; 
v12 = mode_class_0[BYTE2( v9)]; 
return general_operand( op, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
else if ( stack_0->timevar == tv ) 
fwrite( *( ( const void **)&ptr + ( __int16)v5), 7uLL, 1uLL, file); 
fatal_insn_not_found( insn, "insn-attrtab.c", 3443, "athlon_ieu_unit_blockage_range"); 
fprintf( di_0->stream, "\n%*s", 25, &arg0); 
v101 = ( tree_node *)rtl[4]; 
fwrite( &unk_677C4B, 2uLL, 1uLL, asmfile); 
v69 = ( unsigned int)dbxout_type_anonymous_type_number++; 
if ( ( *( _BYTE *)( v54 + 18) & 4) != 0 && !strcmp( lang_hooks_0.name, "GNU C++") ) 
v12 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v26 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg_rtx)] - 5) < 2) + 1; 
fatal_insn_not_found( insn, "insn-attrtab.c", 12429, "get_attr_fp_int_src"); 
recog_data_0.operand[1] = v9.rtx; 
recog_data_0.operand[2] = v98; 
recog_data_0.operand[0] = v100; 
if ( !rtx_equal_p( *( rtx *)( v101 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = v9.rtx; 
recog_data_0.operand[2] = v11; 
recog_data_0.operand[0] = v14; 
if ( !rtx_equal_p( *( rtx *)( v15 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = v21.rtx; 
recog_data_0.operand[2] = v105; 
recog_data_0.operand[0] = v107; 
if ( rtx_equal_p( *( rtx *)( v108 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = v21.rtx; 
recog_data_0.operand[2] = v24; 
recog_data_0.operand[0] = v27; 
if ( rtx_equal_p( *( rtx *)( v28 + 8), recog_data_0.operand[1]) ) 
v6 = gen_rtx_REG( ( machine_mode)( ( ( v4 & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), pointer); 
v8 = adjust_address_1( v7, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), offset, 1, 1); 
v13 = gen_rtx_REG( ( machine_mode)( ( ( v4 & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
v14 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), pointer); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
( *direction)[13 * loop_ptr->depth + sub] = independent; 
cselib_invalidate_regno( dest->fld[0].rtuint, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)); 
if ( push_operand( dest, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)) ) 
rtx v5; // rax 
*( _OWORD *)&v1->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&v1->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&emit->x_first_insn = 0LL; 
v5 = rtx; 
v6->x_last_insn = v5; 
if ( mode_class_0[save_mode[regno]] != MODE_COMPLEX_INT ) 
v16 = mode_class_0[save_mode[regno]] == MODE_COMPLEX_FLOAT; 
v11 = gen_rtx_REG( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)mem), regno); 
free_buffs = ( _cpp_buff_0 *)&v19[v18]; 
if ( ( sch_istable[( unsigned __int8)v8] & 0x400) != 0 ) 
rtx *v35; // rcx 
rtx *reg_loc; // rax 
reg_loc = done_renames->reg_loc; 
v38 = *reg_loc; 
if ( *reg_loc != done_renames->old_reg ) 
*reg_loc = done_renames->new_reg; 
v35 = ( rtx *)( ( ( *v38 >> 13) & 0x7F8) + 472 * v39 + 10653024); 
v35 = &ssa_rename_to_pseudo[( unsigned int)( v39 - 53)]; 
*v35 = done_renames->prev_reg; 
rtx result; // rax 
rtx v5; // rcx 
result = gen_rtx_fmt_E( SEQUENCE, VOIDmode, v3); 
v5 = cfun->emit->x_first_insn; 
if ( v5 ) 
*( _QWORD *)( result->fld[0].rtwint + v6) = v5; 
*( _QWORD *)( result->fld[0].rtwint + v6) = v5; 
v5 = v5[1].fld[0].rtx; 
v5 = v5[1].fld[0].rtx; 
while ( v5 ); 
return result; 
decl = *( tree_node **)( exp->int_cst.int_cst.low + 32); 
v25 = ( const char *)&off_71A333; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 38030, "pent_np_unit_conflict_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
else if ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) 
else if ( !incdec_operand( recog_data_0.operand[2], DImode) 
str_rtx = operand_sub*(short *)0xforce( v20, v10 >> ( 6 - ( v13 == 0)), ( machine_mode)*( ( unsigned __int8 *)v20 + 2)); 
str_rtx = operand_sub*(short *)0xforce( v20, v10 >> ( 6 - ( v13 == 0)), ( machine_mode)*( ( unsigned __int8 *)v20 + 2)); 
base[BYTE3( p)] = ( page_entry_0 **)xcalloc( 1LL << ( 24 - LOBYTE( G.lg_pagesize)), 8uLL); 
fprintf( file, off_685EAB, ( unsigned int)( j + ( i->indx << 7))); 
fprintf( file, off_685EAB, ( unsigned int)( k + ( i->indx << 7) + 64)); 
while ( ( sch_istable[( unsigned __int8)c] & 0x800) != 0 ); 
result = apply_args_size_size; 
if ( apply_args_size_size < 0 ) 
apply_args_size_size = v1; 
apply_args_size_size = 2 * v1; 
return apply_args_size_size; 
if ( v9 && ( unsigned int)( mode_class_0[v8] - 5) > 1 ) 
v15 = apply_args_size_size; 
if ( apply_args_size_size % v14 ) 
v15 = v14 + apply_args_size_size - 1 - ( v14 + apply_args_size_size - 1) % v14; 
v15 = v14 + apply_args_size_size - 1 - ( v14 + apply_args_size_size - 1) % v14; 
apply_args_size_size = v15; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 27443, "k6_alu_unit_conflict_cost"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) && ( ( 1 << ix86_cpu) & x86_movx) == 0 ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
if ( ( which_alternative == 3 || incdec_operand( recog_data_0.operand[2], QImode)) 
&& !incdec_operand( recog_data_0.operand[2], QImode) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) ) 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[1] = ( rtx)v7; 
return gen_split_881( recog_data_0.operand); 
return gen_split_881( recog_data_0.operand); 
return gen_split_881( recog_data_0.operand); 
v154 = *( unsigned __int16 *)recog_data_0.operand[0]; 
rtuint = recog_data_0.operand[0]->fld[0].rtuint; 
else if ( v154 != 61 || v12 || recog_data_0.operand[0]->fld[0].rtint > 3u ) 
if ( !reg_overlap_mentioned_p( recog_data_0.operand[0], ( rtx)v7) ) 
return gen_split_882( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v7; 
v162 = true_regnum( recog_data_0.operand[0]); 
if ( v162 != true_regnum( recog_data_0.operand[1]) ) 
return gen_split_883( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[1] = ( rtx)v16; 
return gen_split_879( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v16; 
return gen_split_885( recog_data_0.operand); 
if ( ( sch_istable[( unsigned __int8)c] & 0x400) != 0 ) 
valuec = ( tree_node *)global_trees; 
rtx v28; // rbx 
rtx v36; // rbx 
v26 = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)v15, v16, 15); 
v27 = gen_rtx_fmt_e( CONST, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v26); 
v28 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v27); 
v28 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v27); 
*( ( _BYTE *)v28 + 3) |= 4u; 
v29 = ix86_GOT_alias_set_set; 
if ( ix86_GOT_alias_set_set == -1 ) 
ix86_GOT_alias_set_set = v29; 
set_mem_alias_set( v28, v29); 
v2 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v30 = gen_movsi( v2, v28); 
v17 = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)v15, v16, 6); 
v18 = gen_rtx_fmt_e( CONST, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v17); 
*( _DWORD *)( buf + 3) = ( _DWORD)&unk_6E7275; 
preal = qToBigEndian<unsigned int>( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)p->fld[0].rtwint), p); 
pimag = gen_imagpart( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)preal), p); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)pat->fld[0].rtwint)] != MODE_COMPLEX_INT ) 
v21 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)pat->fld[0].rtwint)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v16 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
fprintf( dump, " %s:%i", dump_regclass_reg_class_names[classa], ( unsigned int)costs_0[i].cost[classa]); 
fprintf( dump, " %s:%i", dump_regclass_reg_class_names[classa], ( unsigned int)costs_0[i].cost[classa]); 
fprintf( dump, " MEM:%i\n", ( unsigned int)costs_0[i].mem_cost); 
v7 = ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
v7 = ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
v7 = ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
/ ( double)( qty_0[v3].death - qty_0[v3].birth) 
/ ( double)( qty_0[v3].death - qty_0[v3].birth) 
- ( int)( ( double)( qty_0[v8].size * qty_0[v8].freq * floor_log2_wide( qty_0[v8].n_refs)) 
- ( int)( ( double)( qty_0[v8].size * qty_0[v8].freq * floor_log2_wide( qty_0[v8].n_refs)) 
- ( int)( ( double)( qty_0[v8].size * qty_0[v8].freq * floor_log2_wide( qty_0[v8].n_refs)) 
/ ( double)( qty_0[v8].death - qty_0[v8].birth) 
/ ( double)( qty_0[v8].death - qty_0[v8].birth) 
rtx v9; // r15 
rtx v22; // r12 
v9 = *( rtx *)( v2.rtwint + 24); 
if ( *( _WORD *)v9 == 54 
&& v9->fld[0].rtwint + ( int)v7 > *( const unsigned __int16 *)( ( char *)mode_bitsize 
rtx = gen_rtx_fmt_e( USE, ( machine_mode)BYTE2( v3), rtx); 
v9 = gen_rtx_CONST_INT( VOIDmode, v8); 
v17 = mode_class_0[BYTE2( v10)]; 
v22 = copy_rtx( rtx); 
v23 = gen_binary( ASHIFT, ( machine_mode)v16, v21, v9); 
v23 = gen_binary( ASHIFT, ( machine_mode)v16, v21, v9); 
v24 = simplify_gen_unary( NOT, ( machine_mode)v16, v23, ( machine_mode)v16); 
v24 = simplify_gen_unary( NOT, ( machine_mode)v16, v23, ( machine_mode)v16); 
timevar_push( TV_PARSE_0); 
lang_hooks_0.clear_binding_stack( ); 
timevar_pop( TV_PARSE_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
v14 = *( _OWORD *)&v2[v12 * 2 + 2]; 
*( _OWORD *)result[v12 + 1].elem = v14; 
v15 = *( _OWORD *)&v2[v12 * 2 + 6]; 
*( _OWORD *)result[v12 + 3].elem = v15; 
v16 = *( _OWORD *)&v2[v12 * 2 + 10]; 
*( _OWORD *)result[v12 + 5].elem = v16; 
v17 = *( _OWORD *)&v2[v12 * 2 + 14]; 
*( _OWORD *)result[v12 + 7].elem = v17; 
v20 = *( _OWORD *)&v2[v18 / 8 + 2]; 
v2 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), profiler_label); 
temp = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)); 
while ( ( tree_node *)p_chain[3] != values ) 
basic_block bb; // [rsp+90h] [rbp-10h] 
bb = basic_block; 
bb->global_live_at_start = bitmap_initialize( ( bitmap)value); 
bb->global_live_at_end = bitmap_initialize( ( bitmap)value_0); 
bitmap_copy( bb->global_live_at_start, edge_in->dest->global_live_at_start); 
bitmap_copy( bb->global_live_at_end, edge_in->dest->global_live_at_start); 
make_single_succ_edge( bb, edge_in->dest, 1); 
redirect_edge_succ( edge_in, bb); 
else if ( !redirect_edge_and_branch( edge_in, bb) ) 
return bb; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v5), v8) ) 
v10 = assign_stack_local( ( machine_mode)v6, mode_size[v6], 0); 
v10 = gen_reg_rtx( ( machine_mode)v6); 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v5), v12) ) 
rtx v17; // r13 
rtx v52; // r15 
rtx memref; // [rsp+30h] [rbp-98h] 
v23 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
return offsettable_address_p( 1, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), op->fld[0].rtx) != 0; 
internal_error_function( msgid, ( va_list_0 *)va); 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&v1->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&v1->begin_diagnostic; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
if ( !cpp_trigraph_map[v7] ) 
v9 = cpp_trigraph_map[cur[1]]; 
v14 = sch_istable[cur[v12++]]; 
cpp_trigraph_map[v7]); 
htab_traverse( hash_table_0, ( htab_trav)discard_useless_locs, 0LL); 
htab_traverse( hash_table_0, ( htab_trav)discard_useless_values, 0LL); 
v19 = statement_code_p( ( tree_code)v10); 
if ( ( _DWORD)v10 != 2 && !v19 && !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v8) ) 
if ( ( _DWORD)v10 != 2 && !v19 && !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v8) ) 
if ( statement_code_p( ( tree_code)*( ( unsigned __int8 *)*v8 + 16)) && ( *( ( _BYTE *)*v8 + 19) & 4) == 0 ) 
rtl_op = first_rtl_op( ( tree_code)v10); 
if ( !statement_code_p( ( tree_code)v10) ) 
v22 = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v8, &subtrees, func, v20, htab_); 
v22 = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v8, &subtrees, func, v20, htab_); 
v9 = mode_class_0[mode]; 
v11 = mode_class_0[v8] != MODE_FLOAT; 
v6 = gen_lowpart( ( machine_mode)mode, v6); 
v33 = simplify_gen_subreg( ( machine_mode)v14, v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), 0); 
v33 = simplify_gen_subreg( ( machine_mode)v14, v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), 0); 
if ( ( unsigned int)( mode_class_0[( unsigned int)v8] - 7) < 2 ) 
to = simplify_gen_subreg( ( machine_mode)v8, target, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target), 0); 
to = simplify_gen_subreg( ( machine_mode)v8, target, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target), 0); 
rtx v8; // rax 
rtx v9; // rsi 
rtx v10; // rcx 
&& ( v10 = reg_equiv_constant[v5]) != 0LL ) 
rtx = v10; 
v9 = ( rtx)addr[1]; 
|| ( v9 = reg_equiv_constant[rtuint]) == 0LL ) 
v8 = subst_indexed_address( addr->fld[0].rtx); 
if ( v8 != rtx ) 
rtx = v8; 
v9 = v3; 
v9 = subst_indexed_address( v3); 
if ( v9 == v3 ) 
if ( *( _WORD *)v9 == 75 ) 
fld = (  struct rtx_def **)v9->fld; 
return insn_data_0[extendtab[mto][mfrom][unsignedp != 0]].genfun( x, y); 
timevar_get( TV_TOTAL_0, &total_elapsed); 
v5 = simplify_gen_subreg( SImode, op, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), 0); 
v6 = simplify_gen_subreg( SImode, op, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), 4u); 
v4->constructor_stack = constructor_stack_0; 
v4->constructor_range_stack = constructor_range_stack_0; 
v4->spelling = spelling_0; 
v4->next = initializer_stack_0; 
initializer_stack_0 = v4; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
spelling_0 = v12 + 1; 
*( _OWORD *)&result->dw_cfi_oprnd1.dw_cfi_reg_num = 0LL; 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( exp->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
( machine_mode)*( unsigned __int8 *)( v15.rtwint + 2), 
( machine_mode)BYTE2( v4)); 
v16 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
if ( optab_table[30]->handlers[v2].insn_code != CODE_FOR_nothing || mode_class_0[v2] != MODE_CC ) 
return insn_data_0[optab_table[30]->handlers[v3].insn_code].genfun( v8, v10); 
return insn_data_0[optab_table[30]->handlers[v3].insn_code].genfun( v8, v10); 
ereal_atof( &v4, args->str, ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( args->type->block.abstract_origin)) >> 1)); 
ereal_atof( &v3, args->str, ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( args->type->block.abstract_origin)) >> 1)); 
reg_map[reg->fld[0].rtuint] = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg)); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)link), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)link), 
predict_insn_def( copy, PRED_LOOP_HEADER, TAKEN_0); 
predict_insn_def( copy, PRED_LOOP_HEADER, NOT_TAKEN_0); 
rtx v18; // rax 
rtx v38; // rax 
v18 = adjust_automodify_address_1( to, v8, data->to_addr, data->offset, 1); 
v18 = adjust_address_1( to, v8, data->offset, 1, 1); 
info = &reg_avail_info_0[regno]; 
cuid = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
( machine_mode)BYTE2( v8), 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)x + 2), v21); 
( machine_mode)*( unsigned __int8 *)( reloads_subreg_address->fld[0].rtwint + 2)); 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)reloads_subreg_address + 2), v23); 
( machine_mode)*( ( unsigned __int8 *)reloads_subreg_address + 2), 
if ( replace_reloads && recog_data_0.operand[opnum] != x ) 
( machine_mode)*( ( unsigned __int8 *)memloc + 2), 
LODWORD( v1) = file_table_0.table; 
if ( !LODWORD( file_table_0.table) 
|| strcmp( file_name, *( const char **)( cfa_temp.offset + 8LL * LODWORD( file_table_0.table))) ) 
LODWORD( file_table_0.table) = v1; 
LODWORD( file_table_0.table) = v1; 
sprintf( print_insn_tmp, "%4d", insn->fld[0].rtuint); 
return print_insn_tmp; 
if ( v4 == ( tree_node *)global_trees ) 
tree v27; // r12 
tree v28; // rax 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x2a; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x2l; 
recog_data_0.operand[1] = x2l; 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 54 
&& recog_data_0.operand[1]->fld[0].rtwint == -1 
if ( !rtx_equal_p( x3q->fld[0].rtx, recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = x5; 
recog_data_0.operand[2] = ( rtx)x5a[1]; 
recog_data_0.operand[1] = x2l; 
|| !rtx_equal_p( x1q->fld[0].rtx, recog_data_0.operand[1]) 
if ( ( sch_istable[*p] & 0x200) == 0 ) 
if ( ( sch_istable[*q] & 0x204) == 0 ) 
v3 = assign_stack_local( ( machine_mode)v2, mode_size[v2], 0); 
classa = mode_class_0[*( int *)pmode]; 
result_mode = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
v24 = operand_sub*(short *)0xforce( result_val, v25 >> ( 6 - ( v30 == 0)), BLKmode); 
v22 = expand_expr( ( tree)high, v21, ( machine_mode)*( ( unsigned __int8 *)v21 + 2), EXPAND_NORMAL); 
*( _OWORD *)equot = 0LL; 
*( _OWORD *)v9 = 0LL; 
v2 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_info->x)); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_info->x), 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)chain->rld[i].reg_rtx)] != MODE_COMPLEX_INT ) 
v9 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)chain->rld[i].reg_rtx)] == MODE_COMPLEX_FLOAT; 
if ( *( _OWORD *)&t->block.vars == 0LL 
v9 = *( int *)( ( char *)&allocno_0->reg + v8); 
v11 = *( int *)( ( char *)&allocno_0->reg + v8); 
if ( !*( int *)( ( char *)&allocno_0->calls_crossed + v8) ) 
v14 = v162 | *( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->hard_reg_conflicts + v8); 
v15 = *( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->regs_someone_prefers + v8) | v14 | ~regs_used_so_far; 
if ( !_bittest64( ( const __int64 *)&v19, v21) && ix86_hard_regno_mode_ok( v21, ( machine_mode)mode) ) 
v23 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
if ( !_bittest64( ( const __int64 *)&v19, v21) && ix86_hard_regno_mode_ok( v21, ( machine_mode)mode) ) 
v28 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v32 = allocno_0; 
targeta = gen_reg_rtx( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( integer_types[5]->block.abstract_origin)) >> 1)); 
v39 = ( tree_node *)*( &global_trees + 12); 
v53 = build( ( tree_code)( ( ( ( code - 130) & 0xFFFFFFFD | 0x3C00000000uLL) - 1) >> 32), v25, v52, v41); 
disabled_builtin_0 *p; // [rsp+8h] [rbp-18h] 
disabled_builtin_0 *p; // [rsp+8h] [rbp-18h] 
for ( p = disabled_builtins; p; p = p->next ) 
for ( p = disabled_builtins; p; p = p->next ) 
for ( p = disabled_builtins; p; p = p->next ) 
for ( p = disabled_builtins; p; p = p->next ) 
if ( !strcmp( name, p->name) ) 
v3 = gen_rtx_fmt_s( ASM_INPUT, VOIDmode, &arg0); 
output_asm_insn( off_87B914, operands); 
return &arg0; 
v16 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
v2 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v3 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v4 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v15 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
*( _OWORD *)&diagnostic_buffer->state.prefix = 0LL; 
v1->state.format_args = ( va_list_0 *)va; 
*( _OWORD *)&v1->state.diagnostic_count[4] = v16; 
result = expand_mult_add( b, reg, m, a, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 1); 
fatal_insn_not_found( insn, "insn-attrtab.c", 4709, "k6_store_unit_blockage_range"); 
v11 = ( ( unsigned int)( mode_class_0[v9] - 5) < 2) + 1; 
v4 = gen_rtx_REG( ( machine_mode)v2, v3); 
if ( index_type == ( tree_node *)global_trees ) 
p_int_cst = &exp->int_cst.int_cst; 
p_int_cst = &exp->int_cst.int_cst; 
high = ( unsigned __int8 *)p_int_cst; 
if ( v21 != *( tree_node **)( p + 5) ) 
v25 = ( tree_node *)v16[4]; 
v32 = ( tree_node *)v16[4]; 
v13 = lang_hooks_0.expand_constant( exp); 
*hv = ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64; 
return ( ~( v6 ^ h2) & ( v6 ^ ( ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64))) >> 63; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)retvalue)] != MODE_COMPLEX_INT ) 
v8 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)retvalue)] == MODE_COMPLEX_FLOAT; 
if ( !insn_data_0[icode].operand[1].predicate( op0, TImode) ) 
if ( !insn_data_0[icode].operand[2].predicate( op1, TImode) ) 
pat = insn_data_0[icode].genfun( targeta, op0, op1); 
rtx v29; // rbx 
rtx resume; // rdi 
rtx label; // rdi 
rtx continue_label; // rsi 
rtx insns; // [rsp+0h] [rbp-28h] BYREF 
insns = v0; 
insns = get_insns( ); 
convert_from_eh_region_ranges_1( &insns, v13, 0); 
if ( reg_note ) 
rtx result; // rax 
__m256 element; // [rsp+20h] [rbp-78h] BYREF 
v8 = mode_class_0[mode]; 
return gen_rtx_fmt_e( ( rtx_code)( unsigned __int16)v3, mode, x->fld[0].rtx); 
return simplify_gen_subreg( mode, v2, ( machine_mode)v4, 0); 
*( _QWORD *)element.m256_f32 = v16; 
*( _QWORD *)element.m256_f32 = v13; 
slot_with_hash = htab_find_slot_with_hash( v17, &element, v13, INSERT); 
rtx = gen_rtx_fmt_w( CONST_INT, VOIDmode, *( __int64 *)element.m256_f32); 
*( _QWORD *)&element.m256_f32[4] = v21.r[2]; 
v11 = *( tree_node **)( *( _QWORD *)( low + 40) + 40LL); 
&& *( const mode_class *)( ( char *)mode_class_0 + ( ( *( ( _DWORD *)&type->type + 15) >> 7) & 0x1FC)) == MODE_INT ) 
htab_empty( hash_table_0); 
htab_traverse( hash_table_0, cselib_invalidate_mem_1, callmem); 
( machine_mode)BYTE2( ( *( v16 - 3))->value), 
*( v16 - 1) = cselib_lookup( v20, ( machine_mode)*( ( unsigned __int8 *)v18 + 2), 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
*( v26 - 1) = cselib_lookup( ( rtx)*( v26 - 3), ( machine_mode)BYTE2( value), 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v41 = ( ( unsigned int)( mode_class_0[v40] - 5) < 2) + 1; 
htab_traverse( hash_table_0, cselib_invalidate_mem_1, v22); 
cselib_invalidate_regno( v22->fld[0].rtuint, ( machine_mode)BYTE2( v23)); 
v24 = push_operand( v22, ( machine_mode)*( ( unsigned __int8 *)v22 + 2)); 
htab_traverse( hash_table_0, discard_useless_locs, 0LL); 
htab_traverse( hash_table_0, discard_useless_values, 0LL); 
if ( !v2 || ( cannot_inline = ( const char *)&unk_716108, v2->int_cst.int_cst.low == *( &global_trees + 27)) ) 
cannot_inline = ( const char *)&unk_716108; 
return ( const char *)&unk_716178; 
*( _OWORD *)&b->aux = 0LL; 
*( _OWORD *)&b->count = 0LL; 
*( _OWORD *)&b->global_live_at_start = 0LL; 
*( _OWORD *)&b->local_set = 0LL; 
*( _OWORD *)&b->pred = 0LL; 
*( _OWORD *)&b->head_tree = 0LL; 
*( _OWORD *)&b->head = 0LL; 
splay_tree_value v9; // rax 
v9 = global_trees; 
v9 = global_trees; 
if ( high == v9 ) 
if ( low == v9 ) 
if ( high == v9 ) 
v20 = ( tree_node *)v14; 
v15 = swap_condition( ( rtx_code)v15); 
v20 = ( tree_node *)v13; 
if ( can_compare_p( ( rtx_code)v15, ( machine_mode)v12, ccp_store_flag) ) 
rtx *v8; // r14 
rtx *v14; // rbx 
uid_cuid_1 = v3; 
v8 = ( rtx *)xmalloc( ( unsigned int)v7); 
cuid_insn = v8; 
memset( v8, 0, v7); 
v8[v10] = v1; 
v14 = ( rtx *)xmalloc( v13); 
canon_modify_mem_list = v14; 
memset( v14, 0, 8LL * ( int)n_basic_blocks); 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) < *( ( _DWORD *)uid_cuid_1 + occr->insn->fld[0].rtint) 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) < *( ( _DWORD *)uid_cuid_1 + occr->insn->fld[0].rtint) 
rtl_op = first_rtl_op( ( tree_code)v2); 
*( _OWORD *)&result->common.chain = 0LL; 
if ( xexit_cleanup ) 
v34 = ( v32 - 1 < 0) ^ __OFADD__( -1LL, v32) | ( v32 == 1); 
v27 = ( tree_node *)*( &global_trees + 27); 
if ( section_name == ( tree_node *)*( &global_trees + 24) ) 
output_asm_insn( off_806606, xops); 
if ( !alloc_aux_for_blocks_initialized ) 
alloc_aux_for_blocks_initialized = 1; 
v1 = ( tree_node *)*( ( _QWORD *)&ggc_pending_trees->name + elements_used); 
rtl_op = first_rtl_op( ( tree_code)v27); 
if ( !alloc_aux_for_edges_initialized ) 
alloc_aux_for_edges_initialized = 1; 
*( _WORD *)pat = swap_condition( ( rtx_code)v2); 
rtx v17; // rax 
rtx v19; // rax 
rtx v45; // rdx 
rtx v99; // rax 
rtx v110; // rax 
rtx *v114; // r13 
rtx v118; // rbx 
nops = first_rtl_op( ( tree_code)( unsigned __int8)*( ( _DWORD *)&exp->common + 4)); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
|| ( v3 = ( unsigned __int8)BYTE2( *( _DWORD *)x), v4 = mode_class_0[v3], v4 > 8) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v10 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
rtx v12; // r9 
v12 = y; 
v12 = x; 
v6 = (  struct rtx_def *)v12[1]; 
rtx = v12->fld[0].rtx; 
v16 = form_sum( v12, x->fld[0].rtx); 
return gen_rtx_fmt_ee( PLUS, v17, v12, x); 
return gen_rtx_fmt_ee( PLUS, v17, v12, x); 
v12 = v12->fld[0].rtx; 
v12 = v12->fld[0].rtx; 
v20 = gen_rtx_fmt_ee( PLUS, v17, v12, x); 
( machine_mode)*( ( unsigned __int8 *)v18 + 2), 
if ( replace_reloads && recog_data_0.operand[opnum] != x ) 
if ( !in || !*( ( _BYTE *)in + 2) || ix86_hard_regno_mode_ok( v6, ( machine_mode)*( ( unsigned __int8 *)in + 2)) ) 
if ( !out || ix86_hard_regno_mode_ok( v6, ( machine_mode)*( ( unsigned __int8 *)out + 2)) ) 
p_int_cst = &exp->int_cst.int_cst; 
low = ( tree)p_int_cst->low; 
v5 = *( unsigned __int8 *)( p_int_cst->low + 16); 
p_int_cst = &low->int_cst.int_cst; 
v10 = operand_sub*(short *)0xforce( op, v8, ( machine_mode)v5); 
v10 = operand_sub*(short *)0xforce( op, v8, ( machine_mode)v5); 
v11 = operand_sub*(short *)0xforce( v7, v8, ( machine_mode)v5); 
v11 = operand_sub*(short *)0xforce( v7, v8, ( machine_mode)v5); 
rtx v9; // rcx 
rtx i; // rax 
v9 = first; 
if ( *( _WORD *)v9 == 37 ) 
rtuint = v9[2].fld[0].rtuint; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
while ( v9 ); 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, ( __int64)insn_addresses_, ( unsigned int)prescan, v11) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, ( __int64)insn_addresses_, ( unsigned int)prescan, v11) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, ( __int64)insn_addresses_, ( unsigned int)prescan, v11) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, ( __int64)insn_addresses_, ( unsigned int)prescan, v11) ) 
v13 = i->fld[0].rtuint; 
result = ( cpp_context_0 *)xmalloc( 0x38uLL); 
rtx v8; // rax 
rtx v11; // rax 
rtx v12; // r15 
rtx v14; // r15 
rtx v15; // rax 
rtx v16; // r12 
v5 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v11 = protect_from_queue( x->fld[0].rtx, 0); 
if ( v11 != x->fld[0].rtx ) 
v12 = v11; 
v12 = v11; 
rtx v313; // rcx 
rtx *v317; // rbx 
rtx v340; // rbx 
rtx v343; // rax 
if ( !peep2_insn_data_0[v6].insn ) 
reg_set_to_hard_reg_set( &v55, peep2_insn_data_0[v6].live_before); 
if ( !peep2_insn_data_0[v6].insn ) 
reg_set_to_hard_reg_set( v57, peep2_insn_data_0[v6].live_before); 
v12 = v11 + peep2_find_free_register_search_ofs; 
if ( v11 + peep2_find_free_register_search_ofs + 53 <= 52 ) 
v12 = v11 + peep2_find_free_register_search_ofs + 53; 
v19 = ( ( unsigned int)( mode_class_0[v54] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[v54] - 5) < 2 == -1 ) 
v12 = peep2_find_free_register_search_ofs + v46 - 53; 
if ( peep2_find_free_register_search_ofs + v46 <= 52 ) 
v12 = peep2_find_free_register_search_ofs + v46; 
peep2_find_free_register_search_ofs = 0; 
v50 = ( ( unsigned int)( mode_class_0[v54] - 5) < 2) + 1; 
v24 = ( ( unsigned int)( mode_class_0[v54] - 5) < 2) + 1; 
v29 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v24), 80), ( __m128i)xmm*(short *)0x65AE30); 
if ( call_insn_operand( operand0->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx v9; // r12 
rtx v13; // r12 
rtx v16; // r13 
rtx v19; // rax 
rtx v21; // rax 
rtx result; // rax 
for ( loop_ptr = ( loop_1 *)loop_chain->data.l[0]; ; loop_ptr = ( loop_1 *)loop_chain->data.l[loop_idx] ) 
for ( loop_ptr = ( loop_1 *)loop_chain->data.l[0]; ; loop_ptr = ( loop_1 *)loop_chain->data.l[loop_idx] ) 
if ( find_stack_direction_addr ) 
if ( &dummy <= find_stack_direction_addr ) 
find_stack_direction_addr = &dummy; 
ptr_mode = mode_for_size( v2, mode_class_0[v3], 0); 
if ( ( sch_istable[( unsigned __int8)v10] & 0xC00) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v12] & 1) == 0 ) 
if ( mode_class_0[v8] != MODE_COMPLEX_INT ) 
v22 = mode_class_0[v9] == MODE_COMPLEX_FLOAT; 
v7 = ( v6 - 1 < 0) ^ __OFADD__( -1LL, v6) | ( v6 == 1); 
if ( ( sch_istable[v16] & 0x88) != 0 ) 
if ( ( sch_istable[v16] & 0x88) != 0 ) 
if ( ( sch_istable[v16] & 0x88) != 0 ) 
induction_1 *v; // [rsp+68h] [rbp-48h] 
induction_1 *v; // [rsp+68h] [rbp-48h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( v->ext_dependent ) 
v2 = *( _WORD *)v->ext_dependent; 
max = mode_mask_array[( unsigned __int8)BYTE2( *( _DWORD *)v->ext_dependent)] >> 1; 
fprintf( loop_dump_stream, "Verified ext dependent giv at %d of reg %d\n", v->insn->fld[0].rtuint, bl_0->regno); 
v->insn->fld[0].rtuint, 
v->insn->fld[0].rtuint, 
v->insn->fld[0].rtuint, 
*( ( _WORD *)v + 50) = *( ( _WORD *)v + 50) & 0xFFFB | 4; 
*( ( _WORD *)v + 50) = *( ( _WORD *)v + 50) & 0xFFFB | 4; 
rtx v4; // rbx 
rtx v38; // r15 
rtx compound_operation; // rbx 
rtx v46; // r15 
rtx v66; // rax 
rtx v69; // rbx 
rtx v78; // r12 
build_def_use_outer_loop = 0LL; 
build_def_use_nloop = 0; 
build_def_use_du_idx = 0; 
if ( !build_def_use_nloop ) 
LODWORD( v3) = build_def_use_du_idx++; 
du_ptr = ( def_use_0 *)def_use_chain->data.l[( int)v3]; 
du_ptr->outer_loop = build_def_use_outer_loop; 
du_ptr->containing_loop = build_def_use_current_loop; 
if ( i < build_def_use_du_idx ) 
if ( i == build_def_use_du_idx ) 
for ( tmp_duc = ( def_use_0 *)def_use_chain->data.l[i]; tmp_duc->next; tmp_duc = tmp_duc->next ) 
if ( build_def_use_loop_def 
build_def_use_loop_def->outer_loop, 
v5 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), tem); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
return gen_rtx_MEM( ( machine_mode)v9, v11); 
fatal_insn( "could not find a spill register", insn, &off_88ECD0[4], 5051, "failed_reload"); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
temp = allocno_0[( __int64)num].hard_reg_conflicts; 
if ( allocno_0[( __int64)num].calls_crossed ) 
tempb = tempa | ~reg_class_contents[reg_preferred_class( allocno_0[( __int64)num].reg)]; 
allocno_0[( __int64)num].hard_reg_preferences &= ~tempb; 
allocno_0[( __int64)num].hard_reg_copy_preferences &= ~tempb; 
allocno_0[( __int64)num].hard_reg_full_preferences &= ~tempb; 
if ( allocno_0[( __int64)allocno2].size > allocno_0[( __int64)numa].size ) 
if ( allocno_0[( __int64)allocno2].size > allocno_0[( __int64)numa].size ) 
temp2 |= allocno_0[( __int64)allocno2].hard_reg_full_preferences; 
temp_0 |= allocno_0[( __int64)allocno2].hard_reg_full_preferences; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] != MODE_COMPLEX_INT ) 
v9 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] == MODE_COMPLEX_FLOAT; 
ident_hash->alloc_node = ( hashnode ( *)(  struct hash_table *))alloc_node_0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 14632, "get_attr_length_immediate"); 
if ( symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( ( unsigned int)( v18 - 7) < 3 || ( _DWORD)flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( ( _DWORD)flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( !symbolic_operand( recog_data_0.operand[1], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
v5 = recog_data_0.operand[2]; 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
v5 = recog_data_0.operand[2]; 
if ( incdec_operand( recog_data_0.operand[2], HImode) || which_alternative == 2 ) 
v5 = recog_data_0.operand[2]; 
if ( incdec_operand( recog_data_0.operand[2], QImode) || which_alternative == 3 ) 
v17 = mode_class_0[mode]; 
v19 = mode_class_0[mode]; 
v24 = simplify_relational_operation( ( rtx_code)*( _WORD *)v8, op0_mode, v21.rtx, ( rtx)v23); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
rtx v6; // r12 
rtx *v7; // rbx 
rtx v9; // rdx 
v9 = *( rtx *)( v2 + 8); 
if ( !v9 || ( *( _DWORD *)v9 & 0x40000000) == 0 ) 
if ( !v9 || ( *( _DWORD *)v9 & 0x40000000) == 0 ) 
*( _QWORD *)&rtx[2] = gen_rtx_fmt_e( USE, VOIDmode, v9); 
v9 = 0LL; 
v6 = 0LL; 
v7 = *( rtx **)&v4[2 * v5]; 
v8 = *( _WORD *)v7; 
rtx v19; // rbx 
rtx v47; // rdi 
rtx v48; // rax 
rtx v54; // [rsp+10h] [rbp-78h] 
v19 = real_out; 
rtx = v19->fld[0].rtx; 
v17 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v20), *( _DWORD *)&v19[1], ( machine_mode)BYTE2( v15)); 
v17 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v20), *( _DWORD *)&v19[1], ( machine_mode)BYTE2( v15)); 
v12 = assign_stack_local_1( ( machine_mode)v11, mode_size[v11], 0, v6); 
v14 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v15 = gen_rtx_MEM( ( machine_mode)LOBYTE( subr->decl.result->block.supercontext), v14); 
subr->decl.result->decl.rtl = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v17)); 
v2 = force_reg( ( machine_mode)BYTE2( v4), v2); 
rtx incloc; // [rsp+80h] [rbp-30h] 
incloc = value->fld[0].rtx; 
if ( ( unsigned __int16)*( _DWORD *)incloc == 61 ) 
reg_last_reload_reg[incloc->fld[0].rtuint] = 0LL; 
v5 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)incloc), incloc, inc); 
v5 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)incloc), incloc, inc); 
v5 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)incloc), incloc, inc); 
v6 = gen_rtx_fmt_ee( SET, VOIDmode, incloc, v5); 
v7 = gen_move_insn( reloadreg, incloc); 
v12 = gen_move_insn( incloc, reloadreg); 
v10 = gen_move_insn( incloc, reloadreg); 
bi = ( block_info_0)block->aux; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v22 = hash_table_0; 
slot_with_hash = htab_find_slot_with_hash( v22, v24, v21, ( insert_option)( create != 0)); 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
elt = new_cselib_val( ++next_unknown_value, ( machine_mode)v7); 
v49 = hash_table_0; 
v12 = mode_class_0[v7]; 
v14 = cselib_lookup( x->fld[0].rtx, ( machine_mode)v7, create); 
v17 = new_cselib_val( ++next_unknown_value, ( machine_mode)v7); 
v60 = hash_table_0; 
v5 = gen_rtx_fmt_e( CONST, ( machine_mode)v7, x); 
rtx loc[2]; // [rsp+8h] [rbp-10h] BYREF 
loc[0] = last_value; 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), last_value); 
loc[0] = reg_last_set_value[rtuint]; 
if ( !loc[0] 
last_value_validate = get_last_value_validate( loc, v6, *( ( _DWORD *)reg_last_set_label + rtuint), 0); 
result = loc[0]; 
loc[0] = copy_rtx( loc[0]); 
loc[0] = copy_rtx( loc[0]); 
if ( get_last_value_validate( loc, reg_last_set[rtuint], *( ( _DWORD *)reg_last_set_label + rtuint), 1) ) 
return loc[0]; 
if ( recog_data_0.insn != insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
v22 = *( _OWORD *)&args->gp_offset; 
if ( memchr( &unk_73B138, v17, 4uLL) ) 
while ( memchr( &unk_73B138, v17, 4uLL) ); 
v41 = immed_double_const( v44, v46, ( machine_mode)( unsigned __int8)v24); 
v33 = gen_lowpart( ( machine_mode)( unsigned __int8)v24, value); 
v33 = convert_to_mode( ( machine_mode)( unsigned __int8)v24, value, 1); 
fprintf( asmfile, &off_607A24[1], ( unsigned int)current_sym_value); 
operand = insn_data_0[v37].operand; 
if ( !operand->predicate( v27, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
x = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)operand + 8)); 
if ( !operand[2].predicate( v28, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8), v28); 
if ( !operand[3].predicate( v29, ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8), v29); 
v32 = insn_data_0[( int)v37].genfun( x, v31); 
v12 = expand_mult_add( x, reg, v10, v11, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
rtx v55; // rax 
rtx v56; // rcx 
rtx v62; // rax 
rtx v63; // rcx 
rtx *v65; // rbx 
rtx v66; // rax 
rtx *v67; // rcx 
rtx *v68; // rdx 
rtx op; // [rsp+18h] [rbp-60h] BYREF 
rtx v75; // [rsp+20h] [rbp-58h] BYREF 
( rtx_code)( unsigned __int16)*( _DWORD *)v2, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2), 
v11 = gen_rtx( ( rtx_code)v1, ( machine_mode)v2, v10, const_int_rtx[64]); 
rtx v4; // rax 
rtx line_note; // rbp 
rtx v10; // rax 
v4 = head; 
while ( *( _WORD *)v4 != 37 || v4[2].fld[0].rtint <= 0 ) 
while ( *( _WORD *)v4 != 37 || v4[2].fld[0].rtint <= 0 ) 
v4 = ( rtx)v4[1]; 
if ( !v4 ) 
v4 = 0LL; 
v4 = v2; 
line_note = v4; 
line_note = v4; 
line_note = h_i_d[rtint].line_note; 
if ( !line_note || line_note == v4 || v4 && line_note[2].fld[0].rtint == v4[2].fld[0].rtint && line_note[2] == v4[2] ) 
if ( !line_note || line_note == v4 || v4 && line_note[2].fld[0].rtint == v4[2].fld[0].rtint && line_note[2] == v4[2] ) 
if ( !line_note || line_note == v4 || v4 && line_note[2].fld[0].rtint == v4[2].fld[0].rtint && line_note[2] == v4[2] ) 
v9 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v8); 
v12 = gen_rtx_MEM( ( machine_mode)v10, v11); 
fancy_abort( &off_88ECD0[4], 3339, "verify_initial_elim_offsets"); 
v4 = simplify_unary_operation( ( rtx_code)v5, outermode, v3, v21); 
return gen_rtx_fmt_e( ( rtx_code)v5, outermode, v3); 
v4 = simplify_relational_operation( ( rtx_code)v5, v23, v24, v25); 
v27 = swap_condition( ( rtx_code)v5); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
max = first_rtl_op( ( tree_code)( unsigned __int8)*( ( _DWORD *)&xa->common + 4)); 
v11 = force_reg( ( machine_mode)v10, v11); 
v12 = force_reg( ( machine_mode)v10, v12); 
operand0 = gen_reg_rtx( ( machine_mode)v10); 
v17 = gen_reg_rtx( ( machine_mode)v10); 
operand = insn_data_0[insn_code].operand; 
if ( !operand->predicate( operand0, ( machine_mode)v10) || !operand[3].predicate( to, ( machine_mode)v10) ) 
if ( !operand->predicate( operand0, ( machine_mode)v10) || !operand[3].predicate( to, ( machine_mode)v10) ) 
v28 = insn_data_0[v46].genfun( operand0, operand1); 
v30 = mode_class_0[v10]; 
v34 = gen_reg_rtx( ( machine_mode)i); 
v38 = gen_reg_rtx( ( machine_mode)v33); 
v4 = gen_rtx( ( rtx_code)( unsigned __int16)*( _DWORD *)operand3, V4SImode, operand1, operand2); 
tree v40; // rbx 
tree v45; // rax 
tree v46; // rax 
*( _OWORD *)&result->flags = 0LL; 
*( _OWORD *)&result->insns = 0LL; 
*( _OWORD *)&result->src = 0LL; 
*( _OWORD *)&result->pred_next = 0LL; 
v4 = gen_rtx( ( rtx_code)( unsigned __int16)*( _DWORD *)operand3, V4SImode, operand1, operand2); 
*( _OWORD *)&to->first = 0LL; 
*( _OWORD *)( object_base + 24) = v5; 
rtx insn; // [rsp+50h] [rbp-20h] 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
if ( insn ) 
v3 = insn != ( rtx)bb->head[1]; 
uid = insn->fld[0].rtuint; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
return output_832_patterns[locality]; 
reg_dies( v7[2], ( machine_mode)( unsigned __int8)BYTE2( *v7), v5); 
reg_dies( v18[2], ( machine_mode)( unsigned __int8)BYTE2( *v18), v5); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)set->fld[0].rtwint)] != MODE_COMPLEX_INT ) 
v33 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)set->fld[0].rtwint)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v26 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
const_reg = gen_rtx_REG( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), i); 
reg_sum = gen_rtx_fmt_ee( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), const_reg, base); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)usage_rtx)] != MODE_COMPLEX_INT ) 
v9 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v12), v14, ( machine_mode)BYTE2( v11)); 
v9 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v12), v14, ( machine_mode)BYTE2( v11)); 
v17 = ( unsigned int)( ( unsigned int)( mode_class_0[( unsigned __int8)v16] - 5) < 2) + 1; 
v27 = subreg_regno_offset( v22, ( machine_mode)BYTE2( v21), v23, v24); 
v30 = ( ( unsigned int)( mode_class_0[BYTE2( v20)] - 5) < 2) + 1; 
&& ( ( int)v15 < 53 || v30 <= ( int)v17 || ( int)v17 >= qty_0[*( ( int *)reg_qty + v15)].size) ) 
min_class = qty_0[v47[v15]].min_class; 
v54 = qty_0; 
*( ( _DWORD *)reg_next_in_qty + v70) = qty_0[v53].first_reg; 
if ( reg_class_subset_p( v56, qty_0[v55].min_class) ) 
qty_0[v55].min_class = v56; 
if ( reg_class_subset_p( v57, qty_0[v55].alternate_class) ) 
rtx v15; // rax 
v15 = ( rtx)*( ( _QWORD *)v14 + 4); 
if ( *( _WORD *)v15 != 47 ) 
v15 = single_set_2( ( rtx)v14, *( ( rtx *)v14 + 4)); 
v15 = 0LL; 
if ( v15 && (  struct rtx_def *)v15[1] == rtx ) 
if ( v15 && (  struct rtx_def *)v15[1] == rtx ) 
rtx = v15->fld[0].rtx; 
rtx v9; // rbx 
rtx v11; // r15 
rtx v13; // rsi 
rtx v16; // rax 
rtx v17; // [rsp+0h] [rbp-38h] BYREF 
v17 = v3; 
v9 = map->insn_map[rtx->fld[0].rtint]; 
if ( v9 ) 
*( _DWORD *)( *( _QWORD *)&v9[2] + 8LL) += eh_region_offset; 
v17 = copy_rtx_and_substitute( v10, map, 0); 
fatal_insn_not_found( insn, "insn-attrtab.c", 16766, "get_attr_modrm"); 
v4 = recog_data_0.operand[1]; 
v4 = recog_data_0.operand[0]; 
v5 = recog_data_0.operand[1]; 
if ( !register_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( !immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
v5 = recog_data_0.operand[1]; 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
if ( !incdec_operand( recog_data_0.operand[2], DImode) ) 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
if ( !incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( mode_class_0[( unsigned __int8)v16] != MODE_FLOAT ) 
rtx i; // rax 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
v5.rtwint = ( __int64)i->fld[0]; 
deps_0 tmp_deps; // [rsp+10h] [rbp-80h] BYREF 
init_deps( &tmp_deps); 
sched_analyze( &tmp_deps, heada, taila); 
free_deps( &tmp_deps); 
pfile = ( cpp_reader_0 *)xcalloc( 1uLL, 0x340uLL); 
if ( *( _OWORD *)&alias == 0LL && !offset ) 
element = *( _OWORD *)&alias; 
*( _OWORD *)&v8->alias = element; 
*( _OWORD *)&v8->offset = v9; 
|| lang_hooks_0.tree_inlining.tree_chain_matters_p( *tp) ) 
|| lang_hooks_0.tree_inlining.tree_chain_matters_p( *tp) 
else if ( ( sch_istable[c] & 0x10) != 0 ) 
v3 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v4 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v5 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v17 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v21 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
diagnostic_buffer->state.format_args = ( va_list_0 *)va; 
*( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4] = v21; 
*( _OWORD *)v12->state.diagnostic_count = v20; 
lang_hooks_0.set_yydebug( 1); 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2), v2); 
v5 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), const_int_rtx[64]); 
fatal_insn_not_found( insn, "insn-attrtab.c", 19258, "get_attr_pent_pair"); 
v8 = recog_data_0.operand[1]; 
v8 = recog_data_0.operand[0]; 
if ( symbolic_operand( recog_data_0.operand[1], SImode) 
&& ( !( _DWORD)flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
v5 = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( symbolic_operand( recog_data_0.operand[1], DImode) 
&& ( !( _DWORD)flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode)) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
rtx v11; // r14 
v11 = assign_stack_local_1( BLKmode, v9, 0, v10); 
node->int_cst.int_cst.high = ( __int64)v11; 
rtx = v11->fld[0].rtx; 
v13 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
_OWORD *v16; // rax 
_OWORD *v16; // rax 
v16 = ggc_alloc( 0x28uLL); 
*slot = v16; 
*( ( _QWORD *)v16 + 4) = v20; 
v17 = *( _OWORD *)arg0; 
v16[1] = v19; 
*v16 = v17; 
v2 = expand_simple_binop( ( machine_mode)v3, PLUS, operand0, v4, 0LL, 0, OPTAB_DIRECT); 
v2 = expand_simple_binop( ( machine_mode)v3, MINUS, pic_offset_table_rtx, operand0, 0LL, 1, OPTAB_DIRECT); 
if ( ( _DWORD)v5 != 16 && ( _DWORD)v5 != 22 && ( mode_class_0[v5] | 4) != 5 ) 
mode0 = *( ( unsigned __int16 *)insn_data_0[icode].operand + 8); 
v2 = &insn_data_0[icode]; 
if ( mode_class_0[*( ( unsigned __int16 *)&v2->operand[1] + 8)] == MODE_VECTOR_INT 
|| mode_class_0[*( ( unsigned __int16 *)&v2->operand[1] + 8)] == MODE_VECTOR_FLOAT ) 
if ( !insn_data_0[icode].operand[1].predicate( op1, mode1) ) 
pat = insn_data_0[icode].genfun( op0a, op1); 
*( _OWORD *)retstr->r = 0LL; 
ereal_from_int( retstr, low, high, ( machine_mode)v5); 
ereal_from_uint( retstr, low, high, ( machine_mode)v5); 
fatal_insn_not_found( insn, "insn-attrtab.c", 7902, "pent_uv_unit_ready_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_PENTIUM ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) || ix86_cpu != PROCESSOR_PENTIUM ) 
|| !memory_operand( recog_data_0.operand[1], VOIDmode) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_PENTIUM ) 
if ( which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_PENTIUM ) 
&& incdec_operand( recog_data_0.operand[2], DImode) 
|| incdec_operand( recog_data_0.operand[2], DImode) 
&& incdec_operand( recog_data_0.operand[2], DImode) 
|| incdec_operand( recog_data_0.operand[2], DImode) 
|| !incdec_operand( recog_data_0.operand[2], DImode) 
|| ( incdec_operand( recog_data_0.operand[2], DImode) 
&& ( !incdec_operand( recog_data_0.operand[2], DImode) 
&& incdec_operand( recog_data_0.operand[2], SImode) 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
operands[4] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[4]); 
*( _OWORD *)spill_cost = 0LL; 
*( _OWORD *)&spill_cost[4] = 0LL; 
*( _OWORD *)&spill_cost[8] = 0LL; 
*( _OWORD *)&spill_cost[12] = 0LL; 
*( _OWORD *)&spill_cost[16] = 0LL; 
*( _OWORD *)&spill_cost[20] = 0LL; 
*( _OWORD *)&spill_cost[24] = 0LL; 
*( _OWORD *)&spill_cost[28] = 0LL; 
*( _OWORD *)&spill_cost[32] = 0LL; 
fatal_insn_not_found( insn, "insn-attrtab.c", 11973, "get_attr_athlon_fpunits"); 
if ( register_operand( recog_data_0.operand[1], SImode) ) 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) ) 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !register_operand( recog_data_0.operand[1], SImode) ) 
return 3 * ( immediate_operand( recog_data_0.operand[1], VOIDmode) == 0) + 1; 
if ( register_operand( recog_data_0.operand[1], SImode) ) 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) ) 
if ( !immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
v13 = recog_data_0.operand[3]; 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
fprintf( file, off_6474F4, 9LL); 
fprintf( file, off_6474F4, 11LL); 
fprintf( file, off_6474F4, 13LL); 
fprintf( file, off_6474F4, 15LL); 
fprintf( file, off_6474F4, 8LL); 
fprintf( file, off_6474F4, 10LL); 
fprintf( file, off_6474F4, 12LL); 
fprintf( file, off_6474F4, 14LL); 
v6 = ( if_elt *)xrealloc( if_stack_0, 32 * v5); 
if_stack_0 = v6; 
v7 = if_stack_0; 
if_stack_0[v9].compstmt_count = compstmt_count; 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
if ( reg_avail_info_0[rtx->fld[0].rtuint].last_bb == current_bb ) 
return reg_avail_info_0[rtx->fld[0].rtuint].last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[rtx->fld[0].rtuint].last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[rtx->fld[0].rtuint].first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[rtx->fld[0].rtuint].first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
v44 = *( tree_node **)v3; 
*( ( _OWORD *)object_base + 1) = 0LL; 
if ( debug_info_level_0 == DINFO_LEVEL_VERBOSE 
filenamea = &arg0; 
*( _OWORD *)&e->flags = 0LL; 
*( _OWORD *)&e->insns = 0LL; 
*( _OWORD *)&e->src = 0LL; 
*( _OWORD *)&e->pred_next = 0LL; 
value = ( cpp_hashnode_0 *)__h->object_base; 
if ( ( cpp_hashnode_0 *)__h->next_free == value ) 
memset( value, 0, sizeof( cpp_hashnode_0)); 
fatal_insn_not_found( insn, "insn-attrtab.c", 20358, "get_attr_prefix_rep"); 
( machine_mode)( unsigned __int8)BYTE2( *v16), 
( machine_mode)BYTE2( v14)); 
v7 = subreg_regno_offset( v8, ( machine_mode)( unsigned __int8)BYTE2( *v6), v3[4], ( machine_mode)BYTE2( v4)); 
v7 = subreg_regno_offset( v8, ( machine_mode)( unsigned __int8)BYTE2( *v6), v3[4], ( machine_mode)BYTE2( v4)); 
rtx v49; // rbp 
rtx *v55; // rdi 
rtx *v56; // rdi 
rtx ops[16]; // [rsp+10h] [rbp-EC8h] BYREF 
v5 = ix86_memory_move_cost( ( machine_mode)*( unsigned __int8 *)( v3->fld[0].rtwint + 2), GENERAL_REGS, 1); 
costs_0[v7].mem_cost -= frequency * v5; 
&& recog_data_0.n_operands >= 3 
&& *recog_data_0.constraints[1] == 48 
&& !*( ( _BYTE *)recog_data_0.constraints[1] + 1) ) 
if ( ( v8 = *( _DWORD *)recog_data_0.operand[1], ( unsigned __int16)( *( _DWORD *)recog_data_0.operand[1] - 54) <= 0xEu) 
if ( ( v8 = *( _DWORD *)recog_data_0.operand[1], ( unsigned __int16)( *( _DWORD *)recog_data_0.operand[1] - 54) <= 0xEu) 
&& ( v9 = 24599, _bittest( &v9, *( _DWORD *)recog_data_0.operand[1] - 54)) 
if ( !rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[1]) 
while ( ( sch_istable[*( unsigned __int8 *)format_charsa] & 4) != 0 ) 
v3 = &arg0; 
*( _WORD *)operands[1] = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
if ( const0_operand( operands[2], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)) ) 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v23 = mode_class_0[v10]; 
rtx v37; // rax 
rtx v39; // rax 
rtx v40; // rbp 
rtx v41; // rax 
rtx v44; // rax 
rtx v47; // rbp 
rtx v48; // rax 
rtx v52; // rax 
rtx v53; // rax 
if ( !init_library_initialized ) 
init_library_initialized = 1; 
mode0 = *( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8); 
mode1 = *( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8); 
if ( mode_class_0[*( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8)] == MODE_VECTOR_INT 
if ( mode_class_0[*( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8)] == MODE_VECTOR_INT 
|| mode_class_0[*( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8)] == MODE_VECTOR_FLOAT ) 
|| mode_class_0[*( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8)] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode1] == MODE_VECTOR_INT || mode_class_0[mode1] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode1] == MODE_VECTOR_INT || mode_class_0[mode1] == MODE_VECTOR_FLOAT ) 
if ( !insn_data_0[d->icode].operand->predicate( op0, mode0) ) 
if ( !insn_data_0[d->icode].operand[1].predicate( op1, mode1) ) 
pat = insn_data_0[d->icode].genfun( op0, op1, v3); 
fatal_insn_not_found( insn, "insn-attrtab.c", 2626, "athlon_fp_unit_ready_cost"); 
if ( mult_operator( recog_data_0.operand[3], SFmode) 
|| !mult_operator( recog_data_0.operand[3], SFmode) 
&& mult_operator( recog_data_0.operand[3], SFmode) 
&& !mult_operator( recog_data_0.operand[3], SFmode) 
if ( mult_operator( recog_data_0.operand[3], XFmode) 
|| !mult_operator( recog_data_0.operand[3], XFmode) 
if ( mult_operator( recog_data_0.operand[3], TFmode) 
|| !mult_operator( recog_data_0.operand[3], TFmode) 
else if ( mult_operator( recog_data_0.operand[3], SFmode) 
&& mult_operator( recog_data_0.operand[3], SFmode) 
else if ( mult_operator( recog_data_0.operand[3], DFmode) 
&& mult_operator( recog_data_0.operand[3], DFmode) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) 
else if ( mult_operator( recog_data_0.operand[3], TFmode) 
for ( i = 0LL; i < 4 && ( expand_builtin_setjmp_receiver_elim_regs[i].from != 16 || *(int *)0x7D4134[2 * i] != 6); ++i ) 
v6 = gen_rtx_fmt_s( ASM_INPUT, VOIDmode, &arg0); 
loc_result = mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtl)); 
p = lookup( x, v2 & 0x1F, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)); 
predicate = insn_data_0[v15].operand->predicate; 
v18 = predicate( x, ( machine_mode)v11); 
operand = insn_data_0[v16].operand; 
if ( reg_class_subset_p( ( reg_class)c1, ( reg_class)v26) ) 
v25 = ( tree_node *)v22[4]; 
if ( v25 == ( tree_node *)*( &global_trees + 27) ) 
v25 = ( tree_node *)v22[4]; 
if ( *( _OWORD *)&t1 == 0LL || t1 && readonly_fields_p( t1) ) 
rtx last_insn; // rax 
rtx v21; // rbx 
v5 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)v3, v4); 
last_insn = get_last_insn( ); 
if ( last_insn ) 
v21 = last_insn; 
v21 = last_insn; 
while ( *( _WORD *)v21 != 34 ) 
if ( *( _WORD *)v21 == 33 ) 
v21[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], v21[3].fld[0].rtx); 
v21[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], v21[3].fld[0].rtx); 
v21 = ( rtx)v21[1]; 
if ( !v21 ) 
rtx v5; // r14 
rtx v7; // r14 
rtx v8; // r15 
v5 = gen_rtx_fmt_u00( LABEL_REF, VOIDmode, v4); 
mark_jump_label( v5, rtx, 0); 
*( _QWORD *)( *( _QWORD *)&rtx[2] + 32LL) = v5->fld[0].rtwint; 
if ( reg_note ) 
v7 = reg_note; 
v7 = reg_note; 
v4 = *( ( _DWORD *)uid_cuid_1 + this_reg->insn->fld[0].rtint) >> 6; 
v3->elms[v4] |= 1LL << ( *( ( _BYTE *)uid_cuid_1 + 4 * this_reg->insn->fld[0].rtint) & 0x3F); 
if ( ( sch_istable[( unsigned __int8)c] & 0x204) == 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 0x204) == 0 ) 
return ( cpp_hashnode_0 *)ht_lookup( table, value, len, HT_ALLOCED); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x2a; 
if ( ( unsigned __int16)*( _DWORD *)x1f == 47 && rtx_equal_p( x1f->fld[0].rtx, recog_data_0.operand[1]) ) 
if ( rtx_equal_p( x2h, recog_data_0.operand[0]) && ( ( 1 << ix86_cpu) & x86_partial_reg_stall) != 0 ) 
if ( rtx_equal_p( x2h, recog_data_0.operand[0]) && ( ( 1 << ix86_cpu) & x86_partial_reg_stall) == 0 ) 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[2] = x3c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) ) 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x4c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) ) 
recog_data_0.operand[1] = x4; 
if ( ( unsigned int)( mode_class_0[v4] - 5) < 2 ) 
if ( ( unsigned int)( mode_class_0[v9] - 5) >= 2 ) 
rtx v77; // rax 
rtx v78; // rax 
rtx v83; // rsi 
rtx v85; // rdi 
rtx v86; // rdi 
rtx v102; // rdx 
rtx reg; // [rsp+8h] [rbp-70h] 
rtx rega; // [rsp+8h] [rbp-70h] 
rtx regb; // [rsp+8h] [rbp-70h] 
induction_1 *same; // [rsp+50h] [rbp-90h] 
induction_1 *same; // [rsp+50h] [rbp-90h] 
induction_1 *v2; // [rsp+A0h] [rbp-40h] 
induction_1 *v2; // [rsp+A0h] [rbp-40h] 
induction_1 *v2a; // [rsp+A0h] [rbp-40h] 
induction_1 *v2a; // [rsp+A0h] [rbp-40h] 
induction_1 *v2b; // [rsp+A0h] [rbp-40h] 
induction_1 *v2b; // [rsp+A0h] [rbp-40h] 
induction_1 *v; // [rsp+A8h] [rbp-38h] 
induction_1 *v; // [rsp+A8h] [rbp-38h] 
induction_1 *va; // [rsp+A8h] [rbp-38h] 
induction_1 *va; // [rsp+A8h] [rbp-38h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v2 = v->next_iv; v2; v2 = v2->next_iv ) 
for ( v2 = v->next_iv; v2; v2 = v2->next_iv ) 
v8 = ( tree_node *)ggc_alloc( v7); 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
*( _OWORD *)decode = *( _OWORD *)ix86_sched_data.ppro.decode; 
if ( flag_float_store && written && mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)mem)] == MODE_FLOAT ) 
reg = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)mem)); 
bb_info_1 *bi; // [rsp+E0h] [rbp-A0h] 
bb_info_1 *bi; // [rsp+E0h] [rbp-A0h] 
bi = ( bb_info_1 *)v4->aux; 
bi = ( bb_info_1 *)v4->aux; 
if ( ( *( _BYTE *)bi & 1) == 0 ) 
if ( bi->succ_count ) 
if ( !bi->pred_count ) 
*( _BYTE *)bi = *( _BYTE *)bi & 0xFE | 1; 
*( _BYTE *)bi = *( _BYTE *)bi & 0xFE | 1; 
*( _BYTE *)bi = *( _BYTE *)bi & 0xFE | 1; 
*( _BYTE *)bi = *( _BYTE *)bi & 0xFE | 1; 
if ( ( *( _BYTE *)bi & 1) != 0 ) 
if ( bi->succ_count == 1 ) 
--bi->succ_count; 
if ( bi->pred_count == 1 ) 
--bi->pred_count; 
rtx v18; // rax 
rtx i; // rbx 
if ( ( _WORD)v7 != 61 || *( const mode_class *)( ( char *)mode_class_0 + ( ( v7 >> 14) & 0x3FC)) != MODE_INT ) 
if ( ( _WORD)v17 == 61 && *( const mode_class *)( ( char *)mode_class_0 + ( ( v17 >> 14) & 0x3FC)) == MODE_INT ) 
v18 = canonicalize_condition( jump, ( rtx)v5, v14, earliest, v16); 
if ( v18 ) 
v11 = v18; 
for ( i = *earliest; i != jump; i = i[1].fld[0].rtx ) 
for ( i = *earliest; i != jump; i = i[1].fld[0].rtx ) 
for ( i = *earliest; i != jump; i = i[1].fld[0].rtx ) 
v8 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
exc_ptr = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
comma = &arg0; 
result = ( cpp_buffer_0 *)pfile->buffer_ob.object_base; 
*( _OWORD *)&result->buf = 0LL; 
*( _OWORD *)&result->line_base = 0LL; 
*( _OWORD *)&result->backup_to = 0LL; 
*( _OWORD *)&result->last_Wtrigraphs = 0LL; 
*( _OWORD *)&result->dir.dev = 0LL; 
*( _OWORD *)&result->dir.len = 0LL; 
*( _OWORD *)&result->dir.next = 0LL; 
rtx v35; // rbp 
rtx last_insn; // rax 
rtx v57; // rax 
rtx v60; // rbx 
rtx v62; // rbp 
rtx v64; // r13 
rtx v71; // rax 
rtx v84; // rax 
v17 = ( tree_node *)ggc_alloc( 0x28uLL); 
*( _OWORD *)&v17->common.chain = 0LL; 
v5 = ( tree_node *)ggc_alloc( 0x28uLL); 
*( _OWORD *)&v5->common.chain = 0LL; 
rtx end; // rsi 
end = dest->end; 
end = dest->end; 
if ( *( _WORD *)end != 33 ) 
head = end; 
end = ( rtx)end[1]; 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
end = ( rtx)rtx[1]; 
end = 0LL; 
nonnote_insn = emit_insns_after( insns, end); 
*( _OWORD *)&v1->parm_flag = 0LL; 
*( _OWORD *)&v1->this_block = 0LL; 
*( _OWORD *)&v1->shadowed = 0LL; 
*( _OWORD *)&v1->names = 0LL; 
if ( !*p || ( sch_istable[*( unsigned __int8 *)p] & 4) != 0 ) 
decode_g_option_level = read_integral_parameter( p, 0LL, 4); 
if ( decode_g_option_level ) 
v3 = decode_g_option_level; 
decode_g_option_level = v3; 
error( "use -gdwarf -g%d for DWARF v1, level %d", decode_g_option_level, decode_g_option_level); 
error( "use -gdwarf -g%d for DWARF v1, level %d", decode_g_option_level, decode_g_option_level); 
if ( decode_g_option_level == 2 ) 
if ( decode_g_option_level > 3 ) 
decode_g_option_level = debug_info_level_0; 
decode_g_option_level = debug_info_level_0; 
if ( da_len > 1 && !strncmp( arg, off_89BFDE, da_len) ) 
if ( decode_g_option_type_explicitly_set_p && da->debug_type && type != decode_g_option_selected_debug_type ) 
if ( decode_g_option_type_explicitly_set_p && da->debug_type && type != decode_g_option_selected_debug_type ) 
decode_g_option_debug_type_names[decode_g_option_selected_debug_type]); 
rtx v50; // rax 
v36 = print_rtx_hi_name[v25]; 
v36 = print_rtx_qi_name[v25]; 
v36 = print_rtx_hi_name[v40]; 
fprintf( outfile, off_694CF3, ( unsigned int)( v25 - 29)); 
fprintf( outfile, off_690140, note_insn_name[v23]); 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
if ( mode_class_0[mode] != MODE_INT ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)outer), 
rtx v27; // rax 
v13 = gen_rtx_fmt_e( USE, ( machine_mode)BYTE2( v2), rtx); 
v14 = nonzero_bits( v1->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( v1->fld[0].rtwint + 2)); 
v1 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)BYTE2( v2), v15); 
v19 = nonzero_bits( v16->fld[0].rtx, ( machine_mode)v18); 
v31 = nonzero_bits( *( rtx *)( v1->fld[0].rtwint + 8), ( machine_mode)v30); 
( machine_mode)*( ( unsigned __int8 *)v1 + 2), 
v27 = simplify_shift_const( 0LL, ( rtx_code)( v4 + 89), ( machine_mode)v24, v28, ( int)v25 - ( int)v9); 
v27 = simplify_shift_const( 0LL, ( rtx_code)( v4 + 89), ( machine_mode)v24, v28, ( int)v25 - ( int)v9); 
v27 = simplify_shift_const( 0LL, ( rtx_code)( v4 + 89), ( machine_mode)v24, v28, ( int)v25 - ( int)v9); 
tree_node *v2; // rax 
v2 = field_type( tree_node); 
size = simple_type_size_in_bits( v2) >> 3; 
if ( mode && ( v2 & 0xFF0000) == 0 && ( mode_class_0[mode] | 2) != 3 ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
src->fld[0].rtwint - reg_offset_0[regno]); 
reg_offset_0[regno] = src->fld[0].rtwint; 
base_offset = reg_offset_0[src->fld[0].rtuint]; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
base_offset + added_offset - reg_offset_0[regno]); 
reg_offset_0[regno] = sext_for_mode( 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
*( _OWORD *)&v2->stack.chunk_size = 0LL; 
*( _OWORD *)&v2->stack.object_base = 0LL; 
*( _OWORD *)&v2->stack.chunk_limit = 0LL; 
*( _OWORD *)&v2->stack.alignment_mask = 0LL; 
*( _OWORD *)&v2->stack.freefun = 0LL; 
*( ( _OWORD *)&v2->stack + 5) = 0LL; 
change_stack( src->end, &old, v5, ( emit_where)( *( _WORD *)src->end == 33)); 
rtx v8; // rax 
v8 = delete_insn( rtx); 
rtx = v8; 
fatal_insn_not_found( insn, "insn-attrtab.c", 2669, "athlon_muldiv_unit_ready_cost"); 
&& ( v8 = ( unsigned int)reversed_comparison_code_parts( ( rtx_code)v7, v6[1], v6[2], v4)) != UNKNOWN ) 
v11 = gen_rtx_fmt_ee( v8, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v6[1], v6[2]); 
return new_loc_descr( ( dwarf_location_atom)( reg + 80), 0LL, 0LL); 
v3 = spelling_0; 
if ( spelling_base < spelling_0 ) 
v3 = spelling_0; 
recog_data_0.operand[1] = x2y; 
recog_data_0.operand[2] = x2z; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2a; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x2l; 
recog_data_0.operand[2] = x2m; 
recog_data_0.operand[1] = x2bk; 
recog_data_0.operand[2] = x2bl; 
recog_data_0.operand[1] = x4c; 
recog_data_0.operand[2] = x4d; 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v3), v3->fld[0].rtx) 
&& !push_operand( v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)) 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v5), v5->fld[0].rtx) 
fatal_insn_not_found( insn, "insn-attrtab.c", 7919, "pent_uv_unit_blockage_range"); 
*( _OWORD *)&v0->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&v0->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&emit->x_first_insn = 0LL; 
*( _OWORD *)v11 = 0LL; 
*( _OWORD *)v11 = 0LL; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 
fatal_insn_not_found( insn, "insn-attrtab.c", 2686, "athlon_muldiv_unit_blockage_range"); 
rtx v19; // rax 
rtx v27; // r12 
rtx src; // r15 
rtx v37; // r14 
rtx v42; // r14 
rtx v51; // rax 
rtx v69; // rax 
rtx v75; // r14 
v20 = *( _OWORD *)&v2[v18 * 2 + 2]; 
*( _OWORD *)result[v18 + 1].elem = v20; 
v21 = *( _OWORD *)&v2[v18 * 2 + 6]; 
*( _OWORD *)result[v18 + 3].elem = v21; 
v22 = *( _OWORD *)&v2[v18 * 2 + 10]; 
*( _OWORD *)result[v18 + 5].elem = v22; 
v23 = *( _OWORD *)&v2[v18 * 2 + 14]; 
*( _OWORD *)result[v18 + 7].elem = v23; 
v26 = *( _OWORD *)&v2[v24 / 8 + 2]; 
v5 = ( const char *)&unk_80265E; 
v4 = ( const char *)&unk_80265E; 
name = &arg0; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v3 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1], v2); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 28467, "k6_alux_unit_conflict_cost"); 
if ( general_operand( recog_data_0.operand[0], QImode) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( get_attr_type( executing_insn) == TYPE_IMOVX && general_operand( recog_data_0.operand[0], QImode) ) 
if ( ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
else if ( general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative || !general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative == 2 || !general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative == 3 || !general_operand( recog_data_0.operand[0], QImode) ) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( general_operand( recog_data_0.operand[0], QImode) ) 
&& ( new_0 = gen_lowpart_if_possible( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), ent->const_rtx)) != 0LL ) 
if ( ( sch_istable[( unsigned __int8)*p] & 0x8C) == 0 && *p != 46 ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v5 = rtx_alloc( ( rtx_code)( unsigned __int16)*( _DWORD *)orig); 
return &arg0; 
if ( *( _OWORD *)&nodea->block.vars <= __PAIR128__( -1LL, 0LL) ) 
result = expand_mult_add( b, reg, m, a, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg), 1); 
v1 = &arg0; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v12 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
rtx v21; // r14 
rtx v27; // rbp 
rtx v42; // r15 
v21 = x->fld[0].rtx; 
v21 = ( rtx)x[1]; 
v21 = canon_rtx( x); 
v27 = y->fld[0].rtx; 
rtx v37; // r14 
rtx v42; // rax 
rtx x; // [rsp+28h] [rbp-90h] 
|| flag_float_store && *( const mode_class *)( ( char *)mode_class_0 + ( ( v8 >> 14) & 0x3FC)) == MODE_FLOAT ) 
x = v15->fld[0].rtx; 
v16 = true_regnum( x); 
x = ( rtx)v15[1]; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v4 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v3); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest), 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
if ( ++v1 >= ( const  struct builtin *)&off_673E60 ) 
while ( v1 < ( const  struct builtin *)&off_673E60 ); 
cpp_define_builtin( pfile, ( &off_673E80)[v10]); 
v9 = adjust_address_1( v4, ( machine_mode)v1, ( unsigned int)v7, 1, 1); 
operands[1] = gen_lowpart( ( machine_mode)v4, operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
node->int_cst.int_cst = *( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&v4->block.vars; 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
*( _OWORD *)&head->first = 0LL; 
set_diagnostic_context( &dc, msgid, ( va_list_0 *)va, 0LL, 0, 0); 
memset( e, 0, sizeof( edge_def)); 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
if ( !statement_code_p( ( tree_code)( unsigned __int8)*( ( _DWORD *)&( *tpa)->common + 4)) ) 
rtx v18; // r12 
rtx v20; // rbp 
rtx v26; // rbp 
rtx v51; // rax 
rtx v54; // r14 
rtx v57; // r14 
rtx v70; // rax 
rtx v15; // rax 
rtx v16; // rbx 
rtx v23; // rax 
rtx v24; // rbp 
rtx v33; // rax 
rtx v34; // rbx 
fatal_insn_not_found( insn, "insn-attrtab.c", 11506, "pent_np_unit_blockage_range"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
&& q_regs_operand( recog_data_0.operand[0], QImode) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
|| memory_operand( recog_data_0.operand[1], VOIDmode) 
|| !which_alternative && !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| memory_operand( recog_data_0.operand[1], VOIDmode) 
|| which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode)) ) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) ) 
|| !const_int_operand( recog_data_0.operand[2], VOIDmode) 
|| get_attr_imm_disp( insn) != IMM_DISP_TRUE && const_int_operand( recog_data_0.operand[2], VOIDmode)) ) 
if ( get_attr_imm_disp( insn) != IMM_DISP_TRUE && const_int_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( ( nonzero_bits( other, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)) & v5) != 0 ) 
v3 = simplify_shift_const( 0LL, LSHIFTRT, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)src), other, pos); 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 3; 
spelling_0->u.i = bounds; 
++spelling_0; 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
sprintf( buffer->digit_buffer, off_7FB6A9, i); 
v11 = ( tree_node *)*( &global_trees + 27); 
v8 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
v13 = ( _DWORD *)( ( char *)&unk_A1C34C + 4 * ( unsigned int)v8 + 4 * v5); 
rtx in; // rdi 
rtx out_reg; // rdi 
rtx v15; // rbp 
rtx v20; // rbx 
rtx v28; // rax 
rtx v30; // rax 
rtx dead_insn; // [rsp+10h] [rbp-58h] 
dead_insn = spill_reg_store[last_reload_reg]; 
in = rld[v4].in; 
if ( in ) 
v8 = *( _WORD *)in; 
in = rld[v4].in_reg; 
fancy_abort( &off_723588[4], 4663, "reload_reg_reaches_end_p"); 
rtx v13; // rcx 
rtx real_insn; // r14 
rtx v15; // rbx 
rtx v25; // rbx 
rtx v26; // rax 
rtx v30; // rdx 
rtx v33; // rax 
rtx v37; // rdx 
*( _OWORD *)&f->return_rtx = 0LL; 
*( _OWORD *)&f->x_nonlocal_labels = 0LL; 
*( _OWORD *)&f->x_nonlocal_goto_handler_labels = 0LL; 
*( _OWORD *)&f->x_cleanup_label = 0LL; 
*( _OWORD *)&f->x_save_expr_regs = 0LL; 
*( _OWORD *)&f->x_rtl_expr_chain = 0LL; 
*( _OWORD *)&f->x_tail_recursion_reentry = 0LL; 
*( _OWORD *)&f->x_context_display = 0LL; 
*( _OWORD *)&f->x_parm_birth_insn = 0LL; 
v6 = mode_class_0[*( ( unsigned __int8 *)arg1 + 2)]; 
v6 = mode_class_0[v5]; 
deps_0 *succ_deps; // [rsp+50h] [rbp-30h] 
deps_0 *succ_deps; // [rsp+50h] [rbp-30h] 
succ_deps = &bb_deps[bb_succ]; 
succ_rl = &succ_deps->reg_last[reg]; 
namea = lang_hooks_0.init( name); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
while ( ( sch_istable[( unsigned __int8)v8] & 0xC00) == 0 ) 
rtx v10; // r15 
rtx v16; // r14 
rtx regno_note; // r15 
rtx v31; // rbx 
rtx *v37; // rcx 
rtx v64; // r11 
( machine_mode)( unsigned __int8)BYTE2( *v9), 
( machine_mode)BYTE2( v8))] 
v10 = pat_src + 1; 
for ( i = ( int **)v10; ; i = ( int **)( v12 + 2) ) 
( machine_mode)( unsigned __int8)BYTE2( *v14), 
( machine_mode)BYTE2( v13))] 
v18 = ( tree_node *)high; 
v3 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v2); 
fatal_insn_not_found( insn, "insn-attrtab.c", 6280, "k6_alux_unit_blockage_range"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 6263, "k6_alux_unit_ready_cost"); 
if ( ix86_cpu == PROCESSOR_K6 && general_operand( recog_data_0.operand[0], QImode) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
&& ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( ix86_cpu == PROCESSOR_K6 && ( which_alternative || general_operand( recog_data_0.operand[0], QImode)) ) 
if ( ix86_cpu == PROCESSOR_K6 && !which_alternative && general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( ix86_cpu == PROCESSOR_K6 && which_alternative != 2 && general_operand( recog_data_0.operand[0], QImode) ) 
if ( ix86_cpu == PROCESSOR_K6 && which_alternative != 3 && general_operand( recog_data_0.operand[0], QImode) ) 
|| get_attr_type( insn) == TYPE_ALU && general_operand( recog_data_0.operand[0], QImode)) ) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode)) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !general_operand( recog_data_0.operand[0], QImode)) ) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode) 
sprintf( &text, "*.%s%u", ( const char *)&off_73AB98, ( unsigned int)++assemble_end_function_labelno); 
sprintf( &text, "*.%s%u", ( const char *)&off_73AB98, ( unsigned int)++assemble_end_function_labelno); 
fprintf( ( FILE *)asm_out_file, ".%s%u:\n", ( const char *)&off_73AB98, ( unsigned int)assemble_end_function_labelno); 
fprintf( ( FILE *)asm_out_file, ".%s%u:\n", ( const char *)&off_73AB98, ( unsigned int)assemble_end_function_labelno); 
value = lang_hooks_0.tree_inlining.convert_parm_for_inlining( p, elements, fn); 
mtherr( aE, 7); 
v13 = assign_stack_local( ( machine_mode)v9, v12, -( v10 < v11)); 
v13 = assign_stack_local( ( machine_mode)v9, v12, -( v12 != v10)); 
v20 = adjust_address_1( v13, ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v3] + 2), 0LL, 0, 1); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE30); 
v5 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v6 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
fancy_abort( &off_723588[4], 573, "compute_use_by_pseudos"); 
v18 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v16] - 5) < 2) + 1; 
v43 = ( ( unsigned int)( mode_class_0[v41] - 5) < 2) + 1; 
rtx v16; // rbp 
rtx *v17; // rdx 
rtx v18; // rax 
rtx *v19; // rbx 
rtx v20; // rdi 
rtx *fld; // rdx 
rtx *v30; // rcx 
rtx *v46; // rdx 
rtx v58; // rax 
if ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)reg >> 14) & 0x3FC)) - 5) > 1 ) 
rtx v20; // rax 
rtx v26; // rax 
rtx *overflow_arg_area; // rax 
rtx v30; // rax 
( rtx_code)( unsigned __int16)*( _DWORD *)x, 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( rtx_code)( unsigned __int16)*( _DWORD *)x, 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
return simplify_relational_operation( ( rtx_code)( unsigned __int16)*( _DWORD *)x, v5, v4.rtx, ( rtx)v6); 
return simplify_binary_operation( ( rtx_code)v1, v2, v8, rtx); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
recog_data_0.operand[2] = v7.rtx; 
recog_data_0.operand[3] = v108; 
recog_data_0.operand[0] = v110; 
if ( rtx_equal_p( *( rtx *)( v111 + 8), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = v114; 
if ( rtx_equal_p( *( rtx *)( v115 + 8), recog_data_0.operand[3]) ) 
recog_data_0.operand[2] = v7.rtx; 
recog_data_0.operand[3] = v10; 
recog_data_0.operand[0] = v13; 
if ( !rtx_equal_p( *( rtx *)( v14 + 8), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = v17; 
if ( !rtx_equal_p( *( rtx *)( v18 + 8), recog_data_0.operand[3]) ) 
v3 = gen_reg_rtx( ( machine_mode)BYTE2( v2)); 
*( _OWORD *)( object_base + 40) = 0LL; 
*( _OWORD *)( object_base + 24) = 0LL; 
*( _OWORD *)( object_base + 8) = 0LL; 
*( _OWORD *)( object_base + 72) = 0LL; 
*( _OWORD *)( object_base + 120) = 0LL; 
*( _OWORD *)( object_base + 104) = 0LL; 
*( _OWORD *)( object_base + 88) = 0LL; 
*( _OWORD *)( object_base + 56) = 0LL; 
rtx v64; // rbx 
rtx v87; // [rsp+18h] [rbp-C0h] 
v87 = first; 
if ( v87 ) 
rtx = v87; 
if ( !display_target_options_displayed ) 
display_target_options_displayed = 1; 
ix86_fp_comparison_codes( ( rtx_code)v4, &bypass_code, &first_code, second_code); 
v5 = cselib_lookup( x, ( machine_mode)BYTE2( v4), 0); 
v7 = cselib_lookup( y, ( machine_mode)BYTE2( v6), 0); 
rtx v13; // rax 
rtx v19; // rax 
v13 = expand_expr( v12, 0LL, VOIDmode, EXPAND_NORMAL); 
v13 = gen_rtx_CONST_INT( VOIDmode, args[v5 / 0xA8].offset.constant); 
v14 = v13; 
v19 = expand_expr( v18, 0LL, VOIDmode, EXPAND_NORMAL); 
v19 = gen_rtx_CONST_INT( VOIDmode, args[v5 / 0xA8].slot_offset.constant); 
v20 = v19; 
v21 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), rtx, v14); 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
id = ( inline_data_0 *)data; 
if ( lang_hooks_0.tree_inlining.start_inlining( fn) ) 
lang_hooks_0.tree_inlining.end_inlining( fn); 
add_dependence( insn, link->fld[0].rtx, ( reg_note)( unsigned __int8)BYTE2( *( _DWORD *)link)); 
rtx *v16; // r9 
rtx oldest_value_reg; // rax 
rtx *v26; // rdi 
rtx *v27; // rbx 
oldest_value_reg = find_oldest_value_reg( a2, rtx, (  struct value_data *)insn); 
if ( !oldest_value_reg ) 
v9 = oldest_value_reg; 
oldest_value_reg->fld[0].rtuint); 
v16 = ( rtx *)&rtx[1]; 
v16 = ( rtx *)&rtx[1]; 
v26 = ( rtx *)v15; 
rtx v5; // rax 
rtx v6; // rax 
rtx v9; // [rsp+0h] [rbp-28h] BYREF 
rtx p_hard_return; // [rsp+8h] [rbp-20h] BYREF 
if ( !identify_call_return_value( *( rtx *)&orig_insn[2], &p_hard_return, &v9) ) 
if ( !identify_call_return_value( *( rtx *)&orig_insn[2], &p_hard_return, &v9) ) 
|| rtx->fld[0].rtint != p_hard_return->fld[0].rtint 
v5 = next_nonnote_insn( v2); 
if ( !v5 ) 
v2 = v5; 
if ( !parmlist_tags_warning_already ) 
if ( !parmlist_tags_warning_already ) 
parmlist_tags_warning_already = 1; 
fatal_insn_not_found( insn, "insn-attrtab.c", 6297, "ppro_p34_unit_ready_cost"); 
if ( *( _OWORD *)&out.base != 0LL ) 
v15 = ( char *)&off_70CA57; 
v15 = ( char *)&off_70CA51; 
put_condition_code( ( rtx_code)v10, v11, v12, v17, v5); 
v26 = mode_class_0[v9]; 
v7 = ( const char *)&unk_694DB8; 
v7 = ( const char *)&unk_694DB8; 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
assemble_real( ( machine_mode)mode, v7->align, *( realvaluetype *)&constant[1]); 
*( _OWORD *)&varasm->x_first_pool = 0LL; 
induction_1 *giv; // rcx 
induction_1 *giv; // rcx 
induction_1 *v25; // r15 
induction_1 *v25; // r15 
rtx mult_val; // rax 
rtx v29; // rax 
rtx add_val; // rcx 
induction_1 *biv; // r8 
induction_1 *biv; // r8 
rtx v33; // rsi 
rtx v38; // rdi 
rtx v39; // rcx 
*( _OWORD *)v12 = v13; 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
v6 = adjust_address_1( *operands, ( machine_mode)v5, 0LL, 1, 1); 
( machine_mode)v5); 
v12 = gen_rtx_fmt_ee( AND, ( machine_mode)v5, rtwint, v11); 
fatal_insn_not_found( insn, "insn-attrtab.c", 2186, "athlon_fp_add_unit_ready_cost"); 
return build1( ( tree_code)( ( flag_float_store == 0) | 0x72), type, expr); 
if ( symbolic_operand( v4, ( machine_mode)operands) ) 
v14 = mode_class_0[mode]; 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
superset_entry = ( alias_set_entry_0)xmalloc( 0x18uLL); 
warning_with_decl( newdecl, aWeakDeclaratio_0); 
strcpy( visual_tbl, &arg0); 
*( _OWORD *)v6.r = v8; 
*( _OWORD *)&node->block.vars = *( _OWORD *)v6.r; 
*( _OWORD *)&node->block.vars = *( _OWORD *)v6.r; 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
sprintf( v114, "*.%s%u", ( const char *)&off_684265, current_funcdef_number); 
v14 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v13); 
v28 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), "_alloca"); 
if ( mode_class_0[mode] == MODE_INT && !can_compare_p( op, mode, ccp_jump) ) 
if ( ( mode_class_0[*( ( unsigned __int8 *)*reg + 2)] | 4) != 6 ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)] == MODE_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)] == MODE_FLOAT 
|| mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)ix86_compare_op0)] == MODE_COMPLEX_FLOAT 
timevar_push( TV_VARCONST_0); 
timevar_pop( TV_VARCONST_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
v6 = copy_to_mode_reg( ( machine_mode)BYTE2( v7), copy); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dst->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dst)); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v21 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
reg_offset_0[regnoa] = *( _QWORD *)( *( _QWORD *)&set[1] + 8LL); 
offset = reg_offset_0[base_reg->fld[0].rtuint]; 
offset = reg_offset_0[*( unsigned int *)( *( _QWORD *)&src[1] + 8LL)]; 
reg_offset_0[base_regno] = 0LL; 
reg_offset_0[regnoa] = sext_for_mode( dst_mode, reg_offset_0[base_regno] + offset); 
reg_offset_0[regnoa] = sext_for_mode( dst_mode, reg_offset_0[base_regno] + offset); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v16 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[mode] != MODE_FLOAT ) 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
fancy_abort( &off_723588[4], 4527, "reload_reg_free_p"); 
rtx *v16; // r12 
rtx *v19; // rbp 
rtx *v48; // rax 
rtx *v51; // rbx 
rtx *v61; // rsi 
rtx arg0; // [rsp+10h] [rbp-58h] 
rtx value; // [rsp+20h] [rbp-48h] BYREF 
rtx v81; // [rsp+30h] [rbp-38h] 
v16 = ( rtx *)&v6[1]; 
value = ( rtx)v6[1]; 
instantiate_virtual_regs_1( &value, 0LL, 0); 
if ( *( _WORD *)value != 61 && *( _WORD *)value != 75 ) 
if ( *( _WORD *)value != 61 && *( _WORD *)value != 75 ) 
for ( loop_ptr = ( loop_1 *)loop_chain->data.l[0]; ; loop_ptr = ( loop_1 *)loop_chain->data.l[loop_idx] ) 
for ( loop_ptr = ( loop_1 *)loop_chain->data.l[0]; ; loop_ptr = ( loop_1 *)loop_chain->data.l[loop_idx] ) 
if ( statement_code_p( ( tree_code)( unsigned __int8)*( ( _DWORD *)&exp->common + 4)) && exp->common.chain ) 
to = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)expr_set->fld[0].rtwint)); 
v10 = *( tree_node **)( *( _QWORD *)&newa[1] + 8LL); 
if ( mode == VOIDmode || ( v4 & 0xFF0000) != 0 || ( mode_class_0[mode] | 2) == 3 ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v11 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
undo->next = undobuf_0.frees; 
undobuf_0.frees = undo; 
undobuf_0.undos = 0LL; 
fatal_insn_not_found( insn, "insn-attrtab.c", 2152, "athlon_fp_store_unit_ready_cost"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 3477, "athlon_vectordec_unit_ready_cost"); 
edge_list_0 = pre_edge_lcm( gcse_file, n_exprs, transp, comp, antloc, ae_kill, &pre_insert_map, &pre_delete_map); 
rtx v37; // rcx 
fatal_insn_not_found( insn, "insn-attrtab.c", 21978, "get_attr_type"); 
if ( !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !register_operand( recog_data_0.operand[0], QImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
*px = convert_to_mode( ( machine_mode)v9, v11, 0); 
*py = convert_to_mode( ( machine_mode)v9, v12, 0); 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2a; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[1] = x2u; 
recog_data_0.operand[2] = x2v; 
recog_data_0.operand[1] = x2s; 
recog_data_0.operand[2] = x2t; 
recog_data_0.operand[1] = x2o; 
v6 = mode_class_0[v5]; 
induction_1 *v11; // rbp 
induction_1 *v11; // rbp 
( machine_mode)BYTE2( v8)) ) 
v11 = ( induction_1 *)xmalloc( 0xA8uLL); 
v11 = ( induction_1 *)xmalloc( 0xA8uLL); 
v11, 
v11->mem = x; 
v5 = force_reg( ( machine_mode)( ( ( v3 | 0x500000000uLL) - 1) >> 32), buf_addr); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
v12 = gen_rtx_MEM( ( machine_mode)( v2 ^ 5), v11); 
v6 = convert_to_mode( ( machine_mode)v7, v6, 1); 
v10 = gen_rtx_fmt_ee( MULT, ( machine_mode)v8, v6, v9); 
v11 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), table_label); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v8, v10, v11); 
v13 = memory_address_noforce( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v12); 
v14 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5)); 
v15 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v13); 
fatal_insn_not_found( insn, "insn-attrtab.c", 1990, "result_ready_cost"); 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && memory_operand( recog_data_0.operand[1], VOIDmode) 
|| ix86_cpu == PROCESSOR_PENTIUM && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && !which_alternative && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
&& memory_operand( recog_data_0.operand[1], VOIDmode) ) 
&& ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode)) 
&& !incdec_operand( recog_data_0.operand[2], DImode) 
&& !incdec_operand( recog_data_0.operand[2], DImode) 
&& ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
else if ( ix86_cpu == PROCESSOR_K6 && ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
&& !incdec_operand( recog_data_0.operand[2], SImode) 
&& !incdec_operand( recog_data_0.operand[2], SImode) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], operands[5]); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1), 
v5 = expand_expr( v2, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
v6 = expand_expr( v4, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
rtx insn; // [rsp+60h] [rbp-30h] 
rtx etc_note; // [rsp+80h] [rbp-10h] 
rtx start_label; // [rsp+88h] [rbp-8h] 
start_label = cfun->stmt->x_loop_stack->data.cond.endif_label; 
if ( start_label == cfun->stmt->x_loop_stack->data.loop.continue_label ) 
emit_note_before( -94, start_label); 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
if ( ( unsigned __int16)*( _DWORD *)etc_note == 37 ) 
switch ( etc_note[2].fld[0].rtint ) 
etc_note = 0LL; 
if ( etc_note && optimize && !eh_regions && ( !debug_blocks || optimize >= 2) ) 
if ( etc_note[1].fld[0].rtwint ) 
rtx v5; // rbp 
v5 = modify_mem_list[*( int *)( basic_block_for_insn->data.l[rtint] + 88)]; 
if ( v5 ) 
v6 = *( ( _DWORD *)uid_cuid_1 + rtint); 
v7.rtwint = ( __int64)v5->fld[0]; 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v7.rtwint + 8)) > v6 ) 
v5 = ( rtx)v5[1]; 
if ( !v5 ) 
v7.rtwint = ( __int64)v5->fld[0]; 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v7.rtwint + 8)) <= v6 ) 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x3f; 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3d; 
recog_data_0.operand[2] = x3e; 
recog_data_0.operand[2] = x3e; 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3g; 
recog_data_0.operand[2] = x4c; 
|| !ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand) ) 
deps_0 tmp_deps; // [rsp+0h] [rbp-80h] BYREF 
memcpy( &tmp_deps, &bb_deps[bb], sizeof( tmp_deps)); 
memcpy( &tmp_deps, &bb_deps[bb], sizeof( tmp_deps)); 
sched_analyze( &tmp_deps, head, tail); 
propagate_deps( bba, &tmp_deps); 
free_deps( &tmp_deps); 
sprintf( label, "*.%s%u", "LC", ( unsigned int)const_labelno); 
++const_labelno; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
v41 = insn_data_0[insn_code].genfun( v4, v5); 
v9 = mode_class_0[v6]; 
if ( push_operand( v4, ( machine_mode)*( ( unsigned __int8 *)v4 + 2)) ) 
v47 = insn_data_0[v44].genfun( v45, v46); 
v26 = insn_data_0[v48].genfun( v49, v50); 
v73 = expand_binop( ( machine_mode)( v69 ^ 5), v70, v71, v72, global_rtl[2], 0, OPTAB_LIB_WIDEN); 
if ( !v7 || ( v8 = ( tree_node *)*( ( _QWORD *)v7 + 1)) == 0LL ) 
v8 = ( tree_node *)v5; 
v27 = ( tree_node *)low; 
if ( ( sch_istable[( unsigned __int8)v55] & 4) == 0 ) 
while ( ( sch_istable[v55] & 4) != 0 ); 
if ( ( sch_istable[( unsigned __int8)v74[1]] & 4) != 0 
( sch_istable[( unsigned __int8)*format] & 4) != 0) ) 
while ( ( sch_istable[v79] & 4) != 0 ); 
if ( v69 && ( sch_istable[( unsigned __int8)*v80] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)*v80] & 4) != 0 ) 
while ( ( sch_istable[v87] & 4) != 0 ); 
v18 = memory_address_p( ( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), global_rtl[2]); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 31195, "pent_u_unit_blockage"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
|| ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
else if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
rtx v6; // rbx 
v6 = modify_mem_list[bb->index]; 
if ( v6 ) 
v8.rtwint = ( __int64)v6->fld[0]; 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v8.rtwint + 8)) <= v7 ) 
v6 = ( rtx)v6[1]; 
while ( v6 ); 
&& ( v4 = &unk_740000, _bittest64( ( const __int64 *)&v4, v3)) ) 
type->type.align = get_mode_alignment( ( machine_mode)v2); 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v18; 
recog_data_0.operand[0] = ( rtx)v18; 
recog_data_0.operand[0] = v21; 
recog_data_0.operand[0] = rtx; 
if ( !const_int_operand( v8, SImode) || ( recog_data_0.operand[1] = v8, result = 832, !x86_prefetch_sse) ) 
recog_data_0.operand[1] = v7; 
recog_data_0.operand[0] = ( rtx)v13; 
rtx result; // rax 
rtx v15; // r13 
v3 = gen_reg_rtx( ( machine_mode)BYTE2( v4)); 
( machine_mode)*( unsigned __int8 *)( v2->fld[0].rtwint + 2), 
v15 = ( rtx)value[1]; 
v16 = *( _DWORD *)v15; 
switch ( ( unsigned __int16)*( _DWORD *)v15 ) 
if ( v15 == v3 ) 
v15 = negate_rtx( ( machine_mode)BYTE2( v4), *( rtx *)&value[1]); 
v15 = negate_rtx( ( machine_mode)BYTE2( v4), *( rtx *)&value[1]); 
&& *( _WORD *)v15 == 54 
*( _OWORD *)ix86_sched_data.ppro.decode = ( unsigned __int64)insn; 
*( _OWORD *)ix86_sched_data.ppro.decode = ( unsigned __int64)insn; 
*( _OWORD *)ix86_sched_data.ppro.decode = 0uLL; 
while ( strchr( off_8A2756, *p) ) 
&& ( nzb = nonzero_bits( from, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)from)), exact_log2_wide( nzb) >= 0) ) 
&& num_sign_bit_copies( from, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)from)) == mode_bitsize[( unsigned __int8)BYTE2( *( _DWORD *)from)] ) 
v5 = reversed_comparison( cond, ( machine_mode)BYTE2( *( _DWORD *)cond), cond->fld[0].rtx, *( rtx *)&cond[1]); 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
for ( p = spelling_base; p < spelling_0; ++p ) 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v8 = ( tree_node *)global_trees; 
v8 = ( tree_node *)global_trees; 
if ( v14 == ( tree_node *)global_trees ) 
induction_1 *next_induction; // [rsp+0h] [rbp-30h] 
induction_1 *next_induction; // [rsp+0h] [rbp-30h] 
induction_1 *next_inductiona; // [rsp+0h] [rbp-30h] 
induction_1 *next_inductiona; // [rsp+0h] [rbp-30h] 
induction_1 *induction; // [rsp+8h] [rbp-28h] 
induction_1 *induction; // [rsp+8h] [rbp-28h] 
induction_1 *inductiona; // [rsp+8h] [rbp-28h] 
induction_1 *inductiona; // [rsp+8h] [rbp-28h] 
/data/output_dir/patch/gcc/ida/clang/O0/gcc-clang-O0/loop_ivs_free/src/loop.c:5373:48: error: expected expression
next_induction = induction->next_iv; 
next_induction = induction->next_iv; 
free( induction); 
for ( inductiona = iv->giv; inductiona; inductiona = next_inductiona ) 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)flags)] != MODE_COMPLEX_INT ) 
v14 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)flags)] == MODE_COMPLEX_FLOAT; 
temg = gen_peephole2_1276( insn, recog_data_0.operand); 
temf = gen_peephole2_1275( insn, recog_data_0.operand); 
temh = gen_peephole2_1280( insn, recog_data_0.operand); 
temi = gen_peephole2_1281( insn, recog_data_0.operand); 
temj = gen_peephole2_1282( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x2z; 
recog_data_0.operand[3] = x2ba; 
if ( rtx_equal_p( x2ba->fld[0].rtx, recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = x3p; 
temk = gen_peephole2_1260( insn, recog_data_0.operand); 
if ( v7 && ( recog_data_0.operand[1] = x3o, rtx_equal_p( *( rtx *)&x2ba[1], recog_data_0.operand[0])) ) 
if ( v7 && ( recog_data_0.operand[1] = x3o, rtx_equal_p( *( rtx *)&x2ba[1], recog_data_0.operand[0])) ) 
teml = gen_peephole2_1261( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x2z; 
*( _OWORD *)&v2->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&v2->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&emit->x_first_insn = 0LL; 
&& insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
&& insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
&& insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)); 
&& insn_data_0[icode].operand[2].predicate( 
group = ( page_group_0 *)enda; 
group = ( page_group_0 *)( page - 32); 
return in_section_0 == in_data; 
node->value.macro = ( cpp_macro_0 *)new_answer; 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( **( ( _DWORD **)aux + 6) >> 14) & 0x3FC)) == MODE_FLOAT 
*( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v20 >> 14) & 0x3FC)) == MODE_FLOAT) ) 
if ( v12 != ( ( unsigned int)( mode_class_0[v14] - 5) < 2) + 1 ) 
v13 = adjust_address_1( v13, ( machine_mode)v14, 0LL, 1, 1); 
v15 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)v13 + 2), v7); 
rtx *v174; // r13 
rtx *v179; // r14 
rtx *v181; // rax 
rtx *v189; // rbx 
rtx *loc; // [rsp+40h] [rbp-218h] 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB60); 
v4 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB10); 
v5 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v6 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB50); 
v8 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB40); 
v9 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB00); 
v10 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FAF0); 
v11 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB20); 
v11 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71FB20); 
_OWORD *v42; // rax 
_OWORD *v42; // rax 
v7 = *( tree_node **)( v6 + 8); 
if ( lang_hooks_0.honor_readonly ) 
v47 = ( tree_node *)*( &global_trees + 15); 
v42 = ggc_alloc( 0x28uLL); 
*slot = v42; 
rtl_op = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16)); 
v11 = ( tree_node *)i[13]; 
v19 = ( tree_node *)*( ( _QWORD *)&chain->vector.elements + v18); 
induction_1 *tv; // [rsp+20h] [rbp-20h] 
induction_1 *tv; // [rsp+20h] [rbp-20h] 
induction_1 *v; // [rsp+28h] [rbp-18h] 
induction_1 *v; // [rsp+28h] [rbp-18h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( ( *( ( _WORD *)v + 50) >> 2) & 1) == 0 && !v->same ) 
if ( ( ( *( ( _WORD *)v + 50) >> 2) & 1) == 0 && !v->same ) 
if ( !v->new_reg ) 
v->new_reg = gen_reg_rtx( v->mode); 
v->new_reg = gen_reg_rtx( v->mode); 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
insert_before = tv->insn; 
if ( tv->mult_val == const_int_rtx[65] ) 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
fancy_abort( &off_723588[4], 9527, "fixup_abnormal_edges"); 
rtx *v74; // r13 
rtx v75; // rax 
rtx v77; // rbx 
rtx earliest; // [rsp+8h] [rbp-60h] BYREF 
rtx *v142; // [rsp+30h] [rbp-38h] 
condition_0 = get_condition_0( jump, &earliest); 
v40 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)rtx >> 14) & 0x3FC)); 
if ( ( v48 & 0x4000) != 0 || ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
if ( ( v179 & 0x4000) != 0 || ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
result = apply_result_size_size; 
if ( apply_result_size_size < 0 ) 
apply_result_size_size = 0; 
v8 = apply_result_size_size; 
if ( apply_result_size_size % v7 ) 
v8 = v7 + apply_result_size_size - 1 - ( v7 + apply_result_size_size - 1) % v7; 
v8 = v7 + apply_result_size_size - 1 - ( v7 + apply_result_size_size - 1) % v7; 
apply_result_size_size = v8; 
apply_result_size_size = v8 + mode_size[v2]; 
apply_result_size_size = 116; 
*( reload_type *)( v2 + 10629612), 
*( machine_mode *)( v2 + 10629548)); 
return gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, val, next); 
n_operands = recog_data_0.n_operands; 
if ( *v15 < 0 && recog_data_0.operand_type[v16] != OP_OUT ) 
recog_data_0.operand_type[v16] = OP_INOUT; 
recog_data_0.operand_type[j] = OP_INOUT; 
kill_value( recog_data_0.operand[v20], v9); 
kill_value( recog_data_0.operand[v22], v9); 
v29 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v25] - 5) < 2) + 1; 
v30 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
oldest_value_reg = find_oldest_value_reg( ( reg_class)*( ( _DWORD *)&regclass_map + rtuint), reg, v9); 
v69 = gen_rtx_fmt_i0( REG, ( machine_mode)v26, v71); 
if ( !*recog_data_0.constraints[v31] ) 
v32 = recog_data_0.operand[v31]; 
if ( v32->fld[0].rtint == v32[1] || recog_data_0.operand_type[v31] ) 
offset = -args_size_0; 
args_size_0 += offset; 
if ( args_size_0 < 0 ) 
args_size_0 = 0LL; 
dwarf2out_args_size( label, args_size_0); 
dwarf2out_args_size( &arg0, *( _QWORD *)( *( _QWORD *)&insna[1] + 8LL)); 
rtx x; // [rsp+8h] [rbp-40h] BYREF 
x = insns; 
for_each_rtx( &x, insns_for_mem_walk, data); 
rtx = x[1].fld[0].rtx; 
x = rtx; 
error_with_decl( decl, &off_73AD60[4]); 
( rtx_code)( unsigned __int16)*( _DWORD *)if_info->cond, 
if ( ( v5 & 0x4000) == 0 && ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
v26 = ( tree_node *)v20[7]; 
*( _OWORD *)&sequence_result[2] = 0LL; 
*( _OWORD *)sequence_result = 0LL; 
sprintf( lscope_label_name, "*.%s%u", "Lscope", ( unsigned int)dbxout_function_end_scope_labelno); 
fprintf( asmfile, ".%s%u:\n", "Lscope", ( unsigned int)dbxout_function_end_scope_labelno); 
++dbxout_function_end_scope_labelno; 
values = *( tree_node **)( high + 24); 
if ( in_section_0 == in_text ) 
fprintf( ( FILE *)asm_out_file, ( const char *)&off_73AB98 + 4, "\t.zero\t", ( unsigned int)v32); 
v58 = ( tree_node *)v59; 
if ( in_section_0 == in_text ) 
fprintf( ( FILE *)asm_out_file, ( const char *)&off_73AB98 + 4, "\t.zero\t", ( unsigned int)length); 
v4 = gen_rtx( ( rtx_code)( unsigned __int16)*( _DWORD *)operand3, V4SImode, operand1, operand2); 
rtx v21; // rax 
rtx v34; // rax 
rtx nonnote_insn; // rax 
if ( status != NOT_TAKEN_0 ) 
v21 = cse_process_notes( rtx, 0LL); 
v6[3].fld[0].rtwint = ( __int64)v21; 
if ( v21 ) 
v6 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
v10 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( rtuint), 80), ( __m128i)xmm*(short *)0x65AE50); 
v12 = _mm_shuffle_pd( ( __m128d)hard_regs_live, ( __m128d)xmm*(short *)0x68FC00, 2); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE60); 
v17 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v18 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE70); 
v19 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE80); 
v20 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE90); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v12 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
dest = ( cpp_token_0 *)&pfile->a_buff->cur[24 * acount + 16]; 
*( &global_trees + 11) = ( splay_tree_value)build_int_2_wide( 0LL, 0LL); 
*( &global_trees + 12) = ( splay_tree_value)build_int_2_wide( 1uLL, 0LL); 
*( &global_trees + 13) = ( splay_tree_value)build_int_2_wide( 0xFFFFFFFFFFFFFFFFLL, -1LL); 
*( &global_trees + 15) = ( splay_tree_value)size_int_wide( 0LL, SIZETYPE); 
*( &global_trees + 16) = ( splay_tree_value)size_int_wide( 1LL, SIZETYPE); 
*( &global_trees + 17) = ( splay_tree_value)size_int_wide( 0LL, BITSIZETYPE); 
*( &global_trees + 18) = ( splay_tree_value)size_int_wide( 1LL, BITSIZETYPE); 
*( &global_trees + 19) = ( splay_tree_value)size_int_wide( 8LL, BITSIZETYPE); 
*( &global_trees + 27) = ( splay_tree_value)make_node( VOID_TYPE); 
*( &global_trees + 14) = ( splay_tree_value)build_int_2_wide( 0LL, 0LL); 
*( &global_trees + 28) = ( splay_tree_value)build_pointer_type( ( tree)*( &global_trees + 27)); 
*( &global_trees + 29) = ( splay_tree_value)build_pointer_type( v1); 
*( &global_trees + 24) = ( splay_tree_value)make_node( REAL_TYPE); 
*( &global_trees + 25) = ( splay_tree_value)make_node( REAL_TYPE); 
*( &global_trees + 26) = ( splay_tree_value)make_node( REAL_TYPE); 
*( &global_trees + 20) = ( splay_tree_value)make_node( COMPLEX_TYPE); 
*( &global_trees + 21) = ( splay_tree_value)make_node( COMPLEX_TYPE); 
*( &global_trees + 22) = ( splay_tree_value)make_node( COMPLEX_TYPE); 
if ( ( sch_istable[v25] & 0x100) != 0 ) 
v26 = hex_value[v25]; 
if ( ( sch_istable[*v24] & 0x100) != 0 ) 
v27 = hex_value[v25]; 
if ( ( sch_istable[v28] & 0x100) == 0 ) 
v37 = hex_value[v28]; 
if ( ( sch_istable[v28] & 0x100) == 0 ) 
if ( ( sch_istable[**pstr] & 0xAC) != 0 ) 
if ( *( _OWORD *)&x == 0LL ) 
rtx *v18; // rcx 
v18 = ( rtx *)( v13->fld[0].rtwint + 16); 
v18 = const_int_rtx + 520; 
*mult_val = *v18; 
v10 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)op + 2), v8); 
v11 = force_reg( ( machine_mode)BYTE2( v6), op); 
rtx v13; // rbp 
rtx v14; // rbx 
rtx v19; // rax 
rtx v20; // r14 
rtx v22; // r12 
rtx v28; // rax 
_OWORD *v40; // rax 
_OWORD *v40; // rax 
rtx v17; // rbp 
rtx v20; // rax 
induction_1 *v23; // rsi 
induction_1 *v23; // rsi 
rtx v26; // rcx 
rtx label_from_map; // rax 
rtx v37; // rsi 
rtx v45; // rax 
rtx v47; // rax 
rtx v50; // rax 
v54 = store_field( v52, v45, v46, modea, exp, ( machine_mode)v47, v49, v50, alias_set); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v63->common.type->block.abstract_origin)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v53->common.type->block.abstract_origin)) >> 1), 
v20 = expand_expr( from, 0LL, ( machine_mode)*( ( unsigned __int8 *)v16 + 2), EXPAND_NORMAL); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( sizetype_tab[0]->block.abstract_origin)) >> 1), 
v3 = lang_hooks_0.expand_constant( value); 
if ( v18 == ( tree_node *)*( &global_trees + 14) ) 
if ( v19 == ( tree_node *)*( &global_trees + 14) || v18 == ( tree_node *)*( &global_trees + 14) ) 
if ( v19 == ( tree_node *)*( &global_trees + 14) || v18 == ( tree_node *)*( &global_trees + 14) ) 
v29 = mode_class_0[v28]; 
v33 = mode_class_0[v32]; 
v16 = ( tree_node *)*( &global_trees + 25); 
action = set; 
action = set; 
action = push; 
action = push; 
action = pop; 
action = pop; 
if ( tokena == 21 || action != push ) 
if ( tokena == 21 || action != push ) 
if ( action == push && c_lex( &x) != 21 ) 
if ( action == push && c_lex( &x) != 21 ) 
if ( action == push ) 
if ( action == push ) 
if ( action != push ) 
if ( action != push ) 
action = set; 
if ( ( unsigned int)format > 0xFF || ( result = eh_data_format_name_format_names[format]) == 0LL ) 
v81 = mem_loc_descriptor( rtx, ( machine_mode)BYTE2( v26)); 
&& QDefaultAnimationDriver::QDefaultAnimationDriver( token->val.node->ident.str, ( const U_CHAR *)string) == 0; 
*( _OWORD *)&v0->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&v0->first = *( _OWORD *)&emit->x_first_insn; 
*( _OWORD *)&emit->x_first_insn = 0LL; 
*( _OWORD *)&v3->x_first_insn = *( _OWORD *)&v6->first; 
*( _OWORD *)&v3->x_first_insn = *( _OWORD *)&v6->first; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 24966, "k6_fpu_unit_conflict_cost"); 
casenum = mult_operator( recog_data_0.operand[3], SFmode) != 0; 
if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
casenum = mult_operator( recog_data_0.operand[3], XFmode) != 0; 
casenum = mult_operator( recog_data_0.operand[3], TFmode) != 0; 
else if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
if ( ( sch_istable[v9] & 4) == 0 ) 
v7 = 2 * ( ( sch_istable[v9] & 4) == 0) + 8; 
if ( ( sch_istable[v18] & 4) == 0 && ( ( sch_istable[v18] & 0x100) == 0 || v7 != 16) ) 
if ( ( sch_istable[v18] & 4) == 0 && ( ( sch_istable[v18] & 0x100) == 0 || v7 != 16) ) 
v19 = hex_value[v18]; 
if ( ( sch_istable[( unsigned __int8)v34] & 4) == 0 ) 
while ( ( sch_istable[( unsigned __int8)v34] & 4) != 0 ) 
if ( ( sch_istable[v47] & 4) == 0 ) 
v38 = ( char *)&unk_6668B8; 
v38 = ( char *)&unk_6668C8; 
v84 = ( tree_node *)*( &global_trees + 11); 
fprintf( v198.stream, "%-13s ", &off_71BF47); 
v25 = *( tree_node **)( key + 64); 
fprintf( v198.stream, off_71BF36, v24, 6552963LL); 
fprintf( v198.stream, asc_71BF35, 25LL, 6552963LL); 
v13 = *( tree_node **)( key + 32); 
v13 = *( tree_node **)( key + 40); 
if ( lang_hooks_0.tree_dump.dump_tree( &v198, ( tree)key) ) 
v13 = *( tree_node **)( key + 8); 
rtx v8; // rax 
v8 = split_insn( v3); 
if ( v8 ) 
if ( *( _WORD *)v8 == 35 ) 
v8 = ( rtx)v8[1]; 
while ( *( _WORD *)v8 == 35 ); 
v6 = v8; 
*( _OWORD *)&reg_alloc_order[v3] = xmm*(short *)0x6943C0; 
*( _OWORD *)&reg_alloc_order[v3] = xmm*(short *)0x6943C0; 
*( _OWORD *)&reg_alloc_order[v12 + 4] = xmm*(short *)0x6943D0; 
*( _OWORD *)&reg_alloc_order[v12 + 4] = xmm*(short *)0x6943D0; 
*( _OWORD *)&reg_alloc_order[v3] = xmm*(short *)0x6943E0; 
*( _OWORD *)&reg_alloc_order[v3] = xmm*(short *)0x6943E0; 
*( _OWORD *)&reg_alloc_order[v3 + 4] = xmm*(short *)0x6943F0; 
*( _OWORD *)&reg_alloc_order[v3 + 4] = xmm*(short *)0x6943F0; 
*( _OWORD *)&reg_alloc_order[v14] = xmm*(short *)0x694400; 
*( _OWORD *)&reg_alloc_order[v14] = xmm*(short *)0x694400; 
*( _OWORD *)&reg_alloc_order[v14 + 4] = xmm*(short *)0x694410; 
*( _OWORD *)&reg_alloc_order[v14 + 4] = xmm*(short *)0x694410; 
&& !push_operand( desta, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)desta)) ) 
v91 = recog_data_0.operand[v90 / 4]; 
v12 = recog_data_0.operand[v10]; 
induction_1 *v1; // [rsp+0h] [rbp-20h] 
induction_1 *v1; // [rsp+0h] [rbp-20h] 
induction_1 *v; // [rsp+8h] [rbp-18h] 
induction_1 *v; // [rsp+8h] [rbp-18h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( ( *( ( _WORD *)v + 50) >> 2) & 1) == 0 
&& ( !v->same || ( ( *( ( _WORD *)v->same + 50) >> 2) & 1) == 0) 
&& ( !v->same || ( ( *( ( _WORD *)v->same + 50) >> 2) & 1) == 0) 
&& v->giv_type == DEST_REG 
&& *( _DWORD *)reg_n_info->data.l[v->dest_reg->fld[0].rtuint] == v->insn->fld[0].rtint ) 
&& *( _DWORD *)reg_n_info->data.l[v->dest_reg->fld[0].rtuint] == v->insn->fld[0].rtint ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
if ( *( _DWORD *)( reg_n_info->data.l[v->dest_reg->fld[0].rtuint] + 4) == v1->insn->fld[0].rtint ) 
( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), 
( machine_mode)BYTE2( v4)); 
( machine_mode)*( unsigned __int8 *)( v13.rtwint + 2), 
( machine_mode)BYTE2( v6)); 
*( _OWORD *)x.r = *( _OWORD *)&expr->block.vars; 
rtx nonnote_insn; // rax 
rtx *v21; // rax 
v21 = ( rtx *)*( ( _QWORD *)v10 + 2); 
v22 = *( _WORD *)v21; 
if ( *( _WORD *)v21 == 51 || v22 == 59 ) 
set_label_offsets( v21[1], insn, initial_p); 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
v5 = simplify_binary_operation( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), *constptr, v4); 
v9 = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, op1[0]); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, v8); 
( rtx_code)( unsigned __int16)*( _DWORD *)reg_rtx, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg_rtx), 
( machine_mode)*( unsigned __int8 *)( v4->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)*loc + 2), 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v3 = reverse_condition_maybe_unordered( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op1); 
v3 = reverse_condition( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op1); 
rtx v229; // rax 
branch_prob_ignore_next_note = 1; 
rtx v58; // rbp 
rtx *fld; // r13 
rtx *v61; // rbp 
rtx v65; // r12 
rtx v71; // rbx 
if ( recog_data_0.n_operands <= 0 ) 
v2 = ( unsigned __int8)recog_data_0.n_operands + 1LL; 
v6 = *( ( _QWORD *)&changes_allocated + v2); 
v9 = **( ( _DWORD **)&changes_allocated + v2); 
fatal_insn( "unknown insn mode", insn, "i386.c", 9956, "ix86_attr_length_immediate_default"); 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
deps_0 *v14; // rax 
deps_0 *v14; // rax 
deps_0 *v19; // rax 
deps_0 *v19; // rax 
rtx headp; // [rsp+18h] [rbp-130h] BYREF 
deps_0 deps; // [rsp+A0h] [rbp-A8h] BYREF 
rtx tailp[7]; // [rsp+110h] [rbp-38h] BYREF 
v14 = ( deps_0 *)xmalloc( 104LL * ( int)current_nr_blocks); 
v14 = ( deps_0 *)xmalloc( 104LL * ( int)current_nr_blocks); 
bb_deps = v14; 
init_deps( v14); 
*( _OWORD *)&deps.in_post_call_group_p = *( _OWORD *)&bb_deps[v18].in_post_call_group_p; 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), label); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 32953, "fpu_unit_conflict_cost"); 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUM && mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( ix86_cpu != PROCESSOR_PENTIUMPRO || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUM && !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) ) 
|| mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && !which_alternative && mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( !size_int_type_wide_size_htab ) 
size_int_type_wide_size_htab = htab_create( 0x400uLL, size_htab_hash, size_htab_eq, 0LL); 
ggc_add_deletable_htab( size_int_type_wide_size_htab, 0LL, 0LL); 
size_int_type_wide_new_const = make_node( INTEGER_CST); 
ggc_add_tree_root( &size_int_type_wide_new_const, 1); 
v3 = size_int_type_wide_new_const; 
*( _OWORD *)&size_int_type_wide_new_const->block.vars = number; 
*( _OWORD *)&size_int_type_wide_new_const->block.vars = number; 
v5 = size_int_type_wide_new_const; 
*( ( _DWORD *)&size_int_type_wide_new_const->common + 4) = *( ( _DWORD *)&size_int_type_wide_new_const->common + 4) & 0xFFF3FFFF | ( ( v4 & 1) << 18) | ( ( v4 & 1) << 19); 
*( ( _DWORD *)&size_int_type_wide_new_const->common + 4) = *( ( _DWORD *)&size_int_type_wide_new_const->common + 4) & 0xFFF3FFFF | ( ( v4 & 1) << 18) | ( ( v4 & 1) << 19); 
slot = htab_find_slot( size_int_type_wide_size_htab, v5, INSERT); 
v7 = ( tree_node *)*slot; 
v7 = size_int_type_wide_new_const; 
*slot = size_int_type_wide_new_const; 
size_int_type_wide_new_const = make_node( INTEGER_CST); 
fatal_insn_not_found( insn, "insn-attrtab.c", 29, "insn_current_length"); 
if ( mode_class_0[BYTE2( v2)] == MODE_FLOAT 
|| *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x->fld[0].rtwint >> 14) & 0x3FC)) == MODE_FLOAT ) 
if ( *( const mode_class *)( ( char *)mode_class_0 + v3) == MODE_FLOAT ) 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v2 >> 14) & 0x3FC)) == MODE_FLOAT 
v3 = ( tree_node *)ggc_alloc( v2); 
fatal_insn_not_found( insn, "insn-attrtab.c", 4136, "k6_fpu_unit_ready_cost"); 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_K6 
|| !mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) || ix86_cpu != PROCESSOR_K6) 
&& ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) || ix86_cpu != PROCESSOR_K6) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_K6 
|| !mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_K6 
|| !mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_K6 
if ( which_alternative != 2 && mult_operator( recog_data_0.operand[3], SFmode) && ix86_cpu == PROCESSOR_K6 
if ( mult_operator( recog_data_0.operand[3], DFmode) && ix86_cpu == PROCESSOR_K6 
if ( which_alternative != 2 && mult_operator( recog_data_0.operand[3], DFmode) && ix86_cpu == PROCESSOR_K6 
if ( mult_operator( recog_data_0.operand[3], XFmode) && ix86_cpu == PROCESSOR_K6 
if ( mult_operator( recog_data_0.operand[3], TFmode) && ix86_cpu == PROCESSOR_K6 
p_int_cst = &arg0->int_cst.int_cst; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&arg0->block.subblocks; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&arg0->block.subblocks; 
v12 = build( code, type, p_int_cst->low, *p_elements); 
low = p_int_cst->low; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&arg0->block.subblocks; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&arg0->block.subblocks; 
if ( operand_equal_p( ( tree)p_int_cst->high, p_elements[1], 0) ) 
low = higher_prime_number_primes; 
high = &higher_prime_number_primes[30]; 
rtx *v11; // rax 
v11 = *( rtx **)&rtwint[2 * v10]; 
v12 = *( _DWORD *)v11; 
if ( ( unsigned __int16)*( _DWORD *)v11 != 49 ) 
mark_set_1( pbi, ( rtx_code)( unsigned __int16)v12, v11[1], v7, insn, pbi->flags); 
mark_set_1( pbi, ( rtx_code)( unsigned __int16)v12, v11[1], v7, insn, pbi->flags); 
v11 = *( rtx **)( v4->fld[0].rtwint + 8 * v10); 
v12 = *( _DWORD *)v11; 
if ( ( unsigned __int16)*( _DWORD *)v11 == 49 ) 
v7 = v11[1]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 18084, "get_attr_ppro_uops"); 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0 ) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
return memory_operand( recog_data_0.operand[0], VOIDmode) != 0; 
if ( which_alternative != 1 || !const0_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative != 1 || !const0_operand( recog_data_0.operand[2], DImode) ) 
rtx v38; // rax 
rtx v43; // r12 
rtx v44; // rax 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[1] = x1a; 
&& ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] == 54 
&& recog_data_0.operand[1]->fld[0].rtwint == -1 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1b; 
recog_data_0.operand[1] = x1b; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3i; 
recog_data_0.operand[2] = x3l; 
rtx *v45; // r14 
rtx v56; // rax 
rtx v65; // rax 
rtx *v77; // rbp 
rtx v105; // [rsp+70h] [rbp-C8h] BYREF 
rtx *v112; // [rsp+100h] [rbp-38h] 
v105 = op1; 
v26 = &v105; 
v28 = &v105; 
v30 = &v105; 
return sched_target_n_insns < target_n_insns_0; 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
fatal_insn_not_found( insn, "insn-attrtab.c", 10478, "pent_np_unit_ready_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
&& q_regs_operand( recog_data_0.operand[0], QImode) 
|| memory_operand( recog_data_0.operand[1], VOIDmode) 
|| !which_alternative && !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
|| memory_operand( recog_data_0.operand[1], VOIDmode) 
|| which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) 
else if ( !incdec_operand( recog_data_0.operand[2], DImode) 
if ( !incdec_operand( recog_data_0.operand[2], SImode) 
else if ( !incdec_operand( recog_data_0.operand[2], SImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) 
else if ( !incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], QImode) 
&& !incdec_operand( recog_data_0.operand[2], QImode) 
x_arg_pointer_save_area = assign_stack_local_1( ( machine_mode)v3, mode_size[v3], 0, f); 
v12 = gen_rtx( v10, ( machine_mode)v7, v5, v11); 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x2j; 
recog_data_0.operand[0] = x2k; 
if ( rtx_equal_p( x2l->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x2e; 
recog_data_0.operand[0] = x2f; 
if ( rtx_equal_p( x2g->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[0] = x2; 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[*( int *)q2p].n_refs)) 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[*( int *)q2p].n_refs)) 
v4 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[*( int *)q2p].n_refs)) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
v2 = ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
v11 = ( tree_node *)v10; 
sprintf( v27, off_6C5406, v37); 
v8 = operand_sub*(short *)0xforce( x, i, mode); 
timevars[14].name = ( const char *)&off_896C37; 
timevars[15].name = ( const char *)&unk_896C30; 
probability = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
head = new_loc_descr( ( dwarf_location_atom)( LODWORD( cfaa->reg) + 112), cfaa->base_offset, 0LL); 
head = new_loc_descr( ( dwarf_location_atom)( cfaa->reg + 80), 0LL, 0LL); 
induction_1 *i; // rbx 
induction_1 *i; // rbx 
if ( mode_class_0[bl_0->biv->mode] != MODE_INT ) 
for ( i = bl_0->biv; i; i = i->next_iv ) 
for ( i = bl_0->biv; i; i = i->next_iv ) 
for ( i = bl_0->biv; i; i = i->next_iv ) 
for ( i = bl_0->biv; i; i = i->next_iv ) 
v8 = *( ( _WORD *)i + 50); 
mult_val = i->mult_val; 
v6 = fold_rtx_mult_add( v6, mult_val, i->add_val, i->mode); 
v6 = fold_rtx_mult_add( v6, mult_val, i->add_val, i->mode); 
transp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
comp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
sbitmap_vector_ones( transp_0, n_basic_blocks); 
transp_0[i]->elms[0] &= ~1uLL; 
note_stores( *( ( rtx *)v6 + 4), reg_becomes_live_0, &v63); 
v26 = (  struct simple_bitmap_def *)comp_0; 
sbitmap_vector_zero( comp_0, n_basic_blocks); 
v29 = comp_0; 
sbitmap_not( v26, transp_0[v32-- - 2]); 
v33 = pre_edge_lcm( ( FILE *)v26, 1, transp_0, comp_0, antic, ( sbitmap *)v24, &insert_0, &delete); 
v33 = pre_edge_lcm( ( FILE *)v26, 1, transp_0, comp_0, antic, ( sbitmap *)v24, &insert_0, &delete); 
v33 = pre_edge_lcm( ( FILE *)v26, 1, transp_0, comp_0, antic, ( sbitmap *)v24, &insert_0, &delete); 
if ( ( insert_0[v35 - 2]->elms[0] & 1) != 0 ) 
v43 = transp_0[index]; 
if ( ( insert_0[v44 - 2]->elms[0] & 1) != 0 ) 
v50 = transp_0[v49]; 
free( transp_0); 
free( comp_0); 
free( insert_0); 
rtx *v32; // [rsp+18h] [rbp-50h] 
v15 = canon_hash( v7, ( machine_mode)v10); 
v32 = v6; 
v6 = v32; 
if ( mode_class_0[v21] != MODE_INT ) 
if ( mode_class_0[( unsigned int)v21] != MODE_INT ) 
v6 = v32; 
v6 = v32; 
rtx v19; // rbp 
rtx arg0; // [rsp+8h] [rbp-40h] BYREF 
rtx p; // [rsp+18h] [rbp-30h] BYREF 
p = x; 
add_double( *( _QWORD *)&x[1], x[1].fld[0].rtwint, v3, v3 >> 63, ( unsigned __int64 *)&arg0, &i1); 
return immed_double_const( ( __int64)arg0, i1, VOIDmode); 
v19 = force_const_mem( v16, v18); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), v19->fld[0].rtx) ) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), v19->fld[0].rtx) ) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), v19->fld[0].rtx) ) 
return v19; 
if ( !find_constant_term_loc( &p) ) 
v4 = *( tree_node **)( *high + 32LL); 
v6 = ( tree_node *)high[4]; 
predict_insn_def( v13, PRED_BUILTIN_EXPECT, ( prediction)v12); 
else if ( ( sch_istable[( unsigned __int8)c] & 0x400) != 0 ) 
( htab_eq)OT::IntType<unsigned int, 4u>::operator==, 
rtx pool_constant_mark; // rbp 
pool_constant_mark = get_pool_constant_mark( rtx, &pmarked); 
if ( ( unsigned __int16)*( _DWORD *)pool_constant_mark == 68 ) 
if ( ( *( _DWORD *)pool_constant_mark & 0x4000000) == 0 ) 
get_pool_constant_mark( pool_constant_mark, &pmarked); 
rtx = pool_constant_mark; 
pool_constant_mark = rtx; 
pool_constant_mark = rtx; 
v20->dw_loc_oprnd1.v.val_offset = ( unsigned __int64)pool_constant_mark; 
v21->data.l[elements_used] = ( __int64)pool_constant_mark; 
v23 = mem_loc_descriptor( rtx->fld[0].rtx, ( machine_mode)BYTE2( v3)); 
rtx last_value; // rax 
rtx v12; // r12 
rtx *v17; // rdi 
rtx *v21; // r8 
rtx *v23; // r9 
rtx loc; // [rsp+18h] [rbp-50h] BYREF 
rtx orig; // [rsp+20h] [rbp-48h] 
rtx v107; // [rsp+30h] [rbp-38h] 
loc = value; 
v7 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
orig = v3; 
last_value = get_last_value( reg); 
sprintf( v2, "*.%s%u", ( const char *)&off_684265, current_funcdef_number); 
if ( !v7 || ( v8 = ( tree_node *)*( ( _QWORD *)v7 + 1)) == 0LL ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 17669, "get_attr_mode"); 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
v12 = aligned_operand( recog_data_0.operand[1], HImode); 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
var = lang_hooks_0.tree_inlining.copy_res_decl_for_inlining( 
fprintf( file, &off_6474F4[1], _bittest64( ( const __int64 *)&v8, v7)); 
return &arg0; 
this_insn_0 = insna; 
&& recog_data_0.n_operands > 1 
&& *recog_data_0.constraints[0] == 61 
&& *( ( _BYTE *)recog_data_0.constraints[0] + 1) != 38 ) 
for ( i_0 = 1; i_0 < recog_data_0.n_operands; ++i_0 ) 
this_match = requires_inout( recog_data_0.constraints[i_0]); 
if ( this_match == recog_data_0.n_alternatives ) 
r0 = recog_data_0.operand[0]; 
for ( i_0a = 1; i_0a < recog_data_0.n_operands; ++i_0a ) 
|| i_0a == must_match_0 + 1 && *recog_data_0.constraints[i_0a - 1] == 37 
|| i_0a == must_match_0 - 1 && *recog_data_0.constraints[i_0a] == 37) 
&& ( n_matching_alts != recog_data_0.n_alternatives || requires_inout( recog_data_0.constraints[i_0a])) ) 
&& ( n_matching_alts != recog_data_0.n_alternatives || requires_inout( recog_data_0.constraints[i_0a])) ) 
r1 = recog_data_0.operand[i_0a]; 
if ( *recog_data_0.constraints[i_0a] == 112 ) 
if ( r1 == recog_data_0.operand[i_0a] ) 
*( _OWORD *)&buffer->state.cursor = 0LL; 
if ( recog_data_0.insn != insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
fatal_insn_not_found( insn, "recog.c", 2063, "extract_constrain_insn_cached"); 
rtx v13; // rbp 
rtx v15; // rbp 
rtx v17; // rbp 
rtx sched_before_next_call; // rbp 
rtx pending_read_insns; // rbp 
rtx pending_write_insns; // rbp 
rtx last_pending_memory_flush; // rbp 
rtx *listp; // [rsp+8h] [rbp-50h] 
rtx *p_pending_write_mems; // [rsp+10h] [rbp-48h] 
rtx *p_last_function_call; // [rsp+20h] [rbp-38h] 
listp = &deps->pending_read_mems; 
&& mode_class_0[mode] != MODE_INT 
&& mode_class_0[mode] != MODE_PARTIAL_INT ) 
if ( mode_class_0[i] == MODE_CC ) 
reg = gen_rtx_REG( ( machine_mode)i, 58); 
free_edge_list( edge_list_0); 
rtx v3; // r9 
rtx v4; // rcx 
v3 = head; 
if ( *( _WORD *)v3 != 37 ) 
v4 = v3; 
v4 = v3; 
v5 = (  struct rtx_def *)v3[1]; 
v6 = v3; 
v4 = v6[1].fld[0].rtx; 
if ( v4 == rtx ) 
v6 = v4; 
if ( *( _WORD *)v4 != 37 ) 
v5[1].fld[0].rtwint = ( __int64)v4; 
if ( v4 ) 
*( _QWORD *)&v4[1] = v5; 
if ( v4 != rtx ) 
v4 = rtx; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[4]); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v15 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
result = ( _cpp_buff_0 *)&v9[v8]; 
p_free_buffs = ( _cpp_buff_0 *)&pfile->free_buffs; 
result = gen_rtx_CONST_INT( ( machine_mode)code, ( __int64)v11); 
v22 = *( ( unsigned int *)uid_cuid_1 + v21); 
+ ( ( *( ( _DWORD *)uid_cuid_1 + v21) >> 3) & 0x1FFFFFF8)); 
|| ( int)v22 >= *( ( _DWORD *)uid_cuid_1 + rtint) ) 
v12 = *( ( unsigned int *)uid_cuid_1 + v11); 
v13 = *( unsigned __int64 *)( ( char *)reaching_defs[v10]->elms + ( ( *( ( _DWORD *)uid_cuid_1 + v11) >> 3) & 0x1FFFFFF8)); 
|| ( int)v12 >= *( ( _DWORD *)uid_cuid_1 + v9) ) 
rtx v16; // rbp 
rtx *v17; // rax 
rtx v20; // r12 
rtx v21; // r14 
rtx *v22; // rax 
rtx *v30; // rbx 
rtx v32; // [rsp+8h] [rbp-60h] 
rtx v33; // [rsp+10h] [rbp-58h] 
rtx v35; // [rsp+10h] [rbp-58h] 
rtx *listp; // [rsp+18h] [rbp-50h] 
listp = &pbi->mem_set_list; 
v32 = insn; 
rtx v7; // r14 
rtx real_insn; // r15 
rtx v9; // r12 
if ( reg_note ) 
v7 = reg_note; 
v7 = reg_note; 
if ( reg_note->fld[0].rtx != v5 ) 
real_insn = next_real_insn( v5); 
v9 = find_reg_note( v7->fld[0].rtx, REG_RETVAL, 0LL); 
v9 = find_reg_note( v7->fld[0].rtx, REG_RETVAL, 0LL); 
v7->fld[0].rtx, 
real_insn[3].fld[0].rtx); 
v28 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v27] - 5) < 2) + 1; 
timevar_push( TV_CLEANUP_CFG_0); 
timevar_pop( TV_CLEANUP_CFG_0); 
rtx v30; // rax 
v9 = *( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint); 
if ( data->path[v12].status != NOT_TAKEN_0 ) 
data->path[v12].status = NOT_TAKEN_0; 
v21 = *( ( _DWORD *)uid_cuid_0 + rtint); 
if ( data->path[v43].status != NOT_TAKEN_0 ) 
v30 = rtx; 
v30 = v30[1].fld[0].rtx; 
v30 = v30[1].fld[0].rtx; 
while ( v30 && v30 != ( rtx)i && *( _WORD *)v30 != 36 ); 
while ( v30 && v30 != ( rtx)i && *( _WORD *)v30 != 36 ); 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)op0 >> 14) & 0x3FC)) == MODE_FLOAT ) 
*( _OWORD *)rr.r = *( _OWORD *)&arg1a->block.vars; 
p = getpwd_pwd; 
if ( !getpwd_pwd ) 
v1 = getpwd_failure_errno; 
getpwd_failure_errno = e; 
getpwd_pwd = p; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] != MODE_COMPLEX_INT ) 
v19 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] == MODE_COMPLEX_FLOAT; 
if ( !grokdeclarator_already && !pedantic ) 
grokdeclarator_already = 1; 
rtx v15; // r14 
if ( mode_class_0[v14] == MODE_INT ) 
v15 = v13->int_cst.rtl; 
if ( v15 ) 
if ( integer_zerop( v15[6].fld[0].rttree) ) 
if ( !compare_tree_int( *( tree *)&v15[7], initial->string.length - 1LL) ) 
v3 = spelling_0; 
if ( spelling_base < spelling_0 ) 
v3 = spelling_0; 
rtx insn; // [rsp+80h] [rbp-30h] 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
if ( insn ) 
v5 = insn != ( rtx)bb->head[1]; 
uid = insn->fld[0].rtuint; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
*( _OWORD *)&result->block.vars = *( _OWORD *)d.r; 
*( _OWORD *)&result->block.vars = *( _OWORD *)d.r; 
v24 = type_for_mode( ( machine_mode)v19, ( v18 >> 13) & 1); 
v14 = build( ( tree_code)v9, v40, v41, v42, 0LL); 
v2 = convert_to_mode( ( machine_mode)v4, size, 1); 
v15 = gen_rtx_fmt_ee( MINUS, ( machine_mode)v12, v13, v14); 
v18 = gen_rtx_fmt_ee( MINUS, ( machine_mode)v12, v13, v17); 
v25 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v25); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v15 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
v24 = ( ( unsigned int)( mode_class_0[BYTE2( v22)] - 5) < 2) + 1; 
v15 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v32 = _mm_add_epi32( _mm_shuffle_epi32( v31, 80), ( __m128i)xmm*(short *)0x65AE30); 
if ( v13 >= ( unsigned int)( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1 ) 
reg_set_0 **v6; // rcx 
reg_set_0 **v6; // rcx 
reg_set_table = ( reg_set_0 **)xrealloc( reg_set_table, ( unsigned int)( 8 * ( regno + 100))); 
v6 = reg_set_table; 
v6[regno] = ( reg_set_0 *)object_base; 
v6[regno] = ( reg_set_0 *)object_base; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v29 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v25 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[vd->e[sr].mode] != MODE_COMPLEX_INT ) 
v21 = mode_class_0[vd->e[sr].mode] == MODE_COMPLEX_FLOAT; 
v10 = ( _BYTE *)( &off_695658 + 4); 
v10 = ( _BYTE *)( &off_695658 + 7); 
v10 = ( const char *)&off_695658; 
v10 = off_685EAB + 2; 
v10 = ( const char *)&unk_695662; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 31504, "pent_u_unit_conflict_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
|| ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
else if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
&& const_int_operand( recog_data_0.operand[2], VOIDmode) 
v3->eh->exc_ptr = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v75 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 0); 
v69 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 0); 
v71 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 1); 
return insn_data_0[code].name; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
constraints[i] = recog_data_0.constraints[i]; 
modes[i] = recog_data_0.operand_mode[i]; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[i] == 63 ) 
inner = recog_data_0.operand[i]->fld[0].rtx; 
recog_data_0.operand[i] = inner; 
if ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[i] == 66 ) 
record_address_regs( recog_data_0.operand[i]->fld[0].rtx, GENERAL_REGS, 2 * frequency); 
record_address_regs( recog_data_0.operand[i], GENERAL_REGS, 2 * frequency); 
for ( i = 0; i < recog_data_0.n_operands - 1; ++i ) 
for ( j = 0; j < recog_data_0.n_operands; ++j ) 
recog_data_0.n_alternatives, 
recog_data_0.n_operands, 
recog_data_0.operand, 
recog_data_0.n_alternatives, 
recog_data_0.n_operands, 
recog_data_0.operand, 
rtx nonnote_insn; // rax 
rtx v31; // rdi 
rtx v32; // rax 
rtx v35; // [rsp+10h] [rbp-38h] 
v35 = no_share; 
no_share = v35; 
rtx v25; // rbp 
rtx v30; // rax 
rtx *v33; // rax 
rtx v34; // rcx 
rtx *single_use; // rax 
rtx v40; // rax 
rtx v45; // rax 
rtx v46; // rbp 
rtx *result; // rax 
rtx v66; // rax 
rtx v61; // rax 
rtx v134; // rax 
rtx v149; // rax 
recog_data_0.operand[0] = v5.rtx; 
recog_data_0.operand[1] = ( rtx)v53; 
return gen_split_1133( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v8; 
return gen_split_1135( recog_data_0.operand); 
recog_data_0.operand[0] = v5.rtx; 
v3 = mode_class_0[v2]; 
set_diagnostic_context( &v3, msgid, ( va_list_0 *)va, ( const char *)input_filename, lineno, 1); 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[1] = x2d; 
recog_data_0.operand[1] = x3d; 
recog_data_0.operand[1] = x2e; 
recog_data_0.operand[1] = x3f; 
recog_data_0.operand[2] = x3g; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) 
&& rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
recog_data_0.operand[1] = x3f; 
recog_data_0.operand[2] = x3h; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) 
&& rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) 
v7 = mode_class_0[mode]; 
operand = insn_data_0[insn_code].operand; 
v20 = insn_data_0[v46].genfun( v18, v19); 
v25 = convert_modes( ( machine_mode)v23, v6, x, unsignedp); 
v26 = expand_complex_abs( ( machine_mode)v24, v25, 0LL, unsignedp); 
v34 = convert_modes( ( machine_mode)v22, v6, x, unsignedp); 
v26 = expand_complex_abs( ( machine_mode)v22, v34, 0LL, unsignedp); 
output = ( __int64 (  *)(  struct recog_data *, rtx))insn_data_0[code].output; 
output_format = insn_data_0[code].output_format; 
return ( const char *)insn_data_0[code].output; 
return ( const char *)output( &recog_data_0, insn); 
( tree_code)( ( ( *( ( _DWORD *)&exp->common + 4) & 0xFD) == 129) + 59), 
operand = insn_data_0[insn_code].operand; 
if ( operand->predicate( v8, ( machine_mode)v19) && operand[1].predicate( v8, ( machine_mode)v19) ) 
if ( operand->predicate( v8, ( machine_mode)v19) && operand[1].predicate( v8, ( machine_mode)v19) ) 
v30 = operand[2].predicate( v43, ( machine_mode)v19); 
v28 = insn_data_0[v27].operand; 
if ( v28->predicate( v8, ( machine_mode)v19) && v28[1].predicate( v8, ( machine_mode)v19) ) 
if ( v28->predicate( v8, ( machine_mode)v19) && v28[1].predicate( v8, ( machine_mode)v19) ) 
if ( !v28[2].predicate( v14, ( machine_mode)v19) ) 
force_reg( ( machine_mode)v19, v14); 
v38 = insn_data_0[v42].genfun( v34, v35); 
( machine_mode)*( ( unsigned __int8 *)v8 + 2), 
if ( general_operand( v8->fld[0].rtx, ( machine_mode)v19) ) 
v32 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v8->fld[0].rtx); 
v8 = force_reg( ( machine_mode)*( ( unsigned __int8 *)v36 + 2), v36); 
for ( result = &node->value; result->macro; result = ( cpp_hashnode::$14912F6ECDCFBB6AA3A39A6FF3987F98 *)result->macro ) 
for ( result = &node->value; result->macro; result = ( cpp_hashnode::$14912F6ECDCFBB6AA3A39A6FF3987F98 *)result->macro ) 
for ( result = &node->value; result->macro; result = ( cpp_hashnode::$14912F6ECDCFBB6AA3A39A6FF3987F98 *)result->macro ) 
for ( result = &node->value; result->macro; result = ( cpp_hashnode::$14912F6ECDCFBB6AA3A39A6FF3987F98 *)result->macro ) 
if ( LODWORD( result->macro->expansion) == candidate->count ) 
return (  struct answer **)result; 
rtx last_insn; // rax 
rtx j; // rdi 
rtx v28; // r8 
last_insn = get_last_insn( ); 
if ( !last_insn ) 
j = 0LL; 
v28 = 0LL; 
if ( *( _WORD *)last_insn != 32 ) 
if ( *( _WORD *)last_insn != 37 ) 
if ( last_insn[2].fld[0].rtint == -89 ) 
j = last_insn; 
j = last_insn; 
last_insn = ( rtx)last_insn[1]; 
rtx temp_1; // [rsp+B0h] [rbp-130h] 
rtx reg; // [rsp+D8h] [rbp-108h] 
rtx next; // [rsp+E0h] [rbp-100h] 
rtx n; // [rsp+E8h] [rbp-F8h] 
rtx body; // [rsp+F0h] [rbp-F0h] 
rtx fn_reg; // [rsp+100h] [rbp-E0h] 
rtx temp_0; // [rsp+110h] [rbp-D0h] 
rtx temp_0a; // [rsp+110h] [rbp-D0h] 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 22187, "athlon_muldiv_unit_conflict_cost"); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 26032, "k6_load_unit_conflict_cost"); 
casenum = memory_operand( recog_data_0.operand[1], VOIDmode) == 0; 
casenum = which_alternative || !memory_operand( recog_data_0.operand[1], VOIDmode); 
casenum = which_alternative != 1 || !memory_operand( recog_data_0.operand[1], VOIDmode); 
casenum = memory_operand( recog_data_0.operand[0], VOIDmode) == 0; 
casenum = constant_call_address_operand( recog_data_0.operand[0], VOIDmode) != 0; 
casenum = constant_call_address_operand( recog_data_0.operand[1], VOIDmode) != 0; 
v4 = gen_lowpart_for_combine( ( machine_mode)BYTE2( *( _DWORD *)desta), *( rtx *)&setter[1]); 
&& !push_operand( desta, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)desta)) ) 
reg_note = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, datum, insn[3].fld[0].rtx); 
v2 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
print_version( stderr, &arg0); 
v3 = ( tree_node *)*( &global_trees + 16); 
v3 = ( tree_node *)*( &global_trees + 15); 
overflow_arg_area = ( tree_code *)ap[0].overflow_arg_area; 
v1 = ( tree_code *)( ( char *)ap[0].reg_save_area + ( int)ap[0].gp_offset); 
v4 = &arg0; 
v5 = &arg0; 
v6 = &arg0; 
v7 = &arg0; 
p_int_cst = &exp->int_cst.int_cst; 
p_int_cst = &exp->int_cst.int_cst; 
pointer = p_int_cst; 
v48 = ( tree_node *)v42[4]; 
v43 = ( tree_node *)v42[4]; 
v27 = lang_hooks_0.expand_constant( exp); 
rtx v42; // r12 
rtx v46; // r15 
rtx j; // rbx 
rtx dest; // [rsp+10h] [rbp-70h] 
rtx *tmps; // [rsp+18h] [rbp-68h] 
rtx v60; // [rsp+20h] [rbp-60h] 
rtx dst; // [rsp+38h] [rbp-48h] 
rtx y; // [rsp+48h] [rbp-38h] 
dst = orig_dst; 
v10 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v9 + 2)); 
v5 = ( tree_node *)*( &global_trees + 38); 
v5 = ( tree_node *)*( &global_trees + 47); 
v4 = ( tree_node *)*( &global_trees + 37); 
v4 = ( tree_node *)*( &global_trees + 46); 
v6 = ( tree_node *)*( &global_trees + 34); 
*( _OWORD *)( v4 + 9) = 0LL; 
rtx v15; // rbx 
rtx v18; // rax 
rtx v19; // r8 
rtx v21; // r11 
rtx *v22; // rsi 
rtx v25; // rax 
rtx v41; // r12 
rtx v54; // rcx 
tmode = *( ( unsigned __int16 *)insn_data_0[icode].operand + 8); 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
|| !insn_data_0[icode].operand->predicate( target, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
|| !insn_data_0[icode].operand->predicate( target, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
if ( mode_class_0[mode0] == MODE_VECTOR_INT || mode_class_0[mode0] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode0] == MODE_VECTOR_INT || mode_class_0[mode0] == MODE_VECTOR_FLOAT ) 
if ( !insn_data_0[icode].operand[1].predicate( op0, mode0) ) 
if ( !insn_data_0[icode].operand[2].predicate( op0, mode0) ) 
pat = insn_data_0[icode].genfun( target, op0, op1); 
rtx v15; // rax 
rtx result; // rax 
rtx v32; // r12 
rtx v33; // r13 
rtx v38; // rax 
*( _OWORD *)&to->first = 0LL; 
*( _OWORD *)( object_base + 24) = v10; 
_mm_xor_si128( _mm_loadu_si128( ( const __m128i *)v15->bits), ( __m128i)xmm*(short *)0x6596D0), 
*( _OWORD *)object_base = v10; 
rtx *fld; // r15 
rtx v9; // rax 
rtx v10; // rax 
fld = loc; 
v9 = eliminate_regs( rtx, mem_mode, usage); 
rtx = v9; 
if ( v9 == *fld ) 
if ( v9 == *fld ) 
v10 = reg_equiv_constant[rtuint]; 
if ( !v10 ) 
v10 = reg_equiv_mem[rtuint]; 
if ( !v10 ) 
v10 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v11); 
v10 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v11); 
v10 = cfun->emit->x_regno_reg_rtx[rtuint]; 
if ( if_stack_0[v1].needs_warning ) 
if_stack_0[v1].file, 
if_stack_0[v1].line, 
v9 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v10] - 5) < 2) + 1; 
v7 = get_mode_alignment( ( machine_mode)v6) >> 3; 
v4 = gen_rtx_REG( ( machine_mode)v6, i); 
v5 = adjust_address_1( v1, ( machine_mode)v6, v2, 1, 1); 
v8 = adjust_address_1( v1, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 0LL, 1, 1); 
( machine_mode)( 5 - ( ( target_flags & 0x2000000) == 0)), 
if ( mode_class_0[v4] == MODE_INT && *( _WORD *)newval == 54 ) 
if ( rtwint != trunc_int_for_mode( rtwint, ( machine_mode)v4) ) 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
rtx v88; // rax 
rtx v99; // rax 
allocno_0[( __int64)allocno_vec[len]].hard_reg_conflicts |= hard_regs_live; 
ca = simplify_subreg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), c, cmode, 0); 
induction_1 *giv; // rax 
induction_1 *giv; // rax 
induction_1 *v4; // rcx 
induction_1 *v4; // rcx 
giv = bl_0->giv; 
if ( giv ) 
v4 = bl_0->giv; 
v3 = ( ( *( ( _WORD *)v4 + 50) & 4) == 0LL) + ( unsigned __int64)( unsigned int)v3; 
v4 = v4->next_iv; 
v4 = v4->next_iv; 
while ( v4 ); 
if ( ( *( ( _BYTE *)giv + 100) & 4) == 0 ) 
*( __int64 *)( ( char *)&v53 + 8 * v7 - ( ( 8 * v3 + 15) & 0xFFFFFFFFFFFFFFF0LL)) = ( __int64)giv; 
giv = giv->next_iv; 
giv = giv->next_iv; 
while ( giv ); 
v21 = express_from( ( induction_1 *)v17, *( induction_1 **)( v13 + 8 * v19)); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE30); 
v10 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v11 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
v17 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v16] - 5) < 2) + 1; 
v25 = _mm_shuffle_pd( ( __m128d)v18, ( __m128d)xmm*(short *)0x68FC00, 2); 
*( _OWORD *)&v3[v6].dw_fde_current_label = 0LL; 
args_size_0 = 0LL; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
++line_info_table_in_use; 
++separate_line_info_table_in_use; 
fprintf( asm_out_file, "\t%s %d\t%s", "#", debug_insn->fld[0].rtuint, insn_data_0[num].name); 
if ( insn_data_0[num].n_alternatives > 1 ) 
rtx v6; // r15 
rtx v9; // r14 
rtx v10; // rbp 
rtx nonnote_insn; // rax 
rtx v13; // r12 
rtx v14; // rax 
rtx v18; // rax 
rtx v27; // rax 
rtx scan_start; // rax 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->common.type->block.abstract_origin)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( v41 + 60)) >> 1), 
v57 = classify_argument( ( machine_mode)v54, v53.rttree, s, v55 - ( v56 & 0xFFFFFF00)); 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( v21 + 60)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( v30->fld[0].rtwint + 60)) >> 1), 
v87 = xmm*(short *)0x694440; 
user_label_prefix = &arg0; 
v1 = &arg0; 
v0 = &arg0; 
print_version( stderr, &arg0); 
print_switch_values( stderr, 0, 75, &arg0, " ", "\n"); 
rtx insn; // rdi 
rtx v39; // rbx 
rtx v50; // rax 
rtx v51; // rbx 
edge_info_0 = ( edge *)xmalloc( 8LL * edges->num_edges); 
edge_info_0[edge_index] = succ->succ_next; 
v11 = edge_info_0; 
v34 = edge_info_0; 
insn = uses->ref->insn; 
&& *( _WORD *)insn == 32 
if ( insn 
&& ( v19 = ( __int64)insn[2], *( _WORD *)v19 == 47) 
v20 = basic_block_for_insn->data.bb[insn->fld[0].rtint]; 
visit_phi_node( insn, v20); 
fancy_abort( &off_88ECD0[4], 6330, "emit_input_reload_insns"); 
if ( constraint_accepts_reg_p( insn_data_0[v5].operand->constraint, reloadreg) 
fancy_abort( &off_88ECD0[4], 6342, "emit_input_reload_insns"); 
fn = *( tree_node **)( *( _QWORD *)data + 8 * ( *( _QWORD *)( *( _QWORD *)data + 8LL) - 1LL) + 32); 
else if ( lang_hooks_0.tree_inlining.auto_var_in_fn_p( *tp, fn) ) 
new_decl = remap_decl( *tp, ( inline_data_0 *)data); 
if ( lang_hooks_0.tree_inlining.auto_var_in_fn_p( ( *tp)->vector.elements, fn) ) 
copy_scope_stmt( tp, walk_subtrees, ( inline_data_0 *)data); 
v10 = dwarf2out_cfi_label_label_num++; 
v3 = dwarf2out_cfi_label_label; 
sprintf( dwarf2out_cfi_label_label, "*.%s%u", "LCFI", v10); 
assemble_name( ( FILE *)asm_out_file, dwarf2out_cfi_label_label); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
*( _OWORD *)init_cost.cost = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[4] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[4] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[8] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[8] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[12] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[12] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[16] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[16] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[20] = xmm*(short *)0x71E920; 
*( _OWORD *)&init_cost.cost[20] = xmm*(short *)0x71E920; 
reg_pref_0 = 0LL; 
*( _OWORD *)result->bits = 0LL; 
if ( memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ref), rtwint) ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[2] = x3d; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[2] = x3c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1d; 
recog_data_0.operand[1] = x1d; 
recog_data_0.operand[0] = x1; 
for ( i = 0LL; i < 4 && ( expand_nl_goto_receiver_elim_regs[i].from != 16 || *(int *)0x896344[2 * i] != 6); ++i ) 
while ( *( _OWORD *)&edge_list->index_to_edge[v4]->src != __PAIR128__( ( unsigned __int64)succ, ( unsigned __int64)pred) ) 
base = ( cpp_token_0 **)buff->base; 
if ( !peep2_insn_data_0[v3].insn ) 
v6 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] - 5) < 2) + 1; 
rtx base_term; // rax 
|| ( base_term = find_base_term( v18)) == 0LL 
|| ( v28 = *( _DWORD *)base_term, ( _WORD)v28 != 67) && ( ( _WORD)v28 != 68 || ( v28 & 0x4000000) == 0) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)mem + 2)) ) 
v4 = next_qty_0++; 
qty_0[v4].first_reg = regno; 
qty_0[v4].size = size; 
qty_0[v4].mode = mode; 
qty_0[v4].birth = birth; 
qty_0[v4].n_calls_crossed = *( _DWORD *)( reg_n_info->data.l[regno] + 32); 
qty_0[v4].min_class = reg_preferred_class( regno); 
qty_0[qtyno].alternate_class = reg_alternate_class( regno); 
qty_0[qtyno].n_refs = *( _DWORD *)( reg_n_info->data.l[regno] + 16); 
qty_0[qtyno].freq = *( _DWORD *)( reg_n_info->data.l[regno] + 20); 
qty_0[qtyno].changes_mode = *( _BYTE *)( reg_n_info->data.l[regno] + 40); 
result = get_frame_alias_set_set; 
if ( get_frame_alias_set_set == -1 ) 
result = new_alias_set_last_alias_set + 1; 
new_alias_set_last_alias_set = result; 
get_frame_alias_set_set = result; 
get_frame_alias_set_set = 0LL; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 25175, "k6_store_unit_blockage"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative != 1 || const0_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative != 1 || const0_operand( recog_data_0.operand[2], SImode) ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dst->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dst)); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v20 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v16 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
operands[2] = gen_rtx_fmt_e( FLOAT, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)*operands), operands[2]); 
recog_data_0.operand[1] = x2d; 
recog_data_0.operand[1] = x2e; 
recog_data_0.operand[1] = x3e; 
recog_data_0.operand[2] = x3f; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) 
&& rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
recog_data_0.operand[1] = x3e; 
recog_data_0.operand[2] = x3g; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) 
&& rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = x3e; 
induction_1 *giv; // [rsp+30h] [rbp-30h] 
induction_1 *giv; // [rsp+30h] [rbp-30h] 
induction_1 *biv; // [rsp+38h] [rbp-28h] 
induction_1 *biv; // [rsp+38h] [rbp-28h] 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
if ( ( unsigned __int16)*( _DWORD *)pa == 36 || ( unsigned __int16)*( _DWORD *)pa == 33 || biv->insn == pa ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
if ( ( ( *( ( _WORD *)giv + 50) >> 6) & 1) == 0 ) 
if ( ( unsigned __int16)*( _DWORD *)pa != 36 || ( ( *( ( _WORD *)giv + 50) >> 3) & 1) != 0 ) 
if ( giv->mult_val != const_int_rtx[64] && ( *( ( _WORD *)giv + 50) & 1) == 0 ) 
if ( giv->mult_val != const_int_rtx[64] && ( *( ( _WORD *)giv + 50) & 1) == 0 ) 
if ( biv->insn == pa ) 
if ( biv->mult_val == const_int_rtx[65] ) 
i = ( tree_node *)*( &global_trees + 11); 
elements = ( tree_node *)*( &global_trees + 11); 
rtx v53; // rax 
rtx v57; // rax 
rtx v61; // rcx 
rtx v63; // rcx 
rtx v64; // rcx 
rtx v65; // rcx 
rtx v67; // rbp 
v9 = insn_data_0[insn_code].genfun( op1, op2); 
*( machine_mode *)( ( char *)&replacements[0].mode + 3 * v3) = mode; 
v8 = grokdeclarator( declarator, declspecs, ( decl_context)( 4 - ( width == 0LL)), 0); 
rtx *v21; // rax 
rtx *v24; // rbx 
rtx v26; // rcx 
rtx *single_use_1; // rax 
v24 = ( rtx *)&v22[2 * v23]; 
v26 = *v24; 
v26 = *v24; 
single_use_1 = loc; 
if ( *v24 != dest ) 
|| *( _WORD *)v26 != 61 
|| ( single_use_1 = loc, v26->fld[0].rtint != dest->fld[0].rtint) ) 
|| ( single_use_1 = loc, v26->fld[0].rtint != dest->fld[0].rtint) ) 
memset( context, 0, sizeof( diagnostic_context_0)); 
replace_args_0( pfile, node, ( macro_arg_0 *)buff->base); 
scan_rtx_address( v18, v19, INDEX_REGS, v17, ( machine_mode)mode); 
scan_rtx_address( v40, ( rtx *)&v44[2 * v45], a3, v39, ( machine_mode)mode); 
scan_rtx_address( v40, ( rtx *)( v46 + *( ( _QWORD *)v10 + v42)), a3, v39, ( machine_mode)mode); 
scan_rtx_address( v40, ( rtx *)&v10->fld[v48], a3, v39, ( machine_mode)mode); 
v1 = mode_class_0[mode]; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3l; 
recog_data_0.operand[2] = x3n; 
recog_data_0.operand[3] = x2t; 
if ( !rtx_equal_p( x2u->fld[0].rtx, recog_data_0.operand[1]) ) 
if ( !rtx_equal_p( *( rtx *)&x2u[1], recog_data_0.operand[2]) ) 
return gen_split_1003( recog_data_0.operand); 
recog_data_0.operand[1] = x3m; 
recog_data_0.operand[2] = x3o; 
recog_data_0.operand[3] = x2w; 
if ( !rtx_equal_p( x2x->fld[0].rtx, recog_data_0.operand[1]) ) 
if ( !rtx_equal_p( *( rtx *)&x2x[1], recog_data_0.operand[2]) ) 
return gen_split_1005( recog_data_0.operand); 
recog_data_0.operand[0] = x2; 
tmode = *( ( unsigned __int16 *)insn_data_0[icode].operand + 8); 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
|| !insn_data_0[icode].operand->predicate( target, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
|| !insn_data_0[icode].operand->predicate( target, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
v6 = insn_data_0[icode].genfun( target, op0a); 
if ( mode_class_0[mode0] == MODE_VECTOR_INT || mode_class_0[mode0] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode0] == MODE_VECTOR_INT || mode_class_0[mode0] == MODE_VECTOR_FLOAT ) 
if ( !insn_data_0[icode].operand[1].predicate( op0, mode0) ) 
v6 = insn_data_0[icode].genfun( target, op0); 
for ( endp = p; *endp && ( sch_istable[*( unsigned __int8 *)endp] & 4) != 0; ++endp ) 
v6 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[v3])] - 5) < 2) 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)BYTE2( v4), x, c); 
if ( v20 == ( tree_node *)global_trees ) 
rtx v3; // rax 
v3 = reg_known_value[rtuint]; 
if ( v3 ) 
rtx = v3; 
rtx v17; // rdi 
rtx v24; // rdi 
rtx reg; // rdi 
rtx const_value; // rdx 
rtx v47; // rcx 
rtx v56; // rdx 
rtx v57; // rcx 
rtx v68; // rcx 
rtx v69; // r8 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 30374, "pent_uv_unit_blockage"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( incdec_operand( recog_data_0.operand[2], DImode) 
if ( incdec_operand( recog_data_0.operand[2], DImode) 
if ( incdec_operand( recog_data_0.operand[2], SImode) 
if ( incdec_operand( recog_data_0.operand[2], SImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], QImode) 
|| incdec_operand( recog_data_0.operand[2], QImode) 
if ( incdec_operand( recog_data_0.operand[2], QImode) 
if ( incdec_operand( recog_data_0.operand[2], QImode) 
|| ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
v5 = ( tree_node *)*( ( _QWORD *)v4 + 1); 
v8 = ( const char *)&unk_736FFA; 
v8 = ( const char *)&unk_73700E; 
v8 = ( const char *)&unk_737024; 
v8 = ( const char *)&unk_737036; 
v8 = ( const char *)&unk_7370A7; 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
v6 = truth_value_p( ( tree_code)( unsigned __int8)*( ( _DWORD *)&t->common + 4)) != 0; 
rtx v4; // rbx 
v4 = rtx; 
if ( active_insn_p( v4) && ( **( _DWORD **)&v4[2] & 0xFFFE) != 44 ) 
if ( active_insn_p( v4) && ( **( _DWORD **)&v4[2] & 0xFFFE) != 44 ) 
insn_scopes->data.l[v4->fld[0].rtint] = v3; 
else if ( *( _WORD *)v4 == 37 ) 
rtint = v4[2].fld[0].rtint; 
v3 = ( __int64)v4[2]; 
delete_insn( v4); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v1 = stack_0; 
if ( &timevars[timevar] != stack_0->timevar ) 
stack_0 = stack_0->next; 
stack_0 = stack_0->next; 
rtx v47; // rax 
rtx v48; // rax 
rtx v49; // rax 
rtx v50; // rax 
rtx v53; // rax 
rtx v54; // rax 
rtx v55; // rax 
rtx *v57; // rax 
rtx v59; // rax 
rtx v60; // rax 
rtx v40; // rdx 
rtx k; // rbx 
rtx m; // rbx 
rtx v50; // rax 
rtx v62; // r13 
if ( v2 != ( tree_node *)global_trees ) 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
pp = ( page_entry_0 **)*pp; 
gp = ( page_group_0 **)*gp; 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), label); 
v5 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), arguments); 
v16 = get_mode_alignment( ( machine_mode)v15) >> 3; 
v13 = gen_rtx_REG( ( machine_mode)v15, v7); 
v14 = adjust_address_1( v11, ( machine_mode)v15, v12, 1, 1); 
v19 = gen_reg_rtx( ( machine_mode)v17); 
v20 = adjust_address_1( v11, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v18, 1, 1); 
hash = hash_expr( pat, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)pat), &do_not_record_p, expr_hash_table_size); 
rtx v15; // rbx 
rtx *v41; // rdx 
rtx v44; // r15 
rtx v55; // r12 
rtx v56; // rcx 
rtx v61; // r15 
rtx v62; // rbp 
rtx v64; // rcx 
rtx v66; // rbx 
v6 = rndprc; 
wstring[0] = 0; 
strcpy( wstring, " NaN "); 
rndprc = 80; 
strcpy( wstring, " -Infinity "); 
strcpy( wstring, " Infinity "); 
strcpy( wstring, "NaN"); 
v28 = etens[8]; 
*( _WORD *)v36 = bmask[v34] & v37; 
induction_1 *v; // [rsp+30h] [rbp-50h] 
induction_1 *v; // [rsp+30h] [rbp-50h] 
( machine_mode)( unsigned __int8)BYTE2( **( _DWORD **)&set[1]), 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
record_biv( loopa, v, pa, dest_reg, inc_val, mult_val, location, not_every_iterationa, maybe_multiplea); 
_OWORD *v15; // rax 
_OWORD *v15; // rax 
v15 = ggc_alloc( 0x28uLL); 
*slot = v15; 
*( ( _QWORD *)v15 + 4) = v19; 
v15[1] = v18; 
*v15 = v16; 
value = ( tree_node *)*( &global_trees + 12); 
*( _OWORD *)&cfun->x_temp_slots = 0LL; 
rtx v10; // rbp 
v10 = b; 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v10 + 2), v12, v14); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v10 + 2), v12, v14); 
rtx inner; // [rsp+10h] [rbp-20h] 
inner = op->fld[0].rtx; 
if ( !general_operand( inner->fld[0].rtx, v2) ) 
if ( ( unsigned __int16)*( _DWORD *)inner->fld[0].rtwint == 75 ) 
if ( ( unsigned __int16)**( _DWORD **)( inner->fld[0].rtwint + 16) == 54 ) 
if ( *( _QWORD *)( *( _QWORD *)( inner->fld[0].rtwint + 16) + 8LL) == -offset ) 
v8 = general_operand( *( rtx *)( inner->fld[0].rtwint + 8), v3) != 0; 
v2 = ( tree_node *)*( &global_trees + 11); 
if ( mode_class_0[( unsigned __int8)BYTE2( **( _DWORD **)chains->loc)] != MODE_COMPLEX_INT ) 
v9 = mode_class_0[( unsigned __int8)BYTE2( **( _DWORD **)chains->loc)] == MODE_COMPLEX_FLOAT; 
*chain->loc = gen_raw_REG( ( machine_mode)( unsigned __int8)BYTE2( **( _DWORD **)chain->loc), reg); 
result = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), result); 
rtx loc[4]; // [rsp+8h] [rbp-20h] BYREF 
loc[0] = rtx; 
loc[0] = copy_rtx( rtx); 
instantiate_virtual_regs_1( loc, 0LL, 0); 
if ( !memory_address_p( v5, loc[0]) ) 
if ( !memory_address_p( v7, loc[0]) ) 
instantiate_virtual_regs_1( loc, 0LL, 0); 
x->fld[0].rtx = loc[0]; 
if ( memory_address_p( ( machine_mode)BYTE2( v5), rtwint) ) 
dw2_asm_output_data( 1, 0LL, aEndOfChildrenO, diea->die_offset); 
rtx v37; // rbp 
rtx v44; // rax 
rtx v56; // rbx 
rtx j; // rbx 
rtx *v93; // rax 
rtx v95; // rbp 
rtx v115; // rax 
v32 = rtuint + ( ( unsigned int)( mode_class_0[v6] - 5) < 2); 
rtx v3; // r9 
rtx v5; // r11 
rtx v6; // rdx 
rtx v8; // rcx 
rtx v10; // rax 
v3 = 0LL; 
v5 = head; 
if ( *( _WORD *)v5 != 37 ) 
v6 = v5; 
v6 = v5; 
v7 = ( __int64)v5[1]; 
v8 = v5; 
v8 = v5; 
v6 = v8[1].fld[0].rtx; 
if ( mode_class_0[rld[r].mode] != MODE_COMPLEX_INT ) 
v12 = mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT; 
operand = insn_data_0[*( int *)( ( char *)&optab_table[0]->handlers[0].insn_code + v2)].operand; 
if ( !operand->predicate( x, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
|| !operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
|| !operand[2].predicate( y, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v3].genfun( x, x); 
hash_lookup( *( hash_table_0 **)data, ( *r)->fld[0].rtx, 1, 0LL); 
ifme = (  struct insns_for_mem_entry *)hash_lookup( *( hash_table_0 **)data, *r, 0, 0LL); 
*( _OWORD *)x.r = *( _OWORD *)&expr->block.vars; 
v9 = get_mode_alignment( ( machine_mode)v8) >> 3; 
v5 = gen_rtx_REG( ( machine_mode)v8, v2); 
v6 = adjust_address_1( v1, ( machine_mode)v8, v4, 1, 1); 
&& mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_INT 
&& mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x->fld[0].rtwint)] == MODE_INT 
targeta = gen_reg_rtx( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( expa->common.type->block.abstract_origin)) >> 1)); 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)targetb), 
v6 = ( tree_node *)v5; 
if ( *( ( _BYTE *)&type->block.common + 16) == 18 && !type->int_cst.rtl && v6 != ( tree_node *)global_trees ) 
v8 = *( tree_node **)( v7->int_cst.int_cst.low + 32); 
v3 = reverse_condition_maybe_unordered( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op1); 
v3 = reverse_condition( ( rtx_code)( unsigned __int16)*( _DWORD *)new_op1); 
decode_asm_operands( pat, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
decode_asm_operands( pat, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg)); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v11 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
rtx insna; // [rsp+8h] [rbp-38h] 
if ( ( debug_info_level_0 & 0xFFFFFFFE) == 2 
if ( ( debug_info_level_0 & 0xFFFFFFFE) == 2 
fprintf( file, off_694CF3, ( unsigned int)( rtint - 29)); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v21 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] != MODE_COMPLEX_INT ) 
v25 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] == MODE_COMPLEX_FLOAT; 
if ( !insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
if ( !insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
|| !insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
|| !insn_data_0[icode].operand[2].predicate( 
return insn_data_0[icode].genfun( x, x, y); 
peep2_insn_data_0[0].live_before = bitmap_initialize( &head); 
peep2_insn_data_0[1].live_before = bitmap_initialize( &v64); 
peep2_insn_data_0[2].live_before = bitmap_initialize( &v65); 
peep2_insn_data_0[3].live_before = bitmap_initialize( &v66); 
peep2_insn_data_0[4].live_before = bitmap_initialize( &v67); 
peep2_insn_data_0[0].insn = 0LL; 
peep2_insn_data_0[1].insn = 0LL; 
peep2_insn_data_0[2].insn = 0LL; 
peep2_insn_data_0[3].insn = 0LL; 
peep2_insn_data_0[4].insn = global_rtl[0]; 
bitmap_copy( peep2_insn_data_0[4].live_before, v1); 
peep2_insn_data_0[v7].insn = ( rtx)end; 
bitmap_copy( peep2_insn_data_0[peep2_current].live_before, v1); 
insn = peep2_insn_data_0[v16].insn; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v45.rtwint), 
if ( *( _WORD *)peep2_insn_data_0[v49].insn == 34 ) 
v5 = append_random_chars_value; 
if ( !append_random_chars_value ) 
append_random_chars_value = v5; 
v1[v6] = append_random_chars_letters[v5 % 0x3E]; 
v1[v6 + 1] = append_random_chars_letters[v5 / 0x3E 
v1[v6 + 2] = append_random_chars_letters[v5 / 0xF04 
v1[v6 + 3] = append_random_chars_letters[v5 / 0x3A2F8 
v1[v6 + 4] = append_random_chars_letters[v5 / 0xE17810 
v1[v6 + 5] = append_random_chars_letters[v5 / 0x369B13E0 
if ( v9 != 46 && ( sch_istable[v9] & 0x8C) == 0 ) 
v13 = *( tree_node **)( v11 + 8); 
elements = ( tree_node *)v11; 
imag = ( tree_node *)*( &global_trees + 11); 
bi = ( block_info_0)block->aux; 
bi_0 = ( block_info_0)e->dest->aux; 
if ( *( _OWORD *)&args1 != 0LL ) 
v0 = initializer_stack_0; 
v1 = constructor_stack_0; 
if ( !constructor_stack_0 ) 
constructor_stack_0 = constructor_stack_0->next; 
constructor_stack_0 = constructor_stack_0->next; 
if ( constructor_range_stack_0 ) 
constructor_stack_0 = v0->constructor_stack; 
constructor_range_stack_0 = v0->constructor_range_stack; 
spelling_0 = v0->spelling; 
initializer_stack_0 = v0->next; 
if ( *( _OWORD *)arg1 != 0LL ) 
+ ( unsigned __int16)reverse_condition_maybe_unordered( ( rtx_code)*( unsigned __int16 *)arg1[0]) 
node = ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, str, len, HT_NO_INSERT); 
rtx *v14; // rbx 
rtx *v20; // rax 
v14 = ( rtx *)&v5[1]; 
if ( v14 != loc ) 
v5 = *v14; 
( machine_mode)( unsigned __int8)BYTE2( *rtwint), 
( machine_mode)BYTE2( v6)); 
result = ( ( unsigned int)( mode_class_0[v32] - 5) < 2) + 1; 
v20 = ( rtx *)&v5->fld[v17]; 
if ( v20 != loc ) 
v21 = refers_to_regno_p( regno, endregno, *v20, loc); 
result = ( ( unsigned int)( mode_class_0[( unsigned __int8)v28] - 5) < 2) + 1; 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], 0LL); 
v3 = ( tree_node *)v4; 
v2 = *( _OWORD *)&loc_p->reg; 
*( _OWORD *)&cfa.base_offset = *( _OWORD *)&loc_p->base_offset; 
*( _OWORD *)&cfa.base_offset = *( _OWORD *)&loc_p->base_offset; 
*( _OWORD *)&cfa.reg = v2; 
*( ( _OWORD *)v12 + 1) = 0LL; 
if ( !peep2_insn_data_0[v3].insn ) 
induction_1 *v; // [rsp+40h] [rbp-20h] 
induction_1 *v; // [rsp+40h] [rbp-20h] 
induction_1 *va; // [rsp+40h] [rbp-20h] 
induction_1 *va; // [rsp+40h] [rbp-20h] 
v = bl_0->biv; 
while ( v ) 
fprintf( file, " Inc%d: insn %d, incr: ", i, v->insn->fld[0].rtuint); 
print_simple_rtl( file, v->add_val); 
v = v->next_iv; 
v = v->next_iv; 
va = bl_0->giv; 
while ( va ) 
fprintf( file, " Giv%d: insn %d, benefit %d, ", ia, va->insn->fld[0].rtuint, ( unsigned int)va->benefit); 
fprintf( file, " Giv%d: insn %d, benefit %d, ", ia, va->insn->fld[0].rtuint, ( unsigned int)va->benefit); 
if ( va->giv_type ) 
if ( rtx_class[( unsigned __int16)*( _DWORD *)va->insn] == 105 ) 
if ( ( unsigned __int16)**( _DWORD **)&va->insn[2] == 47 ) 
v4 = ( rtx)va->insn[2]; 
v4 = single_set_2( va->insn, *( rtx *)&va->insn[2]); 
v22 = ( tree_node *)*( &global_trees + 12); 
v22 = ( tree_node *)*( &global_trees + 11); 
fatal_insn_not_found( insn, "insn-attrtab.c", 9021, "fpu_unit_ready_cost"); 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( insn) == MEMORY_STORE) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && mult_operator( recog_data_0.operand[3], SFmode) ) 
v10 = ( tree_node *)*( &global_trees + 11); 
tree initial; // rcx 
tree v35; // rdx 
rtx v25; // rax 
rtx v26; // rax 
rtx v32; // rax 
rtx v42; // rax 
rtx v43; // rcx 
rtx *v44; // r14 
n_ops = recog_data_0.n_operands; 
if ( matches >= 0 || recog_op_alt[i][alt].matched >= 0 || predicated && recog_data_0.operand_type[i] == OP_OUT ) 
recog_data_0.operand_type[i] = OP_INOUT; 
kill_value( recog_data_0.operand[ia], vd); 
kill_value( recog_data_0.operand[ib], vd); 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)src)] != MODE_COMPLEX_INT ) 
v20 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)src)] == MODE_COMPLEX_FLOAT; 
if ( mode_class_0[vd->e[regno].mode] != MODE_COMPLEX_INT ) 
v16 = mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_FLOAT; 
newa = find_oldest_value_reg( ( reg_class)regclass_map[regno], src, vd); 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[ic] != 61 
|| recog_data_0.operand[ic]->fld[0].rtint != recog_data_0.operand[ic][1]) ) 
|| recog_data_0.operand[ic]->fld[0].rtint != recog_data_0.operand[ic][1]) ) 
fancy_abort( &off_723588[4], 4739, "reloads_conflict"); 
fprintf( outfile, "%*s", print_indent, &arg0); 
timevar_start( TV_TOTAL_0); 
timevar_stop( TV_TOTAL_0); 
if ( !genrtl_case_label_explained ) 
genrtl_case_label_explained = 1; 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v16 = expand_simple_binop( v33, ( rtx_code)( 76 - ( v8 == 1)), v15, v14, if_info->x, 0, OPTAB_WIDEN); 
temp = force_reg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[1]), operands[1]); 
if ( ( tree_node *)global_trees != attributes ) 
rtx v33; // rsi 
rtx v34; // rax 
rtx v39; // rsi 
rtx v40; // rax 
rtx v42; // rax 
rtx paddressp[32]; // [rsp+30h] [rbp-1A8h] BYREF 
v4 = ( int *)paddressp; 
if ( !LODWORD( paddressp[0]) ) 
insn_data_0[debug_insn[2].fld[0].rtint].name); 
if ( insn_data_0[rtint].n_alternatives >= 2 ) 
v26 = sch_istable[( unsigned __int8)v10]; 
*( _OWORD *)&loops->cfg.dfs_order = 0LL; 
*( _OWORD *)&loops->tree_root = 0LL; 
*( _OWORD *)&loops->num = 0LL; 
*( _OWORD *)&v58->outer = 0LL; 
v9 = ix86_register_move_cost( m1, ( reg_class)v5, class2); 
v4 = ix86_register_move_cost( m1, ( reg_class)v5, class2); 
*( _OWORD *)&deps->pending_read_insns = 0LL; 
*( _OWORD *)&deps->pending_write_insns = 0LL; 
*( _OWORD *)&deps->pending_lists_length = 0LL; 
*( _OWORD *)&deps->last_function_call = 0LL; 
if ( ( predictor_info_0[best_predictor].flags & 1) != 0 ) 
dump_prediction( ( br_predictor)predictor_0, *( _QWORD *)( *( _QWORD *)( ( *pnote)->fld[0].rtwint + 16) + 8LL), bb, v5); 
ret_val = &arg0; 
data_type = &arg0; 
rtx v10; // rax 
rtx v11; // rbx 
rtx v16; // rbx 
rtx constptr; // [rsp+10h] [rbp-38h] BYREF 
v11 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v8)); 
v11 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v8)); 
v8 = force_operand( v8, v11); 
if ( v8 != v11 ) 
emit_move_insn( v11, v8); 
constptr = const_int_rtx[64]; 
v14 = eliminate_constant_term( v8, &constptr); 
rtx v10; // rax 
v10 = find_base_term( v5); 
if ( !v10 ) 
v12 = *( _DWORD *)v10; 
if ( ( unsigned __int16)( *( _DWORD *)v10 - 67) < 2u ) 
return v10; 
base_term = v10; 
v10 = find_base_term( ( rtx)v8[1]); 
if ( v10 ) 
return v10; 
rtx v25; // rax 
rtx v26; // r14 
rtx v31; // rax 
rtx x_nonlocal_goto_handler_slots; // rbx 
rtx v37; // rax 
rtx v41; // rax 
rtx return_rtx; // rbx 
rtx v50; // rcx 
n_operands = recog_data_0.n_operands; 
v2 = ( __int64)*( &changes + n_operands--); 
v4 = constructor_stack_0; 
if ( constructor_stack_0->replacement_value ) 
v4 = constructor_stack_0; 
if ( constructor_stack_0->replacement_value ) 
if ( constructor_stack_0->implicit ) 
if ( !constructor_stack_0->implicit ) 
return ++new_alias_set_last_alias_set; 
ind_ptr = ( induction_0 *)*( ( _QWORD *)&induction_chain->name + induction_chain->elements_used); 
rtx insns; // rax 
rtx rtwint; // rbx 
v20 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 2); 
diddle_return_value( mark_reg_0, global_live_at_start); 
*( _OWORD *)&regs_ever_live[32] = 0LL; 
*( _OWORD *)&regs_ever_live[16] = 0LL; 
*( _OWORD *)regs_ever_live = 0LL; 
insns = get_insns( ); 
if ( insns ) 
rtwint = insns; 
rtwint = insns; 
v18.rtwint = ( __int64)rtwint[1].fld[0]; 
if ( ( unsigned __int16)*( _DWORD *)rtwint == 36 
mtherr( aE, 7); 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v5; 
return gen_split_1179( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v5; 
return gen_split_1178( recog_data_0.operand); 
rtx v10; // r15 
rtx last_insn; // r15 
rtx v24; // rbx 
rtx v29; // rbp 
v10 = insns; 
v11 = v10; 
v11 = v10; 
v10 = v11; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 34651, "pent_np_unit_blockage"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !q_regs_operand( recog_data_0.operand[0], QImode) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
else if ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE ) 
&& ( immediate_operand( recog_data_0.operand[1], VOIDmode) || get_attr_memory( executing_insn) == MEMORY_STORE) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) 
else if ( !incdec_operand( recog_data_0.operand[2], DImode) 
target = expand_simple_unop( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_infoa->x), ABS, b, if_infoa->x, 0); 
target = expand_simple_unop( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target), NEG, target, if_infoa->x, 0); 
fatal_insn_not_found( insn, "insn-attrtab.c", 2135, "athlon_load_unit_ready_cost"); 
rtx v9; // r13 
rtx v10; // r14 
rtx *v18; // r14 
rtx *v19; // rbp 
v3 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x >> 14) & 0x3FC)); 
v9 = expand_compound_operation( rtx); 
v10 = expand_compound_operation( v8); 
v11 = *( _WORD *)v9; 
if ( ( _DWORD)v11 != *( _WORD *)v10 ) 
if ( ( ( *( _DWORD *)v9->fld[0].rtwint ^ *( _DWORD *)v10->fld[0].rtwint) & 0xFF0000) != 0 ) 
if ( ( ( *( _DWORD *)v9->fld[0].rtwint ^ *( _DWORD *)v10->fld[0].rtwint) & 0xFF0000) != 0 ) 
if ( v9[1] != v10[1] ) 
if ( v9[1] != v10[1] ) 
rtx end; // rsi 
end = dest->end; 
end = dest->end; 
if ( *( _WORD *)end != 33 ) 
rtx = end; 
end = ( rtx)end[1]; 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
end = 0LL; 
end = ( rtx)rtx[1]; 
nonnote_insn = emit_insns_after( insns, end); 
v9 = ( tree_node *)high[3]; 
return lang_hooks_0.staticp( arg); 
if ( !initial || !strcmp( lang_hooks_0.name, "GNU C++") && initial == ( tree)global_trees ) 
emit_pop_insn( rtx, old, *( rtx *)&may_move_out_cost[57][15][118 * v11 + 4], EMIT_BEFORE); 
emit_swap_insn( rtx, old, *( rtx *)&may_move_out_cost[57][15][118 * old->reg[( int)v12] + 4]); 
emit_swap_insn( rtx, old, *( rtx *)&may_move_out_cost[57][15][118 * v15 + 4]); 
rtx v12; // r9 
rtx v18; // rdx 
rtx v21; // rbp 
rtx v28; // rax 
rtx v29; // r12 
rtx v25; // rax 
rtx v27; // rax 
induction_1 *v32; // rcx 
induction_1 *v32; // rcx 
rtx src_rega; // [rsp+0h] [rbp-40h] BYREF 
induction_1 *v; // [rsp+8h] [rbp-38h] 
induction_1 *v; // [rsp+8h] [rbp-38h] 
src_rega = src_reg; 
*( &src_rega - 20) = src_reg; 
*( &src_rega - 14) = *mult_val; 
*( &src_rega - 13) = *add_val; 
*( ( _DWORD *)&src_rega - 24) = first_benefit; 
*( ( _WORD *)&src_rega - 38) = 0; 
*( ( _OWORD *)&src_rega - 4) = 0LL; 
*( ( _OWORD *)&src_rega - 4) = 0LL; 
token = ( cpp_token_0 *)lhs; 
rtx *v33; // rax 
rtx v37; // rbp 
rtx *v40; // rsi 
v6 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
*( _OWORD *)&v4[v5].const_rtx = 0LL; 
reg_eqv_table[reg] = ( reg_eqv_elem)-1LL; 
rtx v9; // rbp 
rtx v13; // rdi 
rtx v19; // rbx 
rtx v20; // rax 
rtx v23; // rax 
rtx v25; // rbx 
rtx result; // rax 
else if ( general_operand( b, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)b)) ) 
if ( !general_operand( a, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)a)) ) 
v2 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)a)); 
a = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)a)); 
if ( general_operand( b, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)b)) ) 
v4 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)b)); 
b = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)b)); 
tmpd = gen_rtx_MEM( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_info->x), target); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
if ( !recog_data_0.n_alternatives || !recog_data_0.n_operands ) 
if ( !recog_data_0.n_alternatives || !recog_data_0.n_operands ) 
fatal_insn_not_found( insn, &off_723588[4], 8371, "reload_cse_simplify_operands"); 
v2 = 4LL * recog_data_0.n_alternatives; 
n_operands = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
v7 = recog_data_0.operand[v5]; 
v11 = cselib_lookup( v7, recog_data_0.operand_mode[v5], 0); 
v10 = recog_data_0.operand_mode[v5]; 
n_operands = recog_data_0.n_operands; 
if ( v5 >= recog_data_0.n_operands ) 
if ( recog_data_0.n_operands > 0 ) 
n_alternatives = recog_data_0.n_alternatives; 
v19 = ( int *)( ( char *)equiv_regs - ( ( 4LL * recog_data_0.n_alternatives + 15) & 0xFFFFFFFFFFFFFFF0LL)); 
v20 = recog_data_0.constraints[v15]; 
if ( ( sch_istable[string->text[i]] & 0x204) == 0 && ( string->text[i] != 36 || !pfile->opts.dollars_in_ident) ) 
rtx insn; // [rsp+30h] [rbp-70h] 
rtx old_stack_level; // [rsp+48h] [rbp-58h] BYREF 
rtx before_call; // [rsp+58h] [rbp-48h] 
rtx temp; // [rsp+60h] [rbp-40h] 
rtx structure_value_addra; // [rsp+68h] [rbp-38h] 
rtx targeta; // [rsp+80h] [rbp-20h] 
targeta = target; 
structure_value_addra = structure_value_addr; 
old_stack_level = 0LL; 
before_call = get_last_insn( ); 
timevar_push( TV_INTEGRATION_0); 
temp = expand_inline_function( fndecl, actparms, targeta, ignorea, typea, structure_value_addra); 
temp = expand_inline_function( fndecl, actparms, targeta, ignorea, typea, structure_value_addra); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 33397, "pent_mul_unit_conflict_cost"); 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
free( uid_cuid_1); 
*( _OWORD *)sequence_result = 0LL; 
*( _OWORD *)&sequence_result[2] = 0LL; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2ba; 
&& ( unsigned __int16)recog_data_0.operand[2]->fld[0].rtwint != 0x8000LL ) 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bb; 
|| !rtx_equal_p( x2bc->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bc[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, HImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2c->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2c[1], recog_data_0.operand[2]) 
rtx v19; // r13 
rtx v21; // rbp 
rtx next; // [rsp+0h] [rbp-38h] 
next = 0LL; 
v19 = canon_rtx( rtx); 
if ( ( *( _DWORD *)v19 & 0x4000000) == 0 ) 
v20.rtwint = ( __int64)v19->fld[0]; 
&& ( *( _DWORD *)v19 & 0xFF0000) != 3342336 ) 
if ( next ) 
v21 = next; 
v21 = next; 
v22.rtwint = ( __int64)next->fld[0]; 
v17 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), lab2); 
*( _OWORD *)&df_0->insns[v4].defs = 0LL; 
|| mode_class_0[mode] != MODE_INT 
if ( mode_class_0[mode] == MODE_INT && mode_class_0[oldmode] == MODE_INT ) 
if ( mode_class_0[mode] == MODE_INT && mode_class_0[oldmode] == MODE_INT ) 
rtx v24; // rcx 
rtx v29; // rsi 
rtx v31; // rdx 
rtx *v60; // rbx 
rtx v61; // rax 
rtx v65; // [rsp+10h] [rbp-58h] 
rtx *v69; // [rsp+28h] [rbp-40h] 
rtx v70; // [rsp+30h] [rbp-38h] BYREF 
v69 = pnotes; 
v65 = to_insn; 
to_insn = v65; 
pnotes = v69; 
rtx v28; // r14 
rtx v36; // rax 
rtx const_rtx; // r14 
rtx v47; // r14 
rtx v51; // r15 
rtx v54; // rcx 
rtx *v88; // rbp 
rtx v101; // r15 
rtx v118; // rbp 
rtx v43; // [rsp+18h] [rbp-40h] 
v43 = v12; 
if ( !comparison_dominates_p( ( rtx_code)v16, v17) && !comparison_dominates_p( ( rtx_code)v16, v39) ) 
if ( !comparison_dominates_p( ( rtx_code)v16, v17) && !comparison_dominates_p( ( rtx_code)v16, v39) ) 
v2 = mode_class_0[mode]; 
( *direction)[13 * i] = star; 
( *direction)[13 * i] = merge_dependencies_direction_merge[( *direction)[13 * i]][( *direction)[13 * i + j]]; 
( *direction)[13 * i] = merge_dependencies_direction_merge[( *direction)[13 * i]][( *direction)[13 * i + j]]; 
( *direction)[13 * i] = merge_dependencies_direction_merge[( *direction)[13 * i]][( *direction)[13 * i + j]]; 
( *direction)[13 * i] = merge_dependencies_direction_merge[( *direction)[13 * i]][( *direction)[13 * i + j]]; 
invalidate( dest->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)); 
v7 = **( tree_node ***)( low + 8); 
if ( ( tree_node *)low != v7 && ( !*( _QWORD *)( low + 112) || decl_ultimate_origin( ( tree)low) != v7) ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)srca->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)srca)); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest)); 
v4 = &allocno_0[( __int64)*( ( int *)reg_allocno + src_regno)]; 
v5 = &allocno_0[( __int64)*( ( int *)reg_allocno + src_regno)]; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v27 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
v11 = &allocno_0[( __int64)*( ( int *)reg_allocno + src_regno)]; 
v12 = &allocno_0[( __int64)*( ( int *)reg_allocno + dest_regno)]; 
v13 = &allocno_0[( __int64)*( ( int *)reg_allocno + dest_regno)]; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)srca)] != MODE_COMPLEX_INT ) 
v23 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)srca)] == MODE_COMPLEX_FLOAT; 
v19 = &allocno_0[( __int64)*( ( int *)reg_allocno + dest_regno)]; 
did_insert = pre_edge_insert( edge_list_0, index_map); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg->fld[0].rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)reg)); 
if ( constructor_range_stack_0 ) 
v2->prev = constructor_range_stack_0; 
v2->stack = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
constructor_range_stack_0->next = v2; 
constructor_range_stack_0 = v2; 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v3 = TV_LIFE_0; 
v3 = TV_LIFE_UPDATE_0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 3681, "athlon_vectordec_unit_blockage_range"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_ATHLON ) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_ATHLON ) 
if ( which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_ATHLON ) 
ggc_mark_tree_hash_table( *( hash_table_0 **)elt); 
return new_loc_descr( ( dwarf_location_atom)( reg + 112), offset, 0LL); 
rtx v9; // rax 
rtx v12; // rax 
rtx v19; // [rsp+10h] [rbp-68h] 
rtx v21; // [rsp+20h] [rbp-58h] 
rtx x; // [rsp+28h] [rbp-50h] BYREF 
v19 = cfun->emit->x_regno_reg_rtx[regno]; 
v9 = ( rtx)rtx[2]; 
if ( *( _WORD *)v9 != 47 ) 
v9 = single_set_2( rtx, *( rtx *)&rtx[2]); 
if ( v9 ) 
v10.rtwint = ( __int64)v9->fld[0]; 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v15 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
rtx nonnote_insn; // rax 
rtx v34; // r11 
rtx v44; // rax 
rtx v45; // rbp 
rtx offset; // rax 
rtx *v47; // rbp 
rtx **v51; // r12 
rtx *v53; // rbp 
rtx v84; // rbx 
rtx *v99; // rsi 
rtx v102; // rax 
if ( mode_class_0[mode] == MODE_INT ) 
&& ( !undobuf_0.other_insn || other_insn == undobuf_0.other_insn) 
&& ( !undobuf_0.other_insn || other_insn == undobuf_0.other_insn) 
v1 = gen_rtx_fmt_ee( new_code, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)*cc_use), dest, const_int_rtx[64]); 
mask = nonzero_bits( op0, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op0)); 
undobuf_0.other_insn = other_insn; 
rtx nonnote_insn; // rax 
rtx v4; // r14 
rtx v8; // rax 
nonnote_insn = head; 
if ( rtx_class[*( _WORD *)nonnote_insn] == 105 ) 
v4 = nonnote_insn; 
v4 = nonnote_insn; 
nonnote_insn = next_nonnote_insn( nonnote_insn); 
nonnote_insn = next_nonnote_insn( nonnote_insn); 
&& ( *( _DWORD *)nonnote_insn & 0x10000000) != 0 
while ( nonnote_insn 
&& ( unsigned __int16)*( _DWORD *)nonnote_insn != 36 ); 
for ( i = ( __int64)v4[3]; i; i = *( _QWORD *)( i + 16) ) 
v8 = alloc_INSN_LIST( v4, h_i_d[v7->fld[0].rtint].depend); 
v8 = alloc_INSN_LIST( v4, h_i_d[v7->fld[0].rtint].depend); 
*( ( _BYTE *)v8 + 2) = *( _BYTE *)( i + 2); 
v6 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v7] - 5) < 2) + 1; 
v6 = ( tree_node *)*( &global_trees + 17); 
return ( *( page_entry_0 ***)( ( char *)G.lookup + ( ( ( unsigned __int64)p >> 21) & 0x7F8)))[( ( unsigned __int64)p >> SLOBYTE( G.lg_pagesize)) & ~( -1 << ( 24 - LOBYTE( G.lg_pagesize)))]; 
v6 = &arg0; 
posa = print_single_switch( file, pos, max, indent, v6, terma, "options passed: ", &arg0); 
posa = print_single_switch( filea, posa, maxa, indenta, sepa, terma, *p, &arg0); 
v7 = &arg0; 
posa = print_single_switch( filea, 0, maxa, indenta, v7, terma, "options enabled: ", &arg0); 
rtx v44; // rax 
rtx nonnote_insn; // rax 
rtx v49; // rax 
rtx v51; // rbx 
rtx v53; // rax 
rtx v56; // r15 
v44 = delete_insn( rtx); 
rtx = v44; 
tmode = *( ( unsigned __int16 *)insn_data_0[d->icode].operand + 8); 
mode0 = *( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8); 
mode1 = *( ( unsigned __int16 *)&insn_data_0[d->icode].operand[2] + 8); 
if ( mode_class_0[*( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8)] == MODE_VECTOR_INT 
if ( mode_class_0[*( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8)] == MODE_VECTOR_INT 
|| mode_class_0[*( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8)] == MODE_VECTOR_FLOAT ) 
|| mode_class_0[*( ( unsigned __int16 *)&insn_data_0[d->icode].operand[1] + 8)] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode1] == MODE_VECTOR_INT || mode_class_0[mode1] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[mode1] == MODE_VECTOR_INT || mode_class_0[mode1] == MODE_VECTOR_FLOAT ) 
|| !insn_data_0[d->icode].operand->predicate( target, tmode) ) 
if ( !insn_data_0[d->icode].operand[1].predicate( op0, mode0) ) 
if ( !insn_data_0[d->icode].operand[2].predicate( op1, mode1) ) 
*( _OWORD *)&v10->next_same_hash = 0LL; 
rtx v5; // rax 
rtx v6; // rax 
v5 = pc_set( rtx); 
v6 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v5[1] + 8LL), 0, 0LL, v2); 
v6 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v5[1] + 8LL), 0, 0LL, v2); 
if ( v6 ) 
if ( v6->fld[0].rtx == v2 ) 
v7 = (  struct rtx_def *)v6[1]; 
v8 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v6, VOIDmode, *( rtx *)( v3 + 16), v7); 
v8 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v6, VOIDmode, *( rtx *)( v3 + 16), v7); 
predict_insn_def( rtx, PRED_BUILTIN_EXPECT, ( prediction)( v9 == const_true_rtx)); 
put_reg_into_stack( v11, rtl, decl->common.type, v12, ( machine_mode)v8, v15, 0, ( unsigned __int8)v4, 0LL); 
while ( constructor_stack_0->implicit ) 
v7->next = constructor_stack_0; 
v11 = spelling_0; 
v13 = ( unsigned __int64)( ( char *)spelling_0 - ( char *)spelling_base) >> 4; 
constructor_stack_0 = v7; 
v7->range_stack = constructor_range_stack_0; 
constructor_range_stack_0 = 0LL; 
spelling_0 = v11; 
v11 = spelling_0; 
v19 = ( unsigned __int64)( ( char *)spelling_0 - ( char *)spelling_base) >> 4; 
spelling_0 = v11; 
spelling_0 = v11 + 1; 
if ( mode_class_0[mode] != MODE_FLOAT ) 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
*( _OWORD *)x = 0LL; 
v8 = mode_class_0[v7]; 
v10 = mode_class_0[mode]; 
+ ( ( *( _DWORD *)x >> 13) & 0x7F8)) | rtwint & nonzero_bits( x, ( machine_mode)v7)); 
v60 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v7); 
if ( mode_class_0[mode] == MODE_INT ) 
v35 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v35 + 2), fixed); 
else if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
fprintf( ( FILE *)asm_out_file, off_73AB94, 6755617LL); 
v11 = gen_rtx_fmt_ee( v10, ( machine_mode)*( ( unsigned __int8 *)x + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2a; 
&& ix86_unary_operator_ok( NEG, XFmode, recog_data_0.operand) 
recog_data_0.operand[1] = x2c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[0] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[0] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2b; 
&& ix86_unary_operator_ok( ABS, XFmode, recog_data_0.operand) 
recog_data_0.operand[1] = x1b; 
v10 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v8] - 5) < 2) + 1; 
fancy_abort( &off_723588[4], 8994, "reload_combine_note_use"); 
fancy_abort( &off_723588[4], 9015, "reload_combine_note_use"); 
if ( ( unsigned int)( mode_class_0[v18] - 5) < 2 ) 
if ( in_section_0 != in_bss ) 
in_section_0 = in_bss; 
args = ( macro_arg_0 *)buff->base; 
v3 = stack_0; 
if ( stack_0 ) 
v4 = stack_0->timevar; 
v4->elapsed.user = ( float)( v2 - start_time.user) + stack_0->timevar->elapsed.user; 
v3 = stack_0; 
stack_0 = v5; 
rtx v5; // rdx 
if ( *( _WORD *)head != 37 || ( v5 = head, head[2].fld[0].rtint <= 0) ) 
v5 = v4; 
v4 = v5; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx reg_equal_equiv_note; // rax 
rtx v23; // rax 
rtx v25; // rax 
rtx v27; // rax 
rtx v29; // rax 
rtx v30; // rax 
rtx jump; // rbx 
rtx v33; // rbp 
rtx v34; // rax 
v11 = simplify_subreg( outermode, v16.rtx, ( machine_mode)v17, v20); 
v11 = simplify_subreg( outermode, *v28, ( machine_mode)*( ( unsigned __int8 *)*v28 + 2), byte % v26); 
if ( v12 == v35 && v12 < v9 && mode_class_0[outermode] == MODE_INT ) 
if ( mode_class_0[outermode] != MODE_INT ) 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 22849, "athlon_ieu_unit_blockage"); 
&& symbolic_operand( recog_data_0.operand[1], SImode) 
&& ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
&& q_regs_operand( recog_data_0.operand[0], QImode) 
&& symbolic_operand( recog_data_0.operand[1], DImode) 
&& ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode)) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) 
if ( ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( ( which_alternative == 3 || incdec_operand( recog_data_0.operand[2], QImode)) 
&& !incdec_operand( recog_data_0.operand[2], QImode) ) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, 0); 
( machine_mode)*( unsigned __int8 *)( v1.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
rtx fixed_bit_field; // rax 
rtx v32; // [rsp+20h] [rbp-48h] 
v32 = v13; 
fixed_bit_field = gen_rtx_CONST_INT( VOIDmode, ( ( unsigned __int64)v13->fld[0].rtwint >> v18) & ~( -1LL << v26)); 
fixed_bit_field = extract_fixed_bit_field( *(short *)0xmode, v13, 0LL, v26, v18, 0LL, 1); 
v28 = fixed_bit_field; 
rtx = operand_sub*(short *)0xforce( rtx, v21, v19); 
v13 = v32; 
v12 = ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1; 
v17 = operand_sub*(short *)0xforce( op, v15, v13); 
v18 = operand_sub*(short *)0xforce( v27, v15, v13); 
rtx v15; // rax 
safe_from_p_save_expr_list = 0LL; 
for ( i = safe_from_p_save_expr_list; i; i = i->common.chain ) 
safe_from_p_save_expr_list = tree_cons( exp, 0LL, safe_from_p_save_expr_list); 
safe_from_p_save_expr_list = tree_cons( exp, 0LL, safe_from_p_save_expr_list); 
v15 = exp->decl.rtl; 
if ( !v15 || *( _WORD *)v15 != 66 ) 
if ( !v15 || *( _WORD *)v15 != 66 ) 
rtl = v15->fld[0].rtx; 
rtl_op = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16)); 
return *( ( unsigned __int8 *)&exp->block.common + 16) < 0x93u || lang_hooks_0.safe_from_p( rtx, exp); 
v47 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( v45 >> 14) & 0x3FC)) - 5) < 2) + ( _DWORD)rtint; 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
*( _OWORD *)( object_base + 24) = 0LL; 
*( _OWORD *)object_base = 0LL; 
return off_683D90[v1]; 
*( _OWORD *)value = 0LL; 
*( _OWORD *)&value->un.vechi[13] = 0LL; 
*( _OWORD *)&value->un.vechi[11] = 0LL; 
*( _OWORD *)&value->un.vechi[9] = 0LL; 
*( _OWORD *)&value->un.vechi[7] = 0LL; 
*( _OWORD *)&value->un.vechi[5] = 0LL; 
*( _OWORD *)&value->un.vechi[3] = 0LL; 
*( _OWORD *)&value->un.vechi[1] = 0LL; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest_reg), 
*( _OWORD *)&head->first = 0LL; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 30886, "pent_uv_unit_conflict_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( incdec_operand( recog_data_0.operand[2], DImode) 
if ( incdec_operand( recog_data_0.operand[2], DImode) 
if ( incdec_operand( recog_data_0.operand[2], SImode) 
if ( incdec_operand( recog_data_0.operand[2], SImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
|| incdec_operand( recog_data_0.operand[2], QImode) 
|| incdec_operand( recog_data_0.operand[2], QImode) 
if ( incdec_operand( recog_data_0.operand[2], QImode) 
if ( incdec_operand( recog_data_0.operand[2], QImode) 
|| ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
v8 = rtuint + ( ( unsigned int)( mode_class_0[( unsigned __int8)v7] - 5) < 2) + 1; 
result = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
tree v12; // rax 
tree v14; // rbp 
tree v15; // rax 
v10 = type_for_mode( ( machine_mode)*( ( unsigned __int8 *)add + 2), unsignedp); 
v12 = make_tree( v9, mult); 
v13 = build( MULT_EXPR, v9, tree, v12); 
v14 = fold( v13); 
v15 = make_tree( v10, add); 
v16 = build( PLUS_EXPR, v9, v14, v15); 
v16 = build( PLUS_EXPR, v9, v14, v15); 
rtunion v3; // rax 
if ( ( *( _DWORD *)( v3.rtwint + 16) & 0x800FF) != 25 ) 
v5 = *( _QWORD *)( v3.rtwint + 40); 
v6 = *( _QWORD *)( v3.rtwint + 32); 
if ( v6 < 0 && ( *( _BYTE *)( *( _QWORD *)( v3.rtwint + 8) + 17LL) & 0x20) == 0 ) 
v6 = *( _QWORD *)( v3.rtwint + 32); 
*( _OWORD *)( v17 + 8) = 0LL; 
v8 = ( tree_node *)v17; 
v20 = ( tree_node *)high; 
v20 = ( tree_node *)low; 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
v5 = ( ( unsigned int)( mode_class_0[xmode] - 5) < 2) + 1; 
v6 = ( ( unsigned int)( mode_class_0[ymode] - 5) < 2) + 1; 
recog_data_0.operand[1] = x2p; 
recog_data_0.operand[1] = x2q; 
recog_data_0.operand[1] = x2r; 
recog_data_0.operand[2] = x2u; 
recog_data_0.operand[1] = x2s; 
recog_data_0.operand[2] = x2v; 
recog_data_0.operand[1] = x2t; 
recog_data_0.operand[2] = x2w; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2e; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[2] = x2g; 
fatal_insn_not_found( insn, "insn-attrtab.c", 3460, "athlon_directdec_unit_ready_cost"); 
memset( buffer, 0, sizeof( output_buffer_0)); 
v0 = dwarf2out_cfi_label_label_num++; 
sprintf( dwarf2out_cfi_label_label, "*.%s%u", "LCFI", v0); 
assemble_name( asm_out_file, dwarf2out_cfi_label_label); 
return dwarf2out_cfi_label_label; 
v3 = ( tree_node *)ggc_alloc( v2); 
v12 = ( tree_node *)ggc_alloc( v11); 
deps_0 *v12; // rbp 
deps_0 *v12; // rbp 
v12 = deps; 
reg_last = v12->reg_last; 
add_dependence( insn, ii->fld[0].rtx, ( reg_note)0); 
add_dependence( insn, jj->fld[0].rtx, ( reg_note)0); 
rtx v12; // r15 
v12 = ( rtx)expr[1]; 
if ( *( _WORD *)v12 != 61 ) 
if ( cfa_temp_0 != v36 ) 
if ( cfa_temp_0 != v21 ) 
if ( ( v12->fld[0].rtint & 0xFFFFFFFE) == 6 || cfa.reg != v12->fld[0].rtint ) 
if ( ( v12->fld[0].rtint & 0xFFFFFFFE) == 6 || cfa.reg != v12->fld[0].rtint ) 
v12 = global_rtl[2]; 
v48->reg = v12; 
if ( cfa_temp_0 != *( _DWORD *)( *( _QWORD *)( v16.rtwint + 8) + 8LL) ) 
v14 = ( unsigned __int16)*( _DWORD *)v12; 
switch ( ( unsigned __int16)*( _DWORD *)v12 ) 
cfa_temp_0 = rtx->fld[0].rtuint; 
if ( initial != ( tree_node *)global_trees ) 
rtl_op = first_rtl_op( ( tree_code)( unsigned __int8)v2); 
for ( du_ptr = ( def_use_0 *)*( ( _QWORD *)&def_use_chain->name + def_use_chain->elements_used); 
du_ptr = ( def_use_0 *)*( ( _QWORD *)&def_use_chain->name + def_use_chain->elements_used) ) 
error( "can't use '%s' as a %s register", name, fix_register_what_option[fixed][call_used]); 
v24 = ( page_group_0 *)&v18[v16 - v23]; 
v24 = ( page_group_0 *)( ( char *)v24 - G.pagesize); 
group = ( page_group_0 *)( page - 32); 
v29 = ( page_entry_0 *)xcalloc( 1uLL, n); 
v34 = ( tree_node *)*( &global_trees + 27); 
v1 = ( *( page_entry_0 ***)( ( char *)G.lookup + ( ( ( unsigned __int64)p >> 21) & 0x7F8)))[( ( unsigned __int64)p >> SLOBYTE( G.lg_pagesize)) & ~( -1 << ( 24 - LOBYTE( G.lg_pagesize)))]; 
v6 = rtuint + ( ( unsigned int)( mode_class_0[( unsigned __int8)v5] - 5) < 2) + 1; 
rtx v22; // rax 
rtx v25; // rax 
rtx v47; // rax 
rtx v57; // r13 
v10 = get_mode_alignment( ( machine_mode)v9) >> 3; 
v11 = gen_rtx_REG( ( machine_mode)v9, v2); 
v12 = adjust_address_1( result, ( machine_mode)v9, v3, 1, 1); 
rtx list; // [rsp+18h] [rbp-28h] 
list = reg_equiv[regno].init_insns; 
if ( list != const_int_rtx[64] ) 
while ( list ) 
rtx = list->fld[0].rtx; 
list = ( rtx)list[1]; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 356, "insn_default_length"); 
v5 = recog_data_0.operand[0]; 
v5 = recog_data_0.operand[0]; 
v5 = recog_data_0.operand[0]; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 33187, "pent_mul_unit_blockage"); 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
for ( run = ( cpp_reader_0 *)&pfile->base_run; run; run = ( cpp_reader_0 *)runn ) 
for ( run = ( cpp_reader_0 *)&pfile->base_run; run; run = ( cpp_reader_0 *)runn ) 
runn = ( tokenrun_0 *)run->buffer; 
if ( run != ( cpp_reader_0 *)&pfile->base_run ) 
imag = ( tree_node *)*( &global_trees + 17); 
for ( p = spelling_base; p < spelling_0; ++p ) 
if ( !insn_data_0[1316].operand->predicate( op0, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
if ( !insn_data_0[1316].operand->predicate( op0, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
upper = ( tree_node *)domain[7]; 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] == MODE_COMPLEX_FLOAT; 
return gen_rtx_fmt_e( USE, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2), v2); 
fancy_abort( &off_723588[4], 3642, "finish_spills"); 
fancy_abort( &off_723588[4], 3721, "finish_spills"); 
edge_info_0 *inf; // [rsp+30h] [rbp-30h] 
edge_info_0 *inf; // [rsp+30h] [rbp-30h] 
inf = ( edge_info_0 *)e->aux; 
inf = ( edge_info_0 *)e->aux; 
if ( ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
if ( ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
v1 = &arg0; 
v16 = *( _OWORD *)&orig[v14 + 1].fld[0].rtwint; 
*( _OWORD *)&result[v14].fld[0].rtwint = *( _OWORD *)&orig[v14].fld[0].rtwint; 
*( _OWORD *)&result[v14].fld[0].rtwint = *( _OWORD *)&orig[v14].fld[0].rtwint; 
*( _OWORD *)&result[v14 + 1].fld[0].rtwint = v16; 
v17 = *( _OWORD *)&orig[v14 + 3].fld[0].rtwint; 
*( _OWORD *)&result[v14 + 2].fld[0].rtwint = *( _OWORD *)&orig[v14 + 2].fld[0].rtwint; 
*( _OWORD *)&result[v14 + 2].fld[0].rtwint = *( _OWORD *)&orig[v14 + 2].fld[0].rtwint; 
*( _OWORD *)&result[v14 + 3].fld[0].rtwint = v17; 
v18 = *( _OWORD *)&orig[v14 + 5].fld[0].rtwint; 
rtx i; // rbx 
for ( i = cfun->epilogue_delay_list; i; i = ( rtx)i[1] ) 
for ( i = cfun->epilogue_delay_list; i; i = ( rtx)i[1] ) 
for ( i = cfun->epilogue_delay_list; i; i = ( rtx)i[1] ) 
print_rtl_single( outf, i->fld[0].rtx); 
v3 = ( tree_node *)ggc_alloc( v2); 
fprintf( v21, off_690140, x86_64_reg_class_name[v48[i - 1]]); 
alias_set_entry_0 v4; // rax 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v8 >> 14) & 0x3FC)) == MODE_INT 
v47 = expand_binop( mode, optab_table[21], arg1, v43, 0LL, 0, ( optab_methods)methods); 
v70 = expand_binop( mode, optab_table[21], arg0, v69, 0LL, 0, ( optab_methods)v72); 
v57 = expand_binop( mode, optab_table[21], arg0, v56, 0LL, 0, ( optab_methods)v59); 
v64 = expand_binop( mode, optab_table[21], arg1, v63, 0LL, 0, ( optab_methods)v66); 
v51 = expand_binop( mode, optab_table[21], arg1, v50, 0LL, 0, ( optab_methods)v53); 
v1 = gen_internal_sym_label_num++; 
rtx v14; // rbp 
rtx *v27; // rbp 
v14 = rtx; 
v29 = ( int *)v14[2]; 
rtx v29; // rbx 
rtx v31; // rbp 
rtx v38; // rbx 
rtx *v53; // r9 
rtx v67; // r12 
rtx v74; // rax 
rtx v77; // rcx 
rtx v79; // rcx 
rtx v82; // rcx 
rtx v86; // rbx 
bb_deps = ( deps_0 *)xmalloc( 104LL * ( int)current_nr_blocks); 
sched_rgn_n_insns += sched_n_insns_0; 
v11 = swap_condition( ( rtx_code)*v9); 
y = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v47 + 2)); 
*( _OWORD *)rbit = 0LL; 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x71CED0); 
*( _OWORD *)&v32[v34 - 24] = 0LL; 
*( _OWORD *)&v32[v34 - 16] = 0LL; 
*( _OWORD *)&v32[v34 - 8] = 0LL; 
*( _OWORD *)&v32[v34] = 0LL; 
*( _OWORD *)&s[v43 + 1] = 0LL; 
ok = parse_params( pfile, ( cpp_macro_0 *)macro); 
token = alloc_expansion_token( pfile, ( cpp_macro_0 *)macro); 
token = lex_expansion_token( pfile, ( cpp_macro_0 *)macro); 
token = lex_expansion_token( pfile, ( cpp_macro_0 *)macro); 
&& *( cpp_hashnode_0 **)( *( ( _QWORD *)macro + 1) + 8LL) == node ) 
node->value.macro = ( cpp_macro_0 *)macro; 
if ( !QGenericArgument::QGenericArgument( node->ident.str, "__STDC_", 7uLL) ) 
if ( *v23 != v16 || !byte_A1B5BF[v24] ) 
if ( *v20 != v16 || !byte_A1B5BF[v19] ) 
v11 = force_reg( ( machine_mode)v8, v11); 
v10 = force_reg( ( machine_mode)v8, v10); 
v11 = force_reg( ( machine_mode)v8, v11); 
LODWORD( v8) = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
v11 = gen_reg_rtx( ( machine_mode)v8); 
v23 = mode_class_0[( int)v8]; 
induction_1 *biv; // rbx 
induction_1 *biv; // rbx 
biv = bl_0->biv; 
if ( biv ) 
v3 = *( ( _WORD *)biv + 50); 
mult_val = biv->mult_val; 
result = fold_rtx_mult_add( result, mult_val, biv->add_val, biv->mode); 
result = fold_rtx_mult_add( result, mult_val, biv->add_val, biv->mode); 
biv = biv->next_iv; 
biv = biv->next_iv; 
if ( biv ) 
rtx v112; // r15 
rtx v121; // rbp 
rtx v124; // r12 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v13] - 5) < 2) + 1; 
v20 = _mm_add_epi64( _mm_shuffle_epi32( ( __m128i)x->fld[0].rtuint, 68), ( __m128i)xmm*(short *)0x65ADF0); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE00); 
v26 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v27 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE20); 
v28 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x668290); 
return gen_rtx_fmt_e( CONSTANT_P_RTX, ( machine_mode)value_mode, v1); 
rtx insn; // [rsp+58h] [rbp-28h] 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
if ( insn ) 
v4 = insn != bb->end[1].fld[0].rtx; 
uid = insn->fld[0].rtuint; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)subreg), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)*pat))] 
v38 = force_reg( ( machine_mode)( unsigned __int8)v28, v10); 
v58 = expand_binop( v40, optab_table[23], v10, v56, target, 0, ( optab_methods)methods); 
v37 = immed_double_const( v34, v36, ( machine_mode)*( ( unsigned __int8 *)v10 + 2)); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 26821, "k6_alu_unit_blockage"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) && ( ( 1 << ix86_cpu) & x86_movx) == 0 ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
if ( ( which_alternative == 3 || incdec_operand( recog_data_0.operand[2], QImode)) 
&& !incdec_operand( recog_data_0.operand[2], QImode) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) ) 
*( _OWORD *)&result->decl.common.type = 0LL; 
rtx *v22; // rbx 
v22 = ( rtx *)&x[1]; 
if ( loc == v22 ) 
x = *v22; 
LODWORD( result) = ( ( unsigned int)( mode_class_0[v26] - 5) < 2) + 1; 
LODWORD( result) = ( ( unsigned int)( mode_class_0[( unsigned __int8)result] - 5) < 2) + 1; 
elements = lang_hooks_0.expand_constant( exp); 
v8 = ( tree_node *)high[4]; 
if ( ( sch_istable[( unsigned __int8)i[1]] & 0x88) == 0 || i[2] != 91 ) 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 23760, "athlon_vectordec_unit_blockage"); 
casenum = memory_operand( recog_data_0.operand[1], VOIDmode) == 0; 
casenum = !which_alternative && !memory_operand( recog_data_0.operand[1], VOIDmode); 
casenum = which_alternative == 1 && !memory_operand( recog_data_0.operand[1], VOIDmode); 
fatal_insn_not_found( candidate_insn, "insn-attrtab.c", 24162, "athlon_vectordec_unit_blockage"); 
v6 = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
v6 = which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode); 
v6 = which_alternative != 1 || memory_operand( recog_data_0.operand[1], VOIDmode); 
recog_data_0.operand[5] = x4d; 
recog_data_0.operand[2] = x3n; 
recog_data_0.operand[3] = x3o; 
recog_data_0.operand[4] = x3p; 
recog_data_0.operand[1] = x2y; 
recog_data_0.operand[1] = x3q; 
recog_data_0.operand[2] = x3r; 
recog_data_0.operand[2] = x3b; 
recog_data_0.operand[3] = x3c; 
recog_data_0.operand[1] = x2i; 
if ( rtx_equal_p( x2j->fld[0].rtx, recog_data_0.operand[2]) ) 
if ( rtx_equal_p( *( rtx *)&x2j[1], recog_data_0.operand[3]) ) 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[2] = x3d; 
recorded_label_ref_0 = 1; 
if ( *( _BYTE *)( v14 + 9981631) && !byte_9AA96F[v14] && !byte_9AA92F[v14] && v14 != 7 ) 
if ( *( _BYTE *)( v14 + 9981631) && !byte_9AA96F[v14] && !byte_9AA92F[v14] && v14 != 7 ) 
if ( *( _BYTE *)( m + 9981631) && !byte_9AA96F[m] ) 
v13 += byte_9AA92F[m] == 0; 
ix86_cpu_string = override_options_cpu_names[12]; 
else if ( !strcmp( ix86_asm_string, off_80612B) ) 
if ( !strcmp( ix86_arch_string, override_options_processor_alias_table[i].name) ) 
ix86_arch = override_options_processor_alias_table[i].processor; 
if ( ( override_options_processor_alias_table[i].flags & 4) != 0 && ( target_flags & 0x8000) == 0 ) 
if ( ( override_options_processor_alias_table[i].flags & 0x10) != 0 && ( target_flags & 0x200000) == 0 ) 
if ( ( override_options_processor_alias_table[i].flags & 0x40) != 0 && ( target_flags & 0x800000) == 0 ) 
if ( ( override_options_processor_alias_table[i].flags & 1) != 0 && ( target_flags & 0x20000) == 0 ) 
if ( ( override_options_processor_alias_table[i].flags & 2) != 0 && ( target_flags & 0x80000) == 0 ) 
if ( ( override_options_processor_alias_table[i].flags & 8) != 0 ) 
if ( !strcmp( ix86_cpu_string, override_options_processor_alias_table[ia].name) ) 
ix86_cpu = override_options_processor_alias_table[ia].processor; 
if ( ( override_options_processor_alias_table[ia].flags & 8) != 0 ) 
ix86_cost = override_options_processor_target_table[ix86_cpu].cost; 
target_flags |= override_options_processor_target_table[ix86_cpu].target_enable; 
target_flags &= ~override_options_processor_target_table[ix86_cpu].target_disable; 
align_loops = override_options_processor_target_table[ix86_cpu].align_loop; 
rtx *v50; // rsi 
rtx reloads_toplev; // rax 
rtx v65; // r13 
rtx v135; // rax 
rtx *v160; // rcx 
rtx *v161; // rcx 
rtx v162; // rdx 
*( _OWORD *)&entry_exit_blocks[0].global_live_at_end = 0LL; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 25623, "k6_load_unit_blockage"); 
casenum = memory_operand( recog_data_0.operand[1], VOIDmode) == 0; 
casenum = which_alternative || !memory_operand( recog_data_0.operand[1], VOIDmode); 
casenum = which_alternative != 1 || !memory_operand( recog_data_0.operand[1], VOIDmode); 
casenum = memory_operand( recog_data_0.operand[0], VOIDmode) == 0; 
casenum = constant_call_address_operand( recog_data_0.operand[0], VOIDmode) != 0; 
casenum = constant_call_address_operand( recog_data_0.operand[1], VOIDmode) != 0; 
rtx v35; // rbx 
edge succ; // rdx 
edge v51; // rcx 
succ = entry_exit_blocks[0].succ; 
v51 = succ; 
v51 = succ; 
succ = succ->succ_next; 
succ = succ->succ_next; 
if ( !succ ) 
if ( succ == e ) 
p_succ_next = &v51->succ_next; 
v35 = target->head; 
v35 = emit_label_before( v36, target->head); 
target->head = v35; 
v38 = v35->fld[0].rtint; 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, flag_pedantic_errors == 0); 
return QGenericArgument::QGenericArgument( buf, fmt, ap); 
lang_hooks_0.print_statistics( ); 
fancy_abort( "varasm.c", 839, &off_73A9B0[4]); 
fancy_abort( "varasm.c", 835, &off_73A9B0[4]); 
*p_rtl = adjust_address_1( rtl, ( machine_mode)( unsigned __int8)supercontext, 0LL, 0, 1); 
v26 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), low); 
if ( !ix86_hard_regno_mode_ok( v11, ( machine_mode)v14) ) 
v18 = gen_rtx_fmt_i0( REG, ( machine_mode)LOBYTE( decl->block.supercontext), reg_number); 
v37 = ( ( unsigned int)( mode_class_0[v35] - 5) < 2) + 1; 
v1 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_info->x)); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)if_info->x), 
fatal_insn_not_found( insn, "insn-attrtab.c", 12189, "get_attr_athlon_decode"); 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
reg_set_0 *v36; // rax 
reg_set_0 *v36; // rax 
reg_set_0 *v39; // rax 
reg_set_0 *v39; // rax 
v36 = reg_set_table[rtuint]; 
if ( v36 ) 
v38 = bmap[*( int *)( v37->data.l[v36->insn->fld[0].rtint] + 88)]; 
v36 = v36->next; 
v36 = v36->next; 
while ( v36 ); 
v39 = reg_set_table[rtuint]; 
if ( v39 ) 
v41 = bmap[*( int *)( v40->data.l[v39->insn->fld[0].rtint] + 88)]; 
v39 = v39->next; 
v39 = v39->next; 
while ( v39 ); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), 
if ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)rega)] == MODE_COMPLEX_FLOAT; 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEA0); 
v10 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEB0); 
v11 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEC0); 
v12 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FED0); 
v13 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEE0); 
v14 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEF0); 
v15 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FF00); 
v16 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FF10); 
v17 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FF20); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEA0); 
v20 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEB0); 
v21 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEC0); 
v24 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEA0); 
v27 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEB0); 
v28 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEC0); 
v29 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FED0); 
v30 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEE0); 
v31 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x67FEF0); 
error( "unable to find a register to spill in class `%s'", spill_failure_reg_class_names[a2]); 
fatal_insn( "this is the insn:", insn, &off_88ECD0[4], 1910, "spill_failure"); 
error_for_asm( insn, "can't find a register in class `%s' while reloading `asm'", spill_failure_reg_class_names[a2]); 
fatal_insn_not_found( insn, "insn-attrtab.c", 5779, "k6_alu_unit_ready_cost"); 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) 
|| !symbolic_operand( recog_data_0.operand[1], SImode) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) 
|| ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
|| flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode)) 
if ( incdec_operand( recog_data_0.operand[2], DImode) 
|| !incdec_operand( recog_data_0.operand[2], DImode) 
if ( ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
if ( ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode)) 
if ( incdec_operand( recog_data_0.operand[2], SImode) 
|| !incdec_operand( recog_data_0.operand[2], SImode) 
&& incdec_operand( recog_data_0.operand[2], HImode) 
&& !incdec_operand( recog_data_0.operand[2], HImode) 
if ( incdec_operand( recog_data_0.operand[2], HImode) 
v15 = byte_73A750[v9]; 
if ( byte_73A750[v9] ) 
v12 = byte_73A750[v11]; 
v12 = byte_73A750[v11]; 
set_diagnostic_context( &dc, msgid, ( va_list_0 *)ap, input_filename, lineno, 0); 
if ( ( sch_istable[*( unsigned __int8 *)v32] & 4) != 0 ) 
sprintf( v73, off_73B17B, *( _DWORD *)&x[1]); 
rtx flags_user; // rax 
rtx v8; // rax 
flags_user = next_flags_user( insn); 
if ( !flags_user ) 
rtx = flags_user; 
v2 = ( __int64)flags_user[2]; 
v8 = next_flags_user( rtx); 
if ( v8 ) 
rtx = v8; 
v2 = ( __int64)v8[2]; 
v2 = rtx_alloc( ( rtx_code)*( _WORD *)notes); 
top_of_stack[i] = gen_rtx_MEM( ( machine_mode)i, global_rtl[2]); 
if ( reg_pref_0 ) 
return reg_pref_0[regno].prefclass; 
rtx v10; // rdx 
rtx v12; // rbx 
rtx x_forced_labels; // rax 
rtx v22; // rbx 
rtx v28; // rax 
rtx v31; // r15 
rtx last_insn; // rax 
rtx k; // rax 
if ( ix86_GOT_alias_set_set == -1 ) 
ix86_GOT_alias_set_set = new_alias_set( ); 
return ix86_GOT_alias_set_set; 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
reg_avail_info_0 = v3; 
v13 = reg_avail_info_0; 
v14 = uid_cuid_1; 
v3 = reg_avail_info_0; 
reg_avail_info_0 = 0LL; 
rtx v26; // rbp 
( machine_mode)( unsigned __int8)BYTE2( *v22), 
( machine_mode)BYTE2( v21)); 
v26 = rtx; 
( machine_mode)( unsigned __int8)BYTE2( *rtwint), 
( machine_mode)BYTE2( v27))] 
v26->fld[0].rtwint = ( __int64)rtx; 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x2e; 
recog_data_0.operand[1] = x3i; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2q; 
recog_data_0.operand[2] = x3u; 
recog_data_0.operand[2] = x4t; 
recog_data_0.operand[2] = x4s; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
rtx v33; // rax 
rtx v34; // rax 
rtx *v42; // r9 
rtx v45; // rcx 
rtx ( *v49)[59]; // rcx 
rtx *v51; // rdx 
rtx ( *v61)[59]; // rcx 
rtx **v67; // r10 
rtx v68; // rcx 
rtx *v72; // rdx 
rtx v76; // rcx 
rtx v79; // rsi 
rtx y; // [rsp+0h] [rbp-58h] 
rtx *v37; // [rsp+10h] [rbp-48h] 
y = *p_in; 
if ( !y ) 
if ( v14->in == y ) 
if ( *( _WORD *)y != 61 || dont_share || in->fld[0].rtint != y->fld[0].rtint ) 
if ( *( _WORD *)y != 61 || dont_share || in->fld[0].rtint != y->fld[0].rtint ) 
else if ( !rtx_equal_p( in, y) || dont_share | side_effects_p( v14->in) ) 
if ( !y ) 
if ( !v14->in || v18 == y ) 
if ( *( _WORD *)y == 61 && v18->fld[0].rtint == y->fld[0].rtint ) 
if ( *( _WORD *)y == 61 && v18->fld[0].rtint == y->fld[0].rtint ) 
else if ( rtx_equal_p( v18, y) && !side_effects_p( v14->in) ) 
v37 = p_in; 
if ( init_flow_initialized ) 
init_flow_initialized = 1; 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 22131, "athlon_muldiv_unit_blockage"); 
while ( ( sch_istable[v9] & 4) != 0 ); 
v7 = offsettable_address_p( 0, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), op->fld[0].rtx); 
if ( mode_class_0[v17] == MODE_FLOAT ) 
rtx pool_constant; // r13 
rtx v27; // rax 
rtx *v61; // rcx 
rtx *v68; // rcx 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 25384, "k6_store_unit_conflict_cost"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative != 1 || const0_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative != 1 || const0_operand( recog_data_0.operand[2], SImode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 2203, "athlon_fp_mul_unit_ready_cost"); 
rtx x_pending_chain; // rbx 
rtx dsta; // [rsp+0h] [rbp-80h] BYREF 
rtx *tmps; // [rsp+30h] [rbp-50h] 
rtx src; // [rsp+38h] [rbp-48h] 
v8 = ( rtx *)( ( char *)&dsta - ( ( 8 * v7 + 15) & 0xFFFFFFFFFFFFFFF0LL)); 
src = orig_src; 
dsta = dst; 
tmps = ( rtx *)( ( char *)&dsta - ( ( 8 * v7 + 15) & 0xFFFFFFFFFFFFFFF0LL)); 
tmps = ( rtx *)( ( char *)&dsta - ( ( 8 * v7 + 15) & 0xFFFFFFFFFFFFFFF0LL)); 
else if ( ( sch_istable[( unsigned __int8)ce] & 4) != 0 ) 
parse_number_0( pfile, ( cpp_string_0 *)&result->val, ce, 1); 
parse_number_0( pfile, ( cpp_string_0 *)&result->val, c, 0); 
recog_data_0.operand[2] = x2; 
recog_data_0.operand[0] = x2b; 
recog_data_0.operand[5] = x4; 
recog_data_0.operand[3] = x3c; 
recog_data_0.operand[1] = x2i; 
if ( rtx_equal_p( x3f->fld[0].rtx, recog_data_0.operand[5]) ) 
recog_data_0.operand[4] = x3g; 
if ( rtx_equal_p( x2k->fld[0].rtx, recog_data_0.operand[3]) ) 
if ( rtx_equal_p( x2l->fld[0].rtx, recog_data_0.operand[4]) ) 
if ( rtx_equal_p( x1h->fld[0].rtx, recog_data_0.operand[5]) ) 
rtx op1; // [rsp+138h] [rbp-28h] 
rtx op0; // [rsp+140h] [rbp-20h] 
rtx xa; // [rsp+150h] [rbp-10h] 
xa = x; 
op0 = x->fld[0].rtx; 
op1 = ( rtx)x[1]; 
if ( ( unsigned __int16)*( _DWORD *)op0 == 85 && rtx_equal_p( op0->fld[0].rtx, op1) && !side_effects_p( op1) ) 
if ( ( unsigned __int16)*( _DWORD *)op0 == 85 && rtx_equal_p( op0->fld[0].rtx, op1) && !side_effects_p( op1) ) 
if ( ( unsigned __int16)*( _DWORD *)op0 == 85 && rtx_equal_p( op0->fld[0].rtx, op1) && !side_effects_p( op1) ) 
if ( ( unsigned __int16)*( _DWORD *)op0 == 85 && rtx_equal_p( op0->fld[0].rtx, op1) && !side_effects_p( op1) ) 
v2 = simplify_gen_unary( NOT, mode, *( rtx *)&op0[1], mode); 
xa = gen_binary( AND, mode, v2, op1); 
rtx v7; // r14 
_OWORD *v16; // rax 
_OWORD *v16; // rax 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), rtx, offset); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), v5) 
v6 = force_reg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), rtx); 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v6, offset); 
v7 = change_address_1( memref, VOIDmode, v5, 1); 
v16 = ggc_alloc( 0x28uLL); 
*slot = v16; 
*( ( _QWORD *)v16 + 4) = v21; 
v16[1] = v20; 
*v16 = v17; 
*( _QWORD *)&v7[1] = v14; 
return v7; 
while ( ( sch_istable[v10] & 4) != 0 ); 
while ( ( sch_istable[v9] & 4) != 0 ); 
while ( ( sch_istable[v8] & 4) != 0 ); 
while ( ( sch_istable[v7] & 4) != 0 ); 
( rtx_code)*( _WORD *)comparison, 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 24655, "k6_fpu_unit_blockage"); 
casenum = mult_operator( recog_data_0.operand[3], SFmode) != 0; 
if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
casenum = mult_operator( recog_data_0.operand[3], XFmode) != 0; 
casenum = mult_operator( recog_data_0.operand[3], TFmode) != 0; 
else if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
rtx *v13; // rbp 
rtx v15; // r12 
rtx v22; // rax 
rtx v23; // rax 
rtx v37; // rbx 
rtx v44; // rax 
rtx *v50; // rsi 
rtx *v61; // rax 
mask = ( 8 * eflags_p) | ( 4 * ( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)operands[1])] == MODE_INT)) | ( 2 * unordered_p) | stack_top_dies; 
if ( !output_fp_compare_alt[mask] ) 
return output_fp_compare_alt[mask]; 
sprintf( pic_label_name, "*.%s%u", ( const char *)&off_694A56, 0LL); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
else if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
fatal_insn_not_found( insn, "insn-attrtab.c", 13642, "get_attr_length_address"); 
if ( !constant_call_address_operand( recog_data_0.operand[1], VOIDmode) ) 
v4 = gen_rtx_REG( ( machine_mode)v2, v3); 
v1 = _mm_sub_pd( ( __m128d)_mm_unpacklo_epi32( ( __m128i)nids, ( __m128i)xmm*(short *)0x8021E0), ( __m128d)xmm*(short *)0x8021F0); 
v1 = _mm_sub_pd( ( __m128d)_mm_unpacklo_epi32( ( __m128i)nids, ( __m128i)xmm*(short *)0x8021E0), ( __m128d)xmm*(short *)0x8021F0); 
( __m128d)_mm_unpacklo_epi32( _mm_loadl_epi64( ( const __m128i *)&nelts), ( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
( __m128d)_mm_unpacklo_epi32( _mm_loadl_epi64( ( const __m128i *)&total_bytes), ( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
( __m128d)_mm_unpacklo_epi32( _mm_loadl_epi64( ( const __m128i *)&nelts), ( __m128i)xmm*(short *)0x8021E0), 
rtx result; // rax 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
if ( result == reg_equiv_memory_loc[regno] ) 
return copy_rtx( result); 
return result; 
if ( undobuf_0.frees ) 
buf = undobuf_0.frees; 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
buf->next = undobuf_0.undos; 
undobuf_0.undos = buf; 
rtx v12; // rbx 
rtx v13; // rbp 
rtx v14; // r12 
rtx last_insn; // rbp 
rtx v22; // rbx 
rtx v25; // rbp 
v6 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target)); 
if ( reg_note ) 
return *( _OWORD *)element->bits == 0LL; 
if ( reg_renumber[allocno_0[( __int64)*( int *)&allocno_order[4 * i]].reg] < 0 ) 
if ( reg_renumber[allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg] < 0 ) 
fprintf( file, " %d", ( unsigned int)allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg); 
&& j != allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg ) 
if ( allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].size != 1 ) 
fprintf( file, " ( %d)", ( unsigned int)allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].size); 
fprintf( file, ";; %d conflicts:", ( unsigned int)allocno_0[( __int64)ib].reg); 
fprintf( file, " %d", ( unsigned int)allocno_0[( __int64)j_0].reg); 
if ( ( ( 1LL << j_0a) & allocno_0[( __int64)ib].hard_reg_conflicts) != 0 ) 
if ( ( ( 1LL << j_0b) & allocno_0[( __int64)ib].hard_reg_preferences) != 0 ) 
fprintf( file, ";; %d preferences:", ( unsigned int)allocno_0[( __int64)ib].reg); 
if ( ( ( 1LL << j_0c) & allocno_0[( __int64)ib].hard_reg_preferences) != 0 ) 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v7.rtwint + 8)) >= uid_limit ) 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v8.rtwint + 8)) <= uid_limit ) 
sprintf( v7, &off_607A24[1], type->decl.result->decl.name->identifier.id.len); 
if ( section_name == ( tree_node *)*( &global_trees + 10) ) 
if ( section_name == ( tree_node *)*( &global_trees + 9) ) 
if ( section_name == ( tree_node *)*( &global_trees + 8) ) 
if ( section_name == ( tree_node *)*( &global_trees + 7) ) 
if ( section_name == ( tree_node *)*( &global_trees + 6) ) 
rtx v9; // rax 
rtx v18; // rax 
v9 = rtx; 
v9 = emit_note_before( -98, v9); 
v9 = emit_note_before( -98, v9); 
*( _QWORD *)&v9[2] = i; 
v18 = v11; 
v18 = emit_note_before( -98, v18); 
v18 = emit_note_before( -98, v18); 
*( _QWORD *)&v18[2] = v13; 
classa = mode_class_0[mode]; 
if ( insn_data_0[icode].operand->predicate( test, wider_mode) ) 
v7 = insn_data_0[icode].genfun( test, xa, v6, label); 
v8 = insn_data_0[icodea].genfun( xb); 
v10 = insn_data_0[icodeb].genfun( xc, ya); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
memset( dc, 0, sizeof( diagnostic_context_0)); 
*( _OWORD *)&dc->begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&dc->begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
lang_expand_expr = ( lang_expand_expr_t)c_expand_expr; 
&& mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)valuea)] != MODE_INT ) 
v11 = expand_mult_add( v8, reg, v9, v10, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
*( ( _OWORD *)v4 + 1) = 0LL; 
while ( ( sch_istable[*( ( unsigned __int8 *)p - 1)] & 0x88) == 0 ); 
rtx result; // rax 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v4, const_int_rtx[64]); 
result = rtx->fld[0].rtx; 
if ( ( unsigned __int16)*( _DWORD *)result == 66 ) 
if ( ( unsigned __int8)BYTE2( *( _DWORD *)result) == mode ) 
return result; 
result = gen_lowpart_common( mode, rtx); 
if ( result ) 
return result; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v4, const_int_rtx[64]); 
return gen_rtx_fmt_ee( ( rtx_code)( unsigned __int16)*( _DWORD *)rtx, mode, rtx->fld[0].rtx, *( rtx *)&rtx[1]); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
if ( !result ) 
timevar_push( TV_REST_OF_COMPILATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_JUMP_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_DUMP_0); 
v52 = TV_DUMP_0; 
|| insn_data_0[rtint].n_dups > 0) ) 
if ( ( sch_istable[( unsigned __int8)ca] & 0x100) == 0 ) 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
operand = insn_data_0[v3].operand, 
operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v5].genfun( r0, r1); 
for ( dep_ptr = ( dependence_0 *)dep_chain->data.l[-dest_idx]; dep_ptr; dep_ptr = dep_ptr->next ) 
if ( dep_ptr == ( dependence_0 *)dep_chain->data.l[-src_idx] ) 
n_operands = ( unsigned __int8)recog_data_0.n_operands; 
if ( recog_data_0.n_operands <= 0 ) 
v5 = ( unsigned __int8)recog_data_0.n_operands; 
if ( recog_data_0.n_operands <= 3u ) 
v6 = recog_data_0.n_operands & 0xFC; 
v8 = &matchp->use[( unsigned __int8)recog_data_0.n_operands + 26]; 
v8 = &matchp->use[( unsigned __int8)recog_data_0.n_operands + 26]; 
*( _OWORD *)&v8[v10] = -1LL; 
*( _OWORD *)&v8[v10] = -1LL; 
*( _OWORD *)&v8[v10 - 60] = -1LL; 
*( _OWORD *)&v8[v10 - 60] = -1LL; 
v9 = new_die( ( dwarf_tag)( 4 * ( *( ( _BYTE *)&type->block.common + 16) != 20) + 19), v8, type); 
v5 = convert_modes( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), ptr_mode, size, 1); 
v9 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL || ( BYTE1( decl->block.supercontext) & v5) != 0 ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2ba; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bb; 
|| !rtx_equal_p( x2bc->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bc[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2c->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2c[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) 
v10 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v8] - 5) < 2) + 1; 
return offsettable_address_p( 0, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), op->fld[0].rtx) != 0; 
_OWORD *v16; // rax 
_OWORD *v16; // rax 
v16 = ggc_alloc( 0x28uLL); 
*slot = v16; 
*( ( _QWORD *)v16 + 4) = v20; 
v17 = *( _OWORD *)arg0; 
v16[1] = v19; 
*v16 = v17; 
rtx v18; // r14 
v18 = get_memory_rtx( elements); 
set_mem_align( v18, v11); 
v6 = clear_storage( v18, v17); 
rtx = v18->fld[0].rtx; 
rtx result; // rax 
result = 0LL; 
result = gen_rtx_CONST_INT( VOIDmode, v32); 
return result; 
v7 = *( _OWORD *)&buffer->state.diagnostic_count[4]; 
v6 = *( _OWORD *)buffer->state.diagnostic_count; 
v5 = *( _OWORD *)&buffer->state.cursor; 
v4 = *( _OWORD *)&buffer->state.indent_skip; 
v3 = *( _OWORD *)&buffer->state.prefix; 
*( _OWORD *)&buffer->state.diagnostic_count[4] = v7; 
*( _OWORD *)buffer->state.diagnostic_count = v6; 
*( _OWORD *)&buffer->state.cursor = v5; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
fatal_insn_not_found( insn, "insn-attrtab.c", 6314, "ppro_p2_unit_ready_cost"); 
return &arg0; 
tree v22; // rax 
tree v23; // rax 
tree v24; // rax 
tree v25; // rax 
tree v26; // [rsp+0h] [rbp-48h] 
tree v27; // [rsp+8h] [rbp-40h] 
tree v28; // [rsp+10h] [rbp-38h] 
if ( ( _DWORD)v8 == 46 || ( sch_istable[( unsigned __int8)v8] & 4) != 0 ) 
while ( ( sch_istable[v8] & 4) != 0 ); 
insn = peep2_insn_data_0[v1].insn; 
rtvec v16; // rax 
v5 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
v16 = rtvec_alloc( rtvec->num_elem); 
v5->fld[v13].rtwint = ( __int64)v16; 
if ( v16->num_elem > 0 ) 
return new_loc_descr( ( dwarf_location_atom)( i + 48), i, 0LL); 
rtx real_insn; // rbx 
real_insn = next_real_insn( rtx); 
return real_insn == next_real_insn( v2->fld[0].rtx); 
( machine_mode)*( unsigned __int8 *)( v16.rtwint + 2), 
( machine_mode)BYTE2( v4)); 
rtx v14; // rcx 
v14 = function_tail_eff_head; 
if ( v14 ) 
*( _QWORD *)&v14[1] = rtx; 
if ( !reg_note ) 
if ( *( __int64 *)( reg_note->fld[0].rtwint + 8) > 4999 ) 
real_value_truncate( &v3, ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1), value); 
*( _OWORD *)&cfa.offset = 0LL; 
cfa_temp_0 = -1LL; 
v19 = dwarf2out_cfi_label_label_num++; 
sprintf( dwarf2out_cfi_label_label, "*.%s%u", "LCFI", v19); 
assemble_name( ( FILE *)asm_out_file, dwarf2out_cfi_label_label); 
dwarf2out_frame_debug_expr( *fld, dwarf2out_cfi_label_label); 
v4 = -args_size_0; 
v5 = args_size_0 + v4; 
args_size_0 = v5; 
v6 = dwarf2out_cfi_label_label_num++; 
sprintf( dwarf2out_cfi_label_label, "*.%s%u", "LCFI", v6); 
assemble_name( ( FILE *)asm_out_file, dwarf2out_cfi_label_label); 
def_cfa_1( dwarf2out_cfi_label_label, &cfa); 
v7 = args_size_0; 
if ( old_args_size != args_size_0 ) 
sprintf( producer, "%s %s", lang_hooks_0.name, version_string); 
if ( !strcmp( lang_hooks_0.name, "GNU C++") ) 
else if ( !strcmp( lang_hooks_0.name, "GNU Ada") ) 
else if ( !strcmp( lang_hooks_0.name, "GNU F77") ) 
else if ( !strcmp( lang_hooks_0.name, "GNU Pascal") ) 
else if ( !strcmp( lang_hooks_0.name, "GNU Java") ) 
v10 = _mm_add_epi32( _mm_load_si128( ( const __m128i *)&xmm*(short *)0x7203E0), v9); 
v11 = _mm_add_epi32( _mm_load_si128( ( const __m128i *)&xmm*(short *)0x7203F0), v9); 
v12 = _mm_add_epi32( _mm_load_si128( ( const __m128i *)&xmm*(short *)0x720400), v9); 
v13 = _mm_add_epi32( v9, ( __m128i)xmm*(short *)0x720410); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x720420); 
v17 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x720430); 
v24 = _mm_add_epi64( _mm_shuffle_epi32( ( __m128i)v7, 68), ( __m128i)xmm*(short *)0x68FC00); 
v26 = _mm_shuffle_pd( ( __m128d)reg_set, ( __m128d)xmm*(short *)0x68FC00, 2); 
v30 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x6682A0); 
v31 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x668290); 
v32 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v3 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v4 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v5 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v15 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v19 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
diagnostic_buffer->state.format_args = ( va_list_0 *)va; 
*( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4] = v19; 
*( _OWORD *)v10->state.diagnostic_count = v18; 
induction_1 *v; // [rsp+0h] [rbp-20h] 
induction_1 *v; // [rsp+0h] [rbp-20h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( *( ( _WORD *)v + 50) & 1) == 0 && ( ( *( ( _WORD *)v + 50) >> 1) & 1) == 0 ) 
if ( ( *( ( _WORD *)v + 50) & 1) == 0 && ( ( *( ( _WORD *)v + 50) >> 1) & 1) == 0 ) 
check_final_value( loop, v); 
formal_list = ( char *)&arg0; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
rtx v2; // rbx 
v2 = rtx; 
if ( *( _WORD *)v2 == 35 ) 
nonnote_insn = prev_nonnote_insn( v2); 
if ( *( _WORD *)v2 != 35 ) 
delete_insn( v2); 
else if ( nonnote_insn != (  struct rtx_def *)v2[1] ) 
reorder_insns( v2, v2, nonnote_insn); 
reorder_insns( v2, v2, nonnote_insn); 
if ( mode_class_0[mode] != MODE_COMPLEX_INT ) 
v13 = mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v6 = invert_tree_comparison( ( tree_code)*( ( unsigned __int8 *)&arg->block.common + 16)); 
v9 = *( _OWORD *)&arg->block.vars; 
if ( ( sch_istable[v9] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v9] & 4) != 0 ) 
while ( ( sch_istable[( unsigned __int8)v9] & 4) != 0 ); 
v5 = rtuint + ( ( unsigned int)( mode_class_0[( unsigned __int8)v4] - 5) < 2) + 1; 
fatal_insn_not_found( insn, "insn-attrtab.c", 5131, "k6_load_unit_blockage_range"); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2a; 
if ( ( target_flags & 1) != 0 && ix86_unary_operator_ok( NEG, TFmode, recog_data_0.operand) && pnum_clobbers ) 
recog_data_0.operand[1] = x2c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[0] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2c; 
&& ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[0] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2b; 
if ( ( target_flags & 1) != 0 && ix86_unary_operator_ok( ABS, TFmode, recog_data_0.operand) && pnum_clobbers ) 
recog_data_0.operand[1] = x1b; 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v3 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v3); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v3 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v3); 
v33 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v31); 
v30 = swap_condition( ( rtx_code)*( _WORD *)v25); 
if ( *( _OWORD *)arg0 != 0LL ) 
v7 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v8 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v10 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v5, operands[2], operands[3]); 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
rtx v17; // rdi 
rtx v18; // rsi 
rtx v51; // rdi 
n_operands = ( unsigned __int8)recog_data_0.n_operands; 
if ( !recog_data_0.n_operands || !recog_data_0.n_alternatives ) 
if ( !recog_data_0.n_operands || !recog_data_0.n_alternatives ) 
if ( recog_data_0.n_operands > 0 ) 
memset( s, 255, 4LL * ( unsigned __int8)recog_data_0.n_operands); 
memcpy( dest, recog_data_0.constraints, 8 * n_operands); 
rtx = recog_data_0.operand[v3]; 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v11), 
( machine_mode)BYTE2( v9)); 
v17 = recog_data_0.operand[v14]; 
v17 = recog_data_0.operand[v14]; 
v18 = recog_data_0.operand[v3]; 
rtx v19; // r15 
rtx v22; // rax 
rtx *p_rtl; // r15 
rtx *v26; // rax 
rtx v31; // rax 
v13 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v19 = assign_temp( decl, 1, 1, 1); 
set_mem_attributes( v19, decl, 1); 
decl->decl.rtl = v19; 
if ( !v19 ) 
v19 = decl->decl.rtl; 
v20 = force_operand( v19->fld[0].rtx, rtx); 
( save_level)( x_block_stack->next == 0LL), 
v12 = gen_rtx_MEM( ( machine_mode)LOBYTE( decl->block.supercontext), dynamic_stack_space); 
v21 = promote_mode( type, ( machine_mode)( unsigned __int8)v5, punsignedp, 0); 
timevar_push( TV_LEX_0); 
v1 = cpp_type2name( ( cpp_ttype)v0); 
timevar_pop( TV_LEX_0); 
fatal_insn_not_found( insn, "insn-attrtab.c", 9038, "fpu_unit_blockage_range"); 
v14 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), fixed); 
v15 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v14); 
v14 = force_reg( ( machine_mode)BYTE2( v6), v4); 
v12 = mode_class_0[BYTE2( v6)]; 
v19 = mode_class_0[v18]; 
v30 = mode_class_0[v29]; 
*( _OWORD *)htab = 0LL; 
*( _OWORD *)ptr = 0LL; 
lang_hooks_0.tree_inlining.add_pending_fn_decls( &va, v6); 
v0 = edge_info_0; 
v3 = edge_info_0; 
memset( ( char *)&stack_arg_under_construction + i, 0, v0); 
memset( &( &libiberty_nptr)[i / 8], 0, v0); 
if ( ( ( reaching_defs[*( int *)( basic_block_for_insn->data.l[insn->fld[0].rtint] + 88)]->elms[*( ( _DWORD *)uid_cuid_1 
+ def_insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * def_insn->fld[0].rtint) & 0x3F)) & 1) != 0 ) 
if ( *( ( _DWORD *)uid_cuid_1 + def_insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) ) 
if ( *( ( _DWORD *)uid_cuid_1 + def_insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) ) 
rtx *loc; // [rsp+0h] [rbp-58h] 
rtx pattern; // [rsp+18h] [rbp-40h] 
rtx after; // [rsp+20h] [rbp-38h] 
v6 = table[canon_hash( *( rtx *)&x[1], ( machine_mode)BYTE2( v3)) & 0x1F]; 
loc = ( rtx *)&x[1]; 
v10 = *loc; 
v11 = *( _DWORD *)*loc; 
|| ( v13 = BYTE2( v11), mode_class_0[v13] != MODE_INT) 
|| ( v14 = BYTE2( v12), mode_class_0[v14] != MODE_INT) 
|| !subreg_lowpart_p( *loc) ) 
rtx v7; // rbx 
rtx v9; // rbx 
rtx inline_target; // rcx 
rtx v33; // rbp 
rtx v34; // rax 
rtx v49; // rax 
v9 = ( rtx)rtx[2]; 
v9 = single_set_2( rtx, *( rtx *)&rtx[2]); 
v9 = 0LL; 
inline_target = map->inline_target; 
if ( v9 && !inline_target && ( *( _DWORD *)v9->fld[0].rtwint & 0x4000FFFF) == 1073741885 ) 
rtx v19; // rax 
rtx v26; // rax 
rtx v28; // rbx 
rtx v69; // r13 
rtx *v70; // r15 
rtx v71; // rax 
rtx nonnote_insn; // rax 
rtx v75; // rbp 
rtx *v80; // rbx 
rtx *fld; // r12 
rtx *v83; // rbp 
verbatim( off_690140, v1); 
rtx v15; // rdx 
v15 = head; 
v15 = ( rtx)head[1]; 
if ( v15 != bb_note && v15[1].fld[0].rtx != bb_note ) 
if ( v15 != bb_note && v15[1].fld[0].rtx != bb_note ) 
reorder_insns( bb_note, bb_note, v15); 
if ( **( _WORD **)&this_insn_0[2] == 39 ) 
if ( multiple_sets( this_insn_0) ) 
v5 = *( unsigned int **)( *( _QWORD *)&this_insn_0[2] + 8LL); 
v7 = *( _QWORD *)( *( _QWORD *)( *( _QWORD *)&this_insn_0[2] + 8LL) + 8 * v6); 
v13 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v21 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v19), 80), ( __m128i)xmm*(short *)0x65AE30); 
v23 = ( __m128i)_mm_shuffle_pd( ( __m128d)regs_live, ( __m128d)xmm*(short *)0x68FC00, 2); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v27 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
v6 = transp_0[src->index]; 
rtx insn; // [rsp+48h] [rbp-28h] 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
if ( insn ) 
v4 = insn != ( rtx)bb->head[1]; 
uid = insn->fld[0].rtuint; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
rtx result; // rax 
result = simplify_binary_operation( code, mode, v12, v4); 
if ( !result ) 
result = simplify_relational_operation( code, v9, rtx, v4); 
if ( !result ) 
result = simplify_binary_operation( code, mode, op0, op1); 
if ( !result ) 
return result; 
expr_0->reaching_reg = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v0->fld[0].rtwint)); 
rtx v10; // rcx 
v10 = added_links_insn; 
while ( *( _WORD *)v10 == 32 && **( _WORD **)&v10[2] == 48 ) 
while ( *( _WORD *)v10 == 32 && **( _WORD **)&v10[2] == 48 ) 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
rtint = v10->fld[0].rtint; 
v12 = ( tree_node *)*( &global_trees + 26); 
v15 = *( tree_node **)&f[2 * v7 + 2]; 
values = *( tree_node **)&f[2 * v8 + 2]; 
v10 = *( tree_node **)&f[2 * v7 + 2]; 
v11 = ( tree_node **)&f[2 * v7 + 4]; 
( machine_mode)BYTE2( v7), 
*( ( reg_class *)&regclass_map + v5->fld[0].rtuint), 
v8 = ix86_memory_move_cost( ( machine_mode)BYTE2( v7), class2, 1); 
v10 = cselib_lookup( v5, ( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 0); 
( machine_mode)BYTE2( v15), 
*( ( reg_class *)&regclass_map + loc->fld[0].rtuint), 
run->base = ( cpp_token_0 *)xmalloc( 24LL * count); 
else if ( section_name == ( tree_node *)*( &global_trees + 10) ) 
v8 = ( tree_node *)*( &global_trees + 5); 
else if ( section_name == ( tree_node *)*( &global_trees + 9) ) 
v8 = ( tree_node *)*( &global_trees + 4); 
else if ( section_name == ( tree_node *)*( &global_trees + 8) ) 
v8 = ( tree_node *)*( &global_trees + 3); 
else if ( section_name == ( tree_node *)*( &global_trees + 7) ) 
v8 = ( tree_node *)*( &global_trees + 2); 
v7 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)old_reg + 2)); 
v15 = simplify_and_const_int( 0LL, ( machine_mode)BYTE2( v12), v5->fld[0].rtx, v10); 
v16 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), *( rtx *)&v5[1], v10); 
result[1] = ( rtx_def)_mm_load_si128( &v9); 
( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
( __m128i)xmm*(short *)0x8021E0), 
( __m128d)xmm*(short *)0x8021F0); 
v6 = ( tree_node *)global_trees; 
v6 = ( tree_node *)global_trees; 
alias_set = lang_hooks_0.get_alias_set( elements); 
v20 = ++new_alias_set_last_alias_set; 
alias_set = lang_hooks_0.get_alias_set( section_name); 
alias_set = ++new_alias_set_last_alias_set; 
result->val.node = ( cpp_hashnode_0 *)source; 
fatal_insn_not_found( insn, "insn-attrtab.c", 4923, "k6_load_unit_ready_cost"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && ix86_cpu == PROCESSOR_K6 
|| !memory_operand( recog_data_0.operand[0], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( !which_alternative && memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( which_alternative == 1 && memory_operand( recog_data_0.operand[1], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && ix86_cpu == PROCESSOR_K6 ) 
if ( constant_call_address_operand( recog_data_0.operand[0], VOIDmode) || ix86_cpu != PROCESSOR_K6 ) 
if ( constant_call_address_operand( recog_data_0.operand[1], VOIDmode) || ix86_cpu != PROCESSOR_K6 ) 
v8 = ( tree_node *)*( &global_trees + 15); 
arg0 = ( tree_node *)*( &global_trees + 17); 
rtx v17; // rbp 
rtx *v21; // rbx 
rtx v23; // rbx 
rtx v26; // r13 
v8 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v17 = gen_label_rtx( ); 
*( ( _BYTE *)v17 + 3) |= 0x10u; 
v18 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v17); 
v18 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v17); 
emit_label( v17); 
v13 = gen_rtx_fmt_ee( EXPR_LIST, VOIDmode, v17, arg1a); 
v21 = &cfun->x_nonlocal_goto_handler_slots; 
v23 = *v21; 
rtx v9; // r12 
rtx v14; // rax 
v9 = a->end; 
v9 = ( rtx)v5[1]; 
if ( *( _WORD *)v9 == 37 ) 
*( _OWORD *)&b->pred = 0LL; 
v14 = delete_insn( v5); 
v5 = v14; 
end = v9; 
while ( v9 != end ) 
v18 = v9->fld[0].rtint; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
*( _OWORD *)( xi + 1) = 0LL; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)BYTE2( v9), const_int_rtx[64]); 
v20 = aAddChildDie[11]; 
if ( aAddChildDie[11] == 101 ) 
( machine_mode)BYTE2( v40), 
( machine_mode)*( unsigned __int8 *)( v8->fld[0].rtwint + 2)); 
( machine_mode)BYTE2( v40), 
( machine_mode)*( unsigned __int8 *)( v8->fld[0].rtwint + 2), 
v4 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
*( _OWORD *)&v31[1] = 0LL; 
if ( qty_0[v8].n_calls_crossed > 0 ) 
if ( !qty_0[v8].n_calls_crossed ) 
n_calls_crossed = qty_0[v79].n_calls_crossed; 
if ( 4 * n_calls_crossed < qty_0[v79].n_refs ) 
if ( ( unsigned int)( mode_class_0[v73] - 5) >= 2 ) 
if ( ( unsigned int)( mode_class_0[v73] - 5) > 1 ) 
v39 = ( ( unsigned int)( mode_class_0[v73] - 5) < 2) + 1; 
v44 = _mm_add_epi32( _mm_shuffle_epi32( _mm_cvtsi32_si128( v39), 80), ( __m128i)xmm*(short *)0x65AE30); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v48 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE40); 
if ( file != build_expr_wfl_last_file ) 
build_expr_wfl_last_file = file; 
build_expr_wfl_last_filenode = identifier; 
wfl->int_cst.int_cst.high = ( __int64)build_expr_wfl_last_filenode; 
result = get_varargs_alias_set_set; 
if ( get_varargs_alias_set_set == -1 ) 
result = new_alias_set_last_alias_set + 1; 
new_alias_set_last_alias_set = result; 
get_varargs_alias_set_set = result; 
get_varargs_alias_set_set = 0LL; 
rtx v35; // rax 
rtx nonnote_insn; // rax 
rtx v43; // rax 
rtx v46; // rcx 
rtx v68; // rax 
rtx v77; // rax 
rtx pool_constant; // r15 
if ( ( sch_istable[*v4] & 4) == 0 ) 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
if ( in_section_0 != in_data ) 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
if ( in_section_0 == in_const ) 
if ( *( _OWORD *)&outputs != 0LL ) 
rtx last_value; // rax 
v10 = mode_class_0[( int)v2]; 
v11 = mode_class_0[v5]; 
last_value = get_last_value( v7); 
if ( last_value ) 
v3 = *( _DWORD *)last_value; 
v5 = ( unsigned __int8)BYTE2( *( _DWORD *)last_value); 
LODWORD( v2) = ( unsigned __int8)BYTE2( *( _DWORD *)last_value); 
v7 = last_value; 
|| ( v65 = nonzero_bits( v7, ( machine_mode)v2), _bittest64( &v65, ( unsigned __int8)( v12 - 1))) ) 
v23 = num_sign_bit_copies( v38, ( machine_mode)v2); 
v27 = num_sign_bit_copies( *( rtx *)&v7[1], ( machine_mode)v2); 
v30 = num_sign_bit_copies( v7->fld[0].rtx, ( machine_mode)v2); 
return v8 + copy_cost_0( x, mode, ( reg_class)v7, 2); 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v3 >> 14) & 0x3FC)) == MODE_FLOAT ) 
rtx v49; // rcx 
rtx v52; // rdx 
rtx v56; // rdx 
v49 = global_rtl[4]; 
v52 = v44[2].to_rtx; 
if ( v52 == v53 && v53 != v49 ) 
if ( v52 == v53 && v53 != v49 ) 
if ( *( _WORD *)v54 == 75 && *( rtx *)( v54 + 8) == v52 && ( v55 = *( _QWORD *)( v54 + 16), *( _WORD *)v55 == 54) ) 
v56 = v44[3].to_rtx; 
if ( v56 == v57 && v57 != v49 ) 
if ( v56 == v57 && v57 != v49 ) 
if ( !count_error_warning_message ) 
count_error_warning_message = 1; 
v5 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v6 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v7 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v8 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v9 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
*( _OWORD *)&diagnostic_buffer->state.cursor = *( _OWORD *)&dc->message; 
*( _OWORD *)&diagnostic_buffer->state.cursor = *( _OWORD *)&dc->message; 
tree type; // [rsp+88h] [rbp-78h] 
tree p; // [rsp+90h] [rbp-70h] 
tree fndecla; // [rsp+B8h] [rbp-48h] 
tree actparmsa; // [rsp+C0h] [rbp-40h] 
actparmsa = actparms; 
fndecla = fndecl; 
temp = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)); 
return expand_unop( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), optab_table[17], x, temp, 0); 
rtx v6; // rbx 
rtx *fld; // r13 
v6 = first; 
fld = ( rtx *)first[1].fld; 
v6 = *fld; 
v6 = *fld; 
fld = ( rtx *)v6[1].fld; 
v8.rtwint = ( __int64)v6[1].fld[0]; 
set_block_for_insn( v6, v4); 
v4->end = v6; 
v6 = rtx; 
v6[1].fld[0] = v9; 
*( _QWORD *)( v9.rtwint + 16) = v6; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1b; 
if ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[0] != 66 
|| ( unsigned __int16)*( _DWORD *)recog_data_0.operand[1] != 66 ) 
recog_data_0.operand[0] = x2c; 
recog_data_0.operand[1] = x1c; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2e; 
recog_data_0.operand[1] = x2d; 
recog_data_0.operand[0] = x1; 
htab_empty( hash_table_0); 
if ( ( sch_istable[( unsigned __int8)v8] & 0x10) != 0 ) 
v16 = byte_67FFC0[v15]; 
v16 = byte_67FFC0[v15]; 
v19 = byte_67FFC0[v13]; 
if ( byte_67FFC0[v13] ) 
validate_change( insn, recog_data_0.operand_loc[match_number], src, 1); 
fprintf( file, "; pref %s", dump_flow_info_reg_class_names[v13]); 
v15 = dump_flow_info_reg_class_names[v13]; 
fprintf( file, "; pref %s, else %s", v15, dump_flow_info_reg_class_names[v14]); 
rttree = ( tree_node *)tem[6]; 
v3 = QCameraExposure::setAutoIsoSensitivity( ( tree)tem); 
if ( !do_warn || ( doing_eh_warned & 1) != 0 ) 
doing_eh_warned = 1; 
*( _OWORD *)( ( char *)&replacements[0].where + 3 * v7) = *( _OWORD *)&v4->where; 
*( _OWORD *)( ( char *)&replacements[0].where + 3 * v7) = *( _OWORD *)&v4->where; 
v3 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
v3 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
v3 = ( int)( ( double)( qty_0[q2].size * qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs)) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth) 
- ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
- ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
- ( int)( ( double)( qty_0[q1].size * qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs)) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth) 
v8 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operand1->fld[0].rtx); 
v9 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operand2->fld[0].rtx); 
v13 = *( _OWORD *)&buffer->state.diagnostic_count[4]; 
v2 = *( _OWORD *)&buffer->state.prefix; 
v3 = *( _OWORD *)&buffer->state.indent_skip; 
v4 = *( _OWORD *)&buffer->state.cursor; 
v12 = *( _OWORD *)buffer->state.diagnostic_count; 
*( _OWORD *)&buffer->state.prefix = 0LL; 
buffer->state.format_args = ( va_list_0 *)va; 
*( _OWORD *)&buffer->state.diagnostic_count[4] = v13; 
*( _OWORD *)buffer->state.diagnostic_count = v12; 
if ( use == sibcall_use_normal_0 ) 
else if ( use == sibcall_use_sibcall_0 ) 
if ( use != sibcall_use_tail_recursion_0 ) 
hard_reg_initial_vals->entries = ( initial_value_pair_0 *)xmalloc( 0x50uLL); 
entries = ( initial_value_pair_0 *)xrealloc( hard_reg_initial_vals->entries, 16 * v9); 
result = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
&& ( lang_hooks_0.tree_inlining.disregard_inline_limits( fna) || 10 * fna->decl.u1.i <= compiler_params->value / 2) ) 
if ( !lang_hooks_0.tree_inlining.disregard_inline_limits( fna) ) 
if ( inlinable && lang_hooks_0.tree_inlining.cannot_inline_tree_fn( &fna) ) 
if ( ( unsigned int)( mode_class_0[v3] - 5) >= 2 ) 
*( _OWORD *)p_pred = 0LL; 
v1 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
for ( i = recog_data_0.n_operands - 1; i >= 0; --i ) 
if ( ( unsigned __int16)*( _DWORD *)recog_data_0.operand[i] == 66 ) 
return modified_in_p( recog_data_0.operand[i]->fld[0].rtx, dep_insn); 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2be; 
if ( ix86_match_ccmode( insn, CCGCmode) && ( unsigned __int8)recog_data_0.operand[2]->fld[0].rtwint != 128LL ) 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bf; 
|| !rtx_equal_p( x2bg->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bg[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, QImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2c->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2c[1], recog_data_0.operand[2]) 
rtx base_value; // rax 
rtx v10; // rax 
base_value = find_base_value( rtx->fld[0].rtx); 
if ( base_value ) 
v2 = base_value; 
v10 = find_base_value( v4); 
if ( v10 ) 
v4 = v10; 
*( _OWORD *)&v7->left = 0LL; 
v16 = ( v15 - 1 < 0) ^ __OFADD__( -1LL, v15) | ( v15 == 1); 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_VERBOSE ) 
rtx v42; // rbp 
rtx v46; // rdx 
rtx v47; // rsi 
rtx v50; // rax 
rtx v62; // rax 
rtx v64; // rbp 
rtx v68; // rax 
rtx v71; // rax 
rtx v80; // rax 
*( ( _OWORD *)&newdecl->block + 10) = *( ( _OWORD *)&olddecl->block + 10); 
*( ( _OWORD *)&newdecl->block + 10) = *( ( _OWORD *)&olddecl->block + 10); 
|| mode_class_0[v28] != MODE_INT 
recog_data_0.operand[0] = x3; 
recog_data_0.operand[1] = ( rtx)x1[1]; 
recog_data_0.operand[2] = x3b; 
recog_data_0.operand[0] = x3; 
recog_data_0.operand[1] = ( rtx)x1[1]; 
recog_data_0.operand[2] = x3d; 
recog_data_0.operand[0] = x2e; 
recog_data_0.operand[0] = x2e; 
recog_data_0.operand[0] = x2f; 
if ( rtx_equal_p( *( rtx *)&x2h[1], recog_data_0.operand[0]) ) 
if ( rtx_equal_p( x1f->fld[0].rtx, recog_data_0.operand[0]) 
free_buffs = ( _cpp_buff_0 *)&v11[v10]; 
rtx v39; // r13 
rtx v41; // rax 
rtx v42; // rbp 
rtx v71; // rax 
rtx x; // [rsp+18h] [rbp-3140h] BYREF 
x = *( rtx *)( v27 + 16); 
v28 = *( _WORD *)x; 
for_each_rtx( &x, mark_reg_in_phi, element); 
bitmap_set_bit( element, x->fld[0].rtint); 
v39 = v31[5]; 
htab_clear_slot( hash_table_0, x); 
cpp_register_pragma( parse_in, 0LL, "pack", ( pragma_cb)handle_pragma_pack); 
cpp_register_pragma( parse_in, 0LL, "weak", ( pragma_cb)handle_pragma_weak); 
rtx address; // rcx 
address = temp_slot_from_address->address; 
if ( address ) 
if ( *( _WORD *)address != 3 ) 
address = gen_rtx_fmt_ee( EXPR_LIST, VOIDmode, temp_slot_from_address->address, 0LL); 
v11->address = address; 
v2 = gen_rtx_fmt_ee( EXPR_LIST, VOIDmode, v2, address); 
tree_code_length[1] = ( lang_hooks_0.identifier_size - 24 + 7) >> 3; 
if ( debug_info_level_0 != DINFO_LEVEL_NORMAL ) 
if ( debug_info_level_0 != DINFO_LEVEL_VERBOSE ) 
*( _OWORD *)&next->buff = 0LL; 
if ( ( v2 & 0xFF0000) == 0 && v3 && ( mode_class_0[v3] | 2) != 3 ) 
|| mode_class_0[v3] == MODE_FLOAT && mode_size[v3] > mode_size[BYTE2( v2)] ) 
&& ( *( _WORD *)v9 == 70 || legitimate_address_p( ( machine_mode)BYTE2( v2), v9, 0)) ) 
rtx v7; // rax 
v7 = gen_rtx_fmt_e0( MEM, v6, rtx); 
*( _QWORD *)&v7[1] = 0LL; 
v8 = *( _DWORD *)memref & 0x8000000 | *( _DWORD *)v7 & 0xF7FFFFFF; 
*( _DWORD *)v7 = v8; 
*( _DWORD *)v7 = v9; 
*( _DWORD *)v7 = v10; 
*( _DWORD *)v7 = v11; 
*( _DWORD *)v7 = *( _DWORD *)memref & 0x1000000 | v11 & 0xFEFFFFFF; 
*( _QWORD *)&v7[1] = memref[1]; 
return v7; 
v5 = classify_argument( ( machine_mode)v2, type, v9, 0); 
if ( ( _DWORD)v2 != 51 && ( ( unsigned int)( mode_class_0[v2] - 7) > 1 || int_size_in_bytes( type) != 8) ) 
if ( ( _DWORD)v4 == 6 || ( _DWORD)v4 == 18 || ( unsigned int)( mode_class_0[v4] - 7) <= 1 ) 
sprintf( ( char *)&v11[-4], "%s.%d", "__compound_literal", ( unsigned int)var_labelno); 
++var_labelno; 
v8 = mode_class_0[mode]; 
( reload_type)v12, 
fatal_insn_not_found( insn, "insn-attrtab.c", 20460, "get_attr_prefix_data16"); 
v5 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v6] - 5) < 2) + rtuint; 
if ( debug_info_level_0 != DINFO_LEVEL_TERSE || !deptha ) 
rtx v23; // rax 
v23 = gen_rtx_CONST_INT( VOIDmode, *( _QWORD *)( v20 + 8) * v17); 
v25 = v23; 
rtx v20; // rcx 
fatal_insn_not_found( insn, "insn-attrtab.c", 20323, "get_attr_prefix_0f"); 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
rtx = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
rtx = recog_data_0.operand[0]->fld[0].rtx; 
v8 = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
v8 = recog_data_0.operand[0]->fld[0].rtx; 
v20 = recog_data_0.operand[0]; 
v20 = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
v20 = recog_data_0.operand[0]->fld[0].rtx; 
v20 = recog_data_0.operand[0]->fld[0].rtx; 
v21 = v19->data.i[v20->fld[0].rtint]; 
( *direction)[13 * loop_ptr->depth + sub] = eq; 
( *direction)[13 * loop_ptr->depth + sub] = lt; 
( *direction)[13 * loop_ptr->depth + sub] = gt; 
( *direction)[13 * loop_ptr->depth + sub] = independent; 
rtx x; // [rsp+8h] [rbp-C0h] BYREF 
rtx data[2]; // [rsp+10h] [rbp-B8h] BYREF 
data[0] = ( rtx)&v10; 
x = insns; 
data[1] = rtx; 
for_each_rtx( &x, insns_for_mem_walk, data); 
for_each_rtx( &x, insns_for_mem_walk, data); 
rtx = x; 
x = rtx; 
for ( v5.rtwint = ( __int64)v1[3].fld[0]; ; v5.rtwint = ( __int64)data[0][1] ) 
data[0] = v5.rtx; 
rtx insn; // [rsp+40h] [rbp-20h] 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; ; insn = insn[1].fld[0].rtx ) 
if ( insn ) 
v3 = insn != bb->end[1].fld[0].rtx; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
for ( def_link = df_0->insns[insn->fld[0].rtuint].defs; def_link; def_link = def_link->next ) 
if ( *( _OWORD *)current->bits == 0LL ) 
rtx *p_x_last_insn; // r14 
( machine_mode)*( unsigned __int8 *)( v26.rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( v26.rtwint + 2), 
v1 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
file_table_0.table = ( char **)xcalloc( 0x40uLL, 8uLL); 
file_table_0.allocated = 64; 
file_table_0.in_use = 1; 
file_table_0.last_lookup_index = 0; 
LOBYTE( v16) = canon_hash( x, ( machine_mode)BYTE2( v3)); 
v36 = ( ( unsigned int)( mode_class_0[v35] - 5) < 2) + 1; 
v69 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v68] - 5) < 2) + 1; 
fprintf( file, off_6474F4, ( unsigned int)i); 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3g; 
recog_data_0.operand[2] = x3h; 
recog_data_0.operand[2] = x2i; 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x2j; 
recog_data_0.operand[1] = x3j; 
recog_data_0.operand[2] = x3k; 
recog_data_0.operand[2] = x2l; 
recog_data_0.operand[1] = x3l; 
recog_data_0.operand[2] = x3m; 
recog_data_0.operand[2] = x2n; 
recog_data_0.operand[0] = x2; 
v16 = operand_sub*(short *)0xforce( op0, v11, v15); 
v33 = expand_binop( v27, optab_table[21], v24, v31, 0LL, 0, ( optab_methods)methods); 
v40 = expand_binop( v34, optab_table[23], v24, v38, 0LL, 0, ( optab_methods)v39); 
induction_1 *v; // [rsp+88h] [rbp-28h] 
induction_1 *v; // [rsp+88h] [rbp-28h] 
for ( v = bl_0->biv; ; v = v->next_iv ) 
for ( v = bl_0->biv; ; v = v->next_iv ) 
for ( v = bl_0->biv; ; v = v->next_iv ) 
v10 = v != 0LL; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)v->insn] == 105 ) 
if ( ( unsigned __int16)**( _DWORD **)&v->insn[2] == 47 ) 
v9 = ( rtx)v->insn[2]; 
v9 = single_set_2( v->insn, *( rtx *)&v->insn[2]); 
v9 = single_set_2( v->insn, *( rtx *)&v->insn[2]); 
*( _OWORD *)( aux + 8) = 0LL; 
*( _OWORD *)&result->count = 0LL; 
*( _OWORD *)&result->aux = 0LL; 
*( _OWORD *)&result->global_live_at_start = 0LL; 
*( _OWORD *)&result->local_set = 0LL; 
*( _OWORD *)&result->pred = 0LL; 
*( _OWORD *)&result->head_tree = 0LL; 
*( _OWORD *)&result->head = 0LL; 
v10 = mode_class_0[( unsigned __int8)v8]; 
loop_ptr = ( loop_1 *)*( ( _QWORD *)&loop_chain->name + loop_chain->elements_used); 
rtx v4; // rax 
rtx *elem; // rbp 
rtx v15; // r13 
rtx v16; // rax 
elem = v9->elem; 
*elem = rtl; 
v15 = gen_realpart( ( machine_mode)*( unsigned __int8 *)( rtl->fld[0].rtwint + 2), rtl); 
v15 = gen_realpart( ( machine_mode)*( unsigned __int8 *)( rtl->fld[0].rtwint + 2), rtl); 
v16 = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)v15 + 2), rtl); 
v16 = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)v15 + 2), rtl); 
v16 = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)v15 + 2), rtl); 
if ( *( _WORD *)v15 == 61 ) 
parmdecl_map[v15->fld[0].rtuint] = arguments; 
rtx v7; // rbp 
v7 = insn_queue[( ( _BYTE)v6 + ( _BYTE)q_ptr) & 0x7F]; 
if ( v7 ) 
v8 = v7->fld[0].rtx; 
v7 = ( rtx)v7[1]; 
while ( v7 ); 
highest_order_field_bit_offset = QCameraExposure::setAutoIsoSensitivity( decl); 
_OWORD *v10; // rax 
_OWORD *v10; // rax 
rtx regno_note; // rax 
rtx insns; // rax 
rtx v295; // rax 
if ( *( _BYTE *)( v3 + 9981631) || byte_9AA96F[v3] ) 
v10 = xmalloc( 4 * v5); 
reg_allocno = v10; 
*v10 = -1LL; 
v10[1] = -1LL; 
v10[2] = -1LL; 
v10[3] = -1LL; 
v10[4] = -1LL; 
v10[5] = -1LL; 
v10[6] = -1LL; 
v10[7] = -1LL; 
global_trees = ( splay_tree_value)make_node( ERROR_MARK); 
*( &global_trees + 1) = ( splay_tree_value)make_signed_type( mode_bitsize[2]); 
*( &global_trees + 2) = ( splay_tree_value)make_signed_type( mode_bitsize[3]); 
*( &global_trees + 3) = ( splay_tree_value)make_signed_type( mode_bitsize[4]); 
*( &global_trees + 4) = ( splay_tree_value)make_signed_type( mode_bitsize[5]); 
*( &global_trees + 5) = ( splay_tree_value)make_signed_type( mode_bitsize[6]); 
*( &global_trees + 6) = ( splay_tree_value)make_unsigned_type( mode_bitsize[2]); 
*( &global_trees + 7) = ( splay_tree_value)make_unsigned_type( mode_bitsize[3]); 
*( &global_trees + 8) = ( splay_tree_value)make_unsigned_type( mode_bitsize[4]); 
*( &global_trees + 9) = ( splay_tree_value)make_unsigned_type( mode_bitsize[5]); 
*( &global_trees + 10) = ( splay_tree_value)make_unsigned_type( mode_bitsize[6]); 
set_0 sets[106]; // [rsp+30h] [rbp-D50h] BYREF 
sets[0].src = ( rtx)body[1]; 
sets[0].dest = body->fld[0].rtx; 
sets[n_sets].src = ( rtx)x[1]; 
sets[n_sets++].dest = x->fld[0].rtx; 
dest = sets[i].dest; 
sets[i].dest = dest; 
src = sets[i].src; 
src = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)src), cond, src, dest); 
v1 = cselib_lookup( src, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)dest), 1); 
sets[i].src_elt = v1; 
sets[i].dest_addr_elt = v3; 
return gen_rtx_CONST_INT( ( machine_mode)c, v2); 
for ( dep_ptr = ( dependence_0 *)dep_chain->data.l[0]; dep_ptr; dep_ptr = ( dependence_0 *)dep_chain->data.l[v1] ) 
for ( dep_ptr = ( dependence_0 *)dep_chain->data.l[0]; dep_ptr; dep_ptr = ( dependence_0 *)dep_chain->data.l[v1] ) 
bi = ( block_info_0)b->aux; 
if ( memory_address_p( ( machine_mode)v5, v10) ) 
return adjust_address_1( v4.rtx, ( machine_mode)v5, v6, 1, 1); 
v7 = adjust_address_1( v4.rtx, ( machine_mode)v5, v6, 1, 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
&& *( const mode_class *)( ( char *)mode_class_0 + ( ( v24 >> 14) & 0x3FC)) != MODE_INT ) 
v32 = operand_sub*(short *)0xforce( v16, v31, mode); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
if ( ( *( _BYTE *)( v9.rtwint + 16) | 2) == 15 && *( tree_node **)( *( _QWORD *)( v9.rtwint + 8) + 128LL) == section_name ) 
result = *( insn_code *)( ( char *)&fixtrunctab[0][0][v5] + v6); 
return *( insn_code *)( ( char *)&fixtab[0][0][v5] + v6); 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 29148, "ppro_p0_unit_blockage"); 
|| !symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( which_alternative || !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], SFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( which_alternative == 2 || !mult_operator( recog_data_0.operand[3], DFmode) ) 
else if ( mult_operator( recog_data_0.operand[3], XFmode) ) 
v12 = &optab_table[17]->handlers[v10]; 
v17 = *( insn_code *)( ( char *)&fixtrunctab[0][0][v9] + v16); 
if ( v12->insn_code != CODE_FOR_nothing ) 
v17 = *( insn_code *)( ( char *)&fixtab[0][0][v9] + v16); 
if ( v12->insn_code != CODE_FOR_nothing ) 
v52 = convert_to_mode( ( machine_mode)v11, v52, 0); 
v53 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v52 + 2)); 
v52 = expand_unop( ( machine_mode)*( ( unsigned __int8 *)v52 + 2), optab_table[17], v52, v53, 0); 
v17 = *( insn_code *)( ( char *)&fixtrunctab[0][0][v9] + v21); 
if ( v12->insn_code != CODE_FOR_nothing ) 
v8 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
v8 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v14 = _mm_add_epi64( _mm_shuffle_epi32( ( __m128i)v6, 68), ( __m128i)xmm*(short *)0x65ADF0); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE00); 
v21 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
v22 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE20); 
v23 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x668290); 
v24 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x6682A0); 
invalidate( p->exp->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)p->exp)); 
v5 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v6 = ( cpp_token_0 *)xmalloc( 0x1770uLL); 
v3 = ( tree_node *)ggc_alloc( 0x28uLL); 
*( _OWORD *)&v3->common.chain = 0LL; 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v30[2 * v31 + 2] + 2LL)); 
v4 += canon_hash( v53[1], ( machine_mode)*( ( unsigned __int8 *)v53[1] + 2)); 
v4 += canon_hash( ( rtx)v57, ( machine_mode)*( unsigned __int8 *)( v57 + 2)); 
|| !fixed_regs[rtuint] && *( const mode_class *)( ( char *)mode_class_0 + ( ( v5 >> 14) & 0x3FC)) != MODE_CC) ) 
: section_name == ( tree_node *)*( &global_trees + 5) 
? ( v8 = ( tree_node *)*( &global_trees + 10)) 
: section_name == ( tree_node *)*( &global_trees + 4) 
? ( v8 = ( tree_node *)*( &global_trees + 9)) 
: section_name == ( tree_node *)*( &global_trees + 3) 
? ( v8 = ( tree_node *)*( &global_trees + 8)) 
: section_name == ( tree_node *)*( &global_trees + 2) 
? ( v8 = ( tree_node *)*( &global_trees + 7)) 
tree v8; // rax 
v8 = build( MODIFY_EXPR, type, valist, tree); 
*( ( _BYTE *)&v8->block.common + 17) |= 1u; 
expand_expr( v8, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
if ( !direct_store[mode] && ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
v22 = convert_modes( mode, ( machine_mode)v25, v22, 1); 
v26 = mode_class_0[BYTE2( v24)]; 
if ( v26 != mode_class_0[v27] ) 
v12 = ( const char *)&off_737CD7; 
v16 = *( tree_node **)( key + 64); 
fprintf( di_0->stream, off_737CC6, v15, 6657907LL); 
fprintf( di_0->stream, asc_737CC5, 25LL, 6657907LL); 
v10 = *( tree_node **)( key + 40); 
v10 = *( tree_node **)( key + 32); 
if ( lang_hooks_0.tree_dump.dump_tree( di_0, ( tree)key) ) 
v16 = *( tree_node **)( key + 40); 
newa = simplify_gen_binary( ( rtx_code)( unsigned __int16)*( _DWORD *)*loc, v10, pc->exp, c); 
if ( ( sch_istable[token->val.c] & 0xAC) != 0 ) 
rtx insn; // [rsp+28h] [rbp-18h] 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
if ( insn ) 
v3 = insn != ( rtx)bb->head[1]; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
for ( link = df_0->insns[insn->fld[0].rtuint].defs; link; link = link->next ) 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 23517, "athlon_ieu_unit_conflict_cost"); 
&& symbolic_operand( recog_data_0.operand[1], SImode) 
&& ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
&& q_regs_operand( recog_data_0.operand[0], QImode) 
&& symbolic_operand( recog_data_0.operand[1], DImode) 
&& ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode)) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) 
if ( ( which_alternative == 2 || incdec_operand( recog_data_0.operand[2], HImode)) 
&& !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( ( which_alternative == 3 || incdec_operand( recog_data_0.operand[2], QImode)) 
&& !incdec_operand( recog_data_0.operand[2], QImode) ) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode)) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( ( ( ( 1 << ix86_cpu) & x86_double_with_add) == 0 || !const1_operand( recog_data_0.operand[2], VOIDmode)) 
fatal_insn( "Attempt to delete prologue/epilogue insn:", insn, "flow.c", 1615, "propagate_one_insn"); 
rtx v7; // rbx 
rtx v10; // rbx 
rtx regno_note; // rax 
rtx *v40; // r12 
rtx *v44; // rbx 
rtx v45; // rbp 
rtx v46; // rax 
rtx v67; // rax 
rtx *v78; // rbx 
if ( initial != ( tree_node *)global_trees ) 
v9 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1; 
rtx v28; // rax 
*( ( _OWORD *)object_base + 1) = 0LL; 
if ( reg_note ) 
if ( *( _WORD *)reg_note->fld[0].rtwint == 66 ) 
v28 = ( rtx)insn[2]; 
if ( *( _WORD *)v28 != 47 ) 
v28 = single_set_2( insn, *( rtx *)&insn[2]); 
( rtx_code)( unsigned __int16)*( _DWORD *)ext_dependent, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ext_dependent), 
( rtx_code)( unsigned __int16)*( _DWORD *)ext_dependent, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ext_dependent), 
&& ( mode_class_0[( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1] == MODE_FLOAT 
|| mode_class_0[( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1] == MODE_INT) 
if ( mode_class_0[orig_mode] == MODE_INT ) 
v5 = convert_to_mode( ( machine_mode)v8, v5, 1); 
v4 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
predicate = insn_data_0[1234].operand[1].predicate; 
v26 = *( ( unsigned __int16 *)&insn_data_0[1234].operand[1] + 8); 
predicate = insn_data_0[1234].operand[1].predicate; 
fatal_insn_not_found( insn, "insn-attrtab.c", 5148, "k6_branch_unit_ready_cost"); 
x = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *rtwint)); 
*( _OWORD *)v7 = 0LL; 
*( _OWORD *)( v7 + 16) = 0LL; 
*( _OWORD *)( v7 + 32) = 0LL; 
*( _OWORD *)( v7 + 48) = 0LL; 
*( _OWORD *)( v3 + 32) = 0LL; 
*( _OWORD *)&v11->pred_next = 0LL; 
*( _OWORD *)&v11->src = 0LL; 
*( _OWORD *)&v11->insns = 0LL; 
*( _OWORD *)&v11->flags = 0LL; 
optab_0 optablea; // [rsp+58h] [rbp-8h] 
optab_0 optablea; // [rsp+58h] [rbp-8h] 
optablea = optable; 
v9 = sch_tolower[*( unsigned __int8 *)q]; 
optablea->handlers[mode].libfunc = v14; 
rtx insn; // [rsp+50h] [rbp-20h] 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; ; insn = ( rtx)insn[1] ) 
if ( insn ) 
v4 = insn != ( rtx)bb->head[1]; 
uid = insn->fld[0].rtuint; 
if ( rtx_class[( unsigned __int16)*( _DWORD *)insn] == 105 ) 
return true_dependence( *( ( rtx *)data + 1), *( machine_mode *)data, *x, ( int ( *)( rtx, int))cse_rtx_varies_p); 
s.args_ptr = ( va_list_0 *)va; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)&s.begin_diagnostic = *( _OWORD *)&global_dc->begin_diagnostic; 
*( _OWORD *)xi = 0LL; 
rtx v12; // rcx 
v12 = x1; 
v12 = x1->fld[0].rtx; 
v13 = v12->fld[0].rtuint; 
v15 = mem_loc_descriptor( x1->fld[0].rtx, ( machine_mode)BYTE2( v5)); 
v7 = mem_loc_descriptor( x0->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x0)); 
allocno_0[( __int64)a1].hard_reg_copy_preferences |= allocno_0[( __int64)a2].hard_reg_copy_preferences; 
allocno_0[( __int64)a1].hard_reg_copy_preferences |= allocno_0[( __int64)a2].hard_reg_copy_preferences; 
allocno_0[( __int64)a2].hard_reg_copy_preferences |= allocno_0[( __int64)a1].hard_reg_copy_preferences; 
allocno_0[( __int64)a2].hard_reg_copy_preferences |= allocno_0[( __int64)a1].hard_reg_copy_preferences; 
allocno_0[( __int64)a1].hard_reg_preferences |= allocno_0[( __int64)a2].hard_reg_preferences; 
allocno_0[( __int64)a1].hard_reg_preferences |= allocno_0[( __int64)a2].hard_reg_preferences; 
allocno_0[( __int64)a2].hard_reg_preferences |= allocno_0[( __int64)a1].hard_reg_preferences; 
allocno_0[( __int64)a2].hard_reg_preferences |= allocno_0[( __int64)a1].hard_reg_preferences; 
allocno_0[( __int64)a1].hard_reg_full_preferences |= allocno_0[( __int64)a2].hard_reg_full_preferences; 
allocno_0[( __int64)a1].hard_reg_full_preferences |= allocno_0[( __int64)a2].hard_reg_full_preferences; 
allocno_0[( __int64)a2].hard_reg_full_preferences |= allocno_0[( __int64)a1].hard_reg_full_preferences; 
allocno_0[( __int64)a2].hard_reg_full_preferences |= allocno_0[( __int64)a1].hard_reg_full_preferences; 
v2 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v0); 
v15 = ( tree_node *)ggc_alloc( v14); 
in_section_0 = no_section; 
v8 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v21 = ( ( unsigned int)( mode_class_0[v20] - 5) < 2) + 1; 
v31 = ( ( unsigned int)( mode_class_0[v29] - 5) < 2) + 1; 
v37 = _mm_add_epi64( _mm_shuffle_epi32( ( __m128i)v6, 68), ( __m128i)xmm*(short *)0x65ADF0); 
v39 = _mm_shuffle_pd( ( __m128d)v34, ( __m128d)xmm*(short *)0x68FC00, 2); 
v57 = _mm_add_epi64( _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE00), v37); 
si128 = _mm_load_si128( ( const __m128i *)&xmm*(short *)0x65AE10); 
operand = insn_data_0[v3].operand, 
operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v5].genfun( r0, r1); 
rtx v2; // r14 
rtx v3; // rax 
v2 = 0LL; 
v3 = 0LL; 
v3 = rtx; 
if ( !v2 ) 
v3 = rtx; 
if ( rtx[2] != v2[2] ) 
v3 = rtx; 
if ( rtint != v2[2].fld[0].rtint ) 
v3 = v2; 
v3 = v2; 
v2 = v3; 
v2 = v3; 
v14 = expand_binop( mode, optab_table[23], v27, v12, 0LL, 0, ( optab_methods)methods); 
v23 = expand_binop( mode, optab_table[23], op1, v21, 0LL, 0, ( optab_methods)v22); 
v11 = ( tree_node *)*( &global_trees + 15); 
v12 = expand_expr( valist, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
v14 = ( tree_node *)low; 
fatal_insn( "wrong insn in the fallthru edge", end, "cfgrtl.c", 1717, "verify_flow_info"); 
fatal_insn( "flow control insn inside a basic block", ( rtx)v32, "cfgrtl.c", 1829, "verify_flow_info"); 
fatal_insn( "insn outside basic block", insns, "cfgrtl.c", 1887, "verify_flow_info"); 
fatal_insn( "return not followed by barrier", insns, "cfgrtl.c", 1895, "verify_flow_info"); 
v8 = ( tree_node *)*( &global_trees + 5); 
v8 = ( tree_node *)*( &global_trees + 4); 
v8 = ( tree_node *)*( &global_trees + 3); 
v8 = ( tree_node *)*( &global_trees + 2); 
v8 = ( tree_node *)*( &global_trees + 1); 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx v17; // rax 
rtx mem_set_list; // rbx 
rtx v19; // r14 
v17 = canon_rtx( rtx); 
mem_set_list = pbi->mem_set_list; 
if ( mem_set_list ) 
v19 = v17; 
v19 = v17; 
if ( anti_dependence( rtx, mem_set_list->fld[0].rtx) ) 
v23.rtwint = ( __int64)mem_set_list->fld[0]; 
if ( rtx_equal_p( v19->fld[0].rtx, *( rtx *)( v23.rtwint + 8)) ) 
if ( mode_size[*( ( unsigned __int8 *)v19 + 2)] <= mode_size[*( unsigned __int8 *)( v23.rtwint + 2)] ) 
if ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT ) 
if ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT ) 
rtx v5; // rdx 
rtx v6; // rax 
v5 = *startp; 
v6 = v5; 
v6 = v5; 
v5 = v5[1].fld[0].rtx; 
v5 = v5[1].fld[0].rtx; 
if ( *( _WORD *)v6 == 37 && ( unsigned int)( v6[2].fld[0].rtint + 98) <= 5 ) 
if ( *( _WORD *)v6 == 37 && ( unsigned int)( v6[2].fld[0].rtint + 98) <= 5 ) 
if ( v6 == v2 ) 
v2 = v5; 
v7 = ( __int64)v6[1]; 
*( _QWORD *)&v6[1] = v8; 
v6[1].fld[0].rtwint = ( __int64)v2; 
*( _QWORD *)( v8 + 24) = v6; 
*( _QWORD *)( v6[1].fld[0].rtwint + 16) = v6; 
if ( reg_note ) 
v30 = *( _DWORD *)reg_note->fld[0].rtwint - 58; 
v37 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) == 0) ^ 5), i); 
v9 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 2); 
v11 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v10, global_rtl[4], v9); 
v14 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), global_rtl[4]); 
v19 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v10, global_rtl[2], v9); 
tree *regno_decl; // rbp 
tree result; // r14 
tree *v99; // rbp 
v9 = ( tree_node *)v7; 
v11 = ( tree_node *)high; 
if ( call_insn_operand( operand1->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
*( _OWORD *)&loc->offset = 0LL; 
result = simplify_gen_subreg( mode, x, ( machine_mode)v3, v5); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1; 
teml = gen_peephole2_1246( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
temm = gen_peephole2_1249( insn, recog_data_0.operand); 
recog_data_0.operand[1] = x1; 
|| ( *_pmatch_len = 0, ( temn = gen_peephole2_1252( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1; 
temi = gen_peephole2_1245( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
temj = gen_peephole2_1248( insn, recog_data_0.operand); 
recog_data_0.operand[1] = x1; 
|| ( *_pmatch_len = 0, ( temk = gen_peephole2_1251( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = x1; 
rtx v82; // rax 
rtx v87; // rbx 
rtx v88; // r15 
rtx v90; // rax 
rtx v120; // rax 
rtx *v154; // r15 
rtx v195; // rax 
rtx v211; // rax 
rtx v215; // rax 
rtx v216; // rax 
fatal_insn_not_found( executing_insn, "insn-attrtab.c", 27955, "k6_alux_unit_blockage"); 
if ( general_operand( recog_data_0.operand[0], QImode) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( get_attr_type( executing_insn) == TYPE_IMOVX && general_operand( recog_data_0.operand[0], QImode) ) 
if ( ( !q_regs_operand( recog_data_0.operand[0], QImode) || ( ( 1 << ix86_cpu) & x86_movx) != 0) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
else if ( general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative || !general_operand( recog_data_0.operand[0], QImode) ) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative == 2 || !general_operand( recog_data_0.operand[0], QImode) ) 
if ( which_alternative == 3 || !general_operand( recog_data_0.operand[0], QImode) ) 
|| ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
&& const1_operand( recog_data_0.operand[2], VOIDmode) 
&& general_operand( recog_data_0.operand[0], QImode) ) 
if ( ( ( 1 << ix86_cpu) & x86_double_with_add) != 0 && const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( general_operand( recog_data_0.operand[0], QImode) ) 
*( _OWORD *)x.r = *( _OWORD *)&expr->block.vars; 
rtx x; // [rsp+8h] [rbp-50h] BYREF 
rtx v20; // [rsp+20h] [rbp-38h] 
x = insns; 
x = insns; 
for_each_rtx( &x, find_regno_partial, &data); 
if ( v20 ) 
v9 = gen_move_insn( v20, *( rtx *)( ( char *)const_tiny_rtx[0] + ( ( *( _DWORD *)v20 >> 13) & 0x7F8))); 
v9 = gen_move_insn( v20, *( rtx *)( ( char *)const_tiny_rtx[0] + ( ( *( _DWORD *)v20 >> 13) & 0x7F8))); 
x = rtx; 
x = rtx; 
for_each_rtx( &x, find_regno_partial, &data); 
if ( v20 ) 
v15 = gen_move_insn( v20, *( rtx *)( ( char *)const_tiny_rtx[0] + ( ( *( _DWORD *)v20 >> 13) & 0x7F8))); 
v15 = gen_move_insn( v20, *( rtx *)( ( char *)const_tiny_rtx[0] + ( ( *( _DWORD *)v20 >> 13) & 0x7F8))); 
rtx v15; // rax 
rtx v20; // rax 
uid_cuid_0 = v7; 
v15 = cse_basic_block( v6, last, data.path, around_loop); 
v6 = v15; 
v20 = cse_basic_block( v6, data.last, data.path, around_loop); 
v6 = v20; 
free( uid_cuid_0); 
fprintf( outf, off_6474F4, ( unsigned int)v5); 
fprintf( outf, off_6474F4, ( unsigned int)v8); 
v9 = rhs ? rhs : ( tree_node *)*( &global_trees + 11); 
num = num_sign_bit_copies( *( rtx *)&seta[1], ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)); 
scan_rtx( insna, ( rtx *)v9->fld, a3, action, ( op_type)( 2 * ( v7 != OP_IN)), earlyclobber); 
