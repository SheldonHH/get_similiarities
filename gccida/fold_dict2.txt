( save_level)( x_block_stack->next == 0LL), 
v4 = ( unsigned int)&pfile->buffer->cur[( ( sch_istable[*( ( unsigned __int8 *)pfile->buffer->cur - 1)] & 0x400) == 0) 
v33 = ( ( unsigned int)( mode_class_0[BYTE2( v11)] - 5) < 2) + 1; 
v8 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
if ( v15 == ( _DWORD)v5 || mode_change_ok( v15, ( machine_mode)v5, ( unsigned int)vd) ) 
v12 = gen_rtx_fmt_i0( REG, ( machine_mode)v5, v14); 
if ( base_alias_check( mem2_addr, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), mem_mode) ) 
inout_mode = ( machine_mode *)inout_opnum; 
v40 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v38 + 2)); 
p_time = ( cpp_token_0 *)v15; 
+ ( ( *( ( _DWORD *)uid_cuid_1 + rtint) >> 3) & 0x1FFFFFF8)); 
if ( !_bittest64( &v6, *( ( unsigned int *)uid_cuid_1 + rtint)) ) 
fancy_abort( &off_6CC868[4], 1599, "count_pseudo"); 
v5 = ( ( unsigned int)( mode_class_0[v3] - 5) < 2) + 1; 
v8 = ( _DWORD *)( ( char *)&unk_9CF38C + 4 * v6 + 4 * v2); 
fatal_insn_not_found( insn, "insn-attrtab.c", 15861, "get_attr_memory"); 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
LODWORD( v3) = 2 * ( memory_operand( recog_data_0.operand[0], VOIDmode) != 0) + 1; 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
LODWORD( v3) = 2 * ( memory_operand( recog_data_0.operand[0], VOIDmode) != 0); 
|| ( LODWORD( v3) = 0, !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) 
|| ( LODWORD( v3) = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) 
&& ( !( _DWORD)flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) 
|| !memory_operand( recog_data_0.operand[2], VOIDmode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) 
|| ( LODWORD( v3) = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
timevar_push( TV_INTEGRATION_0); 
v8 = TV_INTEGRATION_0; 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_EXPAND_0); 
v8 = TV_EXPAND_0; 
rtx v47; // [rsp+10h] [rbp-58h] 
rtx *v48; // [rsp+28h] [rbp-40h] 
v48 = pdest; 
v48 = pdest; 
if ( v37 <= 0x34 && !ix86_hard_regno_mode_ok( v37, ( machine_mode)BYTE2( v36)) ) 
if ( v38 <= 0x34 && !ix86_hard_regno_mode_ok( v38, ( machine_mode)*( ( unsigned __int8 *)v27 + 2)) ) 
v47 = succ; 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)nodes[v30] + 2)); 
immediate_operand( recog_data_0.operand[1], VOIDmode); 
v11 = immediate_operand( recog_data_0.operand[1], VOIDmode); 
v28 = general_operand( recog_data_0.operand[0], QImode); 
v16 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v17] - 5) < 2) + 1; 
hitrate = 10000 - predictor_info_0[predictor].hitrate; 
hitrate = predictor_info_0[predictor].hitrate; 
fatal_insn( "VOIDmode on an output", insn, &off_6CC868[4], 6651, "emit_output_reload_insns"); 
v42 = insn_data_0[v20].genfun( v9, v21); 
v19 = gen_lowpart_common( ( machine_mode)v18, v15); 
recog_data_0.insn = 0LL; 
*( _WORD *)&recog_data_0.n_operands = 0; 
recog_data_0.n_alternatives = 0; 
recog_data_0.n_operands = n_operands; 
fatal_insn_not_found( insn, "recog.c", 2139, "extract_insn"); 
recog_data_0.operand, 
recog_data_0.operand_loc, 
recog_data_0.constraints, 
recog_data_0.operand_mode); 
recog_data_0.n_alternatives = 1; 
v11 = *recog_data_0.constraints[0]; 
if ( *recog_data_0.constraints[0] ) 
v12 = recog_data_0.constraints[0] + 1; 
recog_data_0.n_alternatives = v13; 
v15 = *recog_data_0.constraints[i]; 
if ( recog_data_0.n_alternatives >= 31 ) 
make_new_qty( rtint, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
&& ( operand = insn_data_0[insn_code].operand, operand->predicate( 
( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) ) 
v35 = expand_simple_binop( ( machine_mode)*( ( unsigned __int8 *)v30 + 2), AND, v17, v34, 0LL, 1, OPTAB_LIB_WIDEN); 
emit_cmp_and_jump_insns( v35, v40, v41, 0LL, ( machine_mode)*( ( unsigned __int8 *)v35 + 2), 0, v38); 
if ( reg_pref_0 ) 
return reg_pref_0[regno].altclass; 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2), operands[2]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2)); 
v1 = off_63B09B; 
*( _OWORD *)( object_base + 40) = 0LL; 
*( _OWORD *)&v2->loads = 0LL; 
v14 = force_to_mode( compound_operation, ( machine_mode)v12, 0xFFFFFFFFFFFFFFFFLL, 0LL, 0); 
return gen_lowpart_for_combine( ( machine_mode)v12, v42.rtx); 
( rtx_code)( unsigned __int16)*( _DWORD *)compound_operation, 
( machine_mode)v12, 
( machine_mode)*( unsigned __int8 *)( ( *fld)->fld[0].rtwint + 2), 
v56 = gen_rtx_fmt_ee( AND, ( machine_mode)v83, rtwint[1], *( rtx *)&v3[1]); 
if ( rtuint <= 0x34 && !ix86_hard_regno_mode_ok( rtuint, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)i)) ) 
operand = insn_data_0[icode].operand; 
if ( !operand->predicate( v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)) 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
v12 = insn_data_0[icode].genfun( v11, v10); 
fatal_insn_not_found( insn, "insn-attrtab.c", 13072, "get_attr_imm_disp"); 
v17 = recog_data_0.operand[1]; 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
v17 = recog_data_0.operand[1]; 
if ( memory_displacement_operand( recog_data_0.operand[0], VOIDmode) ) 
v4 = recog_data_0.operand[1]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
v7 = recog_data_0.operand[2]; 
if ( _bittest( &v19, ix86_cpu) && const1_operand( recog_data_0.operand[2], VOIDmode) 
if ( ( v6 & 0x4000) == 0 && ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
v1 = mode_class_0[mode]; 
i->reaching_reg = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v5->fld[0].rtwint + 2)); 
v6 = *( ( unsigned int *)uid_cuid_1 + *( ( int *)insn + 2)); 
if ( !gen_aux_info_record_compiled_from_record++ ) 
recog_data_0.operand[1] = v4; 
recog_data_0.operand[1] = v7; 
recog_data_0.operand[2] = v8; 
recog_data_0.operand[1] = v10; 
recog_data_0.operand[2] = v11; 
v12 = ix86_binary_operator_ok( XOR, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v15; 
v18 = ix86_unary_operator_ok( NEG, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v19; 
recog_data_0.operand[1] = ( rtx)v19; 
recog_data_0.operand[1] = ( rtx)v19; 
recog_data_0.operand[1] = ( rtx)v21; 
recog_data_0.operand[1] = v33; 
recog_data_0.operand[1] = ( rtx)v38; 
recog_data_0.operand[2] = v39; 
v40 = ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v88; 
v27 = *( tree_node **)( v23 + 104); 
v32 = *( tree_node **)( v23 + 8); 
v1 = ( tree_node *)*( &global_trees + 27); 
v2 = ( tree_node *)*( &global_trees + 24); 
v5 = safe_hash( related_value, ( machine_mode)*( ( unsigned __int8 *)related_value + 2)); 
v2 = lookup( v4, v5 & 0x1F, ( machine_mode)*( ( unsigned __int8 *)v4 + 2)); 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, 1); 
|| ( ( v10 = ( int *)reg_n_info->data.l[a1], v11 = *( ( _DWORD *)uid_cuid_0 + v10[1]), v11 > cse_basic_block_end) 
|| *( ( _DWORD *)uid_cuid_0 + *v10) < cse_basic_block_start) 
&& v11 > *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[first_reg] + 4)))) ) 
recog_data_0.operand[0] = ( rtx)v7; 
recog_data_0.operand[1] = v51; 
recog_data_0.operand[2] = v54; 
recog_data_0.operand[3] = v56; 
recog_data_0.operand[4] = v58; 
return gen_split_938( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v7; 
recog_data_0.operand[1] = v10; 
recog_data_0.operand[2] = v13; 
recog_data_0.operand[3] = v15; 
recog_data_0.operand[4] = v17; 
return gen_split_937( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v7; 
recog_data_0.operand[1] = v32; 
recog_data_0.operand[2] = v35; 
recog_data_0.operand[3] = v37; 
recog_data_0.operand[4] = v39; 
return gen_split_944( recog_data_0.operand); 
if ( general_operand( v2, ( machine_mode)*( ( unsigned __int8 *)reaching_reg + 2)) ) 
result = hex_value[( unsigned __int8)c]; 
if ( ( sch_istable[v18] & 0x88) == 0 ) 
rtx v19; // rax 
rtx v27; // rax 
rtx v34; // rbp 
rtx v47; // r12 
rtx fixed_bit_field; // rax 
move_by_pieces_1( insn_data_0[insn_code].genfun, i, &v18); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
while ( constructor_stack_0->implicit ) 
if ( constructor_range_stack_0 ) 
v2 = constructor_stack_0; 
spelling_0 = &spelling_base[constructor_depth]; 
constructor_range_stack_0 = v2->range_stack; 
spelling_0 = &spelling_base[depth]; 
constructor_stack_0 = v2->next; 
if ( constructor_stack_0 ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
post_mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), birth, 2 * this_insn_number, v3); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
qty_0[v4].death = -1; 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( sizetype_tab[0]->block.abstract_origin)) >> 1), 
v7 = ( reg_class *)( v5 + 10314208); 
v14 = ( ( unsigned int)( mode_class_0[inmode] - 5) < 2) + 1; 
v18 = ( ( unsigned int)( mode_class_0[outmode] - 5) < 2) + 1; 
rtint = this_insn_1[2].fld[0].rtint; 
if ( insn_data_0[rtint].n_operands >= 2 ) 
p_constraint = &insn_data_0[v26].operand[1].constraint; 
v31.rtwint = ( __int64)this_insn_1[3].fld[0]; 
v32 = ( machine_mode *)( v5 + 10314216); 
v40 = ( ( unsigned int)( mode_class_0[v39] - 5) < 2) + 1; 
if ( v40 > ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( **( _DWORD **)( v31.rtwint + 8))] - 5) < 2) + 1 ) 
*( _OWORD *)&v3->block.fragment_chain = 0LL; 
if ( !strcmp( name, aE) ) 
warning( ( &off_6C5140)[code - 1], v3); 
v7 = gen_rtx_CONST_INT( ( machine_mode)memref, mode_size[v4]); 
mode_alignment = get_mode_alignment( ( machine_mode)v4); 
*( _QWORD *)&v3[1] = get_mem_attrs( v6, 0LL, 0LL, v7, mode_alignment, ( machine_mode)v4); 
rtx *v11; // rax 
v11 = phi_alternative( *( rtx *)&rtx[2], bb->index); 
if ( v11 ) 
v12 = fn( rtx, *( _DWORD *)( *( _QWORD *)( v10 + 8) + 8LL), ( *v11)->fld[0].rtint, data); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v23[2 * v24 + 2] + 2LL), 
v32 = hash_expr_1( ( rtx)v31, ( machine_mode)*( unsigned __int8 *)( v31 + 2), do_not_record_p); 
tree v29; // rbp 
tree v33; // rax 
tree v34; // rax 
mode_alignment = get_mode_alignment( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)object)); 
v22 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), to->fld[0].rtx); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( sizetype_tab[0]->block.abstract_origin)) >> 1), 
htab_delete( hash_table_0); 
if ( *( _OWORD *)&low->block.vars < *( _OWORD *)( v2 + 32) ) 
if ( *( _OWORD *)&low->block.vars < *( _OWORD *)( v2 + 32) ) 
if ( *( _OWORD *)&v5->block.vars < *( _OWORD *)&high->block.vars ) 
if ( *( _OWORD *)&v5->block.vars < *( _OWORD *)&high->block.vars ) 
rtx v24; // r15 
rtx rtwint; // rax 
v18 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)x)] - 5) < 2) + 1; 
v24 = *( rtx *)( v10.rtwint + 8); 
rtwint = *( rtx *)( v10.rtwint + 16); 
rtwint = *( rtx *)( v10.rtwint + 8); 
v24 = *( rtx *)( v10.rtwint + 16); 
rtwint = 0LL; 
v24 = 0LL; 
v6 = ( ( unsigned int)( mode_class_0[v2] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1; 
v14 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v18 = ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
v22 = ( ( unsigned int)( mode_class_0[v20] - 5) < 2) + 1; 
if ( ix86_hard_regno_mode_ok( regno, ( machine_mode)v20) ) 
v13 = immed_double_const( cnst1, v12, ( machine_mode)v10); 
v15 = convert_to_mode( ( machine_mode)v10, op0, unsignedp); 
v16 = expand_mult( ( machine_mode)v10, v15, v13, 0LL, 0); 
v20 = expand_shift( RSHIFT_EXPR, ( machine_mode)v10, v16, v17, 0LL, 1); 
v40 = expand_binop( ( machine_mode)v10, ( optab_0)v27, op0, v39, 0LL, unsignedp == 0, OPTAB_WIDEN); 
v40 = expand_binop( ( machine_mode)v10, ( optab_0)v27, op0, v39, 0LL, unsignedp == 0, OPTAB_WIDEN); 
v44 = expand_shift( RSHIFT_EXPR, ( machine_mode)v10, v41, v43, 0LL, 1); 
v45 = convert_modes( mode, ( machine_mode)v10, v44, unsignedp); 
v36 = expand_binop( ( machine_mode)v10, v33, op0, v52, 0LL, v29, OPTAB_WIDEN); 
v8 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5->label); 
rtl = gen_rtx_MEM( ( machine_mode)v7, v8); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
rtx v40; // rax 
rtx v51; // rax 
rtx v67; // rax 
rtx v73; // rax 
sprintf( xstrerror_buf, aUndocumentedEr, ( unsigned int)errnum); 
v14 = ( tree_node *)*( &global_trees + 16); 
v25 = ( tree_node *)*( &global_trees + 12); 
( rtx_code)*( _WORD *)x, 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
return force_reg( ( machine_mode)BYTE2( v2), x); 
v4 = force_reg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v4), v4); 
v5 = expand_expr( ( tree)low, 0LL, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), EXPAND_NORMAL); 
if ( check_mode && !ix86_hard_regno_mode_ok( v5, ( machine_mode)( unsigned __int8)BYTE2( *rtwint)) ) 
v4 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v2] - 5) < 2) + 1; 
*( _OWORD *)&b->aux = 0LL; 
*( _OWORD *)&b->count = 0LL; 
*( _OWORD *)&b->global_live_at_start = 0LL; 
*( _OWORD *)&b->local_set = 0LL; 
*( _OWORD *)&b->pred = 0LL; 
*( _OWORD *)&b->head_tree = 0LL; 
*( _OWORD *)&b->head = 0LL; 
( machine_mode)v16, 
( machine_mode)v14, 
do_tablejump( v15, ( machine_mode)v16, v18, table_label, default_label); 
if ( ( sch_istable[( unsigned __int8)v1[v2]] & 4) == 0 ) 
recog_data_0.operand[1] = ( rtx)v4; 
|| !rtx_equal_p( *( rtx *)( v6 + 16), recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = rtx; 
recog_data_0.operand[2] = v65; 
v68 = recog_data_0.operand[1]; 
recog_data_0.operand[1] = v79; 
recog_data_0.operand[2] = v65; 
v68 = recog_data_0.operand[1]; 
recog_data_0.operand[1] = v15; 
recog_data_0.operand[2] = v65; 
v68 = recog_data_0.operand[1]; 
recog_data_0.operand[2] = v17; 
v14 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)if_info->cond + 2), cmp_a, cmp_b); 
v15 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v14, vtrue, vfalse); 
if ( !general_operand( cmp_a, ( machine_mode)*( ( unsigned __int8 *)cmp_a + 2)) 
|| !general_operand( cmp_b, ( machine_mode)*( ( unsigned __int8 *)cmp_b + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
result = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v6, result); 
( machine_mode)v9, 
rtx v8; // rcx 
v8 = function_tail_eff_head; 
if ( v8 ) 
*( _QWORD *)&v8[1] = rtx; 
if ( reg_note ) 
if ( *( __int64 *)( reg_note->fld[0].rtwint + 8) <= 4999 ) 
|| ( v4 = gen_lowpart_for_combine( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v3), x), !rtx_equal_p( v3, v4)) ) 
v6 = gen_lowpart_for_combine( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), y); 
induction_1 *i; // rbx 
induction_1 *i; // rbx 
induction_1 *same; // rax 
induction_1 *same; // rax 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
same = i->same; 
same = i->same; 
if ( same && ( *( ( _BYTE *)same + 100) & 4) != 0 ) 
if ( same && ( *( ( _BYTE *)same + 100) & 4) != 0 ) 
*( ( _BYTE *)i + 100) |= 4u; 
if ( ( *( ( _BYTE *)i + 100) & 4) != 0 ) 
if ( same ) 
i->new_reg = replace_rtx( i->new_reg, same->dest_reg, same->new_reg); 
i->new_reg = replace_rtx( i->new_reg, same->dest_reg, same->new_reg); 
i->new_reg = replace_rtx( i->new_reg, same->dest_reg, same->new_reg); 
i->new_reg = replace_rtx( i->new_reg, same->dest_reg, same->new_reg); 
*( _OWORD *)&v4.first = 0LL; 
mergeable_constant_section( ( machine_mode)LOBYTE( v5->block.supercontext), v6, 0); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
v7 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v5] - 5) < 2) + 1; 
v13 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, &value); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)v1 + 2), *( rtx *)&v1[1], &v3); 
( va_list_0 *)va, 
if ( mode_class_0[( unsigned __int8)v5] != MODE_FLOAT ) 
v1 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v21 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)*v94 >> 14) & 0x3FC)) - 5) < 2) 
v25 = reload_reg_reaches_end_p( v22, *( _DWORD *)( v16 + 10314264), *( reload_type *)( v16 + 10314284)); 
if ( reload_reg_reaches_end_p( v38, *( _DWORD *)( v96 + 10314264), *( reload_type *)( v96 + 10314284)) ) 
v52 = ( ( unsigned int)( mode_class_0[v53] - 5) < 2) + 1; 
v57 = ( ( unsigned int)( mode_class_0[v56] - 5) < 2) + 1; 
v81 = ( char *)&unk_9CF8CC + 4 * v80; 
v44 = ( ( unsigned int)( mode_class_0[v43] - 5) < 2) + 1; 
v33 = ( ( unsigned int)( mode_class_0[v34] - 5) < 2) + 1; 
sprintf( v8, "*.%s%u", ( const char *)&off_624A4C, stmt->identifier.id.len >> 2); 
add_dependence_list_and_free( insn, &deps->pending_write_insns, ( reg_note)( ( for_read == 0) | 0xE)); 
add_dependence_list_and_free( insn, &deps->last_pending_memory_flush, ( reg_note)( ( for_read == 0) | 0xE)); 
v15 = build( ( tree_code)v6, type, v32, v35, v29); 
v15 = build( ( tree_code)v6, tt, v19, v10); 
v15 = build1( ( tree_code)v6, type, v24); 
v15 = build( ( tree_code)v6, type, v30, v14); 
if ( !expand_builtin_va_arg_gave_help ) 
expand_builtin_va_arg_gave_help = 1; 
v15 = gen_rtx_MEM( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1), v14); 
v6 = *( tree_node **)( v4.rtwint + 8); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), 
v11 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v10] - 5) < 2) + 1; 
v18 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
v32 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v31] - 5) < 2) + 1; 
v29 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v28] - 5) < 2) + 1; 
fwrite( &unk_607BEF, 0x11uLL, 1uLL, outf); 
return force_reg( ( machine_mode)v3, exp); 
return copy_to_mode_reg( ( machine_mode)v3, exp); 
v4 = gen_reg_rtx( ( machine_mode)v3); 
*( _OWORD *)&reload_inherited[160] = 0LL; 
*( _OWORD *)&reload_inherited[144] = 0LL; 
*( _OWORD *)&reload_inherited[128] = 0LL; 
*( _OWORD *)&reload_inherited[112] = 0LL; 
*( _OWORD *)&reload_inherited[96] = 0LL; 
*( _OWORD *)&reload_inherited[80] = 0LL; 
*( _OWORD *)&reload_inherited[64] = 0LL; 
*( _OWORD *)&reload_inherited[48] = 0LL; 
*( _OWORD *)&reload_inherited[32] = 0LL; 
if ( base_alias_check( addr, y, ( machine_mode)*( ( unsigned __int8 *)x + 2), v6) ) 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v13] - 5) < 2) + 1; 
v25 = ( v14 - 1 < 0) ^ __OFADD__( -1, v14) | ( v14 == 1); 
v25 = ( v14 - 1 < 0) ^ __OFADD__( -1, v14) | ( v14 == 1); 
cselib_lookup( v15->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 1); 
if ( reg_note ) 
v2.rtwint = ( __int64)reg_note->fld[0]; 
rtx v20; // rcx 
v20 = reg_equiv_mem[rtint]; 
if ( v20 ) 
v21 = v20->fld[0].rtx; 
v10 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
*( _OWORD *)v10.r = a7; 
*( _OWORD *)a1 = *( _OWORD *)v8->r; 
v4 = ( tree_node *)*( &global_trees + 30); 
v6 = ( tree_node **)( &global_trees + 88); 
p_imag = ( tree_node **)( &global_trees + 88); 
if ( !cpp_trigraph_map[v3] ) 
cpp_trigraph_map[v3]); 
v4 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), pointer); 
v5 = adjust_address_1( v4, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), offset, 1, 1); 
v6 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
v6 = ( &off_6C5190)[v3]; 
return ( alias_set_entry_0)v1->value; 
v7 = *( const char *const *)( ( char *)resolve_unique_section_prefixes[v4] 
*( _OWORD *)&element->next = 0LL; 
else if ( mode_class_0[BYTE2( v5)] == MODE_INT && !can_compare_p( NE, ( machine_mode)BYTE2( v5), ccp_jump) ) 
else if ( mode_class_0[BYTE2( v5)] == MODE_INT && !can_compare_p( NE, ( machine_mode)BYTE2( v5), ccp_jump) ) 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
while ( ( sch_istable[v3] & 0x204) != 0 ); 
v6 = ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, cur - 1, ( int)v2 - ( ( int)cur - 1), HT_ALLOC); 
rtx v27; // rax 
rtx v40; // r12 
rtx val; // [rsp+30h] [rbp-58h] 
( machine_mode)BYTE2( v21), 
( machine_mode)( unsigned __int8)v22); 
v25 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v22] - 5) < 2) + 1; 
v27 = gen_rtx_REG( v24, rtint); 
rtx = v27; 
v19 = ( ( unsigned int)( mode_class_0[v18] - 5) < 2) + 1; 
val = insn; 
v40 = mode->reg_next_use[bit]; 
v40 = 0LL; 
return copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), x); 
operand0 = gen_reg_rtx( ( machine_mode)v13); 
addr = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
operand = insn_data_0[v16].operand; 
if ( !operand[2].predicate( const_int_rtx[64], ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
v20 = insn_data_0[v16].genfun( operand0, v19); 
return convert_to_mode( ( machine_mode)v10, operand0, 0); 
*( _OWORD *)d.r = *( _OWORD *)&exp->block.vars; 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( exp->common.type->block.abstract_origin)) >> 1), 
v9 = costs_0; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
if ( ( sch_istable[v11] & 4) != 0 && !*( ( _BYTE *)v9 + 1) ) 
undos = undobuf_0.undos; 
if ( undobuf_0.undos ) 
undos->next = undobuf_0.frees; 
undobuf_0.frees = undos; 
undobuf_0.undos = 0LL; 
v9 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
fatal_insn_not_found( insn, "insn-attrtab.c", 13438, "get_attr_i387"); 
v5 = recog_data_0.operand[3]; 
v5 = recog_data_0.operand[3]; 
v5 = recog_data_0.operand[3]; 
if ( get_attr_type( insn) == TYPE_FOP || mult_operator( recog_data_0.operand[3], TFmode) ) 
fprintf( v1, "%s, ", reg_class_names_0[*( ( int *)v2 - 20)]); 
fprintf( v1, "%ssecondary_in_icode = %s", "\n\t", insn_data_0[v8].name); 
fprintf( v1, "%ssecondary_out_icode = %s", v9, insn_data_0[v10].name); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
*( _OWORD *)&loc->offset = 0LL; 
( machine_mode)*( ( unsigned __int8 *)var + 2), 
rtx v14; // rax 
rtx x; // [rsp+0h] [rbp-68h] BYREF 
rtx v27; // [rsp+8h] [rbp-60h] 
rtx v28; // [rsp+10h] [rbp-58h] 
rtx parts; // [rsp+18h] [rbp-50h] BYREF 
rtx memref; // [rsp+20h] [rbp-48h] BYREF 
rtx y; // [rsp+28h] [rbp-40h] BYREF 
v14 = copy_rtx( *operands); 
*operands = v14; 
*( ( _BYTE *)v14 + 2) = 5 - ( ( target_flags & 0x2000000) == 0); 
p_parts = &parts; 
v6 = ix86_split_to_parts( operands[1], &parts, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
*( _OWORD *)v85 = 0LL; 
*( _OWORD *)words = 0LL; 
*( _OWORD *)v78 = 0LL; 
recog_data_0.operand[1] = v17; 
recog_data_0.operand[2] = v18; 
v21 = ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v13; 
recog_data_0.operand[2] = v83; 
v21 = ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v22; 
recog_data_0.operand[2] = v27; 
v21 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[2] = ( rtx)v23; 
v21 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v30; 
v21 = ix86_unary_operator_ok( NEG, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v33; 
recog_data_0.operand[2] = v34; 
v21 = ix86_binary_operator_ok( AND, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v37; 
if ( !general_operand( x, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x)) ) 
if ( !want_to_gcse_p_test_insn ) 
want_to_gcse_p_test_insn = make_insn_raw( v5); 
want_to_gcse_p_test_insn[1] = 0LL; 
ggc_add_rtx_root( &want_to_gcse_p_test_insn, 1); 
*( _BYTE *)( *( _QWORD *)( *( _QWORD *)&want_to_gcse_p_test_insn[2] + 8LL) + 2LL) = *( ( _BYTE *)x + 2); 
v6 = want_to_gcse_p_test_insn; 
*( _QWORD *)( *( _QWORD *)&want_to_gcse_p_test_insn[2] + 16LL) = x; 
rtx last_value; // rcx 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)rtx >> 14) & 0x3FC)) == MODE_CC ) 
last_value = get_last_value( rtx); 
if ( last_value ) 
if ( *( _WORD *)last_value == 74 ) 
( rtx_code)*( _WORD *)exp, 
*( rtx *)&last_value[1], 
last_value->fld[0].rtx, 
&& ( !v6 || g2->giv_type || !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)g2->mem + 2), v6)) ) 
*( _OWORD *)v27 = 0LL; 
*( _OWORD *)v25 = 0LL; 
rtx v26; // [rsp+28h] [rbp-50h] BYREF 
induction_1 *v; // [rsp+30h] [rbp-48h] 
induction_1 *v; // [rsp+30h] [rbp-48h] 
rtx v28; // [rsp+38h] [rbp-40h] 
rtx last_consec_insn; // [rsp+40h] [rbp-38h] BYREF 
if ( !general_induction_var( loop, *( rtx *)&v8[1], &v26, &add_val, &v23, &ext_val, 0, &pbenefit, VOIDmode) ) 
&v26, 
if ( ( unsigned int)rtuint < ( unsigned int)max_reg_before_loop && rtx != v26 ) 
v28 = v26; 
v28 = v26; 
|| ( pbenefit = consec_sets_giv( loop, pbenefit, p, v26, rtx, &add_val, &v23, &ext_val, &last_consec_insn)) != 0 ) 
|| ( pbenefit = consec_sets_giv( loop, pbenefit, p, v26, rtx, &add_val, &v23, &ext_val, &last_consec_insn)) != 0 ) 
v56 = convert_modes( v7, ( machine_mode)v11, v55, v10); 
v49 = convert_modes( v7, ( machine_mode)v11, v48, v10); 
v42 = convert_modes( v7, ( machine_mode)v11, v41, v10); 
v44 = convert_modes( v7, ( machine_mode)v11, v43, v10); 
v75 = convert_modes( v7, ( machine_mode)v11, v74, v10); 
v9 = ( tree_node *)i[4]; 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)object), object->fld[0].rtx) ) 
v5 = mode_class_0[( unsigned __int8)v3]; 
v10 = hash_table_0; 
v16 = ( tree_node *)j[4]; 
aka = ( tree_node *)prev_try->aka; 
v15 = ( tree_node *)v13->aka; 
fprintf( file, ( const char *)&off_6E2E28 + 4, "\t.zero\t", v11); 
p_int_cst = &exp->int_cst.int_cst; 
low = p_int_cst->low; 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)( low + 32); 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)( low + 32); 
v3 += int_byte_position( ( tree)p_int_cst->high); 
v9 = *( tree_node **)( low + 40); 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)( low + 32); 
p_int_cst = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)( low + 32); 
args[v6 / 0xA8].value = convert_modes( mode, ( machine_mode)v9, v8, args[v6 / 0xA8].unsignedp); 
expand_mult( ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v3, v2, 0LL, 1); 
timevar_push( TV_CPP_0); 
timevar_pop( TV_CPP_0); 
p_str = ( tree_node *)&v3->val.node[-1].ident.str; 
if ( ( sch_istable[v3->val.c] & 0xAC) == 0 ) 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v11 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v11 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, j, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, j, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
&& ( _DWORD)v2 == reverse_condition( ( rtx_code)v4) 
v12 = gen_rtx( v10, ( machine_mode)v7, v11, v5); 
v28 = hash_rtx( ( rtx)v27, ( machine_mode)*( unsigned __int8 *)( v27 + 2), 0); 
rtx v19; // [rsp+0h] [rbp-38h] BYREF 
v19 = v7; 
v19 = v12; 
v19 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&x[1]); 
v19 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&x[1]); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, v19); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, v19); 
rtx = v19->fld[0].rtx; 
fld = v19->fld; 
find_reloads_address( mode, &v19, rtx, ( rtx *)fld, opnum, type, ind_levels, 0LL); 
if ( mode_class_0[v16] != MODE_INT ) 
|| ( mode_class_0[*( unsigned __int8 *)( v15->fld[0].rtwint + 2)] == MODE_CC) != ( mode_class_0[v34] != MODE_CC) ) 
|| ( mode_class_0[*( unsigned __int8 *)( v15->fld[0].rtwint + 2)] == MODE_CC) != ( mode_class_0[v34] != MODE_CC) ) 
if ( v21 > 0x40 || mode_class_0[*( unsigned __int8 *)( v15->fld[0].rtwint + 2)] != MODE_INT || ( _DWORD)v21 != 1 ) 
|| ( mode_class_0[*( unsigned __int8 *)( v15->fld[0].rtwint + 2)] == MODE_CC) != ( mode_class_0[v36] != MODE_CC) ) 
|| ( mode_class_0[*( unsigned __int8 *)( v15->fld[0].rtwint + 2)] == MODE_CC) != ( mode_class_0[v36] != MODE_CC) ) 
if ( mode_class_0[v27] == MODE_CC ) 
rtx v4; // r14 
if ( reg_note && x ) 
v4 = reg_note; 
v4 = reg_note; 
rtx[3].fld[0].rtwint = ( __int64)gen_rtx_fmt_ee( EXPR_LIST, XCmode, v4->fld[0].rtx, rtx[3].fld[0].rtx); 
emit_unop_insn( v7, x, v12, ( rtx_code)( 2 * ( v10 != 0) + 125)); 
if ( v18 < mode_bitsize[v19] && can_float_p( v19, ( machine_mode)v17, 0) != CODE_FOR_nothing ) 
emit_cmp_and_jump_insns( v15, const_int_rtx[64], GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v15 + 2), 0, fixmodea); 
v33 = &off_6C2B50 + ( char)v32; 
v33 = &off_6C2B68 + ( char)v44; 
v33 = &off_6C2B80 + ( char)v42; 
v33 = &off_6C2B98 + ( char)v43; 
( machine_mode)*( ( unsigned __int8 *)v29 + 2), 
v48 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)v29 + 2), v31); 
return ( _cpp_buff_0 *)&v3[v2]; 
allocno_0[v8].hard_reg_conflicts |= hard_regs_live; 
p_hard_reg_conflicts = &allocno_0->hard_reg_conflicts; 
if ( recog_data_0.n_operands > 0 ) 
v4 = recog_data_0.operand_loc[v1]; 
if ( ( unsigned __int16)( *( _WORD *)recog_data_0.operand[v1] - 66) > 0xCu 
|| !_bittest( &v2, *( _DWORD *)recog_data_0.operand[v1] - 66) ) 
recog_data_0.operand[v1] = v3; 
while ( v1 < recog_data_0.n_operands ); 
if ( recog_data_0.n_dups > 0 ) 
v7 = recog_data_0.dup_loc[v5]; 
*recog_data_0.dup_loc[v5] = v6; 
while ( v5 < recog_data_0.n_dups ); 
rtx result; // rax 
result = 0LL; 
return result; 
fprintf( asm_out_file, ( const char *)&off_6E2E28 + 4, "\t.zero\t", ( unsigned int)size); 
rtx result; // rax 
tree v23; // rax 
tree chain; // rax 
tree v29; // rbx 
tree *p_tree_value; // r14 
tree v48; // rbx 
predictor_info_0[predictor].name, 
rtx op; // [rsp+18h] [rbp-60h] BYREF 
if ( *( _WORD *)op == 66 && !offsettable_memref_p( op) ) 
if ( *( _WORD *)op == 66 && !offsettable_memref_p( op) ) 
if ( !push_operand( op, VOIDmode) ) 
*( ( _BYTE *)op + 2) = 5 - ( ( target_flags & 0x2000000) == 0); 
v8 = op; 
parts[2] = op; 
split_ti( &op, 1, parts, parts + 1); 
if ( *( _WORD *)op == 61 ) 
*parts = gen_rtx_REG( DImode, op->fld[0].rtint); 
v7 = gen_rtx_REG( SImode, op->fld[0].rtint + 1); 
else if ( offsettable_memref_p( op) ) 
v9 = adjust_address_1( op, DImode, 0LL, 1, 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
class2 = ( machine_mode *)*( int *)( v13 + 10314208); 
LODWORD( in) = subreg_regno_offset( rtuint, ( machine_mode)*( ( unsigned __int8 *)v21 + 2), v16, v20); 
if ( ( count_error_warning_message & 1) == 0 ) 
count_error_warning_message = 1; 
v4 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)if_info->x >> 14) & 0x3FC)); 
v14 = code[v11]; 
v15 = unsignedp[v13]; 
( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
hash_table_0 = htab_create( 0x1FuLL, get_value_hash, entry_and_rtx_equal_p, 0LL); 
v16 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1; 
( machine_mode)*( ( unsigned __int8 *)ad + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)v66 + 2), 
v8 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( **( _DWORD **)( v3.rtwint + 8))] - 5) < 2) + 1; 
if ( reg_class_subset_p( v2, qty_0[v3].min_class) ) 
qty_0[v3].min_class = v2; 
if ( reg_class_subset_p( v4, qty_0[v3].alternate_class) ) 
qty_0[v3].alternate_class = v4; 
qty_0[v3].changes_mode = 1; 
( machine_mode)*( unsigned __int8 *)( v10.rtwint + 2), 
( machine_mode)BYTE2( v5)); 
v13 = ( ( unsigned int)( mode_class_0[v14] - 5) < 2) + 1; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
*( _OWORD *)&cfa->offset = 0LL; 
if ( in_section_0 != in_named || strcmp( name, in_named_name) ) 
in_section_0 = v2; 
return *( const mode_class *)( ( char *)mode_class_0 + ( ( v3 >> 14) & 0x3FC)) == MODE_FLOAT; 
changes = ( change_t_0 *)xrealloc( changes, 32LL * v9); 
rtx last_insn; // rbp 
rtx v12; // rax 
rtx v15; // r14 
rtx v19; // r13 
rtx secondary_mem; // r14 
rtx v32; // rbp 
last_insn = get_last_insn( ); 
&& ( v10 = gen_lowpart_common( ( machine_mode)v9, out)) != 0LL ) 
v3 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v12 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
ix86_fp_comparison_codes( ( rtx_code)( unsigned __int16)v2, ( rtx_code *)&v5, &first_code, ( rtx_code *)&v5 + 1); 
rtx v64; // rax 
rtx v90; // r15 
rtx v121; // rbp 
rtx v123; // rax 
rtx v127; // r14 
rtx *v51; // rax 
rtx v53; // rax 
rtx v55; // rax 
rtx v59; // r12 
rtx v65; // rax 
rtx v70; // rax 
rtx v71; // r14 
do_compare_rtx_and_jump( v19, v16, unsigned_code, v17, ( machine_mode)v15, v18, if_false_label, v20); 
return in_section_0 == in_text; 
sprintf( &v6[v7], " %-33s", &unk_6D3EF7); 
v6 = lang_hooks_0.expand_constant( exp); 
v4 = simplify_subreg( v3, v2.rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2.rtwint), *( _DWORD *)&v1[1]); 
v8 = ( const char *)&unk_6C3BD6; 
*( _OWORD *)&cum->sse_words = 0LL; 
*( _OWORD *)&cum->words = 0LL; 
if ( !insn_data_0[1159].operand->predicate( loc, ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32) ) 
v1 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), loc); 
v3 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
while ( v4 == 46 || ( sch_istable[v4] & 0x204) != 0 ); 
if ( ( _DWORD)v4 != 46 && ( sch_istable[( unsigned __int8)v4] & 0x204) == 0 ) 
if ( section_name == ( tree_node *)*( &global_trees + 5) ) 
if ( section_name == ( tree_node *)*( &global_trees + 4) ) 
if ( section_name == ( tree_node *)*( &global_trees + 3) ) 
if ( section_name == ( tree_node *)*( &global_trees + 2) ) 
if ( section_name == ( tree_node *)*( &global_trees + 1) ) 
v15 = ( ( unsigned int)( mode_class_0[v13] - 5) < 2) + 1; 
v26 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( **( _DWORD **)v19->loc >> 14) & 0x3FC)) - 5) < 2) 
rtx v10; // rbx 
rtx pending_read_insns; // rbx 
rtx *p_pending_read_mems; // rbp 
rtx v13; // rbp 
rtx pending_write_insns; // rbx 
rtx *p_pending_write_mems; // r12 
rtx v16; // r12 
rtx i; // rbx 
rtx v27; // rax 
rtx v19; // [rsp+0h] [rbp-38h] BYREF 
v19 = v3; 
v19 = y; 
if ( ( unsigned __int16)v6 == 75 && ( constant_term_loc = find_constant_term_loc( &v19)) != 0LL ) 
v19 = *constant_term_loc; 
*v14 = v19; 
free( reg_pref_0); 
if ( reg_pref_0 ) 
reg_pref_0 = reg_pref_buffer; 
v3 = ( tree_node *)v2[1]; 
v5 = gen_rtx_CONST_INT( ( machine_mode)mem, mode_size[v6]); 
*( _QWORD *)&mem[1] = get_mem_attrs( set, v3, v4, v5, v8, ( machine_mode)*( ( unsigned __int8 *)mem + 2)); 
if ( **( _WORD **)( v5.rtwint + 16) == 54 && !memory_address_p( ( machine_mode)BYTE2( v4), x->fld[0].rtx) ) 
fprintf( file, off_607A24, ( unsigned int)v5->index); 
fprintf( file, &off_607A24[1], ( unsigned int)v10); 
fputs( dump_edge_info_bitnames[v10], file); 
if ( ( tree_node *)*v11 == elements ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
predicate = insn_data_0[( _QWORD)insn_code].operand->predicate; 
v14 = insn_data_0[v12].genfun( x, insn_code); 
rtx operand0; // [rsp+28h] [rbp-1650h] 
rtx operand0a; // [rsp+28h] [rbp-1650h] 
rtx x; // [rsp+30h] [rbp-1648h] BYREF 
operand0 = ( rtx)v9; 
|| ( v15 = ( _QWORD)operand0 * *( _QWORD *)( v14 + 8), v15 > 0x1000) 
x = v18; 
x = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v19, v18); 
x = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v19, v18); 
v20 = remove_constant_addition( &x); 
rtx *v13; // r13 
v12 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v11] - 5) < 2) + 1; 
v13 = loc; 
df_ref_record_1( df_0, v18, v13, insn, ref_type, ref_flags); 
v13 = *( tree_node **)( high + 40); 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v6; 
|| ( recog_data_0.operand[0] = v9, !ix86_match_ccmode( insn, CCGCmode)) 
|| ( result = 213LL, recog_data_0.operand[2]->fld[0].rtint == 0x80000000) ) 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = ( rtx)v12; 
&& rtx_equal_p( *( rtx *)( v181 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v181 + 16), recog_data_0.operand[2]) 
v15 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v12; 
&& rtx_equal_p( *( rtx *)( v14 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v14 + 16), recog_data_0.operand[2]) 
v15 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v16; 
recog_data_0.operand[2] = v17; 
recog_data_0.operand[0] = v185; 
if ( ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
if ( ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
if ( !v17 || !v18 || ( v19 = *( tree_node **)( v17[4] + 128LL), v19 == ( tree_node *)*( &global_trees + 27)) ) 
sprintf( v16, &off_607A24[1], v7); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
operand = insn_data_0[insn_code].operand; 
v15 = ( *( (  struct rtx_def *(  **)( rtx, rtx))&insn_data_0[0].genfun + ( _QWORD)v70))( v13, v14); 
v17 = mode_class_0[mode]; 
( machine_mode)i, 
v23 = expand_unop( ( machine_mode)v21, unoptab, v22, 0LL, unsignedp); 
v62 = operand_sub*(short *)0xforce( operand1, v59, mode); 
if ( generating_concat_p && ( v2 = mode_class_0[mode], ( unsigned int)( v2 - 5) <= 1) ) 
v12 = mode_class_0[mode]; 
v2 = ( tree_node *)ggc_alloc( v1); 
v2 = ix86_expand_compare( ( rtx_code)*( _WORD *)operand0, 0LL, 0LL); 
if ( reg_note ) 
v8 = *( _QWORD *)( reg_note->fld[0].rtwint + 8); 
if ( recog_data_0.n_operands > 0 ) 
if ( recog_data_0.n_alternatives > 0 ) 
v1 = ( char *)recog_data_0.constraints[v0]; 
v5 = ( reg_class *)( v4 + v3 + 9791416); 
while ( v2 < recog_data_0.n_alternatives ); 
while ( v0 < recog_data_0.n_operands ); 
*( _OWORD *)a1 = *( _OWORD *)v8; 
v6 = mode_class_0[mode]; 
return gen_rtx_CONST_INT( ( machine_mode)op, v9); 
return gen_rtx_CONST_INT( ( machine_mode)op, v9); 
return gen_rtx_CONST_INT( ( machine_mode)op, v9); 
return gen_rtx_CONST_INT( ( machine_mode)op, v9); 
htab_traverse( hash_table_0, cselib_invalidate_mem_1, mem_rtx); 
if ( !( bitpos % get_mode_alignment( ( machine_mode)BYTE2( v12))) ) 
sprintf( v6, "*.%s%u", ( const char *)&off_624A4C, stmt->identifier.id.len >> 2); 
v10 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x >> 14) & 0x3FC)); 
v12 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)val >> 14) & 0x3FC)); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
( machine_mode)BYTE2( v21)); 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
( machine_mode)BYTE2( v16), 
v14 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v13] - 5) < 2) + 1; 
*( _OWORD *)&v6->left = 0LL; 
result = construct_container( ( machine_mode)v2, valtype, 1, 6, 8, x86_64_int_return_registers, 0); 
v3 = mode_class_0[v2]; 
return gen_rtx_REG( ( machine_mode)v2, v4); 
if ( ( sch_istable[v2] & 4) != 0 ) 
operand = insn_data_0[icode].operand; 
if ( !operand[opnum].predicate( v11, ( machine_mode)*( ( unsigned __int16 *)&operand[opnum] + 8)) ) 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[opnum] + 8), v11); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
&& ( reg_note = find_reg_note( insn, REG_UNUSED, rtx)) != 0LL ) 
fancy_abort( &off_6CC868[4], 6967, "do_output_reload"); 
v11 = expand_shift( ( tree_code)v42, mode, v23, expa, v17, 1); 
v24 = expand_shift( ( tree_code)v43, mode, v23, v22, 0LL, 1); 
if ( mode_class_0[v4] != MODE_FLOAT 
if ( ( mode_class_0[mode] | 2) == 3 ) 
*( _OWORD *)v24 = 0LL; 
*( _OWORD *)v22 = 0LL; 
sprintf( str, &off_607A24[1], *( _DWORD *)&x[1]); 
v12 = off_6B2B5B; 
v24[1] = ( char *)&unk_6D4017; 
rtx v16; // rsi 
v16 = reg_map[v15]; 
if ( !v16 || *( _WORD *)v16 != 63 ) 
if ( !v16 || *( _WORD *)v16 != 63 ) 
v7 = simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
v7 = simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
v7 = simplify_gen_subreg( ( machine_mode)BYTE2( v8), v16, ( machine_mode)BYTE2( v14), *( _DWORD *)&x[1]); 
v8 = v52 == swap_condition( ( rtx_code)v46) 
rtx v20; // rax 
rtx v26; // rax 
rtx *clobber_reg; // [rsp+88h] [rbp-48h] 
n_operands = recog_data_0.n_operands; 
v36 = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
v7 = recog_data_0.operand[v6]; 
recog_data_0.operand[v6] = rtx; 
clobber_reg = 0LL; 
clobber_reg = ( rtx *)&reg_used_as_output[-( ( 8 * v12 + 15) & 0xFFFFFFFFFFFFFFF0LL)]; 
clobber_reg[v15++] = v17; 
v20 = recog_data_0.operand[v19]; 
v20 = recog_data_0.operand[v19]; 
if ( *( _WORD *)v20 != 61 ) 
rtint = v20->fld[0].rtint; 
exp = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)exp + 2), const_rtx); 
v11 = safe_hash( exp, ( machine_mode)BYTE2( v9)); 
v12 = lookup( exp, v11 & 0x1F, ( machine_mode)*( ( unsigned __int8 *)exp + 2)); 
v27 = mode_class_0[v26]; 
return general_operand( op, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
fwrite( *( ( const void **)&ptr + ( __int16)v5), 7uLL, 1uLL, file); 
fwrite( &unk_61E84B, 2uLL, 1uLL, asmfile); 
v45 = ( unsigned int)dbxout_type_anonymous_type_number++; 
if ( ( *( _BYTE *)( v41 + 18) & 4) != 0 && !strcmp( lang_hooks_0.name, "GNU C++") ) 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v6 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), pointer); 
v8 = adjust_address_1( v7, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), offset, 1, 1); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
cselib_invalidate_regno( dest->fld[0].rtuint, ( machine_mode)BYTE2( v4)); 
if ( push_operand( dest, ( machine_mode)*( ( unsigned __int8 *)dest + 2)) ) 
v24 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
v16 = adjust_address_1( v16, ( machine_mode)v17, 0LL, 1, 1); 
v19 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)v16 + 2), v7); 
if ( ( sch_istable[( unsigned __int8)v11] & 0x400) != 0 ) 
rtx v16; // rdi 
v16 = *( rtx *)( v15 + 8); 
rtuint = v16->fld[0].rtuint; 
v16 = ssa_rename_from_lookup( rtuint); 
if ( !v16 ) 
v18 = ssa_rename_to_lookup( v16); 
( machine_mode)*( ( unsigned __int8 *)op + 2)); 
v11 = operand_sub*(short *)0xforce( 
G.lookup[v2] = ( page_entry_0 **)xcalloc( 1LL << v4, 8uLL); 
if ( ( sch_istable[*( _QWORD *)&c] & 0x800) == 0 ) 
if ( apply_args_size_size < 0 ) 
apply_args_size_size = v1; 
apply_args_size_size = 2 * v1; 
v6 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
if ( apply_args_size_size % v12 ) 
apply_args_size_size = v12 + apply_args_size_size - 1 - ( v12 + apply_args_size_size - 1) % v12; 
apply_args_size_size = v12 + apply_args_size_size - 1 - ( v12 + apply_args_size_size - 1) % v12; 
apply_args_size_size = v12 + apply_args_size_size - 1 - ( v12 + apply_args_size_size - 1) % v12; 
v13 = apply_args_size_size; 
apply_args_reg_offset[i] = apply_args_size_size; 
apply_args_size_size = v13 + mode_size[v3]; 
return apply_args_size_size; 
recog_data_0.operand[0] = ( rtx)v4; 
recog_data_0.operand[1] = ( rtx)v6; 
return gen_split_881( recog_data_0.operand); 
return gen_split_881( recog_data_0.operand); 
return gen_split_881( recog_data_0.operand); 
v10 = *( unsigned __int16 *)recog_data_0.operand[0]; 
rtuint = recog_data_0.operand[0]->fld[0].rtuint; 
else if ( v10 != 61 || recog_data_0.operand[0]->fld[0].rtint > 3u ) 
&& !reg_overlap_mentioned_p( recog_data_0.operand[0], ( rtx)v6) ) 
return gen_split_882( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v6; 
v162 = true_regnum( recog_data_0.operand[0]); 
if ( v162 == true_regnum( recog_data_0.operand[1]) ) 
return gen_split_883( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v4; 
recog_data_0.operand[1] = ( rtx)v12; 
return gen_split_879( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v12; 
return gen_split_885( recog_data_0.operand); 
if ( ( sch_istable[( unsigned __int8)v3] & 0x400) != 0 ) 
v8 = ( tree_node *)global_trees; 
rtx v19; // rbp 
rtx v27; // rbp 
rtx v32; // rbx 
if ( local_symbolic_operand( orig, ( machine_mode)reg) ) 
if ( local_symbolic_operand( v21, ( machine_mode)reg) && *( _WORD *)v22 == 54 ) 
v5 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v24, v22); 
v7 = gen_rtx_fmt_e( CONST, ( machine_mode)( 5 - v6), v5); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v32 = legitimize_pic_address( *( rtx *)&rtx[1], v31); 
if ( *( _WORD *)v32 == 75 ) 
v34 = **( _DWORD **)&v32[1]; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v32->fld[0].rtx); 
v32 = ( rtx)v32[1]; 
*( _DWORD *)( buf + 3) = ( _DWORD)&unk_6E7275; 
LODWORD( v5) = ( int)( ( double)( *( int *)( ( char *)&qty_0->size + v5) 
* *( int *)( ( char *)&qty_0->freq + v5) 
* floor_log2_wide( *( int *)( ( char *)&qty_0->n_refs + v5))) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
rtx v12; // rbp 
rtx v22; // r12 
v12 = *( rtx *)( v4.rtwint + 24); 
if ( *( _WORD *)v12 == 54 
&& v12->fld[0].rtwint + ( int)v10 > *( const unsigned __int16 *)( ( char *)mode_bitsize 
rtx = gen_rtx_fmt_e( USE, ( machine_mode)BYTE2( v5), rtx); 
for ( op1 = v12; *( _WORD *)rtx == 63; rtx = rtx->fld[0].rtx ) 
v15 = mode_class_0[v14]; 
v22 = copy_rtx( rtx); 
v23 = gen_binary( ASHIFT, ( machine_mode)v14, v21, op1); 
v24 = simplify_gen_unary( NOT, ( machine_mode)v14, v23, ( machine_mode)v14); 
v24 = simplify_gen_unary( NOT, ( machine_mode)v14, v23, ( machine_mode)v14); 
v2 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), profiler_label); 
else if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
v8 = assign_stack_local( ( machine_mode)v6, mode_size[v6], 0); 
v8 = gen_reg_rtx( ( machine_mode)v6); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v8->block.abstract_origin)) >> 1), 
ix86_va_arg_intreg, 
v14 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->block.abstract_origin)) >> 1), 
v19 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v20 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v31 = expand_expr( v30, x, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
v20 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
return offsettable_address_p( 1, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), op->fld[0].rtx) != 0; 
internal_error_function( msgid, ( va_list_0 *)va); 
set_diagnostic_context( &v2, msgid, ( va_list_0 *)va, input_filename, lineno, 0); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v5 = cpp_trigraph_map[*( ( unsigned __int8 *)buffer->cur + 1)]; 
while ( v9 < ( unsigned __int64)rlimit && ( sch_istable[*v8] & 0x800) != 0 ); 
if ( ( sch_istable[*v8] & 0x400) == 0 ) 
htab_traverse( hash_table_0, discard_useless_locs, 0LL); 
htab_traverse( hash_table_0, discard_useless_values, 0LL); 
if ( statement_code_p( ( tree_code)v13) && ( *( ( _BYTE *)*v9 + 19) & 4) == 0 ) 
result = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v9, &subtrees, v43, data, htab_); 
result = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v9, &subtrees, v43, data, htab_); 
v28 = statement_code_p( ( tree_code)v13); 
if ( ( _DWORD)v13 == 2 || v28 || lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v9) ) 
if ( ( _DWORD)v13 == 2 || v28 || lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v9) ) 
v5 = mode_class_0[mode]; 
v6 = mode_class_0[v4] != MODE_FLOAT; 
v8 = gen_lowpart( ( machine_mode)mode, v8); 
if ( ( unsigned int)( v5 - 7) < 2 || ( unsigned int)( mode_class_0[( unsigned int)v4] - 7) <= 1 ) 
v10 = simplify_gen_subreg( ( machine_mode)v4, x, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 0); 
v10 = simplify_gen_subreg( ( machine_mode)v4, x, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 0); 
v13 = simplify_gen_subreg( ( machine_mode)v11, v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2), 0); 
v13 = simplify_gen_subreg( ( machine_mode)v11, v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2), 0); 
*( _OWORD *)&result->dw_cfi_oprnd1.dw_cfi_reg_num = 0LL; 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( exp->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
v16 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
if ( optab_table[30]->handlers[v2].insn_code == CODE_FOR_nothing && mode_class_0[v2] == MODE_CC ) 
return insn_data_0[optab_table[30]->handlers[v3].insn_code].genfun( v6, v9); 
return insn_data_0[optab_table[30]->handlers[v3].insn_code].genfun( v6, v9); 
store_by_pieces_2( insn_data_0[insn_code].genfun, i, data); 
v2 = reg_avail_info_0; 
v3 = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
reg_avail_info_0[regno].last_set = v3; 
( machine_mode)*( ( unsigned __int8 *)arg0 + 2), 
if ( replace_reloads && recog_data_0.operand[opnum] != arg0 ) 
( machine_mode)*( ( unsigned __int8 *)memloc + 2), 
reloads_subreg_address = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v21); 
( machine_mode)*( unsigned __int8 *)( arg0->fld[0].rtwint + 2)); 
( machine_mode)*( ( unsigned __int8 *)arg0 + 2), 
&& ( !strict_memory_address_p( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), reloads_subreg_address->fld[0].rtx) 
LODWORD( indirect) = file_table_0.table; 
if ( !LODWORD( file_table_0.table) 
|| strcmp( file_name, *( const char **)( cfa_temp.offset + 8LL * LODWORD( file_table_0.table))) ) 
LODWORD( file_table_0.table) = indirect; 
LODWORD( file_table_0.table) = v3; 
tree v26; // r12 
tree v27; // rax 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[1] = v22; 
recog_data_0.operand[0] = v6; 
recog_data_0.operand[1] = v70; 
recog_data_0.operand[2] = v74; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[2] = v16; 
recog_data_0.operand[2] = ( rtx)v15; 
recog_data_0.operand[2] = ( rtx)v15; 
recog_data_0.operand[1] = v79; 
recog_data_0.operand[2] = v84; 
recog_data_0.operand[2] = v84; 
recog_data_0.operand[2] = v98; 
recog_data_0.operand[2] = ( rtx)v82; 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[1] = v33; 
recog_data_0.operand[2] = *( rtx *)( v34 + 16); 
v3 = assign_stack_local( ( machine_mode)v2, mode_size[v2], 0); 
v10 = force_reg( ( machine_mode)v9, v10); 
v11 = force_reg( ( machine_mode)v9, v11); 
v10 = force_reg( ( machine_mode)v9, v10); 
v27 = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
if ( !can_compare_p( *pcomparison, ( machine_mode)v9, purpose) ) 
v32 = mode_class_0[v9]; 
src = operand_sub*(short *)0xforce( result_val, v20 >> ( 6 - ( ( target_flags & 0x2000000) == 0)), BLKmode); 
v17 = expand_expr( ( tree)high, v16, ( machine_mode)*( ( unsigned __int8 *)v16 + 2), EXPAND_NORMAL); 
v6 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2)); 
( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
v9 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
spill_failure( chain->insn, *( reg_class *)( v13 + 10314208)); 
v9 = *( int *)( ( char *)&allocno_0->reg + v8); 
v108 = ( unsigned __int64)*( _DWORD *)cfun->emit->x_regno_reg_rtx[*( int *)( ( char *)&allocno_0->reg + v8)] >> 16; 
v11 = ( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[*( int *)( ( char *)&allocno_0->reg + v8)]); 
if ( !*( int *)( ( char *)&allocno_0->calls_crossed + v8) ) 
v13 = v109 | *( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->hard_reg_conflicts + v8); 
v14 = *( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->regs_someone_prefers + v8) | v13 | ~regs_used_so_far; 
v107 = ( unsigned __int8)BYTE2( *( _DWORD *)cfun->emit->x_regno_reg_rtx[*( int *)( ( char *)&allocno_0->reg + v8)]); 
if ( !_bittest64( ( const __int64 *)&v14, v17) && ix86_hard_regno_mode_ok( v17, ( machine_mode)v11) ) 
v19 = ( ( unsigned int)( mode_class_0[( unsigned int)v11] - 5) < 2) + 1; 
v26 = ~v14 & *( HARD_REG_ELT_TYPE *)( ( _BYTE *)&allocno_0->hard_reg_copy_preferences + v104); 
v2 = gen_reg_rtx( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( integer_types[5]->block.abstract_origin)) >> 1)); 
v39 = ( tree_node *)*( &global_trees + 12); 
v53 = build( ( tree_code)( ( ( ( code - 130) & 0xFFFFFFFD | 0x3C00000000uLL) - 1) >> 32), v25, v52, v41); 
v6 = expand_mult_add( b, reg, m, a, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
v10 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
v4 = gen_rtx_REG( ( machine_mode)v2, v3); 
p_int_cst = &exp->int_cst.int_cst; 
p_int_cst = &exp->int_cst.int_cst; 
high = ( unsigned __int8 *)p_int_cst; 
if ( v21 != *( tree_node **)( p + 5) ) 
v26 = ( tree_node *)v25[4]; 
v16 = lang_hooks_0.expand_constant( exp); 
*hv = ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64; 
return ( ~( v6 ^ h2) & ( v6 ^ ( ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64))) >> 63; 
v5 = ( ( unsigned int)( mode_class_0[v3] - 5) < 2) + 1; 
rtx result; // rax 
__m256 v18; // [rsp+40h] [rbp-58h] BYREF 
v8 = mode_class_0[mode]; 
return gen_rtx_fmt_e( ( rtx_code)( unsigned __int16)v3, mode, rtx); 
return simplify_gen_subreg( mode, rtx, ( machine_mode)v4, 0); 
*( _QWORD *)&v18.m256_f32[4] = d.r[2]; 
*( _OWORD *)v18.m256_f32 = *( _OWORD *)d.r; 
if ( ( v8 | 2) == 3 && ( unsigned __int16)v3 == 55 && mode_class_0[v4] == MODE_FLOAT ) 
*( _QWORD *)v18.m256_f32 = etarsingle( d); 
*( _OWORD *)&v18.m256_f32[2] = 0LL; 
*( _OWORD *)&v18.m256_f32[2] = 0LL; 
v11 = *( tree_node **)( *( _QWORD *)( low + 40) + 40LL); 
&& *( const mode_class *)( ( char *)mode_class_0 + ( ( *( ( _DWORD *)&type->type + 15) >> 7) & 0x1FC)) == MODE_INT ) 
v14 = swap_condition( ( rtx_code)v14); 
if ( !can_compare_p( ( rtx_code)v14, ( machine_mode)v10, ccp_store_flag) ) 
if ( ( v25 == 1317 || only_cheap && *( ( unsigned __int16 *)insn_data_0[v25].operand + 8) != mode) 
v38 = emit_store_flag( target, ( rtx_code)v14, v35, v37, ( machine_mode)v10, v52, 1); 
target = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
v40 = compare_from_rtx( v33, v34, ( rtx_code)v14, v52, ( machine_mode)v10, 0LL); 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + rtint) ) 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + rtint) ) 
rtl_op = first_rtl_op( ( tree_code)v2); 
v4 = ( tree_node *)ggc_alloc( 0x28uLL); 
*( _OWORD *)&v4->common.chain = 0LL; 
v34 = ( v32 - 1 < 0) ^ __OFADD__( -1LL, v32) | ( v32 == 1); 
v26 = ( tree_node *)*( &global_trees + 27); 
if ( alloc_aux_for_blocks_initialized ) 
alloc_aux_for_blocks_initialized = 1; 
v3 = ( tree_node *)*( ( _QWORD *)&ggc_pending_trees->name + elements_used); 
rtl_op = first_rtl_op( ( tree_code)v27); 
if ( alloc_aux_for_edges_initialized ) 
alloc_aux_for_edges_initialized = 1; 
*( _WORD *)pat = swap_condition( ( rtx_code)v2); 
rtx *fld; // rcx 
rtx v48; // rbp 
rtx v74; // rbx 
rtx v85; // rax 
rtx *v92; // r14 
rtx v97; // rbx 
rtx v106; // rbx 
rtl_op = first_rtl_op( ( tree_code)( unsigned __int8)v2); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
v21 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v6, v9, v3); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v6, v9, v3); 
( machine_mode)*( ( unsigned __int8 *)memrefloc + 2), 
if ( replace_reloads && recog_data_0.operand[opnum] != x ) 
if ( *( ( _BYTE *)in + 2) && !ix86_hard_regno_mode_ok( v3, ( machine_mode)*( ( unsigned __int8 *)in + 2)) ) 
if ( !ix86_hard_regno_mode_ok( v3, ( machine_mode)*( ( unsigned __int8 *)out + 2)) ) 
p_int_cst = &exp->int_cst.int_cst; 
low = ( tree)p_int_cst->low; 
v5 = *( unsigned __int8 *)( p_int_cst->low + 16); 
p_int_cst = &low->int_cst.int_cst; 
v11 = operand_sub*(short *)0xforce( op, v9, ( machine_mode)v6); 
v11 = operand_sub*(short *)0xforce( op, v9, ( machine_mode)v6); 
v12 = operand_sub*(short *)0xforce( v8, v9, ( machine_mode)v6); 
v12 = operand_sub*(short *)0xforce( v8, v9, ( machine_mode)v6); 
result = ( cpp_context_0 *)xmalloc( 0x38uLL); 
rtx v8; // rax 
rtx v11; // rax 
rtx v12; // r15 
rtx v13; // r15 
rtx v14; // rax 
rtx v15; // r12 
v5 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v11 = protect_from_queue( x->fld[0].rtx, 0); 
if ( v11 != x->fld[0].rtx ) 
v12 = v11; 
if ( !peep2_insn_data_0[v5].insn ) 
reg_set_to_hard_reg_set( &v32, peep2_insn_data_0[v5].live_before); 
if ( !peep2_insn_data_0[v5].insn ) 
reg_set_to_hard_reg_set( &v33, peep2_insn_data_0[v5].live_before); 
v15 = peep2_find_free_register_search_ofs + i - 53; 
if ( peep2_find_free_register_search_ofs + i <= 52 ) 
v15 = peep2_find_free_register_search_ofs + i; 
v20 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v24 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
peep2_find_free_register_search_ofs = v28; 
peep2_find_free_register_search_ofs = 0; 
if ( call_insn_operand( operand0->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx i; // [rsp+40h] [rbp-78h] 
v17 = mode_class_0[mode]; 
i = op1; 
if ( ( sch_istable[( unsigned __int8)v10] & 0xC00) == 0 ) 
while ( v12 != -1 && ( sch_istable[( unsigned __int8)v12] & 1) != 0 ); 
v7 = ( v6 - 1 < 0) ^ __OFADD__( -1LL, v6) | ( v6 == 1); 
if ( ( sch_istable[v15] & 0x88) != 0 ) 
induction_1 *giv; // rbp 
induction_1 *giv; // rbp 
giv = bl_0->giv; 
if ( giv ) 
ext_dependent = ( unsigned int *)giv->ext_dependent; 
giv->insn->fld[0].rtuint, 
fprintf( loop_dump_stream, "Failed ext dependent giv at %d, %s\n", giv->insn->fld[0].rtuint, v17); 
*( ( _BYTE *)giv + 100) |= 4u; 
giv = giv->next_iv; 
giv = giv->next_iv; 
while ( giv ); 
rtx v5; // r12 
rtx v43; // r8 
rtx v45; // rbx 
rtx v70; // rax 
rtx v77; // rcx 
rtx v88; // rax 
rtx last_value; // rax 
v6 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), tem); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v6); 
return gen_rtx_MEM( ( machine_mode)v10, v12); 
fatal_insn( "could not find a spill register", insn, &off_6CC868[4], 5051, "failed_reload"); 
*( _OWORD *)&rld[v2 / 0x68].in = 0LL; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
v5 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
fatal_insn_not_found( insn, "insn-attrtab.c", 14632, "get_attr_length_immediate"); 
if ( symbolic_operand( recog_data_0.operand[1], SImode) ) 
|| ( _DWORD)flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( ( unsigned int)( which_alternative - 2) > 2 || !aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( ( _DWORD)flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( symbolic_operand( recog_data_0.operand[1], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
v7 = recog_data_0.operand[2]; 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
v7 = recog_data_0.operand[2]; 
if ( incdec_operand( recog_data_0.operand[2], HImode) || which_alternative == 2 ) 
v7 = recog_data_0.operand[2]; 
v22 = mode_class_0[mode]; 
v24 = mode_class_0[mode]; 
v17 = simplify_relational_operation( ( rtx_code)*( _WORD *)v7, op0_mode, v7->fld[0].rtx, *( rtx *)&v7[1]); 
v9 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
rtx v22; // r15 
rtx v32; // rbx 
( machine_mode)( unsigned __int8)BYTE2( *rtwint), 
( machine_mode)BYTE2( v16)); 
v22 = real_in; 
v22 = real_in; 
v24 = ( _DWORD *)v22->fld[0].rtwint; 
( machine_mode)( unsigned __int8)BYTE2( *v24), 
v13 = assign_stack_local( ( machine_mode)v12, mode_size[v12], 0); 
v15 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v18 = gen_rtx_MEM( ( machine_mode)LOBYTE( subr->decl.result->block.supercontext), v15); 
subr->decl.result->decl.rtl = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v17)); 
v5 = force_reg( ( machine_mode)BYTE2( v3), x); 
v14 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( unsigned __int8 *)( v6.rtwint + 2), v6.rtx, arg1); 
rtx v25; // r12 
rtx *v27; // rbx 
*( _OWORD *)&v37.top = *( _OWORD *)&aux->top; 
*( _OWORD *)&v37.top = *( _OWORD *)&aux->top; 
fprintf( v21, off_607A24, ( unsigned int)i); 
v25 = v2->end; 
if ( *( _WORD *)v25 == 33 ) 
v25 = ( rtx)v25[1]; 
v27 = ( rtx *)( FP_mode_reg + 120); 
v28 = gen_rtx_fmt_ee( SET, VOIDmode, *v27, nan); 
v25 = emit_insn_after( v28, v25); 
v25 = emit_insn_after( v28, v25); 
subst_stack_regs( v25, &v37); 
v27 += 59; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v13 = hash_table_0; 
slot_with_hash = htab_find_slot_with_hash( v13, v14, v12, ( insert_option)( create != 0)); 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
*htab_find_slot_with_hash( hash_table_0, x, v7->value, INSERT) = v7; 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), last_value); 
if ( recog_data_0.insn != insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
v26 = gen_lowpart( ( machine_mode)v19, value); 
v26 = convert_to_mode( ( machine_mode)v19, value, 1); 
v28 = mask_rtx( ( machine_mode)v19, 0, bitsize, 0); 
value = expand_binop( ( machine_mode)v19, v27, value, v28, 0LL, 1, OPTAB_LIB_WIDEN); 
value = expand_shift( LSHIFT_EXPR, ( machine_mode)v19, value, v29, 0LL, 1); 
fprintf( asmfile, &off_607A24[1], ( unsigned int)current_sym_value); 
operand = insn_data_0[v34].operand; 
if ( !operand->predicate( v24, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
x = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)operand + 8)); 
if ( !operand[2].predicate( v25, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8), v25); 
if ( !operand[3].predicate( v26, ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8), v26); 
v29 = insn_data_0[( int)v34].genfun( x, v28); 
( rtx_code)( unsigned __int16)v4, 
( machine_mode)BYTE2( v4), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( rtx_code)( unsigned __int16)v4, 
( machine_mode)BYTE2( v4), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)BYTE2( v4), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)BYTE2( v4), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( rtx_code)( unsigned __int16)*( _DWORD *)v2, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v2), 
v11 = gen_rtx( ( rtx_code)v1, ( machine_mode)v2, v10, const_int_rtx[64]); 
rtx v4; // rax 
rtx line_note; // rbp 
rtx v10; // rax 
v4 = head; 
v4 = head; 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
v4 = ( rtx)v4[1]; 
while ( v4 ); 
line_note = v4; 
line_note = v4; 
line_note = v2; 
|| ( line_note = h_i_d[rtint].line_note) == 0LL 
|| line_note == v4 
|| line_note == v4 
|| v4 && line_note[2].fld[0].rtint == v4[2].fld[0].rtint && line_note[2] == v4[2] ) 
v8 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v7); 
v11 = gen_rtx_MEM( ( machine_mode)v9, v10); 
return simplify_gen_unary( ( rtx_code)v5, v6, v3, v18); 
return simplify_gen_binary( ( rtx_code)v5, v6, v7, v8); 
return simplify_gen_ternary( ( rtx_code)v5, v24, v11, v26, v13, v14); 
return simplify_gen_relational( ( rtx_code)v5, v25, v20, v21, v22); 
v3 = simplify_gen_subreg( v6, v15, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), *( _DWORD *)&x[1]); 
rtl_op = first_rtl_op( ( tree_code)v8); 
if ( !first_rtl_op( ( tree_code)v8) ) 
v11 = force_reg( ( machine_mode)v10, v11); 
v12 = force_reg( ( machine_mode)v10, v12); 
v17 = gen_reg_rtx( ( machine_mode)v10); 
v18 = gen_reg_rtx( ( machine_mode)v10); 
operand = insn_data_0[insn_code].operand; 
if ( !operand->predicate( operand0, ( machine_mode)v10) || !operand[3].predicate( to, ( machine_mode)v10) ) 
if ( !operand->predicate( operand0, ( machine_mode)v10) || !operand[3].predicate( to, ( machine_mode)v10) ) 
v29 = insn_data_0[v47].genfun( operand0, operand1); 
v31 = mode_class_0[v10]; 
v35 = gen_reg_rtx( ( machine_mode)i); 
v39 = gen_reg_rtx( ( machine_mode)v34); 
tree v37; // rbx 
tree v42; // rax 
tree v43; // rax 
v29 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), to->fld[0].rtx); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
*( _OWORD *)&result->insns = 0LL; 
*( _OWORD *)&result->src = 0LL; 
*( _OWORD *)&result->pred_next = 0LL; 
*( _OWORD *)&result->flags = 0LL; 
*( _OWORD *)v4->bits = *( _OWORD *)first->bits; 
*( _OWORD *)&v4->next = 0LL; 
v9 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v12), v14, ( machine_mode)BYTE2( v11)); 
v9 += subreg_regno_offset( rtuint, ( machine_mode)BYTE2( v12), v14, ( machine_mode)BYTE2( v11)); 
v18 = ( unsigned int)( ( unsigned int)( mode_class_0[( unsigned __int8)v17] - 5) < 2) + 1; 
v29 = subreg_regno_offset( v23, ( machine_mode)BYTE2( v22), v24, ( machine_mode)BYTE2( v21)); 
v29 = subreg_regno_offset( v23, ( machine_mode)BYTE2( v22), v24, ( machine_mode)BYTE2( v21)); 
v32 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v31] - 5) < 2) + 1; 
&& ( ( int)rtint < 53 || v32 <= ( int)v18 || ( int)v18 >= qty_0[*( ( int *)reg_qty + rtint)].size) 
if ( reg_meets_class_p( v30, qty_0[*( ( int *)reg_qty + rtint)].min_class) ) 
v59 = qty_0; 
*( ( _DWORD *)reg_next_in_qty + v57) = qty_0[v60].first_reg; 
v62 = qty_0; 
qty_0[v60].n_calls_crossed += *( _DWORD *)( reg_n_info->data.l[v57] + 32); 
rtx v15; // rax 
v15 = ( rtx)*( ( _QWORD *)v14 + 4); 
if ( *( _WORD *)v15 != 47 ) 
v15 = single_set_2( ( rtx)v14, *( ( rtx *)v14 + 4)); 
v15 = 0LL; 
if ( v15 && (  struct rtx_def *)v15[1] == rtx ) 
if ( v15 && (  struct rtx_def *)v15[1] == rtx ) 
rtx = v15->fld[0].rtx; 
rtx v8; // r12 
rtx v9; // r15 
rtx v12; // rsi 
rtx v15; // rax 
rtx v16; // [rsp+0h] [rbp-38h] BYREF 
v16 = v3; 
v8 = map->insn_map[rtx->fld[0].rtint]; 
if ( v8 ) 
|| ( v16 = copy_rtx_and_substitute( rtx[3].fld[0].rtx, map, 0), 
subst_constants( &v16, 0LL, map, 0), 
v9 = v16, 
v9 = v16, 
v8[3].fld[0].rtwint = ( __int64)v16, 
v8[3].fld[0].rtwint = ( __int64)v16, 
fatal_insn_not_found( insn, "insn-attrtab.c", 16766, "get_attr_modrm"); 
v4 = recog_data_0.operand[1]; 
v4 = recog_data_0.operand[0]; 
v7 = recog_data_0.operand[1]; 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
v7 = recog_data_0.operand[1]; 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
v5 = recog_data_0.operand[2]; 
v5 = recog_data_0.operand[2]; 
v5 = recog_data_0.operand[2]; 
v5 = recog_data_0.operand[2]; 
return !register_operand( recog_data_0.operand[1], SImode) && !register_operand( recog_data_0.operand[1], HImode); 
if ( *( _OWORD *)&alias == 0LL && !offset ) 
element = *( _OWORD *)&alias; 
*( _OWORD *)&v8->alias = element; 
*( _OWORD *)&v8->offset = v9; 
else if ( ( sch_istable[v6] & 0x10) != 0 ) 
v3 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v4 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v5 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v13 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v17 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
diagnostic_buffer->state.format_args = ( va_list_0 *)va; 
*( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4] = v17; 
*( _OWORD *)v8->state.diagnostic_count = v16; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1); 
v5 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), const_int_rtx[64]); 
fatal_insn_not_found( insn, "insn-attrtab.c", 19258, "get_attr_pent_pair"); 
v8 = recog_data_0.operand[1]; 
v8 = recog_data_0.operand[0]; 
if ( !( _DWORD)flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode) ) 
v20 = recog_data_0.operand[1]; 
v5 = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !( _DWORD)flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
v20 = recog_data_0.operand[1]; 
rtx v11; // r15 
v11 = assign_stack_local_1( BLKmode, v9, 0, v10); 
node->int_cst.int_cst.high = ( __int64)v11; 
rtx = v11->fld[0].rtx; 
v5 = gen_rtx_CONST_INT( ( machine_mode)mem, mode_size[v6]); 
*( _QWORD *)&mem[1] = get_mem_attrs( v3, expr, v4, v5, v8, ( machine_mode)*( ( unsigned __int8 *)mem + 2)); 
v2 = expand_simple_binop( ( machine_mode)v3, PLUS, operand0, v4, 0LL, 0, OPTAB_DIRECT); 
v2 = expand_simple_binop( ( machine_mode)v3, MINUS, pic_offset_table_rtx, operand0, 0LL, 1, OPTAB_DIRECT); 
if ( ( ( _DWORD)v4 == 16 || ( _DWORD)v4 == 22 || ( mode_class_0[v4] | 4) == 5) && computed >= 33 ) 
*( _OWORD *)retstr->r = 0LL; 
ereal_from_int( retstr, low, high, ( machine_mode)v5); 
ereal_from_uint( retstr, low, high, ( machine_mode)v5); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
operands[4] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[4]); 
*( _OWORD *)spill_cost = 0LL; 
*( _OWORD *)&spill_cost[4] = 0LL; 
*( _OWORD *)&spill_cost[8] = 0LL; 
*( _OWORD *)&spill_cost[12] = 0LL; 
*( _OWORD *)&spill_cost[16] = 0LL; 
*( _OWORD *)&spill_cost[20] = 0LL; 
*( _OWORD *)&spill_cost[24] = 0LL; 
*( _OWORD *)&spill_cost[28] = 0LL; 
*( _OWORD *)&spill_cost[32] = 0LL; 
fatal_insn_not_found( insn, "insn-attrtab.c", 11973, "get_attr_athlon_fpunits"); 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !register_operand( recog_data_0.operand[1], SImode) ) 
return 3 * ( immediate_operand( recog_data_0.operand[1], VOIDmode) == 0) + 1; 
if ( !register_operand( recog_data_0.operand[1], SImode) 
&& !immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !register_operand( recog_data_0.operand[1], SImode) 
&& !immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
v11 = recog_data_0.operand[3]; 
if ( which_alternative || mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( reg_avail_info_0[x->fld[0].rtuint].last_bb != current_bb ) 
return reg_avail_info_0[x->fld[0].rtuint].last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[x->fld[0].rtuint].last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[x->fld[0].rtuint].first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return reg_avail_info_0[x->fld[0].rtuint].first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
*( ( _OWORD *)object_base + 1) = 0LL; 
fatal_insn_not_found( insn, "insn-attrtab.c", 20358, "get_attr_prefix_rep"); 
v43 = ( format_wanted_type_0 *)&v177; 
if ( ( sch_istable[v36] & 4) != 0 ) 
while ( ( sch_istable[v36] & 4) != 0 ); 
if ( ( sch_istable[( unsigned __int8)v44[1]] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)*format] & 4) != 0 ) 
while ( ( sch_istable[v47] & 4) != 0 ); 
types = ( format_wanted_type_0 *)&v170; 
*( _WORD *)operands[1] = swap_condition( ( rtx_code)*( _WORD *)v2); 
if ( const0_operand( operands[2], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)) ) 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v25 = mode_class_0[v10]; 
result = mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtl)); 
v3 = lookup( x, v2 & 0x1F, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
predicate = insn_data_0[v15].operand->predicate; 
v18 = predicate( x, ( machine_mode)v11); 
operand = insn_data_0[v16].operand; 
if ( reg_class_subset_p( ( reg_class)c1, ( reg_class)v26) ) 
if ( *( _OWORD *)&t1 != 0LL 
rtx last_insn; // rax 
rtx v21; // rbx 
last_insn = get_last_insn( ); 
if ( last_insn ) 
v21 = last_insn; 
v21 = last_insn; 
while ( *( _WORD *)v21 != 34 ) 
if ( *( _WORD *)v21 == 33 ) 
v21[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], v21[3].fld[0].rtx); 
v21[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], v21[3].fld[0].rtx); 
v21 = ( rtx)v21[1]; 
if ( !v21 ) 
rtx v5; // r14 
rtx v7; // r14 
rtx v8; // r15 
v5 = gen_rtx_fmt_u00( LABEL_REF, VOIDmode, v4); 
mark_jump_label( v5, rtx, 0); 
*( _QWORD *)( *( _QWORD *)&rtx[2] + 32LL) = v5->fld[0].rtwint; 
if ( reg_note ) 
reg_set_0 *v3; // rax 
reg_set_0 *v3; // rax 
v3 = reg_set_table[regno]; 
if ( v3 ) 
v5 = uid_cuid_1; 
rtint = v3->insn->fld[0].rtint; 
v3 = v3->next; 
v3 = v3->next; 
while ( v3 ); 
while ( ( sch_istable[( unsigned __int8)v7] & 0x204) != 0 || v7 == 36 && pfile->opts.dollars_in_ident ) 
if ( ( sch_istable[( unsigned __int8)v7] & 0x204) == 0 ) 
return ( cpp_hashnode_0 *)ht_lookup( v14, v15, ( int)v12 - ( int)object_base, HT_ALLOCED); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
ix86_fp_comparison_codes( code, ( rtx_code *)&v3 + 1, &first_code, ( rtx_code *)&v3); 
recog_data_0.operand[0] = v5; 
recog_data_0.operand[1] = ( rtx)v6; 
if ( rtx_equal_p( v9, recog_data_0.operand[0]) ) 
if ( rtx_equal_p( v9, recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = v17; 
recog_data_0.operand[2] = v83; 
if ( *( _WORD *)recog_data_0.operand[1] != 66 ) 
recog_data_0.operand[1] = rtx; 
recog_data_0.operand[2] = v83; 
if ( *( _WORD *)recog_data_0.operand[1] != 66 ) 
recog_data_0.operand[1] = v87; 
recog_data_0.operand[2] = v83; 
if ( *( _WORD *)recog_data_0.operand[1] != 66 ) 
recog_data_0.operand[1] = v19; 
v5 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[v9] - 5) < 2) + 1; 
rtx equiv_value; // rax 
rtx v63; // rbp 
rtx v65; // rax 
rtx v66; // rax 
rtx v69; // rax 
rtx v75; // rax 
rtx v88; // rax 
rtx mult1; // [rsp+8h] [rbp-70h] 
rtx mult1a; // [rsp+8h] [rbp-70h] 
induction_1 *i; // rbx 
induction_1 *i; // rbx 
induction_1 *j; // rbp 
induction_1 *j; // rbp 
induction_1 *giv; // rbx 
induction_1 *giv; // rbx 
induction_1 *same; // rax 
induction_1 *same; // rax 
induction_1 *same_insn; // rdx 
induction_1 *same_insn; // rdx 
induction_1 *v41; // rax 
induction_1 *v41; // rax 
rtx new_reg; // rax 
induction_1 *m; // rax 
induction_1 *m; // rax 
induction_1 *k; // rax 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars ) 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars ) 
rtx v56; // rdx 
rtx v57; // rcx 
rtx v74; // rax 
rtx insn; // [rsp+8h] [rbp-B0h] BYREF 
rtx x; // [rsp+20h] [rbp-98h] 
insn = insn_in_loop; 
v8 = ( __int64)insn[4]; 
v13 = any_condjump_p( insn); 
insn_in_loop = next_insn_in_loop( loop, insn); 
insn = insn_in_loop; 
insn = i; 
v83 = insn; 
rtx v17; // rax 
rtx i; // rbx 
if ( ( _WORD)v7 == 61 && *( const mode_class *)( ( char *)mode_class_0 + ( ( v7 >> 14) & 0x3FC)) == MODE_INT ) 
v8 = reverse_condition( ( rtx_code)*v5); 
return gen_rtx_fmt_ee( v8, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v6, *( ( rtx *)v5 + 2)); 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v16 >> 14) & 0x3FC)) != MODE_INT ) 
v17 = canonicalize_condition( jump, ( rtx)v5, reverse, earliest, v15); 
v4 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
result = ( cpp_buffer_0 *)pfile->buffer_ob.object_base; 
*( _OWORD *)&result->cur = 0LL; 
*( _OWORD *)&result->prev = 0LL; 
*( _OWORD *)&result->rlimit = 0LL; 
*( _OWORD *)&result->warned_cplusplus_comments = 0LL; 
*( _OWORD *)&result->dir.sysp = 0LL; 
*( _OWORD *)&result->dir.ino = 0LL; 
*( _OWORD *)&result->dir.name = 0LL; 
rtx v31; // rbp 
rtx v38; // rax 
rtx last_insn; // rax 
rtx v57; // rax 
rtx v60; // rbx 
rtx v61; // rbp 
rtx v62; // r12 
rtx v63; // r15 
*( _OWORD *)&binding_level->parm_flag = 0LL; 
*( _OWORD *)&binding_level->this_block = 0LL; 
*( _OWORD *)&binding_level->shadowed = 0LL; 
*( _OWORD *)&binding_level->names = 0LL; 
rtx v51; // rax 
fprintf( outfile, off_607A24, *( _DWORD *)&in_rtx[2]); 
fprintf( outfile, off_607A24, *( _DWORD *)&in_rtx[3]); 
v35 = print_rtx_hi_name[v23]; 
v35 = print_rtx_qi_name[v23]; 
v35 = print_rtx_hi_name[in_rtx->fld[0].rtuint]; 
fprintf( outfile, off_63A0C3, ( unsigned int)( v23 - 29)); 
fprintf( outfile, off_607A24, rtuint); 
fprintf( outfile, off_607A24); 
fprintf( outfile, off_607A24, *( unsigned int *)( v14.rtwint + 8)); 
set_diagnostic_context( &v2, msgid, ( va_list_0 *)va, input_filename, lineno, flag_pedantic_errors == 0); 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
v26 = gen_rtx_fmt_e( USE, ( machine_mode)BYTE2( v2), v1->fld[0].rtx); 
v10 = nonzero_bits( v1->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( v1->fld[0].rtwint + 2)); 
v28 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), rtx); 
v30 = nonzero_bits( *( rtx *)( v1->fld[0].rtwint + 8), ( machine_mode)v29); 
( machine_mode)*( ( unsigned __int8 *)v1 + 2), 
v23 = simplify_shift_const( 0LL, ( rtx_code)( v3 + 89), ( machine_mode)v20, v27, ( int)v21 - ( int)v7); 
tree_node *v3; // rax 
v3 = field_type( tree_node); 
v2 = simple_type_size_in_bits( v3) >> 3; 
if ( mode && ( v2 & 0xFF0000) == 0 && ( mode_class_0[mode] | 2) != 3 ) 
*( _OWORD *)&v2->stack.chunk_size = 0LL; 
*( _OWORD *)&v2->stack.object_base = 0LL; 
*( _OWORD *)&v2->stack.chunk_limit = 0LL; 
*( _OWORD *)&v2->stack.alignment_mask = 0LL; 
*( _OWORD *)&v2->stack.freefun = 0LL; 
*( ( _OWORD *)&v2->stack + 5) = 0LL; 
v16 = *( _OWORD *)( aux + 24); 
*( _OWORD *)&old.top = v16; 
*( _OWORD *)&old.top = v16; 
change_stack( src->end, &old, v5, ( emit_where)( *( _WORD *)src->end == 33)); 
*( _OWORD *)&old.top = v16; 
v7 = gen_rtx_fmt_ee( v5, ( machine_mode)*( unsigned __int8 *)( v4 + 2), *( rtx *)( v4 + 8), *( rtx *)( v4 + 16)); 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v3), v3->fld[0].rtx) 
&& !push_operand( v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)) 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)v5), v5->fld[0].rtx) 
*( _OWORD *)&emit->x_first_insn = 0LL; 
rtx v17; // rax 
rtx v29; // r13 
rtx v36; // rdi 
rtx v46; // rax 
rtx v48; // r13 
rtx v51; // r12 
rtx *v52; // rax 
rtx v56; // rbx 
rtx v58; // rbx 
rtx v60; // rax 
rtx v20; // r14 
rtx v34; // r14 
rtx v41; // r15 
rtx v42; // r14 
rtx v51; // rbx 
rtx v59; // rax 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v3 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1], v2); 
result = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)v3 + 2), const_rtx); 
v5 = rtx_alloc( ( rtx_code)( unsigned __int16)*( _DWORD *)orig); 
v6 = expand_mult_add( b, reg, m, a, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
rtx v15; // rbx 
rtx v32; // r15 
rtx v41; // rax 
rtx v45; // rax 
v15 = ( rtx)y[1]; 
v15 = y->fld[0].rtx; 
v15 = canon_rtx( v16); 
if ( rtx_equal_for_memref_p( rtx, v15) ) 
&& ( c >= 0 || ( c + ysize < 0) ^ __OFADD__( c, ysize) | ( c + ysize == 0)) ) 
if ( *( _WORD *)v15 == 75 ) 
v18 = v15->fld[0].rtx; 
v19 = (  struct rtx_def *)v15[1]; 
rtx v22; // rax 
rtx v30; // rax 
rtx v40; // rax 
rtx datum; // [rsp+40h] [rbp-78h] 
rtx v122; // [rsp+70h] [rbp-48h] 
|| ( v103 = 0, v34 = 0, *( const mode_class *)( ( char *)mode_class_0 + ( ( v7 >> 14) & 0x3FC)) != MODE_FLOAT) ) 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
v9 = adjust_address_1( v4, ( machine_mode)v1, v7, 1, 1); 
operands[1] = gen_lowpart( ( machine_mode)v3, operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
node->int_cst.int_cst = *( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)&v3->block.vars; 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
*( _OWORD *)&head->first = 0LL; 
diagnostic_for_asm( insn, msgid, ( va_list_0 *)va, 0); 
*( _OWORD *)&e->flags = 0LL; 
*( _OWORD *)&e->insns = 0LL; 
*( _OWORD *)&e->src = 0LL; 
*( _OWORD *)&e->pred_next = 0LL; 
set_diagnostic_context( &v2, msgid, ( va_list_0 *)va, input_filename, lineno, 1); 
rtx *v59; // r15 
rtx *v67; // [rsp+18h] [rbp-60h] 
v59 = loc; 
if ( !validate_change( v60, v59, v61, 0) && !validate_replace_rtx( v10, v61, v60) ) 
if ( !validate_change( v60, v59, v62, 0) && !validate_replace_rtx( v10, v62, v60) ) 
adjust_address_1( v14, ( machine_mode)BYTE2( v12), 0LL, 0, 1); 
if ( int_mode_for_mode( ( machine_mode)BYTE2( v15)) == BLKmode ) 
v67 = loc; 
v9 = gen_lowpart_if_possible( ( machine_mode)*( unsigned __int8 *)( v7.rtwint + 2), op1); 
v9 = gen_rtx_SUBREG( ( machine_mode)v8, op1, 0); 
v13 = gen_lowpart_if_possible( ( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), op0); 
v13 = gen_rtx_SUBREG( ( machine_mode)v12, op0, 0); 
v17 = gen_lowpart_if_possible( ( machine_mode)*( unsigned __int8 *)( v15.rtwint + 2), op1); 
v17 = gen_rtx_SUBREG( ( machine_mode)v16, op1, 0); 
v21 = gen_lowpart_if_possible( ( machine_mode)*( unsigned __int8 *)( v19.rtwint + 2), op0); 
v21 = gen_rtx_SUBREG( ( machine_mode)v20, op0, 0); 
if ( ( v17 & nonzero_bits( v15, ( machine_mode)v20)) == 0 ) 
v26 = simplify_shift_const( 0LL, LSHIFTRT, ( machine_mode)*( unsigned __int8 *)( v3 + 2), v15, v19); 
v28 = force_to_mode( v26, ( machine_mode)v25, v27, v2.rtx, 0); 
v11 = ( tree_node *)*( &global_trees + 27); 
v8 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
v13 = ( _DWORD *)( ( char *)&unk_9CF38C + 4 * v8 + 4 * v5); 
rtx in; // rdi 
rtx out_reg; // rdi 
rtx v29; // rax 
rtx v32; // rax 
rtx dead_insn; // [rsp+18h] [rbp-60h] 
dead_insn = spill_reg_store[last_reload_reg]; 
in = rld[v5 - 1].in; 
if ( in ) 
if ( *( _WORD *)in == 66 || reload_inheritance_insn[v5 + 179] ) 
in = rld[v5 - 1].in_reg; 
while ( *( _WORD *)in == 63 ) 
in = in->fld[0].rtx; 
in = in->fld[0].rtx; 
if ( rtx_equal_p( in, rtx) ) 
fancy_abort( &off_6CC868[4], 4663, "reload_reg_reaches_end_p"); 
rtx v62; // [rsp+0h] [rbp-78h] 
rtx v63; // [rsp+0h] [rbp-78h] 
v62 = ( rtx)v34; 
v34 = ( __int64)v62; 
v7 = mode_class_0[v6]; 
deps_0 *v15; // rcx 
deps_0 *v15; // rcx 
deps_0 *v23; // [rsp+30h] [rbp-68h] 
deps_0 *v23; // [rsp+30h] [rbp-68h] 
v23 = bb_deps; 
bitmap_operation( &v23[v22].reg_last_in_use, &v23[v22].reg_last_in_use, from2, BITMAP_IOR); 
bitmap_operation( &v23[v22].reg_last_in_use, &v23[v22].reg_last_in_use, from2, BITMAP_IOR); 
&v23[v22].pending_read_insns, 
&v23[v22].pending_read_mems); 
&v23[v4].pending_write_insns, 
&v23[v4].pending_write_mems); 
v23[v22].last_pending_memory_flush); 
v23[v4].last_pending_memory_flush = concat_INSN_LIST( 
v23[v4].pending_lists_length += pred_deps->pending_lists_length; 
v23[v4].pending_flush_length += pred_deps->pending_flush_length; 
v23[v4].last_function_call = concat_INSN_LIST( pred_deps->last_function_call, v23[v22].last_function_call); 
v23[v4].last_function_call = concat_INSN_LIST( pred_deps->last_function_call, v23[v22].last_function_call); 
v23[v22].sched_before_next_call); 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
while ( ( sch_istable[( unsigned __int8)v7] & 0xC00) == 0 ) 
v18 = ( tree_node *)high; 
v3 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v2); 
mtherr( aE, 7); 
v13 = assign_stack_local( ( machine_mode)v9, v12, -( v10 < v11)); 
v13 = assign_stack_local( ( machine_mode)v9, v12, -( v12 != v10)); 
v18 = adjust_address_1( v13, ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v3] + 2), 0LL, 0, 1); 
fancy_abort( &off_6CC868[4], 573, "compute_use_by_pseudos"); 
v18 = ( ( unsigned int)( mode_class_0[v16] - 5) < 2) + 1; 
rtx v55; // rax 
rtx memloc; // rbp 
rtx v67; // rbp 
rtx v80; // rbx 
rtx *v96; // rdx 
if ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)reg >> 14) & 0x3FC)) - 5) > 1 ) 
rtx v20; // rax 
rtx *overflow_arg_area; // rax 
rtx v25; // rax 
rtx v29; // rax 
( rtx_code)( unsigned __int16)*( _DWORD *)x, 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( rtx_code)( unsigned __int16)*( _DWORD *)x, 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
result = simplify_relational_operation( ( rtx_code)( unsigned __int16)*( _DWORD *)x, v5, x->fld[0].rtx, *( rtx *)&x[1]); 
result = simplify_binary_operation( ( rtx_code)v1, v2, v7, rtx); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), 
v3 = gen_reg_rtx( ( machine_mode)BYTE2( v2)); 
ix86_fp_comparison_codes( ( rtx_code)v4, &bypass_code, &first_code, second_code); 
v5 = cselib_lookup( x, ( machine_mode)BYTE2( v4), 0); 
v7 = cselib_lookup( y, ( machine_mode)BYTE2( v6), 0); 
rtx v13; // rax 
rtx v19; // rax 
v13 = expand_expr( v12, 0LL, VOIDmode, EXPAND_NORMAL); 
v13 = gen_rtx_CONST_INT( VOIDmode, args[v5 / 0xA8].offset.constant); 
v14 = v13; 
v19 = expand_expr( v18, 0LL, VOIDmode, EXPAND_NORMAL); 
v19 = gen_rtx_CONST_INT( VOIDmode, args[v5 / 0xA8].slot_offset.constant); 
v20 = v19; 
v21 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), rtx, v14); 
add_dependence( insn, *( rtx *)( i + 8), ( reg_note)*( unsigned __int8 *)( i + 2)); 
rtx v5; // rax 
rtx v6; // rax 
rtx v9; // [rsp+0h] [rbp-28h] BYREF 
rtx p_hard_return; // [rsp+8h] [rbp-20h] BYREF 
if ( !identify_call_return_value( *( rtx *)&orig_insn[2], &p_hard_return, &v9) ) 
if ( !identify_call_return_value( *( rtx *)&orig_insn[2], &p_hard_return, &v9) ) 
|| rtx->fld[0].rtint != p_hard_return->fld[0].rtint 
v5 = next_nonnote_insn( v2); 
if ( !v5 ) 
v2 = v5; 
if ( *( _OWORD *)&out.base != 0LL ) 
fprintf( file, off_63A1D6, scale); 
fprintf( file, off_63A1DA, scale); 
v18 = ( char *)&off_63B9CA; 
v18 = ( char *)&off_6B55F1; 
put_condition_code( ( rtx_code)v13, v14, v15, v20, v5); 
v24 = mode_class_0[v12]; 
v7 = ( const char *)&unk_63A188; 
v7 = ( const char *)&unk_63A188; 
induction_1 *giv; // rcx 
induction_1 *giv; // rcx 
induction_1 *v24; // r14 
induction_1 *v24; // r14 
rtx *v27; // rsi 
rtx mult_val; // rax 
rtx v32; // rax 
rtx add_val; // rcx 
induction_1 **p_next_iv; // rbx 
induction_1 **p_next_iv; // rbx 
induction_1 *v35; // rax 
induction_1 *v35; // rax 
induction_1 **p_giv; // rbx 
induction_1 **p_giv; // rbx 
induction_1 *v37; // rax 
v6 = adjust_address_1( *operands, ( machine_mode)v5, 0LL, 1, 1); 
( machine_mode)v5); 
v13 = gen_rtx_fmt_ee( AND, ( machine_mode)v5, v10, v12); 
return build1( ( tree_code)v4, type, expr); 
return build1( ( tree_code)v4, type, expr); 
if ( symbolic_operand( v5, ( machine_mode)operands) ) 
v8 = force_reg( ( machine_mode)v4, v5); 
v6 = gen_reg_rtx( ( machine_mode)v4); 
v13 = mode_class_0[mode]; 
alias_set_entry_0 v3; // rax 
*( _OWORD *)v6.r = v8; 
*( _OWORD *)&node->block.vars = *( _OWORD *)v6.r; 
*( _OWORD *)&node->block.vars = *( _OWORD *)v6.r; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
sprintf( v22, "*.%s%u", ( const char *)&off_629E39, current_funcdef_number); 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
if ( mode_class_0[mode] == MODE_INT && !can_compare_p( op, mode, ccp_jump) ) 
if ( ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v2 >> 14) & 0x3FC)) | 4) != 6 ) 
timevar_push( TV_VARCONST_0); 
v14 = TV_VARCONST_0; 
timevar_push( TV_SYMOUT_0); 
v14 = TV_SYMOUT_0; 
v6 = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int8 *)loc + 2), copy); 
if ( mode_class_0[mode] != MODE_FLOAT ) 
fancy_abort( &off_6CC868[4], 4527, "reload_reg_free_p"); 
rtx v15; // rax 
rtx v27; // rax 
rtx v29; // rax 
rtx *v31; // rsi 
rtx v55; // rbx 
rtx *v57; // rbp 
rtx insn; // [rsp+0h] [rbp-68h] 
rtx arg0b; // [rsp+8h] [rbp-60h] 
rtx y; // [rsp+18h] [rbp-50h] 
rtx value; // [rsp+20h] [rbp-48h] BYREF 
rtx *v75; // [rsp+30h] [rbp-38h] 
v18 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*fld + 2)); 
if ( mode == VOIDmode || ( v4 & 0xFF0000) != 0 || ( mode_class_0[mode] | 2) == 3 ) 
undos = undobuf_0.undos; 
if ( undobuf_0.undos ) 
undos->next = undobuf_0.frees; 
undobuf_0.frees = undos; 
undobuf_0.undos = 0LL; 
edge_list_0 = pre_edge_lcm( gcse_file, n_exprs, transp, comp, antloc, ae_kill, &pre_insert_map, &pre_delete_map); 
rtx v37; // rcx 
fatal_insn_not_found( insn, "insn-attrtab.c", 21978, "get_attr_type"); 
v27 = recog_data_0.operand[1]; 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !register_operand( recog_data_0.operand[0], QImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
*px = convert_to_mode( ( machine_mode)v9, v11, 0); 
*py = convert_to_mode( ( machine_mode)v9, v12, 0); 
v4 = mode_class_0[v3]; 
induction_1 *v11; // rbp 
induction_1 *v11; // rbp 
( machine_mode)BYTE2( v8)) ) 
v11 = ( induction_1 *)xmalloc( 0xA8uLL); 
v11 = ( induction_1 *)xmalloc( 0xA8uLL); 
v11, 
v11->mem = x; 
v3 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), buf_addr); 
v5 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v3); 
v10 = gen_rtx_MEM( ( machine_mode)v2, v9); 
v6 = convert_to_mode( ( machine_mode)v7, v6, 1); 
v10 = gen_rtx_fmt_ee( MULT, ( machine_mode)v8, v6, v9); 
v11 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), table_label); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v8, v10, v11); 
v13 = memory_address_noforce( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v12); 
v14 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5)); 
v15 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) == 0 || ( _DWORD)flag_pic != 0) ^ 5), v13); 
fatal_insn_not_found( insn, "insn-attrtab.c", 1990, "result_ready_cost"); 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUMPRO || ( v3 = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || ( v3 = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUM && !incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( ix86_cpu != PROCESSOR_PENTIUM || incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], operands[5]); 
v5 = expand_expr( v2, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
v6 = expand_expr( v4, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
recog_data_0.operand[1] = v17; 
recog_data_0.operand[2] = v18; 
v21 = ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v13; 
recog_data_0.operand[2] = v92; 
recog_data_0.operand[2] = v92; 
v21 = ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand); 
recog_data_0.operand[1] = v22; 
recog_data_0.operand[2] = v27; 
v21 = ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand); 
recog_data_0.operand[2] = ( rtx)v23; 
recog_data_0.operand[2] = ( rtx)v23; 
v21 = ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand); 
recog_data_0.operand[1] = v30; 
v34 = ix86_unary_operator_ok( NEG, DImode, recog_data_0.operand); 
recog_data_0.operand[1] = v30; 
v21 = ix86_unary_operator_ok( NEG, DImode, recog_data_0.operand); 
deps_0 deps; // [rsp+10h] [rbp-78h] BYREF 
*( _OWORD *)&deps.in_post_call_group_p = *( _OWORD *)&bb_deps[v1].in_post_call_group_p; 
*( _OWORD *)&deps.in_post_call_group_p = *( _OWORD *)&bb_deps[v1].in_post_call_group_p; 
*( _OWORD *)&deps.in_post_call_group_p = *( _OWORD *)&bb_deps[v1].in_post_call_group_p; 
v2 = *( _OWORD *)&bb_deps[v1].pending_read_insns; 
v3 = *( _OWORD *)&bb_deps[v1].pending_write_insns; 
v4 = *( _OWORD *)&bb_deps[v1].pending_lists_length; 
*( _OWORD *)&deps.last_function_call = *( _OWORD *)&bb_deps[v1].last_function_call; 
*( _OWORD *)&deps.last_function_call = *( _OWORD *)&bb_deps[v1].last_function_call; 
*( _OWORD *)&deps.last_function_call = *( _OWORD *)&bb_deps[v1].last_function_call; 
v24 = insn_data_0[insn_code].genfun( x, y); 
v5 = mode_class_0[v2]; 
if ( push_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
v46 = insn_data_0[v43].genfun( v44, v45); 
v50 = insn_data_0[v47].genfun( v48, v49); 
v60 = expand_binop( ( machine_mode)( v56 ^ 5), v57, v58, v59, global_rtl[2], 0, OPTAB_LIB_WIDEN); 
v70 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v67, v68, v69); 
v22 = ( tree_node *)low; 
type->type.align = get_mode_alignment( ( machine_mode)v2); 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v18; 
recog_data_0.operand[0] = ( rtx)v18; 
recog_data_0.operand[0] = v21; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v8; 
recog_data_0.operand[1] = v7; 
recog_data_0.operand[0] = ( rtx)v13; 
( machine_mode)*( unsigned __int8 *)( v3->fld[0].rtwint + 2), 
v12 = negate_rtx( ( machine_mode)BYTE2( v5), *( rtx *)&value[1]); 
v15 = expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v6, v14, v12, subtarget, 0, OPTAB_LIB_WIDEN); 
subtarget = gen_reg_rtx( ( machine_mode)BYTE2( v5)); 
v24 = *( _OWORD *)&args->gp_offset; 
if ( memchr( &off_6E33E0, v19, 4uLL) ) 
while ( memchr( &off_6E33E0, v19, 4uLL) ); 
rtx result; // rax 
rtx v19; // rdx 
rtx compound_operation; // rbp 
rtx *y; // [rsp+8h] [rbp-80h] 
rtx ya; // [rsp+8h] [rbp-80h] 
rtx ina; // [rsp+20h] [rbp-68h] 
rtx inb; // [rsp+20h] [rbp-68h] 
if ( spelling_base < spelling_0 ) 
v2 = spelling_0; 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
recog_data_0.operand[6] = v80; 
recog_data_0.operand[4] = v84; 
recog_data_0.operand[5] = v86; 
recog_data_0.operand[3] = v89; 
recog_data_0.operand[0] = v96; 
recog_data_0.operand[1] = v98; 
recog_data_0.operand[2] = v100; 
recog_data_0.operand[7] = v103; 
recog_data_0.operand[8] = v109; 
|| !rtx_equal_p( *( rtx *)( v116 + 8), recog_data_0.operand[7]) 
|| !rtx_equal_p( *( rtx *)( v116 + 16), recog_data_0.operand[8]) 
|| !peep2_reg_dead_p( 4, recog_data_0.operand[7]) 
|| !peep2_reg_dead_p( 4, recog_data_0.operand[8]) ) 
result = gen_peephole2_1208( insn, recog_data_0.operand); 
recog_data_0.operand[4] = v13; 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( **( ( _DWORD **)aux + 6) >> 14) & 0x3FC)) == MODE_FLOAT 
*( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v15 >> 14) & 0x3FC)) == MODE_FLOAT) ) 
if ( v10 == ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1 ) 
v14 = adjust_address_1( v14, ( machine_mode)v15, 0LL, 1, 1); 
v16 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)v14 + 2), v7); 
v7 = ( tree_node *)v6[1]; 
v11 = gen_rtx_CONST_INT( ( machine_mode)ref, mode_size[v10]); 
if ( !lang_hooks_0.honor_readonly 
v9 = gen_rtx_CONST_INT( ( machine_mode)v26, v27); 
v9 = gen_rtx_CONST_INT( ( machine_mode)v32, v33); 
rtl_op = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16)); 
v11 = ( tree_node *)i[13]; 
v19 = ( tree_node *)*( ( _QWORD *)&chain->vector.elements + v18); 
induction_1 *i; // r12 
induction_1 *i; // r12 
induction_1 *j; // rbx 
induction_1 *j; // rbx 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
for ( i = bl_0->giv; i; i = i->next_iv ) 
if ( ( *( ( _BYTE *)i + 100) & 4) == 0 && !i->same ) 
if ( ( *( ( _BYTE *)i + 100) & 4) == 0 && !i->same ) 
if ( !i->new_reg ) 
i->new_reg = gen_reg_rtx( i->mode); 
i->new_reg = gen_reg_rtx( i->mode); 
for ( j = bl_0->biv; j; j = j->next_iv ) 
for ( j = bl_0->biv; j; j = j->next_iv ) 
for ( j = bl_0->biv; j; j = j->next_iv ) 
for ( j = bl_0->biv; j; j = j->next_iv ) 
add_val = j->add_val; 
mult_val = i->mult_val; 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
fancy_abort( &off_6CC868[4], 9527, "fixup_abnormal_edges"); 
if ( apply_result_size_size < 0 ) 
apply_result_size_size = 0; 
if ( apply_result_size_size % v6 ) 
apply_result_size_size = v6 + apply_result_size_size - 1 - ( v6 + apply_result_size_size - 1) % v6; 
apply_result_size_size = v6 + apply_result_size_size - 1 - ( v6 + apply_result_size_size - 1) % v6; 
apply_result_size_size = v6 + apply_result_size_size - 1 - ( v6 + apply_result_size_size - 1) % v6; 
apply_result_size_size += mode_size[v1]; 
apply_result_size_size = 116; 
return apply_result_size_size; 
*( reload_type *)( v2 + 10314284), 
*( machine_mode *)( v2 + 10314220)); 
return gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, val, next); 
v5 = -args_size_0; 
v7 = args_size_0 + v5; 
args_size_0 = v6; 
def_cfa_1( dwarf2out_cfi_label_label, &cfa); 
v3 = args_size_0; 
v4 = dwarf2out_cfi_label_label; 
rtx x; // [rsp+8h] [rbp-40h] BYREF 
x = insns; 
for_each_rtx( &x, insns_for_mem_walk, data); 
rtx = x[1].fld[0].rtx; 
x = rtx; 
error_with_decl( decl, &off_6E2FF0[4]); 
( rtx_code)*( _WORD *)if_info->cond, 
*( _OWORD *)&sequence_result[2] = 0LL; 
*( _OWORD *)sequence_result = 0LL; 
v15 = ( tree_node *)v14; 
values = ( tree_node *)*p_chain; 
v5 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
if ( ( sch_istable[v23] & 0x100) != 0 ) 
if ( ( sch_istable[v23] & 0x100) == 0 ) 
if ( ( sch_istable[( unsigned __int8)pc] & 0xAC) == 0 ) 
if ( *( _OWORD *)&x == 0LL ) 
rtx *v17; // rcx 
v17 = ( rtx *)( v13->fld[0].rtwint + 16); 
v17 = const_int_rtx + 520; 
*mult_val = *v17; 
v11 = force_reg( ( machine_mode)BYTE2( v6), op); 
v10 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)op + 2), v8); 
rtx v12; // rax 
rtx v13; // rbp 
rtx v15; // rax 
rtx v16; // rbp 
rtx v22; // rax 
v12 = copy_rtx( rtx); 
v13 = v12; 
v13 = v12; 
|| *( _WORD *)v12 != 135 
rtx v18; // rax 
rtx v22; // rax 
rtx label_from_map; // rax 
rtx v26; // r13 
rtx v28; // rax 
rtx v31; // rax 
induction_1 *v39; // r13 
induction_1 *v39; // r13 
rtx v41; // rax 
rtx v42; // rdx 
v50 = store_field( targeta, v41, v42, v48, exp, ( machine_mode)v44, v45, type, alias_set); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v58->common.type->block.abstract_origin)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v49->common.type->block.abstract_origin)) >> 1), 
v20 = expand_expr( from, 0LL, ( machine_mode)*( ( unsigned __int8 *)v18 + 2), EXPAND_NORMAL); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( sizetype_tab[0]->block.abstract_origin)) >> 1), 
v3 = lang_hooks_0.expand_constant( value); 
elements = *( tree_node **)( high + 32); 
v35 = mode_class_0[v34]; 
v41 = mode_class_0[v40]; 
v14 = ( tree_node *)*( &global_trees + 25); 
if ( ( unsigned int)format > 0xFF || ( result = eh_data_format_name_format_names[format]) == 0LL ) 
list_head = mem_loc_descriptor( rtx, ( machine_mode)BYTE2( v18)); 
v35 = new_loc_descr( ( dwarf_location_atom)v7, 0LL, 0LL); 
if ( ( sch_istable[v6] & 4) == 0 ) 
v5 = 2 * ( ( sch_istable[v6] & 4) == 0) + 8; 
if ( ( sch_istable[v14] & 4) != 0 || ( sch_istable[v14] & 0x100) != 0 && v5 == 16 ) 
if ( ( sch_istable[v14] & 4) != 0 || ( sch_istable[v14] & 0x100) != 0 && v5 == 16 ) 
v15 = hex_value[v14]; 
if ( ( sch_istable[( unsigned __int8)v32] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v32] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v32] & 4) == 0 ) 
v38 = ( tree)&unk_60D418; 
v38 = ( tree)&unk_60D428; 
v76 = recog_data_0.operand[v75]; 
( machine_mode)*( unsigned __int8 *)( v5.rtwint + 2), 
( machine_mode)BYTE2( v3)); 
( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)y)); 
rtx nonnote_insn; // rax 
rtx *v21; // rax 
v21 = ( rtx *)*( ( _QWORD *)v10 + 2); 
v22 = *( _WORD *)v21; 
if ( *( _WORD *)v21 == 51 || v22 == 59 ) 
set_label_offsets( v21[1], insn, initial_p); 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
v5 = simplify_binary_operation( PLUS, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)x), *constptr, v4); 
v9 = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, op1[0]); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, v8); 
( machine_mode)*( unsigned __int8 *)( ( *loc)->fld[0].rtwint + 2), 
v9 = gen_rtx_SUBREG( ( machine_mode)v11, reg_rtx->fld[0].rtx, v12 - v12 % mode_size[v11]); 
( rtx_code)( unsigned __int16)*( _DWORD *)*loc, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)*loc), 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx *v37; // rbp 
rtx v43; // [rsp+18h] [rbp-70h] 
|| ( v43 = *loc, v46 = to, ( ( *( _DWORD *)from ^ v8) & 0xFFFFFF) == 0) 
v4 = v43; 
v4 = v43; 
v17 = swap_condition( ( rtx_code)v47); 
if ( recog_data_0.n_operands <= 0 ) 
v2 = recog_data_0.n_operands + 1LL; 
v5 = **( ( _DWORD **)&changes_allocated + v2); 
|| ( v6 = *( ( _QWORD *)&changes_allocated + v2), *( _WORD *)v6 != 54) 
fatal_insn( "unknown insn mode", insn, "i386.c", 9956, "ix86_attr_length_immediate_default"); 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), label); 
if ( !size_int_type_wide_size_htab ) 
size_int_type_wide_size_htab = htab_create( 0x400uLL, size_htab_hash, size_htab_eq, 0LL); 
ggc_add_deletable_htab( size_int_type_wide_size_htab, 0LL, 0LL); 
size_int_type_wide_new_const = make_node( INTEGER_CST); 
ggc_add_tree_root( &size_int_type_wide_new_const, 1); 
v2 = size_int_type_wide_new_const; 
*( _OWORD *)&size_int_type_wide_new_const->block.vars = number; 
*( _OWORD *)&size_int_type_wide_new_const->block.vars = number; 
v3 = force_fit_type( size_int_type_wide_new_const, 0); 
*( ( _DWORD *)&size_int_type_wide_new_const->common + 4) = *( ( _DWORD *)&size_int_type_wide_new_const->common + 4) & 0xFFF3FFFF | ( ( v3 & 1) << 18) | ( ( v3 & 1) << 19); 
*( ( _DWORD *)&size_int_type_wide_new_const->common + 4) = *( ( _DWORD *)&size_int_type_wide_new_const->common + 4) & 0xFFF3FFFF | ( ( v3 & 1) << 18) | ( ( v3 & 1) << 19); 
slot = htab_find_slot( size_int_type_wide_size_htab, size_int_type_wide_new_const, INSERT); 
slot = htab_find_slot( size_int_type_wide_size_htab, size_int_type_wide_new_const, INSERT); 
v5 = ( tree_node *)*slot; 
v5 = size_int_type_wide_new_const; 
*slot = size_int_type_wide_new_const; 
if ( mode_class_0[BYTE2( v3)] == MODE_FLOAT 
|| *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x->fld[0].rtwint >> 14) & 0x3FC)) == MODE_FLOAT ) 
if ( *( const mode_class *)( ( char *)mode_class_0 + v4) == MODE_FLOAT ) 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v3 >> 14) & 0x3FC)) == MODE_FLOAT ) 
v3 = ( tree_node *)ggc_alloc( v2); 
v2 = ( unsigned __int64 *)higher_prime_number_primes; 
mark_set_1( pbi, ( rtx_code)( unsigned __int16)v12, *( ( rtx *)v11 + 1), v7, insn, pbi->flags); 
mark_set_1( pbi, ( rtx_code)( unsigned __int16)v8, v4->fld[0].rtx, v7, insn, pbi->flags); 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
rtx *v54; // rbp 
rtx v55; // rax 
rtx v79; // [rsp+60h] [rbp-C8h] BYREF 
rtx *v90; // [rsp+F0h] [rbp-38h] 
v79 = op1; 
v28 = &v79; 
v90 = v28; 
v28 = v90 + 2; 
*( _OWORD *)&base[16 * v48] = *( _OWORD *)&base[v46]; 
*( _OWORD *)&base[16 * v48] = *( _OWORD *)&base[v46]; 
x_arg_pointer_save_area = assign_stack_local_1( ( machine_mode)v3, mode_size[v3], 0, f); 
v12 = gen_rtx( v10, ( machine_mode)v7, v5, v11); 
recog_data_0.operand[1] = v8.rtx; 
recog_data_0.operand[2] = v31; 
recog_data_0.operand[0] = v33; 
if ( !rtx_equal_p( *( rtx *)( v34 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = v8.rtx; 
recog_data_0.operand[2] = v10; 
|| ( recog_data_0.operand[0] = v13, v14 = *( _QWORD *)( v12 + 16), ( *( _DWORD *)v14 & 0xFFFFFF) != 327755) 
|| !rtx_equal_p( *( rtx *)( v14 + 8), recog_data_0.operand[1]) 
recog_data_0.operand[0] = v7; 
recog_data_0.operand[0] = v7; 
recog_data_0.operand[1] = v49; 
recog_data_0.operand[2] = v52; 
recog_data_0.operand[3] = v54; 
v55 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)recog_data_0.operand[1] >> 14) & 0x3FC)); 
v55 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)recog_data_0.operand[1] >> 14) & 0x3FC)); 
v57 = *( _DWORD *)recog_data_0.operand[1] & 0xFF0000; 
v11 = ( tree_node *)v10; 
sprintf( v27, off_6C5406, v37); 
v8 = operand_sub*(short *)0xforce( x, i, mode); 
if ( mode_class_0[bl_0->biv->mode] != MODE_INT ) 
v14 = safe_hash( v5, ( machine_mode)v9); 
v15 = lookup( v5, v14 & 0x1F, ( machine_mode)*( ( unsigned __int8 *)v5 + 2)); 
if ( mode_class_0[v16] != MODE_INT ) 
if ( mode_class_0[( unsigned int)v16] != MODE_INT ) 
rtx v18; // rbp 
rtx v21; // [rsp+8h] [rbp-40h] BYREF 
rtx p; // [rsp+18h] [rbp-30h] BYREF 
p = x; 
add_double( *( _QWORD *)&x[1], x[1].fld[0].rtwint, v3, v3 >> 63, ( unsigned __int64 *)&v21, &i1); 
return immed_double_const( ( __int64)v21, i1, VOIDmode); 
v18 = force_const_mem( v15, v17); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v18 + 2), v18->fld[0].rtx) ) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v18 + 2), v18->fld[0].rtx) ) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v18 + 2), v18->fld[0].rtx) ) 
return v18; 
v3 = trunc_int_for_mode( v3, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v4 = *( tree_node **)( *high + 32LL); 
v6 = ( tree_node *)high[4]; 
predict_insn_def( v13, PRED_BUILTIN_EXPECT, ( prediction)v12); 
else if ( ( sch_istable[( unsigned __int8)v3] & 0x400) != 0 ) 
list_head[0] = mem_loc_descriptor( rtx->fld[0].rtx, ( machine_mode)BYTE2( v4)); 
rtx *v15; // rcx 
rtx *v19; // rbx 
rtx *v20; // r8 
rtx v22; // rbx 
rtx v30; // rbp 
rtx x; // [rsp+8h] [rbp-40h] BYREF 
rtx v35; // [rsp+10h] [rbp-38h] 
x = value; 
v6 = ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1; 
x = replace_rtx( v14, reg, rtx); 
v35 = reg; 
v15 = &reg_last_set_value[rtuint]; 
v19 = &reg_last_death[rtuint]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 17669, "get_attr_mode"); 
|| ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) 
|| ( v16 = aligned_operand( recog_data_0.operand[1], HImode), result = MODE_SI, !v16) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
fprintf( file, &off_607A24[1], _bittest64( ( const __int64 *)&v8, v7)); 
fatal_insn_not_found( insn, "recog.c", 2063, "extract_constrain_insn_cached"); 
rtx v3; // rbx 
rtx v4; // rax 
v3 = head; 
if ( *( _WORD *)v3 == 37 ) 
v4 = unlink_line_notes( v3, rtx); 
v4 = unlink_line_notes( v3, rtx); 
if ( v3 == tail ) 
if ( v3 == head ) 
v3 = v4; 
v3 = v4; 
if ( v4 == rtx ) 
v3 = v3[1].fld[0].rtx; 
v3 = v3[1].fld[0].rtx; 
while ( v3 != rtx ); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[4]); 
v4 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
p_free_buffs = ( _cpp_buff_0 **)*p_free_buffs; 
result = gen_rtx_CONST_INT( ( machine_mode)code, ( __int64)v11); 
rtx v18; // rbp 
rtx v19; // rbx 
rtx *v20; // rax 
rtx v31; // [rsp+8h] [rbp-70h] 
rtx *listp; // [rsp+28h] [rbp-50h] 
listp = &pbi->mem_set_list; 
v31 = v6; 
free_EXPR_LIST_list( listp); 
v27 = ( int *)*( ( _QWORD *)v31 + v24); 
v12 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v7->exp >> 14) & 0x3FC)) 
timevar_push( TV_CLEANUP_CFG_0); 
timevar_pop( TV_CLEANUP_CFG_0); 
rtx real_insn; // rax 
rtx v30; // rax 
rtx v36; // rcx 
v8 = *( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint); 
real_insn = next_real_insn( insn); 
v47 = real_insn; 
if ( data->path[v13].status != NOT_TAKEN_0 ) 
data->path[v13].status = NOT_TAKEN_0; 
if ( ( int)rtint <= max_uid && *( ( _DWORD *)uid_cuid_0 + rtint) >= v16 ) 
v16 = *( ( _DWORD *)uid_cuid_0 + rtint); 
v22 = *( ( _DWORD *)uid_cuid_0 + rtint); 
if ( data->path[v46].status != NOT_TAKEN_0 ) 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)op0 >> 14) & 0x3FC)) == MODE_FLOAT ) 
v22 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg_rtx)] - 5) < 2) + 1; 
if ( mode_class_0[v8] != MODE_INT ) 
rtx v24; // [rsp+10h] [rbp-38h] 
for ( i = bb->end; i && i != ( rtx)k->head[1]; i = ( rtx)v24[1] ) 
*( _OWORD *)&result->block.vars = *( _OWORD *)d.r; 
*( _OWORD *)&result->block.vars = *( _OWORD *)d.r; 
v2 = convert_to_mode( ( machine_mode)v4, size, 1); 
v14 = gen_rtx_fmt_ee( MINUS, ( machine_mode)v10, v12, v13); 
v26 = gen_rtx_fmt_ee( MINUS, ( machine_mode)v10, v12, v27); 
v19 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v19); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx *v20; // [rsp+10h] [rbp-38h] 
v20 = &last_set[rtint]; 
v12 = ( ( unsigned int)( mode_class_0[v13] - 5) < 2) + 1; 
v20[v11++] = insn; 
reg_set_0 **v4; // rcx 
reg_set_0 **v4; // rcx 
reg_set_table = ( reg_set_0 **)grealloc( ( char *)reg_set_table, 8 * ( regno + 100)); 
v4 = reg_set_table; 
v4[regno] = ( reg_set_0 *)object_base; 
v4[regno] = ( reg_set_0 *)object_base; 
v8 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)dest)] - 5) < 2) + 1; 
v13 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v9 = ( const char *)&unk_63AA3F; 
v9 = ( const char *)&unk_63AA42; 
v9 = ( const char *)&off_63AA3B; 
v9 = ( const char *)&unk_63AA45; 
return insn_data_0[code].name; 
rtx v8; // rax 
rtx ops[16]; // [rsp+100h] [rbp-1A8h] BYREF 
if ( recog_data_0.n_operands > 0 ) 
if ( recog_data_0.n_operands > 0 ) 
n_operands = ( unsigned int)recog_data_0.n_operands; 
memcpy( dest, recog_data_0.constraints, 8 * n_operands); 
memcpy( ops, recog_data_0.operand_mode, 4 * n_operands); 
memcpy( ops, recog_data_0.operand_mode, 4 * n_operands); 
if ( recog_data_0.n_operands > 0 ) 
v8 = recog_data_0.operand[v5]; 
v8 = recog_data_0.operand[v5]; 
if ( *( _WORD *)v8 == 63 ) 
recog_data_0.operand[v5] = v8->fld[0].rtx; 
recog_data_0.operand[v5] = v8->fld[0].rtx; 
rtx = recog_data_0.operand[v5]; 
while ( v5 < recog_data_0.n_operands ); 
rtx v21; // rax 
rtx nonnote_insn; // rax 
rtx v30; // rdi 
rtx v31; // rax 
rtx v34; // [rsp+10h] [rbp-38h] 
v34 = no_share; 
rtx v23; // rax 
rtx *single_use; // rax 
rtx **v33; // rbx 
rtx v36; // rax 
rtx v37; // rbp 
rtx v52; // rbp 
rtx *v60; // rax 
rtx v65; // rbx 
rtx *v67; // rax 
recog_data_0.operand[0] = v4.rtx; 
recog_data_0.operand[1] = ( rtx)v48; 
return gen_split_1133( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v7; 
return gen_split_1135( recog_data_0.operand); 
recog_data_0.operand[0] = v4.rtx; 
recog_data_0.operand[1] = v13; 
return gen_split_943( recog_data_0.operand); 
recog_data_0.operand[0] = v4.rtx; 
recog_data_0.operand[1] = v15; 
v3 = mode_class_0[v2]; 
set_diagnostic_context( &v3, msgid, ( va_list_0 *)va, input_filename, lineno, 1); 
v6 = mode_class_0[mode]; 
operand = insn_data_0[insn_code].operand; 
v16 = insn_data_0[v48].genfun( last_insn, v15); 
v21 = convert_modes( ( machine_mode)i, mode, x, unsignedp); 
v22 = expand_complex_abs( ( machine_mode)v20, v21, 0LL, unsignedp); 
v37 = convert_modes( ( machine_mode)v35, mode, x, unsignedp); 
v38 = expand_complex_abs( ( machine_mode)v35, v37, 0LL, unsignedp); 
result = ( const char *)insn_data_0[code].output; 
output_format = insn_data_0[code].output_format; 
return ( const char *)( ( __int64 (  *)(  struct recog_data *))result)( &recog_data_0); 
( tree_code)( ( ( *( ( _DWORD *)&exp->common + 4) & 0xFD) == 129) + 59), 
operand = insn_data_0[insn_code].operand; 
if ( operand->predicate( operand1, ( machine_mode)v19) && operand[1].predicate( operand1, ( machine_mode)v19) ) 
if ( operand->predicate( operand1, ( machine_mode)v19) && operand[1].predicate( operand1, ( machine_mode)v19) ) 
v21 = operand[2].predicate( v16, ( machine_mode)v19) != 0; 
v28 = insn_data_0[v26].operand; 
if ( v28->predicate( operand1, ( machine_mode)v19) && v28[1].predicate( operand1, ( machine_mode)v19) ) 
if ( v28->predicate( operand1, ( machine_mode)v19) && v28[1].predicate( operand1, ( machine_mode)v19) ) 
if ( !v28[2].predicate( x, ( machine_mode)v19) ) 
force_reg( ( machine_mode)v19, x); 
v29 = insn_data_0[v27].genfun( operand1, operand1); 
if ( general_operand( operand1->fld[0].rtx, ( machine_mode)v19) ) 
v34 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operand1->fld[0].rtx); 
v37 = force_reg( ( machine_mode)*( ( unsigned __int8 *)v36 + 2), v36); 
if ( !v28[2].predicate( x, ( machine_mode)v19) ) 
force_reg( ( machine_mode)v19, x); 
rtx v37; // rbp 
rtx v40; // rax 
rtx v42; // rdx 
rtx v43; // rcx 
rtx set_dest; // rbx 
rtx v50; // rbx 
rtx v52; // rax 
rtx v55; // rax 
rtx v61; // rbx 
reg_note = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, datum, insn[3].fld[0].rtx); 
v2 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
p_int_cst = &exp->int_cst.int_cst; 
p_int_cst = &exp->int_cst.int_cst; 
pointer = p_int_cst; 
v31 = ( tree_node *)v30[4]; 
v20 = lang_hooks_0.expand_constant( exp); 
rtx srca; // [rsp+8h] [rbp-68h] 
rtx dest; // [rsp+10h] [rbp-60h] 
rtx *tmps; // [rsp+20h] [rbp-50h] 
rtx dst; // [rsp+30h] [rbp-40h] 
dst = orig_dst; 
v9 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v8 + 2)); 
tmps = v5; 
v10 = dst; 
v11 = *( _DWORD *)dst; 
if ( ( unsigned __int16)( *( _DWORD *)dst - 65) >= 2u ) 
if ( !rtx_equal_p( dst, src) ) 
v12 = dst; 
v14 = assign_stack_temp( ( machine_mode)*( ( unsigned __int8 *)dst + 2), ssizea, 0); 
*( _OWORD *)&result->block.fragment_chain = 0LL; 
rtx v16; // r15 
rtx v17; // r13 
rtx v18; // rax 
rtx v20; // r10 
rtx v44; // rax 
v16 = ( rtx)insn[2]; 
v17 = insn; 
if ( *( _WORD *)v16 != 47 ) 
v16 = single_set_2( insn, *( rtx *)&insn[2]); 
v17 = insn; 
v16 = 0LL; 
rtx v15; // rax 
rtx result; // rax 
rtx v32; // r12 
rtx v33; // r13 
rtx v38; // rax 
*( _OWORD *)&to->first = 0LL; 
replace_pseudos_in_call_usage( ( rtx *)v3->fld, ( machine_mode)BYTE2( v4), usage); 
v17 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v7 + 2), v16); 
fancy_abort( &off_6CC868[4], 627, "replace_pseudos_in_call_usage"); 
v8 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v9] - 5) < 2) + 1; 
*loc = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), const_int_rtx[64]); 
v7 = get_mode_alignment( ( machine_mode)v6) >> 3; 
v4 = gen_rtx_REG( ( machine_mode)v6, i); 
v5 = adjust_address_1( v1, ( machine_mode)v6, v2, 1, 1); 
v8 = adjust_address_1( v1, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 0LL, 1, 1); 
( machine_mode)( 5 - ( ( target_flags & 0x2000000) == 0)), 
if ( mode_class_0[v4] == MODE_INT && *( _WORD *)newval == 54 ) 
if ( rtwint != trunc_int_for_mode( rtwint, ( machine_mode)v4) ) 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
rtx v93; // rax 
v2 = allocno_0; 
induction_1 *giv; // rcx 
induction_1 *giv; // rcx 
induction_1 *v6; // rax 
induction_1 *v6; // rax 
induction_1 **v11; // rdx 
induction_1 **v11; // rdx 
induction_1 *v16; // rbx 
induction_1 *v16; // rbx 
induction_1 *v21; // r12 
induction_1 *v21; // r12 
induction_1 **v25; // rdx 
induction_1 **v25; // rdx 
induction_1 *v27; // rax 
induction_1 *v27; // rax 
induction_1 **v28; // r8 
induction_1 **v28; // r8 
induction_1 *v37; // rbx 
induction_1 *v37; // rbx 
v13 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v12] - 5) < 2) + 1; 
sprintf( v7, "*.%s%u", ( const char *)&off_629E39, current_funcdef_number); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_629E39, current_funcdef_number); 
*( _OWORD *)&v2[v5].dw_fde_current_label = 0LL; 
args_size_0 = 0LL; 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( type->common.type->block.abstract_origin)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( v13 + 8) + 60LL)) >> 1), 
v27 = classify_argument( ( machine_mode)v24, v23.rttree, s, v25 - ( v26 & 0xFFFFFF00)); 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( rtl->fld[0].rtwint + 60)) >> 1), 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( v48 + 60)) >> 1), 
*( _OWORD *)classes = xmm*(short *)0x639810; 
rtx in_reg; // rax 
rtx v21; // rcx 
rtx *v24; // r14 
rtx v26; // rbp 
rtx x; // [rsp+10h] [rbp-48h] 
rtx xa; // [rsp+10h] [rbp-48h] 
rtx insn; // [rsp+18h] [rbp-40h] 
insn = chain->insn; 
x = old; 
equiv_reg = find_equiv_reg( old, insn, ALL_REGS, -1, 0LL, 0, inmode); 
v3 = dwarf2out_cfi_label_label; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
*( _OWORD *)result->bits = 0LL; 
if ( !memory_address_p( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ref), ref->fld[0].rtx) ) 
while ( *( _OWORD *)&edge_list->index_to_edge[v4]->src != __PAIR128__( ( unsigned __int64)succ, ( unsigned __int64)pred) ) 
base = ( cpp_token_0 **)buff->base; 
if ( !peep2_insn_data_0[v3].insn ) 
v6 = ( ( unsigned int)( mode_class_0[( unsigned __int8)BYTE2( *( _DWORD *)reg)] - 5) < 2) + 1; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)mem + 2)) ) 
v4 = next_qty_0++; 
v6 = qty_0; 
qty_0[v7].first_reg = v5; 
qty_0[v7].min_class = reg_preferred_class( v5); 
v9 = qty_0; 
qty_0[v7].alternate_class = v8; 
if ( get_frame_alias_set_set == -1 ) 
get_frame_alias_set_set = new_alias_set( ); 
return get_frame_alias_set_set; 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
v10 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( _DWORD *)( k + 48), *( rtx *)( j + 72), *( rtx *)( k + 64)); 
v8 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( _DWORD *)( k + 48), v9, v7); 
rtx v46; // rax 
rtx v54; // rax 
rtx v58; // rax 
rtx v62; // rcx 
rtx v64; // rcx 
rtx v65; // rcx 
v9 = insn_data_0[insn_code].genfun( op1, op2); 
*( machine_mode *)( ( char *)&replacements[0].mode + 3 * v3) = mode; 
rtx *v22; // rax 
rtx *v25; // rbx 
rtx v27; // rcx 
rtx *single_use_1; // rax 
v25 = ( rtx *)&v23[2 * v24]; 
v27 = *v25; 
v27 = *v25; 
single_use_1 = loc; 
if ( *v25 != dest ) 
|| *( _WORD *)v27 != 61 
|| ( single_use_1 = loc, v27->fld[0].rtint != dest->fld[0].rtint) ) 
|| ( single_use_1 = loc, v27->fld[0].rtint != dest->fld[0].rtint) ) 
single_use_1 = find_single_use_1( dest, v25); 
replace_args_0( pfile, node, ( macro_arg_0 *)v3->base); 
scan_rtx_address( insn, v20, INDEX_REGS, action, ( machine_mode)mode); 
scan_rtx_address( insn, fld, GENERAL_REGS, action, ( machine_mode)mode); 
scan_rtx_address( insn, ( rtx *)( v14 + *( ( _QWORD *)v6 + v10)), a3, action, ( machine_mode)mode); 
scan_rtx_address( insn, ( rtx *)&v6->fld[v8], a3, action, ( machine_mode)mode); 
v2 = regno[mode - 15]; 
v1 = mode_class_0[mode]; 
recog_data_0.operand[0] = ( rtx)v4; 
recog_data_0.operand[1] = v39; 
recog_data_0.operand[2] = v40; 
recog_data_0.operand[3] = v42; 
if ( rtx_equal_p( *( rtx *)( v43 + 8), recog_data_0.operand[1]) ) 
v44 = rtx_equal_p( *( rtx *)( v43 + 16), recog_data_0.operand[2]); 
return gen_split_1003( recog_data_0.operand); 
recog_data_0.operand[1] = v7; 
recog_data_0.operand[2] = v8; 
recog_data_0.operand[3] = v11; 
if ( rtx_equal_p( *( rtx *)( v12 + 8), recog_data_0.operand[1]) ) 
v13 = rtx_equal_p( *( rtx *)( v12 + 16), recog_data_0.operand[2]); 
return gen_split_1005( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v4; 
recog_data_0.operand[1] = v19; 
recog_data_0.operand[2] = v24; 
&& dead_or_set_p( insn, recog_data_0.operand[1]) 
&& !reg_mentioned_p( recog_data_0.operand[1], recog_data_0.operand[0]) ) 
&& !reg_mentioned_p( recog_data_0.operand[1], recog_data_0.operand[0]) ) 
rtx v10; // rax 
rtx v13; // rax 
v10 = gen_rtx_CONST_INT( VOIDmode, v6->fld[0].rtwint + c->fld[0].rtwint); 
rtx = v10; 
v13 = sge_plus_constant( x->fld[0].rtx, c); 
v13 = sge_plus_constant( v6, c); 
rtwint = v13; 
rtx v3; // rax 
v3 = reg_known_value[rtuint]; 
if ( v3 ) 
rtx = v3; 
rtx const_value; // rdx 
rtx v26; // rcx 
rtx v34; // rdx 
rtx v35; // rcx 
rtx v40; // rax 
rtx v45; // rcx 
rtx v46; // r8 
rtx v47; // r9 
v6 = ( const char *)&unk_6DF04A; 
v6 = ( const char *)&unk_6DF05E; 
v6 = ( const char *)&unk_6DF074; 
v6 = ( const char *)&unk_6DF086; 
v6 = ( const char *)&unk_6DF0F7; 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
v5 = truth_value_p( ( tree_code)( unsigned __int8)v1); 
rtx v4; // rbx 
v4 = rtx; 
if ( active_insn_p( v4) && ( **( _DWORD **)&v4[2] & 0xFFFE) != 44 ) 
if ( active_insn_p( v4) && ( **( _DWORD **)&v4[2] & 0xFFFE) != 44 ) 
insn_scopes->data.l[v4->fld[0].rtint] = v3; 
else if ( *( _WORD *)v4 == 37 ) 
rtint = v4[2].fld[0].rtint; 
v3 = ( __int64)v4[2]; 
delete_insn( v4); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v1 = stack_0; 
if ( &timevars[timevar] != stack_0->timevar ) 
stack_0 = stack_0->next; 
stack_0 = stack_0->next; 
rtx v21; // rax 
rtx v26; // rax 
rtx v39; // r12 
rtx v51; // rbp 
rtx v52; // r12 
v26 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target)); 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v5 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), arguments); 
v16 = get_mode_alignment( ( machine_mode)v15) >> 3; 
v13 = gen_rtx_REG( ( machine_mode)v15, v7); 
v14 = adjust_address_1( v11, ( machine_mode)v15, v12, 1, 1); 
v19 = gen_reg_rtx( ( machine_mode)v17); 
v20 = adjust_address_1( v11, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v18, 1, 1); 
v2 = hash_expr( pat, ( machine_mode)*( ( unsigned __int8 *)pat + 2), do_not_record_p, expr_hash_table_size); 
rtx v22; // rcx 
v22 = note_list; 
v22[1].fld[0] = v18; 
v4 = ( tree_node *)v2[1]; 
v6 = gen_rtx_CONST_INT( ( machine_mode)mem, mode_size[v7]); 
*( _QWORD *)&mem[1] = get_mem_attrs( v3, v4, v5, v6, align, ( machine_mode)*( ( unsigned __int8 *)mem + 2)); 
rtx v23; // rax 
v23 = mult; 
v23 = mult; 
return gen_rtx_CONST_INT( VOIDmode, -( v23->fld[0].rtwint * v22->fld[0].rtwint)); 
b = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v10, v15); 
result = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), result); 
v7 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
rtx v3; // rbx 
rtx v4; // rax 
v3 = head; 
if ( *( _WORD *)v3 == 37 ) 
v4 = unlink_other_notes( v3, rtx); 
v4 = unlink_other_notes( v3, rtx); 
if ( v3 == tail ) 
if ( v3 == head ) 
v3 = v4; 
v3 = v4; 
if ( v4 == rtx ) 
v3 = v3[1].fld[0].rtx; 
v3 = v3[1].fld[0].rtx; 
while ( v3 != rtx ); 
v27 = ( machine_mode *)( v3 + 10314220); 
if ( reload_reg_free_p( spill_regs[v5], *( _DWORD *)( v4 + 40), *( reload_type *)( v4 + 60)) 
( reload_type)*( _DWORD *)( v4 + 60), 
v15 = ( ( unsigned int)( mode_class_0[v13] - 5) < 2) + 1; 
v22 = reload_reg_free_p( v20, *( _DWORD *)( v4 + 40), *( reload_type *)( v4 + 60)); 
operand = insn_data_0[v2].operand; 
if ( !operand->predicate( x, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
|| !operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
|| !operand[2].predicate( y, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v3].genfun( x, x); 
v9 = get_mode_alignment( ( machine_mode)v8) >> 3; 
v5 = gen_rtx_REG( ( machine_mode)v8, v2); 
v6 = adjust_address_1( v1, ( machine_mode)v8, v4, 1, 1); 
if ( mode_class_0[v3] != MODE_INT ) 
if ( mode_class_0[v4] != MODE_INT ) 
v8 = gen_reg_rtx( ( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( v3->common.type->block.abstract_origin)) >> 1)); 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( imag->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
*( optab_0 *)*( &off_600D88 + v9), 
*( optab_0 *)*( &off_600D88 + v9), 
emit_cmp_and_jump_insns( v6, v6, EQ, 0LL, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), 0, label); 
if ( ( debug_info_level_0 & 0xFFFFFFFE) == 2 
if ( ( debug_info_level_0 & 0xFFFFFFFE) == 2 
fatal_insn_not_found( insn, "final.c", 2551, "final_scan_insn"); 
fatal_insn( "could not split insn", insn, "final.c", 2622, "final_scan_insn"); 
output_asm_insn( insn_template, recog_data_0.operand); 
fprintf( file, off_63A0C3, ( unsigned int)( rtint - 29)); 
v13 = *( tree_node **)( v11 + 8); 
elements = ( tree_node *)v11; 
imag = ( tree_node *)*( &global_trees + 11); 
if ( *( _OWORD *)&args1 != 0LL ) 
elements = *( tree_node **)( v3 + 32); 
if ( *( _OWORD *)arg1 != 0LL ) 
+ ( unsigned __int16)reverse_condition_maybe_unordered( ( rtx_code)*( unsigned __int16 *)arg1[0]) 
result = ( ( unsigned int)( mode_class_0[v31] - 5) < 2) + 1; 
result = ( ( unsigned int)( mode_class_0[( unsigned __int8)v28] - 5) < 2) + 1; 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], 0LL); 
v3 = ( tree_node *)v4; 
v2 = *( _OWORD *)&loc_p->base_offset; 
*( _OWORD *)&cfa.reg = *( _OWORD *)&loc_p->reg; 
*( _OWORD *)&cfa.reg = *( _OWORD *)&loc_p->reg; 
*( _OWORD *)&cfa.base_offset = v2; 
v3 = *( _OWORD *)&loc_p->base_offset; 
*( _OWORD *)&v11.reg = *( _OWORD *)&loc_p->reg; 
*( _OWORD *)&v11.reg = *( _OWORD *)&loc_p->reg; 
*( _OWORD *)&v11.base_offset = v3; 
if ( __PAIR128__( v11.offset, v5) != *( _OWORD *)&v12.reg 
if ( !peep2_insn_data_0[v3].insn ) 
p_int_cst = &t->int_cst.int_cst; 
low = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)p_int_cst->low; 
low = ( tree_int_cst::$A887AD9C3C6C8CC7716950D571F57C9D *)p_int_cst->low; 
v5 = *( unsigned __int8 *)( p_int_cst->low + 16); 
v6 = low[2].low; 
v7 = low->high; 
v10 = ( tree_node *)*( &global_trees + 11); 
tree v76; // r12 
fancy_abort( &off_6CC868[4], 4739, "reloads_conflict"); 
if ( !genrtl_case_label_explained ) 
genrtl_case_label_explained = 1; 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
v16 = expand_simple_binop( v33, ( rtx_code)( 76 - ( v8 == 1)), v15, v14, if_info->x, 0, OPTAB_WIDEN); 
fprintf( asm_out_file, &off_607A24[1], ( unsigned int)insn_counter); 
v12 = sch_istable[( unsigned __int8)v7]; 
if ( ( sch_istable[*( ( unsigned __int8 *)v2 + 2)] & 4) == 0 ) 
while ( ( sch_istable[v20] & 4) != 0 ); 
while ( ( sch_istable[v18] & 4) != 0 ); 
v7 = ix86_register_move_cost( m1, ( reg_class)v3, class2); 
v10 = ix86_register_move_cost( m1, ( reg_class)v3, class2); 
*( _OWORD *)&deps->pending_read_insns = 0LL; 
*( _OWORD *)&deps->pending_write_insns = 0LL; 
*( _OWORD *)&deps->pending_lists_length = 0LL; 
*( _OWORD *)&deps->last_function_call = 0LL; 
rtx arg1; // [rsp+0h] [rbp-38h] BYREF 
arg1 = v2; 
v9 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), x); 
if ( general_operand( v5, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
arg1 = const_int_rtx[64]; 
v14 = eliminate_constant_term( v5, &arg1); 
v15 = arg1; 
if ( arg1 == const_int_rtx[64] 
rtx v4; // rax 
v4 = find_base_term( v3); 
if ( !v4 ) 
v6 = *( _DWORD *)v4; 
if ( ( unsigned __int16)( *( _DWORD *)v4 - 67) < 2u ) 
return v4; 
base_term = v4; 
v4 = find_base_term( ( rtx)v9[1]); 
if ( v4 ) 
return v4; 
rtx v20; // rax 
rtx v24; // rax 
rtx return_rtx; // rbx 
rtx v31; // rax 
rtx v34; // rbp 
v20 = current_function_decl->decl.rtl; 
if ( !v20 ) 
v20 = current_function_decl->decl.rtl; 
if ( *( _WORD *)v20 != 66 ) 
v21.rtwint = ( __int64)v20->fld[0]; 
v24 = expand_builtin_return_addr( BUILT_IN_RETURN_ADDRESS, 0, global_rtl[4]); 
n_operands = recog_data_0.n_operands; 
v2 = ( __int64)*( &changes + n_operands--); 
if ( constructor_stack_0->replacement_value ) 
constructor_stack_0->replacement_value = value; 
if ( constructor_stack_0->replacement_value ) 
while ( constructor_stack_0->implicit ) 
if ( constructor_range_stack_0 ) 
spelling_0 = &spelling_base[constructor_depth]; 
return ++new_alias_set_last_alias_set; 
mtherr( aE, 7); 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v5; 
return gen_split_1179( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v5; 
return gen_split_1178( recog_data_0.operand); 
rtx v10; // r15 
rtx rtwint; // r14 
rtx v20; // rbx 
rtx last_insn; // r15 
rtx v26; // rbp 
v10 = insns; 
rtwint = v10; 
rtwint = v10; 
rtwint = ( rtx)v12.rtwint; 
rtwint = v10; 
rtx v19; // rax 
rtx earliest; // [rsp+10h] [rbp-38h] BYREF 
alt_condition = noce_get_alt_condition( if_info, a, &earliest); 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), ABS, a, if_info->x, 0); 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), ABS, a, if_info->x, 0); 
if ( v5 && v19 ) 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), NEG, v19, if_info->x, 0); 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), NEG, v19, if_info->x, 0); 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), NEG, v19, if_info->x, 0); 
v19 = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)v19 + 2), NEG, v19, if_info->x, 0); 
if ( v19 ) 
if ( v19 != x ) 
noce_emit_move_insn( x, v19); 
rtx v9; // r13 
rtx v10; // r14 
rtx v17; // rax 
rtx *fld; // rbp 
rtx *v21; // r14 
v3 = *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)x >> 14) & 0x3FC)); 
v9 = expand_compound_operation( rtx); 
v10 = expand_compound_operation( v8); 
v11 = *( _WORD *)v9; 
if ( ( _DWORD)v11 == *( _WORD *)v10 ) 
if ( ( ( *( _DWORD *)v9->fld[0].rtwint ^ *( _DWORD *)v10->fld[0].rtwint) & 0xFF0000) == 0 
if ( ( ( *( _DWORD *)v9->fld[0].rtwint ^ *( _DWORD *)v10->fld[0].rtwint) & 0xFF0000) == 0 
rtx end; // rsi 
end = dest->end; 
end = dest->end; 
if ( *( _WORD *)end != 33 ) 
rtx = end; 
end = ( rtx)end[1]; 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
end = 0LL; 
end = ( rtx)rtx[1]; 
nonnote_insn = emit_insns_after( insns, end); 
LODWORD( v2) = lang_hooks_0.staticp( arg); 
if ( !initial || !strcmp( lang_hooks_0.name, "GNU C++") && initial == ( tree)global_trees ) 
emit_pop_insn( rtx, old, *( rtx *)&may_move_out_cost[57][15][118 * v11 + 4], EMIT_BEFORE); 
rtx v19; // rbp 
rtx v20; // r15 
rtx v24; // rax 
rtx v25; // r12 
rtx v29; // r12 
rtx v35; // rax 
rtx v22; // rax 
rtx v24; // rax 
induction_1 *v26; // rcx 
induction_1 *v26; // rcx 
induction_1 *v; // [rsp+0h] [rbp-50h] BYREF 
induction_1 *v; // [rsp+0h] [rbp-50h] BYREF 
rtx *add_vala; // [rsp+8h] [rbp-48h] 
rtx src_rega; // [rsp+10h] [rbp-40h] BYREF 
src_rega = src_reg; 
*( &v - 20) = ( induction_1 *)src_rega; 
*( &v - 20) = ( induction_1 *)src_rega; 
*( &v - 14) = ( induction_1 *)*mult_val; 
*( &v - 14) = ( induction_1 *)*mult_val; 
token = ( cpp_token_0 *)lhs; 
rtx *v26; // rcx 
rtx v30; // rbx 
v6 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), i); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
*( _OWORD *)&v4[v5].const_rtx = 0LL; 
reg_eqv_table[reg] = ( reg_eqv_elem)-1LL; 
rtx v27; // rax 
rtx v34; // rax 
rtx v47; // rax 
rtx v48; // rbp 
rtx v50; // rbx 
x = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
&& ( ( orig = insn_a, rtx_equal_p( b, x)) || general_operand( b, ( machine_mode)*( ( unsigned __int8 *)b + 2))) ) 
if ( general_operand( b, ( machine_mode)*( ( unsigned __int8 *)b + 2)) ) 
v12 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)b + 2)); 
v29 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)b + 2)); 
if ( general_operand( vtrue, ( machine_mode)*( ( unsigned __int8 *)vtrue + 2)) ) 
vtrue = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)vtrue + 2)); 
v35 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)vtrue + 2)); 
v23 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v15->x + 2), v16); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)( unsigned __int16)*( _DWORD *)operands[3], 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)operands[3]), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
if ( recog_data_0.n_alternatives && recog_data_0.n_operands ) 
if ( recog_data_0.n_alternatives && recog_data_0.n_operands ) 
fatal_insn_not_found( insna, &off_6CC868[4], 8371, "reload_cse_simplify_operands"); 
v2 = 4LL * recog_data_0.n_alternatives; 
if ( recog_data_0.n_operands > 0 ) 
v6 = *( _DWORD *)recog_data_0.operand[v4]; 
if ( recog_data_0.operand_mode[v4] ) 
if ( ++v4 >= recog_data_0.n_operands ) 
v8 = cselib_lookup( recog_data_0.operand[v4], recog_data_0.operand_mode[v4], 0); 
v8 = cselib_lookup( recog_data_0.operand[v4], recog_data_0.operand_mode[v4], 0); 
if ( recog_data_0.n_operands > 0 ) 
n_alternatives = recog_data_0.n_alternatives; 
v16 = ( int *)( ( char *)equiv_regs - ( ( 4LL * recog_data_0.n_alternatives + 15) & 0xFFFFFFFFFFFFFFF0LL)); 
v17 = recog_data_0.constraints[v12]; 
mode = recog_data_0.operand_mode[v12]; 
v13 = true_regnum( recog_data_0.operand[v12]); 
rtx psave; // [rsp+8h] [rbp-40h] BYREF 
rtx last_insn; // [rsp+10h] [rbp-38h] 
psave = 0LL; 
last_insn = get_last_insn( ); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
if ( last_insn ) 
rtx = last_insn[1].fld[0].rtx; 
emit_stack_save( SAVE_BLOCK, &psave, 0LL); 
emit_stack_restore( SAVE_BLOCK, psave, 0LL); 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v6; 
|| ( recog_data_0.operand[0] = v9, !ix86_match_ccmode( insn, CCGCmode)) 
|| ( result = 219LL, LOWORD( recog_data_0.operand[2]->fld[0].rtuint) == 0x8000) ) 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = v12; 
&& rtx_equal_p( *( rtx *)( v13 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v13 + 16), recog_data_0.operand[2]) 
v14 = ix86_binary_operator_ok( MINUS, HImode, recog_data_0.operand); 
recog_data_0.operand[1] = v15; 
recog_data_0.operand[2] = v16; 
recog_data_0.operand[0] = v85; 
v31 = recog_data_0.operand[1]; 
recog_data_0.operand[0] = v19; 
&& rtx_equal_p( *( rtx *)( v20 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v20 + 16), recog_data_0.operand[2]) 
v14 = ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand); 
recog_data_0.operand[1] = v21; 
rtx v18; // rax 
v18 = canon_rtx( rtx); 
if ( ( *( ( _BYTE *)v18 + 3) & 4) == 0 ) 
v19.rtwint = ( __int64)v18->fld[0]; 
add_to_mem_set_list( v10, v18); 
v17 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), lab2); 
*( _OWORD *)&df_0->insns[v4].defs = 0LL; 
if ( mode_class_0[mode] == MODE_INT && ( _WORD)v9 == 54 && mode_bitsize[mode] == 128 ) 
if ( mode_class_0[v8] != MODE_INT || mode_class_0[oldmode] != MODE_INT ) 
if ( mode_class_0[v8] != MODE_INT || mode_class_0[oldmode] != MODE_INT ) 
rtx v33; // rax 
rtx v34; // r15 
rtx *v59; // rbx 
rtx v68; // [rsp+40h] [rbp-38h] BYREF 
v33 = remove_death( rtuint, v7); 
v34 = v33; 
v34 = v33; 
if ( v33 ) 
rtwint = ( unsigned int *)v33->fld[0].rtwint; 
v42 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 
+ ( ( *( _DWORD *)v34->fld[0].rtwint >> 14) & 0x3FC)) 
v44 = ( ( unsigned int)( mode_class_0[v38] - 5) < 2) + 1; 
if ( v34 ) 
rtx v63; // rax 
rtx const_rtx; // rbp 
rtx v78; // rax 
rtx v80; // rbx 
rtx v82; // rax 
rtx v86; // rax 
rtx *v93; // rcx 
rtx v96; // rbx 
rtx v98; // r12 
rtx v43; // [rsp+18h] [rbp-40h] 
v43 = v12; 
if ( !comparison_dominates_p( ( rtx_code)v16, v17) && !comparison_dominates_p( ( rtx_code)v16, v39) ) 
if ( !comparison_dominates_p( ( rtx_code)v16, v17) && !comparison_dominates_p( ( rtx_code)v16, v39) ) 
v2 = mode_class_0[mode]; 
v7 = **( tree_node ***)( low + 8); 
if ( ( tree_node *)low != v7 && ( !*( _QWORD *)( low + 112) || decl_ultimate_origin( ( tree)low) != v7) ) 
v6 = pre_edge_insert( edge_list_0, v0); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
return new_loc_descr( ( dwarf_location_atom)v4, v5, offset); 
return new_loc_descr( ( dwarf_location_atom)v4, v5, offset); 
rtx v26; // [rsp+40h] [rbp-38h] 
v26 = replacement; 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx compound_operation; // rbx 
rtx *v5; // r12 
rtx *single_use; // rax 
rtx *v8; // rbp 
rtx v9; // rax 
rtx *v12; // rdi 
rtx v3; // r14 
rtx v5; // rax 
rtx v6; // r12 
rtx v7; // rax 
v3 = head; 
if ( rtx_class[*( _WORD *)v3] == 105 ) 
v3 = group_leader( v3); 
v3 = group_leader( v3); 
for ( i = ( __int64)v3[3]; i; i = *( _QWORD *)( i + 16) ) 
v5 = group_leader( *( rtx *)( i + 8)); 
if ( v5 == *( rtx *)( i + 8) ) 
v6 = v5; 
v6 = v5; 
v6 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v7] - 5) < 2) + 1; 
remove_invalid_subreg_refs( v9, *( _DWORD *)&x[1], ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v5 = ( tree_node *)*( &global_trees + 17); 
return ( *( page_entry_0 ***)( ( char *)G.lookup + ( ( ( unsigned __int64)p >> 21) & 0x7F8)))[( ( unsigned __int64)p >> SLOBYTE( G.lg_pagesize)) & ~( -1 << ( 24 - LOBYTE( G.lg_pagesize)))]; 
v13 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), arg0); 
*( _OWORD *)&v10->next_same_hash = 0LL; 
( machine_mode)supercontext_low, 
while ( constructor_stack_0->implicit ) 
v7->next = constructor_stack_0; 
constructor_stack_0 = v7; 
constructor_depth = ( unsigned __int64)( ( char *)spelling_0 - ( char *)spelling_base) >> 4; 
v7->range_stack = constructor_range_stack_0; 
constructor_range_stack_0 = 0LL; 
v14 = ( tree_node *)*( &global_trees + 17); 
if ( mode_class_0[mode] != MODE_FLOAT ) 
rtx v54; // rdi 
v7 = mode_class_0[v6]; 
v10 = mode_class_0[mode]; 
|| mode_class_0[v53] == MODE_INT && mode_class_0[v2] == MODE_INT) 
|| mode_class_0[v53] == MODE_INT && mode_class_0[v2] == MODE_INT) 
&& ( ( v54 = reg_last_set[x->fld[0].rtuint], rtint = v54->fld[0].rtint, ( int)rtint <= max_uid_cuid) 
&& ( ( v54 = reg_last_set[x->fld[0].rtuint], rtint = v54->fld[0].rtint, ( int)rtint <= max_uid_cuid) 
: ( v56 = insn_cuid( v54)), 
v4 = mode_mask_array[v6] & nonzero_bits( x->fld[0].rtx, ( machine_mode)v6); 
if ( mode_class_0[v2] == MODE_INT ) 
v11 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v11 + 2), fixed); 
v12 = gen_rtx_fmt_ee( v11, ( machine_mode)*( ( unsigned __int8 *)x + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
v13 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v11] - 5) < 2) + 1; 
fancy_abort( &off_6CC868[4], 8994, "reload_combine_note_use"); 
fancy_abort( &off_6CC868[4], 9015, "reload_combine_note_use"); 
v20 = ( ( unsigned int)( mode_class_0[v19] - 5) < 2) + 1; 
if ( in_section_0 != in_bss ) 
in_section_0 = in_bss; 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, v3); 
v2->next = stack_0; 
stack_0 = v2; 
rtx v5; // rdx 
if ( *( _WORD *)head != 37 || ( v5 = head, head[2].fld[0].rtint <= 0) ) 
v5 = v4; 
v4 = v5; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx v17; // rcx 
rtx v20; // rax 
rtx i; // rbx 
rtx v23; // rbp 
rtx v27; // [rsp+8h] [rbp-50h] 
rtx v37; // rbx 
rtx *v43; // rbx 
rtx v44; // rbp 
rtx memref; // [rsp+8h] [rbp-40h] 
memref = v7; 
v7 = memref; 
if ( v12 == v9 && v12 < v10 && mode_class_0[outermode] == MODE_INT ) 
v14 = constant_subword( memref, byte >> ( 3 - ( ( target_flags & 0x2000000) == 0)), v5); 
v7 = memref; 
v7 = memref; 
if ( mode_class_0[outermode] == MODE_INT ) 
|| ( v39 = ix86_hard_regno_mode_ok( memref->fld[0].rtint, v5), v38 = 1, !v39) ) 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, 0); 
( machine_mode)*( unsigned __int8 *)( v1.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
rtx fixed_bit_field; // rax 
rtx v33; // [rsp+10h] [rbp-48h] 
v33 = v10; 
fixed_bit_field = gen_rtx_CONST_INT( VOIDmode, ( ( unsigned __int64)v10->fld[0].rtwint >> v19) & ~( -1LL << v27)); 
fixed_bit_field = extract_fixed_bit_field( *(short *)0xmode, v10, 0LL, v27, v19, 0LL, 1); 
v30 = fixed_bit_field; 
rtx = operand_sub*(short *)0xforce( rtx, v22, v20); 
v10 = v33; 
v12 = ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1; 
v17 = operand_sub*(short *)0xforce( op, v15, v13); 
v18 = operand_sub*(short *)0xforce( v27, v15, v13); 
safe_from_p_save_expr_list = 0LL; 
for ( i = safe_from_p_save_expr_list; i; i = i->common.chain ) 
safe_from_p_save_expr_list = tree_cons( exp, 0LL, safe_from_p_save_expr_list); 
safe_from_p_save_expr_list = tree_cons( exp, 0LL, safe_from_p_save_expr_list); 
rtl_op = first_rtl_op( ( tree_code)*( unsigned __int8 *)( v3 + 16)); 
v23 = *( tree_node **)( v3 + 8 * j + 32); 
if ( *( unsigned __int8 *)( v3 + 16) < 0x93u || lang_hooks_0.safe_from_p( rtx, ( tree)v3) ) 
imag = *( tree_node **)v3; 
( machine_mode)( ( unsigned __int8)HIBYTE( *( _WORD *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 60LL)) >> 1), 
return off_629850[v1]; 
*( _OWORD *)value = 0LL; 
*( _OWORD *)&value->un.vechi[13] = 0LL; 
*( _OWORD *)&value->un.vechi[11] = 0LL; 
*( _OWORD *)&value->un.vechi[9] = 0LL; 
*( _OWORD *)&value->un.vechi[7] = 0LL; 
*( _OWORD *)&value->un.vechi[5] = 0LL; 
*( _OWORD *)&value->un.vechi[3] = 0LL; 
*( _OWORD *)&value->un.vechi[1] = 0LL; 
( machine_mode)*( ( unsigned __int8 *)dest_reg + 2), 
*( _OWORD *)&head->first = 0LL; 
v8 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v7] - 5) < 2) + 1; 
result = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
tree v12; // rax 
tree v14; // rbp 
tree v15; // rax 
v10 = type_for_mode( ( machine_mode)*( ( unsigned __int8 *)add + 2), unsignedp); 
v12 = make_tree( v9, mult); 
v13 = build( MULT_EXPR, v9, tree, v12); 
v14 = fold( v13); 
v15 = make_tree( v10, add); 
v16 = build( PLUS_EXPR, v9, v14, v15); 
v16 = build( PLUS_EXPR, v9, v14, v15); 
v8 = *( tree_node **)( high + 32); 
v9 = *( tree_node **)( high + 24); 
v5 = ( ( unsigned int)( mode_class_0[xmode] - 5) < 2) + 1; 
v6 = ( ( unsigned int)( mode_class_0[ymode] - 5) < 2) + 1; 
v0 = dwarf2out_cfi_label_label_num++; 
sprintf( dwarf2out_cfi_label_label, "*.%s%u", "LCFI", v0); 
assemble_name( asm_out_file, dwarf2out_cfi_label_label); 
return dwarf2out_cfi_label_label; 
deps_0 *v47; // r13 
deps_0 *v47; // r13 
add_dependence_list( val, reg_last[v33].sets, ( reg_note)0); 
add_dependence_list( val, reg_last[v33].clobbers, ( reg_note)0); 
add_dependence_list_and_free( val, &v45[v46].sets, ( reg_note)0); 
add_dependence_list_and_free( val, &v45[v46].clobbers, ( reg_note)0); 
v47 = deps; 
cfa_temp_0 = rtx->fld[0].rtuint; 
cfa_temp_0 = cfa.reg; 
if ( *( _WORD *)v26 != 61 || cfa_temp_0 != *( _DWORD *)( v26 + 8) || **( _WORD **)( v9 + 16) != 54 ) 
if ( cfa_temp_0 != rtuint ) 
cfa_temp_0 = rtuint; 
if ( cfa_temp_0 != v34 ) 
cfa_temp_0 = cfa.reg; 
if ( cfa_temp_0 == *( _DWORD *)( v19 + 8) && *( rtx *)( v9 + 16) == global_rtl[2] ) 
cfa_temp_0 = rtx->fld[0].rtuint; 
if ( initial != ( tree_node *)global_trees ) 
rtl_op = first_rtl_op( ( tree_code)( unsigned __int8)v2); 
v26 = ( tree_node *)*( &global_trees + 27); 
v5 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v6] - 5) < 2) + 1; 
rtx v22; // rax 
rtx v40; // rax 
rtx v44; // rax 
rtx v48; // r13 
rtx v55; // rax 
v10 = get_mode_alignment( ( machine_mode)v9) >> 3; 
v11 = gen_rtx_REG( ( machine_mode)v9, v2); 
v12 = adjust_address_1( result, ( machine_mode)v9, v3, 1, 1); 
if ( ( unsigned int)debug_info_level_0 >= DINFO_LEVEL_NORMAL ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 356, "insn_default_length"); 
v5 = recog_data_0.operand[0]; 
v5 = recog_data_0.operand[0]; 
v5 = recog_data_0.operand[0]; 
imag = ( tree_node *)*( &global_trees + 17); 
if ( spelling_base < spelling_0 ) 
if ( ++v1 >= spelling_0 ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
if ( !insn_data_0[1316].operand->predicate( v5, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
if ( !insn_data_0[1316].operand->predicate( v5, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
v5 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
v8 = ( tree_node *)rtl[7]; 
return gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1); 
result = rtx_alloc( ( rtx_code)*( _WORD *)orig); 
v3 = ( tree_node *)ggc_alloc( v2); 
alias_set_entry_0 v4; // rax 
&& *( const mode_class *)( ( char *)mode_class_0 + ( ( v10 >> 14) & 0x3FC)) == MODE_INT 
if ( unsignedp || !flag_trapv || ( v63 = optab_table + 40, mode_class_0[v12] != MODE_INT) ) 
v4 = swap_condition( ( rtx_code)*( unsigned __int16 *)v3); 
if ( *v23 != v16 || !byte_9CE5FF[v24] ) 
if ( *v20 != v16 || !byte_9CE5FF[v19] ) 
induction_1 *biv; // rbx 
induction_1 *biv; // rbx 
biv = bl_0->biv; 
if ( !biv ) 
v3 = *( ( _WORD *)biv + 50); 
if ( biv->mult_val == const_int_rtx[65] ) 
v1 = fold_rtx_mult_add( v1, const_int_rtx[65], biv->add_val, biv->mode); 
v1 = fold_rtx_mult_add( v1, const_int_rtx[65], biv->add_val, biv->mode); 
biv = biv->next_iv; 
biv = biv->next_iv; 
if ( biv ) 
rtx v41; // r14 
rtx v49; // rax 
rtx v63; // [rsp+10h] [rbp-48h] 
v13 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v12] - 5) < 2) + 1; 
*( _OWORD *)&v16->next_same_value = 0LL; 
v63 = x; 
v28 = v63; 
v28 = v63; 
v28 = v63; 
v28 = v63; 
return gen_rtx_fmt_e( CONSTANT_P_RTX, ( machine_mode)v2, v3); 
( machine_mode)( unsigned __int8)BYTE2( *rtwint), 
( machine_mode)BYTE2( v3))] 
x = force_reg( ( machine_mode)*( ( unsigned __int8 *)v9 + 2), v9); 
v9 = expand_shift( RSHIFT_EXPR, ( machine_mode)v20, v9, v22, v23, 1); 
*( _OWORD *)&result->common.chain = 0LL; 
rtx *v11; // rax 
rtx v12; // rdx 
rtx *v17; // rbx 
rtx *v23; // rdx 
rtx *v39; // [rsp+10h] [rbp-48h] 
v39 = loc; 
v36 = ( ( unsigned int)( mode_class_0[v37] - 5) < 2) + 1; 
v34 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v33] - 5) < 2) + 1; 
loc = v39; 
v23 = ( rtx *)&rtx->fld[v19]; 
if ( v23 != loc ) 
v24 = refers_to_regno_for_reload_p( v20, endregno, *v23, loc); 
loc = v39; 
v11 = ( rtx *)( fld->rtwint + 8); 
elements = lang_hooks_0.expand_constant( exp); 
v7 = ( tree_node *)high[4]; 
if ( ( sch_istable[v10] & 0x88) != 0 && v9[2] == 91 ) 
recog_data_0.operand[5] = v8; 
recog_data_0.operand[2] = v9; 
recog_data_0.operand[3] = v10; 
recog_data_0.operand[4] = v11; 
recog_data_0.operand[1] = v15; 
recog_data_0.operand[1] = v17; 
recog_data_0.operand[2] = v18; 
recog_data_0.operand[2] = ( rtx)v23; 
recog_data_0.operand[3] = v24; 
|| ( recog_data_0.operand[1] = v27, v28 = *( _QWORD *)( v26 + 16), ( *( _DWORD *)v28 & 0xFFFFFF) != 327760) 
|| !rtx_equal_p( *( rtx *)( v28 + 8), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = ( rtx)v23; 
recog_data_0.operand[2] = v88; 
recog_data_0.operand[3] = v90; 
if ( rtx_equal_p( *( rtx *)( v91 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v91 + 16), recog_data_0.operand[2]) ) 
recog_data_0.operand[4] = v93; 
v29 = rtx_equal_p( *( rtx *)( v28 + 16), recog_data_0.operand[3]); 
rtx v44; // rax 
rtx *v50; // rsi 
rtx v69; // r14 
rtx dummy_reload; // rax 
basic_block v12; // r15 
rtx v18; // rbx 
v12 = create_basic_block( src->index + 1, rtx, 0LL); 
v12->count = e->count; 
v12->frequency = ( e->src->frequency * e->probability + 5000) / 10000; 
v12->loop_depth = target->loop_depth; 
v12->global_live_at_start = bitmap_initialize( ( bitmap)object_base); 
v12->global_live_at_end = bitmap_initialize( ( bitmap)v15); 
bitmap_copy( v12->global_live_at_start, target->global_live_at_start); 
bitmap_copy( v12->global_live_at_end, target->global_live_at_start); 
edge = make_edge( e->src, v12, 1); 
redirect_edge_pred( e, v12); 
src = v12; 
v12 = 0LL; 
v18 = block_label( target); 
v19 = gen_jump( v18); 
diagnostic_for_decl( decl, msgid, ( va_list_0 *)va, flag_pedantic_errors == 0); 
decl->decl.rtl = adjust_address_1( rtl, ( machine_mode)LOBYTE( decl->block.supercontext), 0LL, 0, 1); 
if ( ix86_hard_regno_mode_ok( v9, ( machine_mode)v11) ) 
v14 = gen_rtx_fmt_i0( REG, ( machine_mode)LOBYTE( decl->block.supercontext), reg_number); 
v18 = ( ( unsigned int)( mode_class_0[supercontext_low] - 5) < 2) + 1; 
v27 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), low); 
v9 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2)); 
( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), 
fatal_insn_not_found( insn, "insn-attrtab.c", 12189, "get_attr_athlon_decode"); 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
reg_set_0 *v32; // rax 
reg_set_0 *v32; // rax 
reg_set_0 *v36; // rax 
reg_set_0 *v36; // rax 
v32 = reg_set_table[rtuint]; 
if ( v32 ) 
v35 = bmap[*( int *)( v34->data.l[v32->insn->fld[0].rtint] + 88)]; 
v32 = v32->next; 
v32 = v32->next; 
while ( v32 ); 
v36 = reg_set_table[rtuint]; 
if ( v36 ) 
v39 = bmap[*( int *)( v38->data.l[v36->insn->fld[0].rtint] + 88)]; 
v36 = v36->next; 
v36 = v36->next; 
while ( v36 ); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), 
if ( *( _OWORD *)&idom != 0LL ) 
error( "unable to find a register to spill in class `%s'", spill_failure_reg_class_names[a2]); 
fatal_insn( "this is the insn:", insn, &off_6CC868[4], 1910, "spill_failure"); 
error_for_asm( insn, "can't find a register in class `%s' while reloading `asm'", spill_failure_reg_class_names[a2]); 
sprintf( v14, off_6D4004, rtuint); 
if ( ( sch_istable[*( unsigned __int8 *)reg_names[rtuint]] & 4) != 0 ) 
sprintf( v14, off_6E3423, *( _DWORD *)&x[1]); 
sprintf( v14, ( const char *)&off_6D3FF3, *( unsigned int *)( x->fld[0].rtwint + 8)); 
rtx flags_user; // rax 
rtx v8; // rax 
flags_user = next_flags_user( insn); 
if ( !flags_user ) 
rtx = flags_user; 
v2 = ( __int64)flags_user[2]; 
v8 = next_flags_user( rtx); 
if ( v8 ) 
rtx = v8; 
v2 = ( __int64)v8[2]; 
v2 = rtx_alloc( ( rtx_code)*( _WORD *)notes); 
if ( reg_pref_0 ) 
return reg_pref_0[regno].prefclass; 
if ( ix86_GOT_alias_set_set == -1 ) 
ix86_GOT_alias_set_set = new_alias_set( ); 
return ix86_GOT_alias_set_set; 
set_diagnostic_context( &v2, msgid, ( va_list_0 *)va, input_filename, lineno, 0); 
reg_avail_info_0 = (  struct reg_avail_info *)gmalloc( 12 * max_gcse_regno); 
v2 = reg_avail_info_0; 
if ( reg_note ) 
if ( !reg_note && set_p ) 
free( reg_avail_info_0); 
reg_avail_info_0 = 0LL; 
rtx *fld; // rsi 
rtx v30; // rax 
rtx v38; // rsi 
rtx **v47; // rsi 
rtx v49; // rax 
rtx v60; // rsi 
rtx v64; // rdx 
rtx *v39; // [rsp+18h] [rbp-40h] 
v39 = p_in; 
*v39 = v23->in; 
while ( ( sch_istable[v7] & 4) != 0 ); 
rtx v8; // r13 
rtx result; // rax 
rtx v18; // rax 
rtx *v56; // rcx 
rtx *v58; // rcx 
v8 = avoid_constant_pool_reference( rtx); 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)rtx >> 14) & 0x3FC)) == MODE_CC ) 
if ( swap_commutative_operands_p( v8, v9) ) 
v12 = v8; 
v8 = v9; 
rtx bit_field; // rax 
rtx v36; // [rsp+8h] [rbp-78h] 
rtx *tmps; // [rsp+38h] [rbp-48h] 
rtx src; // [rsp+48h] [rbp-38h] 
src = orig_src; 
tmps = v6; 
v36 = dst; 
emit_move_insn( v14, src); 
v6 = tmps; 
tmps[v8] = v14; 
else if ( ( sch_istable[( unsigned __int8)v15] & 4) != 0 ) 
parse_number_0( pfile, ( cpp_string_0 *)&cur_token->val, v15, 1); 
parse_number_0( pfile, ( cpp_string_0 *)&cur_token->val, v5, 0); 
v35 = nonzero_bits( ( rtx)rtwint, ( machine_mode)v4); 
v36 = ( v35 & nonzero_bits( ( rtx)v6, ( machine_mode)v4)) == 0; 
result = reversed_comparison( ( rtx)rtwint, ( machine_mode)v4, *( ( rtx *)rtwint + 1), *( ( rtx *)rtwint + 2)); 
result = reversed_comparison( ( rtx)rtwint, ( machine_mode)v4, *( ( rtx *)rtwint + 1), *( ( rtx *)rtwint + 2)); 
return gen_rtx_fmt_ee( v32, ( machine_mode)v4, v31, v30); 
v15 = simplify_gen_unary( NOT, ( machine_mode)v4, v65, ( machine_mode)v4); 
v15 = simplify_gen_unary( NOT, ( machine_mode)v4, v65, ( machine_mode)v4); 
v38 = gen_binary( XOR, ( machine_mode)v4, ( rtx)rtwint, ( rtx)v6); 
return simplify_gen_unary( NOT, ( machine_mode)v4, v38, ( machine_mode)v4); 
return simplify_gen_unary( NOT, ( machine_mode)v4, v38, ( machine_mode)v4); 
&& ( ~*( _QWORD *)( v6 + 8) & nonzero_bits( x->fld[0].rtx, ( machine_mode)v4)) == 0 
rtx v8; // r15 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), rtx, offset); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), v5) 
v6 = force_reg( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx), rtx); 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v6, offset); 
v8 = change_address_1( memref, VOIDmode, v5, 1); 
v10 = *( tree_node **)( v9 + 8); 
*( _QWORD *)&v8[1] = get_mem_attrs( v7, v10, 0LL, 0LL, v11, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
*( _QWORD *)&v8[1] = get_mem_attrs( v7, v10, 0LL, 0LL, v11, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
*( _QWORD *)&v8[1] = get_mem_attrs( v7, v10, 0LL, 0LL, v11, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
return v8; 
while ( ( sch_istable[v9] & 4) != 0 ); 
return reversed_comparison_code_parts( ( rtx_code)v3, comparison->fld[0].rtx, *( rtx *)&comparison[1], comparison); 
rtx *v13; // rbp 
rtx v15; // r14 
rtx *rtwint; // rdi 
rtx v24; // rax 
rtx v30; // rax 
rtx *v32; // rsi 
rtx *v41; // r12 
rtx v51; // rax 
rtx v62; // [rsp+10h] [rbp-68h] 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
fatal_insn_not_found( insn, "insn-attrtab.c", 13642, "get_attr_length_address"); 
if ( !constant_call_address_operand( recog_data_0.operand[1], VOIDmode) ) 
v4 = gen_rtx_REG( ( machine_mode)v2, v3); 
rtx result; // rax 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
if ( result == reg_equiv_memory_loc[regno] ) 
return copy_rtx( result); 
return result; 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
rtx v13; // r14 
rtx v14; // rbx 
rtx v15; // r12 
rtx v19; // rbp 
rtx last_insn; // r14 
rtx v23; // rbx 
rtx v26; // rbp 
v6 = gen_reg_rtx( ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)target)); 
return *( _OWORD *)element->bits == 0LL; 
v7 = *( ( _DWORD *)uid_cuid_1 + *( int *)( v5->fld[0].rtwint + 8)); 
sprintf( v7, &off_607A24[1], type->decl.result->decl.name->identifier.id.len); 
if ( section_name == ( tree_node *)*( &global_trees + 10) ) 
if ( section_name == ( tree_node *)*( &global_trees + 9) ) 
if ( section_name == ( tree_node *)*( &global_trees + 8) ) 
if ( section_name == ( tree_node *)*( &global_trees + 7) ) 
if ( section_name == ( tree_node *)*( &global_trees + 6) ) 
v31 = mode_class_0[v8]; 
if ( insn_data_0[insn_code].operand->predicate( v10, v8) ) 
v14 = insn_data_0[( int)insn_code].genfun( v10, operand1a); 
v16 = insn_data_0[v15].genfun( operand1b, v9); 
v21 = insn_data_0[v17].genfun( v19, v20); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
memset( dc, 0, sizeof( diagnostic_context_0)); 
if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
*( ( _OWORD *)v4 + 1) = 0LL; 
while ( ( sch_istable[v5] & 0x88) == 0 ); 
rtx result; // rax 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v4, v8); 
|| ( result = rtx->fld[0].rtx, ( unsigned __int16)*( _DWORD *)result != 66) 
|| ( result = rtx->fld[0].rtx, ( unsigned __int16)*( _DWORD *)result != 66) 
|| ( rtx = rtx->fld[0].rtx, ( unsigned __int8)BYTE2( *( _DWORD *)result) != mode) ) 
result = gen_lowpart_common( mode, rtx); 
if ( !result ) 
return gen_rtx_fmt_ee( ( rtx_code)( unsigned __int16)*( _DWORD *)rtx, mode, rtx->fld[0].rtx, *( rtx *)&rtx[1]); 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v4, v8); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
if ( result ) 
return result; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v4, v8); 
timevar_push( TV_REST_OF_COMPILATION_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_TO_SSA_0); 
timevar_pop( TV_TO_SSA_0); 
timevar_push( TV_SSA_CCP_0); 
timevar_pop( TV_SSA_CCP_0); 
timevar_push( TV_SSA_DCE_0); 
timevar_pop( TV_SSA_DCE_0); 
timevar_push( TV_FROM_SSA_0); 
timevar_pop( TV_FROM_SSA_0); 
timevar_push( TV_JUMP_0); 
timevar_push( TV_IFCVT_0); 
timevar_pop( TV_IFCVT_0); 
timevar_pop( TV_JUMP_0); 
if ( rtint < 0 || insn_data_0[rtint].n_dups > 0 ) 
if ( ( sch_istable[v11] & 0x100) == 0 ) 
operand = insn_data_0[v3].operand, 
operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v5].genfun( r0, r1); 
v9 = new_die( ( dwarf_tag)( 4 * ( *( ( _BYTE *)&type->block.common + 16) != 20) + 19), v8, type); 
v5 = convert_modes( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), ptr_mode, size, 1); 
v5 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v5); 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL || ( BYTE1( decl->block.supercontext) & v5) != 0 ) 
if ( ( unsigned int)debug_info_level_0 < DINFO_LEVEL_NORMAL ) 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v6; 
|| ( recog_data_0.operand[0] = v9, ( target_flags & 0x2000000) == 0) 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = v13; 
&& rtx_equal_p( *( rtx *)( v14 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v14 + 16), recog_data_0.operand[2]) 
v15 = ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand); 
recog_data_0.operand[1] = v16; 
recog_data_0.operand[2] = v17; 
recog_data_0.operand[0] = v85; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& !pic_symbolic_operand( recog_data_0.operand[2], VOIDmode) ) 
recog_data_0.operand[0] = v20; 
&& rtx_equal_p( *( rtx *)( v21 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v21 + 16), recog_data_0.operand[2]) 
&& ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) 
v10 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v8] - 5) < 2) + 1; 
return offsettable_address_p( 0, ( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)op), op->fld[0].rtx) != 0; 
v4 = ( tree_node *)v2[1]; 
v5 = gen_rtx_CONST_INT( ( machine_mode)mem, mode_size[v6]); 
*( _QWORD *)&mem[1] = get_mem_attrs( v3, v4, offset, v5, v8, ( machine_mode)*( ( unsigned __int8 *)mem + 2)); 
rtx memory_rtx; // r14 
memory_rtx = get_memory_rtx( elements); 
set_mem_align( memory_rtx, v11); 
v6 = clear_storage( memory_rtx, v18); 
rtx = memory_rtx->fld[0].rtx; 
v18 = mode_class_0[mode]; 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( v14 >> 14) & 0x3FC)) == MODE_FLOAT 
v17 = ( rtx_def)v8->fld[0].rtwint; 
v7 = *( _OWORD *)&buffer->state.diagnostic_count[4]; 
v6 = *( _OWORD *)buffer->state.diagnostic_count; 
v5 = *( _OWORD *)&buffer->state.cursor; 
v4 = *( _OWORD *)&buffer->state.indent_skip; 
v3 = *( _OWORD *)&buffer->state.prefix; 
*( _OWORD *)&buffer->state.diagnostic_count[4] = v7; 
*( _OWORD *)buffer->state.diagnostic_count = v6; 
*( _OWORD *)&buffer->state.cursor = v5; 
tree v22; // rax 
tree v23; // rax 
tree v24; // rax 
tree v25; // rax 
tree v26; // [rsp+0h] [rbp-48h] 
tree v27; // [rsp+8h] [rbp-40h] 
tree v28; // [rsp+10h] [rbp-38h] 
if ( ( _DWORD)v10 == 46 || ( sch_istable[( unsigned __int8)v10] & 4) != 0 ) 
while ( ( sch_istable[v10] & 4) != 0 ); 
insn = peep2_insn_data_0[v1].insn; 
rtvec v17; // rax 
v5 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
v17 = rtvec_alloc( rtvec->num_elem); 
v5->fld[v14].rtwint = ( __int64)v17; 
if ( v17->num_elem > 0 ) 
return new_loc_descr( ( dwarf_location_atom)v2, i, 0LL); 
rtx real_insn; // rbx 
real_insn = next_real_insn( rtx); 
LODWORD( v8) = real_insn == next_real_insn( y->fld[0].rtx); 
LODWORD( v10) = subreg_regno_offset( v12, ( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), v11, v6); 
dwarf2out_frame_debug_expr( *fld, dwarf2out_cfi_label_label); 
cfa_temp_0 = -1LL; 
check_final_value( loop, ( induction_1 *)j); 
v3 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v6 = invert_tree_comparison( ( tree_code)*( ( unsigned __int8 *)&arg->block.common + 16)); 
v9 = *( _OWORD *)&arg->block.vars; 
if ( ( sch_istable[v10] & 4) == 0 ) 
if ( ( sch_istable[*( unsigned __int8 *)v9] & 4) != 0 ) 
while ( ( sch_istable[( unsigned __int8)v10] & 4) != 0 ); 
v3 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v4] - 5) < 2) + 1; 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v22 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v22); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v22 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v22); 
v26 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v29 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v27); 
if ( *( _OWORD *)arg0 != 0LL ) 
v5 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v6 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v8 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v3, operands[2], operands[3]); 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
rtx v20; // rdi 
rtx v21; // rsi 
if ( recog_data_0.n_operands && recog_data_0.n_alternatives ) 
if ( recog_data_0.n_operands && recog_data_0.n_alternatives ) 
if ( recog_data_0.n_operands > 0 ) 
n_operands = ( unsigned int)recog_data_0.n_operands; 
memcpy( dest, recog_data_0.constraints, v4); 
if ( recog_data_0.n_operands > 0 ) 
rtx = recog_data_0.operand[v6]; 
( machine_mode)( unsigned __int8)BYTE2( *rtwint), 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)rtx)); 
v20 = recog_data_0.operand[v18]; 
v20 = recog_data_0.operand[v18]; 
v21 = recog_data_0.operand[v6]; 
rtx v18; // r15 
rtx *p_rtl; // r15 
rtx v24; // rax 
rtx *v25; // rax 
rtx v26; // rax 
rtx v28; // rax 
rtx v29; // rax 
v11 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v18 = assign_temp( decl, 1, 1, 1); 
set_mem_attributes( v18, decl, 1); 
decl->decl.rtl = v18; 
if ( !v18 ) 
v18 = decl->decl.rtl; 
v12 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), fixed); 
v13 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v12); 
lang_hooks_0.tree_inlining.add_pending_fn_decls( &va, v7); 
v6 = *( ( unsigned int *)uid_cuid_1 + v5); 
v7 = *( unsigned __int64 *)( ( char *)reaching_defs[v4]->elms + ( ( *( ( _DWORD *)uid_cuid_1 + v5) >> 3) & 0x1FFFFFF8)); 
if ( ( _DWORD)v4 == *( _DWORD *)( basic_block_for_insn->data.l[v5] + 88) && ( int)v6 < *( ( _DWORD *)uid_cuid_1 + rtint) ) 
rtx *loc; // [rsp+0h] [rbp-58h] 
rtx data; // [rsp+10h] [rbp-48h] BYREF 
rtx pattern; // [rsp+18h] [rbp-40h] 
rtx object; // [rsp+20h] [rbp-38h] 
v7 = canon_hash( *( rtx *)&x[1], ( machine_mode)BYTE2( v3)); 
v8 = lookup( v4, v7 & 0x1F, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
loc = ( rtx *)&x[1]; 
if ( *( _WORD *)*loc != 61 ) 
v10 = notreg_cost( *loc, SET); 
rtx v8; // r13 
rtx v10; // r13 
rtx inline_target; // rcx 
rtx v27; // rbp 
rtx v28; // rax 
rtx v36; // rax 
rtx y; // [rsp+8h] [rbp-50h] 
rtx arg0[9]; // [rsp+10h] [rbp-48h] 
v8 = ( rtx)rtx[2]; 
v8 = single_set_2( rtx, *( rtx *)&rtx[2]); 
rtx v22; // rax 
rtx v28; // rcx 
rtx v30; // rax 
rtx v35; // rbx 
rtx v41; // rdx 
rtx nonnote_insn; // rax 
rtx v60; // rbp 
rtx v64; // rax 
rtx v70; // rax 
rtx *fld; // r14 
if ( **( _WORD **)&this_insn_0[2] == 39 ) 
if ( multiple_sets( this_insn_0) ) 
v4 = **( int **)( *( _QWORD *)&this_insn_0[2] + 8LL); 
v6 = *( _QWORD *)( *( _QWORD *)( *( _QWORD *)&this_insn_0[2] + 8LL) + 8 * v5 - 8); 
regno_note = find_regno_note( this_insn_0, REG_INC, rtint); 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
qty_0[v12].death = v8 + 2 * this_insn_number; 
v6 = transp_0[src->index]; 
rtx result; // rax 
result = simplify_relational_operation( code, v11, rtx, v4); 
if ( result ) 
return result; 
result = simplify_binary_operation( code, mode, rtx, v4); 
if ( result ) 
return result; 
v22->reaching_reg = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( insn->fld[0].rtwint + 2)); 
values = *( tree_node **)&f[2 * v7 + 2]; 
v9 = *( tree_node **)&f[2 * v6 + 2]; 
v10 = ( tree_node **)&v18[2 * v6]; 
v15 = *( tree_node **)&f[2 * v6 + 2]; 
( machine_mode)BYTE2( v7), 
*( ( reg_class *)&regclass_map + v5->fld[0].rtuint), 
v8 = ix86_memory_move_cost( ( machine_mode)BYTE2( v7), class2, 1); 
v10 = cselib_lookup( v5, ( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 0); 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)loc), 
*( ( reg_class *)&regclass_map + loc->fld[0].rtuint), 
v2 = ( cpp_token_0 *)xmalloc( 24LL * count); 
v2->new_reg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v2->old_reg + 2)); 
v15 = simplify_and_const_int( 0LL, ( machine_mode)BYTE2( v12), v5->fld[0].rtx, v10); 
v16 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), *( rtx *)&v5[1], v10); 
result[1] = ( rtx_def)_mm_load_si128( &v9); 
v10 = lang_hooks_0.get_alias_set( v9); 
pointer_alias_set = ( tree *)lang_hooks_0.get_alias_set( section_name); 
result->val.node = ( cpp_hashnode_0 *)source; 
arg0 = ( tree_node *)*( &global_trees + 15); 
arg1 = ( tree_node *)*( &global_trees + 17); 
emit_stack_restore( ( save_level)( x_block_stack->next == 0LL), next_label, 0LL); 
rtx v9; // rbp 
v9 = ( rtx)v5[1]; 
v9 = a->end; 
*( _OWORD *)&b->pred = 0LL; 
end = v9; 
for ( ; v9 != end; v9 = v9[1].fld[0].rtx ) 
for ( ; v9 != end; v9 = v9[1].fld[0].rtx ) 
for ( ; v9 != end; v9 = v9[1].fld[0].rtx ) 
set_block_for_insn( v9, a); 
*( _OWORD *)( xi + 1) = 0LL; 
rtx v13; // rbp 
rtx v14; // rax 
rtx v29; // rax 
rtx v30; // rax 
rtx v40; // rax 
rtx v44; // rax 
rtx v48; // rax 
v13 = v6; 
v4 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
if ( ( *( ( _BYTE *)cfun + 425) & 1) == 0 || ( result = -1, qty_0[qtyno].n_calls_crossed <= 0) ) 
if ( !qty_0[qtyno].n_calls_crossed ) 
v13 |= 1LL << aGlobalC[v14]; 
v22 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
n_calls_crossed = qty_0[qtyno].n_calls_crossed; 
if ( 4 * n_calls_crossed < qty_0[qtyno].n_refs ) 
if ( get_varargs_alias_set_set == -1 ) 
get_varargs_alias_set_set = new_alias_set( ); 
return get_varargs_alias_set_set; 
if ( *( _OWORD *)&outputs != 0LL ) 
rtx last_value; // rax 
v7 = mode_class_0[v2]; 
v9 = mode_class_0[v5]; 
last_value = get_last_value( x); 
if ( last_value ) 
v45 = last_value; 
return v8 + copy_cost_0( x, mode, ( reg_class)v7, 2); 
if ( *( const mode_class *)( ( char *)mode_class_0 + ( ( *( _DWORD *)v5 >> 14) & 0x3FC)) == MODE_FLOAT ) 
fancy_abort( &off_6CC868[4], 2839, "elimination_effects"); 
fancy_abort( &off_6CC868[4], 2698, "elimination_effects"); 
v5 = *( _OWORD *)&diagnostic_buffer->state.prefix; 
v6 = *( _OWORD *)&diagnostic_buffer->state.indent_skip; 
v7 = *( _OWORD *)&diagnostic_buffer->state.cursor; 
v8 = *( _OWORD *)diagnostic_buffer->state.diagnostic_count; 
v9 = *( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4]; 
*( _OWORD *)&diagnostic_buffer->state.diagnostic_count[4] = v9; 
*( _OWORD *)v4->state.diagnostic_count = v8; 
*( _OWORD *)&v4->state.cursor = v7; 
v36 = function_arg( args_so_far, ( machine_mode)v34, rttree, v35); 
locate_and_pad_parm( ( machine_mode)v34, rttree, v38 != 0, fndecl, v20, p_size - 2, p_size, &v49); 
( machine_mode)( ( unsigned __int8)HIBYTE( WORD2( rttree->block.abstract_origin)) >> 1), 
v1 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
return expand_unop( ( machine_mode)*( ( unsigned __int8 *)x + 2), optab_table[17], x, v1, 0); 
rtx v6; // rbx 
rtx *fld; // r13 
v6 = first; 
fld = ( rtx *)first[1].fld; 
v6 = *fld; 
v6 = *fld; 
fld = ( rtx *)v6[1].fld; 
v8.rtwint = ( __int64)v6[1].fld[0]; 
set_block_for_insn( v6, v4); 
v4->end = v6; 
v6 = rtx; 
v6[1].fld[0] = v9; 
*( _QWORD *)( v9.rtwint + 16) = v6; 
htab_empty( hash_table_0); 
fprintf( file, "; pref %s", dump_flow_info_reg_class_names[v10]); 
v12 = dump_flow_info_reg_class_names[v10]; 
fprintf( file, "; pref %s, else %s", v12, dump_flow_info_reg_class_names[v11]); 
if ( i[1] != 37 || ( rttree = ( tree_node *)i[6]) == 0LL ) 
if ( ( doing_eh_warned & 1) == 0 ) 
doing_eh_warned = 1; 
*( _OWORD *)( ( char *)&replacements[0].where + 3 * v7) = *( _OWORD *)&v4->where; 
*( _OWORD *)( ( char *)&replacements[0].where + 3 * v7) = *( _OWORD *)&v4->where; 
LODWORD( v2) = ( int)( ( double)( *( int *)( ( char *)&qty_0->size + v2) 
* *( int *)( ( char *)&qty_0->freq + v2) 
* floor_log2_wide( *( int *)( ( char *)&qty_0->n_refs + v2))) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v2) - *( int *)( ( char *)&qty_0->birth + v2)) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v2) - *( int *)( ( char *)&qty_0->birth + v2)) 
- ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
- ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
- ( int)( ( double)( qty_0[v3].size * qty_0[v3].freq * floor_log2_wide( qty_0[v3].n_refs)) 
/ ( double)( qty_0[v3].death - qty_0[v3].birth) 
/ ( double)( qty_0[v3].death - qty_0[v3].birth) 
v23 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operand1->fld[0].rtx); 
v8 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operand2->fld[0].rtx); 
if ( use == sibcall_use_normal_0 ) 
else if ( use == sibcall_use_sibcall_0 ) 
if ( use != sibcall_use_tail_recursion_0 ) 
hard_reg_initial_vals->entries = ( initial_value_pair_0 *)xmalloc( 0x50uLL); 
hard_reg_initial_vals->entries = ( initial_value_pair_0 *)xrealloc( hard_reg_initial_vals->entries, 16 * v6); 
result = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
if ( lang_hooks_0.tree_inlining.disregard_inline_limits( fn) 
if ( !lang_hooks_0.tree_inlining.disregard_inline_limits( fnp) ) 
v10 = !v4 || lang_hooks_0.tree_inlining.cannot_inline_tree_fn( &fnp) != 0; 
v4 = ( ( unsigned int)( mode_class_0[v3] - 5) < 2) + 1; 
*( _OWORD *)p_pred = 0LL; 
v1 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v6; 
|| ( recog_data_0.operand[0] = v9, !ix86_match_ccmode( insn, CCGCmode)) 
|| ( result = 225LL, LOBYTE( recog_data_0.operand[2]->fld[0].rtwint) == 0x80) ) 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = v12; 
&& rtx_equal_p( *( rtx *)( v13 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v13 + 16), recog_data_0.operand[2]) 
matched = ix86_binary_operator_ok( MINUS, QImode, recog_data_0.operand); 
recog_data_0.operand[1] = v15; 
recog_data_0.operand[2] = v16; 
recog_data_0.operand[0] = v92; 
v31 = recog_data_0.operand[1]; 
recog_data_0.operand[0] = v19; 
&& rtx_equal_p( *( rtx *)( v20 + 8), recog_data_0.operand[1]) 
&& rtx_equal_p( *( rtx *)( v20 + 16), recog_data_0.operand[2]) 
matched = ix86_binary_operator_ok( PLUS, QImode, recog_data_0.operand); 
recog_data_0.operand[1] = v21; 
rtx base_value; // rax 
rtx v10; // rax 
base_value = find_base_value( rtx->fld[0].rtx); 
if ( base_value ) 
v2 = base_value; 
v10 = find_base_value( v4); 
if ( v10 ) 
v4 = v10; 
*( _OWORD *)&v9->left = 0LL; 
v16 = ( v15 - 1 < 0) ^ __OFADD__( -1LL, v15) | ( v15 == 1); 
&& mode_class_0[( int)v8] == MODE_INT 
if ( ( v3 & 0xFF0000) == 0 && v4 && ( mode_class_0[v4] | 2) != 3 ) 
if ( mode_class_0[v9] != MODE_FLOAT || mode_size[v9] <= mode_size[BYTE2( v11)] ) 
v15 = 4 * ( legitimate_address_p( ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v14, 0) != 0); 
rtx v7; // rax 
v7 = gen_rtx_MEM( v6, rtx); 
v8 = *( _DWORD *)memref & 0x8000000 | *( _DWORD *)v7 & 0xF7FFFFFF; 
*( _DWORD *)v7 = v8; 
*( _DWORD *)v7 = v9; 
*( _DWORD *)v7 = v10; 
*( _DWORD *)v7 = v11; 
*( _DWORD *)v7 = *( _DWORD *)memref & 0x1000000 | v11 & 0xFEFFFFFF; 
*( _QWORD *)&v7[1] = memref[1]; 
return v7; 
v7 = mode_class_0[mode]; 
find_reloads_address( v5, 0LL, v10->fld[0].rtx, ( rtx *)v10->fld, v14, ( reload_type)v12, 0, 0LL); 
fatal_insn_not_found( insn, "insn-attrtab.c", 20460, "get_attr_prefix_data16"); 
v5 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v6] - 5) < 2) + rtuint; 
rtx v17; // rax 
v17 = gen_rtx_CONST_INT( VOIDmode, *( _QWORD *)( v14 + 8) * v11); 
v19 = v17; 
rtx v18; // rcx 
fatal_insn_not_found( insn, "insn-attrtab.c", 20323, "get_attr_prefix_0f"); 
if ( ( unsigned int)( which_alternative - 2) <= 2 && aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
rtx = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
rtx = recog_data_0.operand[0]->fld[0].rtx; 
v18 = recog_data_0.operand[0]; 
v18 = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
v18 = recog_data_0.operand[0]->fld[0].rtx; 
v18 = recog_data_0.operand[0]->fld[0].rtx; 
v19 = insn_addresses_->data.i[v18->fld[0].rtint]; 
v21 = gen_rtx_CONST_INT( ( machine_mode)v20, arg); 
( machine_mode)*( unsigned __int8 *)( v25.rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( v25.rtwint + 2), 
v1 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[2]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), operands[3]); 
LOBYTE( v14) = canon_hash( x, ( machine_mode)BYTE2( v3)); 
v17 = lookup_for_remove( x, i, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v20 = ( ( unsigned int)( mode_class_0[v19] - 5) < 2) + 1; 
v34 = ( ( unsigned int)( *( const mode_class *)( ( char *)mode_class_0 
v18 = operand_sub*(short *)0xforce( op0, v12, v17); 
induction_1 *i; // r12 
induction_1 *i; // r12 
induction_1 *biv; // rax 
induction_1 *biv; // rax 
for ( i = v3->biv; i; i = i->next_iv ) 
for ( i = v3->biv; i; i = i->next_iv ) 
for ( i = v3->biv; i; i = i->next_iv ) 
for ( i = v3->biv; i; i = i->next_iv ) 
insn = i->insn; 
if ( rtx_class[*( _WORD *)i->insn] == 105 ) 
biv = v3->biv; 
v27 = gen_reg_rtx( biv->mode); 
v7 = gen_move_insn( biv->src_reg, y); 
*( _OWORD *)( aux + 8) = 0LL; 
*( _OWORD *)&result->aux = 0LL; 
*( _OWORD *)&result->global_live_at_start = 0LL; 
*( _OWORD *)&result->local_set = 0LL; 
*( _OWORD *)&result->pred = 0LL; 
*( _OWORD *)&result->head_tree = 0LL; 
*( _OWORD *)&result->head = 0LL; 
*( _OWORD *)&result->count = 0LL; 
rtx v7; // rbp 
v7 = insn_queue[( ( _BYTE)v6 + ( _BYTE)q_ptr) & 0x7F]; 
if ( v7 ) 
v8 = v7->fld[0].rtx; 
v7 = ( rtx)v7[1]; 
while ( v7 ); 
rtx v12; // rax 
rtx arg1; // [rsp+10h] [rbp-D78h] 
rtx arg2[430]; // [rsp+18h] [rbp-D70h] 
arg2[v8 - 1] = *( rtx *)( v7 + 16); 
arg2[v8] = *( rtx *)( v7 + 8); 
arg1 = *( rtx *)( v1 + 16); 
arg2[0] = *( rtx *)( v1 + 8); 
rtx = arg2[v9]; 
arg2[v9] = rtx; 
v12 = arg2[v9 - 1]; 
v12 = arg2[v9 - 1]; 
return gen_rtx_CONST_INT( ( machine_mode)c, v2); 
if ( memory_address_p( ( machine_mode)v5, v9) ) 
return adjust_address_1( v4.rtx, ( machine_mode)v5, v6, 1, 1); 
v7 = adjust_address_1( v4.rtx, ( machine_mode)v5, v6, 1, 1); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
&& *( const mode_class *)( ( char *)mode_class_0 + ( ( v26 >> 14) & 0x3FC)) != MODE_INT ) 
v32 = operand_sub*(short *)0xforce( op, v30, mode); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
operand = insn_data_0[v60].operand; 
v67 = insn_data_0[v61].genfun( binoptaba, from); 
if ( *( tree_node **)( v9->fld[0].rtwint + 128) == section_name ) 
if ( ( *( _BYTE *)( v14.rtwint + 16) | 2) == 15 && *( tree_node **)( *( _QWORD *)( v14.rtwint + 8) + 128LL) == section_name ) 
result = *( insn_code *)( ( char *)&fixtrunctab[0][0][v5] + v6); 
return *( insn_code *)( ( char *)&fixtab[0][0][v5] + v6); 
&& can_fix_p( ( machine_mode)v14, v12, 0, &truncp_ptr) != CODE_FOR_nothing ) 
ya = immed_real_const_1( ( machine_mode)v13, d); 
v24 = convert_to_mode( ( machine_mode)v13, v24, 0); 
emit_cmp_and_jump_insns( v24, ya, GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v24 + 2), 0, label); 
( machine_mode)*( ( unsigned __int8 *)v24 + 2), 
if ( *( insn_code *)( ( char *)&optab_table[30]->handlers[0].insn_code + ( ( *( _DWORD *)v22 >> 12) & 0xFF0)) != CODE_FOR_nothing ) 
( machine_mode)*( ( unsigned __int8 *)v11 + 2), 
v42 = gen_rtx_fmt_e( ( rtx_code)( 2 * v39 + 126), ( machine_mode)*( ( unsigned __int8 *)v11 + 2), v38); 
v42 = gen_rtx_fmt_e( ( rtx_code)( 2 * v39 + 126), ( machine_mode)*( ( unsigned __int8 *)v11 + 2), v38); 
emit_unop_insn( fixed, y, v10, ( rtx_code)( 2 * ( v8 != 0) + 126)); 
v8 = rtx_alloc( ( rtx_code)( unsigned __int16)v2); 
v8 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v22[2 * v23 + 2] + 2LL)); 
|| !fixed_regs[rtuint] && *( const mode_class *)( ( char *)mode_class_0 + ( ( v4 >> 14) & 0x3FC)) != MODE_CC) ) 
tree v8; // rax 
v8 = build( MODIFY_EXPR, type, valist, tree); 
*( ( _BYTE *)&v8->block.common + 17) |= 1u; 
expand_expr( v8, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
&& ( mode == BLKmode || direct_store[mode] || ( unsigned int)( mode_class_0[mode] - 5) <= 1) 
v24 = convert_modes( mode, ( machine_mode)v26, v24, 1); 
v22 = *( const mode_class *)( ( char *)mode_class_0 + ( ( v21 >> 14) & 0x3FC)); 
if ( v22 != mode_class_0[v23] ) 
v10 = *( tree_node **)( key + 32); 
if ( !lang_hooks_0.tree_dump.dump_tree( di_0, ( tree)key) ) 
v13 = *( tree_node **)( key + 40); 
v13 = *( tree_node **)( key + 32); 
v13 = *( tree_node **)( key + 32); 
v13 = *( tree_node **)( key + 32); 
LOBYTE( v27) = canon_hash( v5, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v28 = lookup( v5, v27 & 0x1F, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
LOBYTE( v46) = canon_hash( rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
( rtx_code)*( _WORD *)*v3, 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
fatal_insn( "Attempt to delete prologue/epilogue insn:", insn, "flow.c", 1615, "propagate_one_insn"); 
rtx *v43; // rdi 
rtx *v54; // rbp 
rtx *v55; // rbx 
rtx regno_note; // rbp 
rtx *v63; // rbp 
rtx v69; // rsi 
rtx *reg; // [rsp+8h] [rbp-60h] 
rtx *rega; // [rsp+8h] [rbp-60h] 
rtx v80; // [rsp+18h] [rbp-50h] 
rtx v81; // [rsp+18h] [rbp-50h] 
v43 = v10; 
if ( initial != ( tree_node *)global_trees ) 
v9 = ( ( unsigned int)( mode_class_0[( unsigned __int8)v14] - 5) < 2) + 1; 
rtx reg_equal_equiv_note; // rax 
rtx v19; // rax 
reg_equal_equiv_note = find_reg_equal_equiv_note( insn); 
if ( reg_equal_equiv_note ) 
if ( ( v10 = *( _DWORD *)reg_equal_equiv_note->fld[0].rtwint, ( unsigned __int16)( v10 - 54) <= 0xEu) 
rtx = reg_equal_equiv_note->fld[0].rtx; 
|| ( reg_note = find_reg_note( insn, REG_EQUIV, 0LL)) != 0LL && *( _WORD *)reg_note->fld[0].rtwint == 66 ) 
|| ( reg_note = find_reg_note( insn, REG_EQUIV, 0LL)) != 0LL && *( _WORD *)reg_note->fld[0].rtwint == 66 ) 
v19 = ( rtx)insn[2]; 
if ( *( _WORD *)v19 != 47 ) 
( rtx_code)( unsigned __int16)*( _DWORD *)ext_dependent, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ext_dependent), 
( rtx_code)( unsigned __int16)*( _DWORD *)ext_dependent, 
( machine_mode)( unsigned __int8)BYTE2( *( _DWORD *)ext_dependent), 
v5 = convert_to_mode( ( machine_mode)v7, v5, 1); 
v4 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v13 = *( ( unsigned __int16 *)&insn_data_0[1234].operand[1] + 8); 
predicate = insn_data_0[1234].operand[1].predicate; 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
rtx v19; // rbp 
rtx cond_earliest; // rbx 
rtx to; // [rsp+0h] [rbp-B8h] 
rtx v37; // [rsp+20h] [rbp-98h] 
v37 = active_insn; 
if ( rtx_class[*( _WORD *)v37] == 105 ) 
/data/output_dir/patch/gcc/ida/clang/O1/gcc-clang-O1/noce_process_if_block/src/ifcvt.c:2154:34: error: expected expression
v11 = single_set_2( v37, *( rtx *)&v37[2]); 
v11 = single_set_2( v37, *( rtx *)&v37[2]); 
to = v18; 
v19 = ( rtx)v18[2]; 
if ( *( _WORD *)v19 != 47 ) 
set_diagnostic_context( &v27, msgid, ( va_list_0 *)&v14, file, line, 1); 
*( _OWORD *)xi = 0LL; 
v2 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), v0); 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v19 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
fancy_abort( &off_6CC868[4], 4328, "clear_reload_reg_in_use"); 
operand = insn_data_0[v3].operand, 
operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[v5].genfun( r0, r1); 
v13 = gen_rtx_fmt_ee( ( rtx_code)v6, mode, adj_operand, v12); 
v18 = gen_rtx_fmt_ee( ( rtx_code)v6, mode, v14, v17); 
v11 = ( tree_node *)*( &global_trees + 15); 
v12 = expand_expr( valist, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), EXPAND_NORMAL); 
rtx v38; // rax 
rtx insns; // [rsp+10h] [rbp-48h] 
insns = get_insns( ); 
fatal_insn( "wrong insn in the fallthru edge", end, "cfgrtl.c", 1717, "verify_flow_info"); 
v6 = ( unsigned __int16 *)insns; 
v6 = ( unsigned __int16 *)insns; 
v38 = v20->end; 
if ( k == v38[1].fld[0].rtx ) 
if ( v38 == ( rtx)v42 ) 
fatal_insn( "flow control insn inside a basic block", ( rtx)v42, "cfgrtl.c", 1829, "verify_flow_info"); 
v6 = ( unsigned __int16 *)insns; 
v8 = ( tree_node *)*( &global_trees + 5); 
v8 = ( tree_node *)*( &global_trees + 4); 
v8 = ( tree_node *)*( &global_trees + 3); 
v8 = ( tree_node *)*( &global_trees + 2); 
v8 = ( tree_node *)*( &global_trees + 1); 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx v18; // rax 
rtx mem_set_list; // rbp 
rtx v20; // r13 
v24 = ( ( unsigned int)( mode_class_0[v23] - 5) < 2) + 1; 
v18 = canon_rtx( rtx); 
mem_set_list = pbi->mem_set_list; 
if ( mem_set_list ) 
v20 = v18; 
v20 = v18; 
if ( anti_dependence( rtx, mem_set_list->fld[0].rtx) ) 
v25.rtwint = ( __int64)mem_set_list->fld[0]; 
if ( rtx_equal_p( v20->fld[0].rtx, *( rtx *)( v25.rtwint + 8)) ) 
rtx v5; // rdx 
rtx v6; // rax 
v5 = *startp; 
v6 = v5; 
v6 = v5; 
v5 = v5[1].fld[0].rtx; 
v5 = v5[1].fld[0].rtx; 
if ( *( _WORD *)v6 == 37 && ( unsigned int)( v6[2].fld[0].rtint + 98) <= 5 ) 
if ( *( _WORD *)v6 == 37 && ( unsigned int)( v6[2].fld[0].rtint + 98) <= 5 ) 
if ( v6 == v2 ) 
v2 = v5; 
v7 = ( __int64)v6[1]; 
*( _QWORD *)&v6[1] = v8; 
v6[1].fld[0].rtwint = ( __int64)v2; 
*( _QWORD *)( v8 + 24) = v6; 
*( _QWORD *)( v6[1].fld[0].rtwint + 16) = v6; 
if ( reg_note ) 
v32 = *( _DWORD *)reg_note->fld[0].rtwint - 58; 
v10 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 2); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v11, global_rtl[4], v10); 
v15 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), global_rtl[4]); 
v21 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v11, global_rtl[2], v10); 
v35 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) == 0) ^ 5), i); 
v8 = ( tree_node *)low; 
v10 = ( tree_node *)high; 
if ( call_insn_operand( operand1->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)) ) 
( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32), 
recog_data_0.operand[0] = v6.rtx; 
recog_data_0.operand[1] = v6.rtx; 
result = gen_peephole2_1246( insn, recog_data_0.operand); 
recog_data_0.operand[0] = v6.rtx; 
result = gen_peephole2_1249( insn, recog_data_0.operand); 
recog_data_0.operand[1] = v6.rtx; 
result = gen_peephole2_1252( insn, recog_data_0.operand); 
recog_data_0.operand[0] = v6.rtx; 
recog_data_0.operand[1] = v6.rtx; 
result = gen_peephole2_1245( insn, recog_data_0.operand); 
recog_data_0.operand[0] = v6.rtx; 
result = gen_peephole2_1248( insn, recog_data_0.operand); 
recog_data_0.operand[1] = v6.rtx; 
result = gen_peephole2_1251( insn, recog_data_0.operand); 
induction_1 *v5; // rbp 
induction_1 *v5; // rbp 
v5 = ( induction_1 *)gen_rtx_REG( *(short *)0xmode, 58); 
v5 = ( induction_1 *)gen_rtx_REG( *(short *)0xmode, 58); 
addr_placeholder = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000 | 0x500000000uLL) - 1) >> 32)); 
v14 = loop_giv_reduce_benefit( (  struct loop *)p_regno, (  struct iv_class *)i, v5, v12); 
fprintf( outf, off_607A24, ( unsigned int)v7); 
scan_rtx( insn, ( rtx *)v7->fld, a3, action, ( op_type)( 2 * ( type != OP_IN)), earlyclobber); 
