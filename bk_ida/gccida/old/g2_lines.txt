p_free_buffs = ( _cpp_buff_0 *)&pfile->free_buffs; 
result = ( _cpp_buff_0 *)&v5[v4]; 
v2 = ( cpp_token_0 *)xmalloc( 24LL * count); 
if ( ( sch_istable[*v8] & 0x800) == 0 ) 
else if ( ( sch_istable[( unsigned __int8)v49] & 4) != 0 ) 
parse_number( pfile, ( cpp_string_0 *)&cur_token->val, v49, 1); 
else if ( ( sch_istable[( unsigned __int8)v39] & 0x400) != 0 ) 
if ( ( sch_istable[( unsigned __int8)v41] & 0x400) != 0 ) 
v43 = ( unsigned int)&pfile->buffer->cur[( ( sch_istable[*( ( unsigned __int8 *)pfile->buffer->cur - 1)] & 0x400) == 0) 
parse_number( pfile, ( cpp_string_0 *)&cur_token->val, v5, 0); 
if ( ( sch_istable[( unsigned __int8)v16] & 0x204) != 0 ) 
while ( ( sch_istable[( unsigned __int8)v16] & 0x204) != 0 ); 
tokenrun_0 *cur_run; // rdi 
tokenrun_0 *cur_run; // rdi 
cur_run = pfile->cur_run; 
if ( pfile->cur_token == cur_run->limit ) 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
v12 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v12 + 2), fixed); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
tree_node *elements; // rdi 
fancy_abort( ( const char *)&a, 9320, "add_byte_size_attribute"); 
elements = result->vector.elements; 
if ( elements ) 
if ( host_integerp( elements, 1) ) 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4441, "AT_unsigned"); 
fancy_abort( ( const char *)&a, 8599, "add_data_member_location_attribute"); 
if ( v20 == reverse_condition( ( rtx_code)v21) 
*hv = ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64; 
return ( ( ( ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64) ^ v6) & ~( v6 ^ h2)) >> 63; 
v18 = gen_rtx_fmt_e( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v19); 
v18 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v17, v16); 
fancy_abort( ( const char *)&a, 8989, "add_location_or_const_value_attribute"); 
if ( mode_class_0[v9] != MODE_FLOAT ) 
fancy_abort( ( const char *)&a, 8722, "add_const_value_attribute"); 
fancy_abort( ( const char *)&a, 8713, "add_const_value_attribute"); 
fancy_abort( ( const char *)&a, 8757, "add_const_value_attribute"); 
fancy_abort( ( const char *)&a, 9026, "add_location_or_const_value_attribute"); 
compiler_params = ( param_info_0 *)xrealloc( compiler_params, 24 * ( num_compiler_params + n)); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)addr + 2), addr->fld[0].rtx, v6); 
rtx v10; // r13 
rtx v11; // r12 
rtx v13; // r12 
rtx v15; // rdi 
v10 = *( rtx *)( v9 + 16); 
v11 = copy_rtx( rtx); 
v11 = v26; 
v13 = change_address_1( memref, mode, v26, validate); 
v10 = 0LL; 
v10 = 0LL; 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v6 = ( ( unsigned int)( mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] - 5) < 2) + 1; 
alias_set_entry_0 v5; // rdx 
fancy_abort( ( const char *)&stru_665A39, 3535, "aligned_operand"); 
if ( initialized_6 ) 
initialized_6 = 1; 
if ( initialized_2 ) 
initialized_2 = 1; 
return gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, val, next); 
uid_cuid_1 = v3; 
reg_set_table = ( reg_set_0 **)gmalloc( 8 * ( n_regs + 100)); 
v4 = convert_to_mode( ( machine_mode)v7, v4, 1); 
v3 = gen_reg_rtx( ( machine_mode)v9); 
v10 = *( ( unsigned __int16 *)&insn_data_0[1234].operand[1] + 8); 
predicate = insn_data_0[1234].operand[1].predicate; 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
emit_cmp_and_jump_insns( v17, v4, GEU, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1, label); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v22 = expand_divmod( 0, TRUNC_DIV_EXPR, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v20, v21, 0LL, 1); 
v3 = expand_mult( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v22, v23, 0LL, 1); 
free( reg_pref_0); 
if ( reg_pref_0 ) 
reg_pref_0 = reg_pref_buffer; 
v12 = assign_stack_local( ( machine_mode)( unsigned __int8)i, v11, -( v10 > v9)); 
v12 = assign_stack_local( ( machine_mode)i, v11, -( v11 != v9)); 
v17 = adjust_address_1( v12, ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v3] + 2), 0LL, 0, 1); 
*xp = adjust_address_1( ( *xp)->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), *( _DWORD *)&v1[1], 1, 1); 
( machine_mode)*( ( unsigned __int8 *)v1 + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
verbatim( off_661611, v1); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
if ( size_11 >= 0 ) 
return size_11; 
size_11 = v1; 
size_11 = 2 * v1; 
else if ( ( unsigned int)( mode_class_0[v3] - 5) >= 2 ) 
if ( size_11 % v8 ) 
size_11 = v8 * ( ( size_11 + v8 - 1) / v8); 
size_11 = v8 * ( ( size_11 + v8 - 1) / v8); 
v9 = size_11; 
apply_args_reg_offset[i] = size_11; 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)object + 2), object->fld[0].rtx) ) 
new_renames->new_reg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)old_reg + 2)); 
rtx v5; // r12 
rtx v6; // r13 
if ( ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT ) 
v5 = expand_compound_operation( rtx); 
v6 = expand_compound_operation( v4); 
LOWORD( v7) = *( _WORD *)v5; 
if ( *( _WORD *)v5 == *( _WORD *)v6 ) 
if ( *( _WORD *)v5 == *( _WORD *)v6 ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) == *( _BYTE *)( v6->fld[0].rtwint + 2) && v5[1] == v6[1] ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) == *( _BYTE *)( v6->fld[0].rtwint + 2) && v5[1] == v6[1] ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) == *( _BYTE *)( v6->fld[0].rtwint + 2) && v5[1] == v6[1] ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) == *( _BYTE *)( v6->fld[0].rtwint + 2) && v5[1] == v6[1] ) 
if ( subreg_lowpart_p( v5) ) 
if ( size_5 >= 0 ) 
return size_5; 
size_5 = 0; 
if ( size_5 % v4 ) 
size_5 = v4 * ( ( size_5 + v4 - 1) / v4); 
size_5 = v4 * ( ( size_5 + v4 - 1) / v4); 
size_5 += mode_size[v3]; 
size_5 = 116; 
v15 = hex_value[( unsigned __int8)*i]; 
v11 = sch_istable[( unsigned __int8)*v9]; 
if ( ( sch_istable[*v21] & 4) == 0 ) 
if ( ( sch_istable[v9] & 4) != 0 || v9 == 46 ) 
while ( ( sch_istable[v9] & 4) != 0 ); 
if ( ( sch_istable[*( ( unsigned __int8 *)constraint + 1)] & 4) != 0 ) 
while ( ( sch_istable[*( unsigned __int8 *)v4] & 4) != 0 ); 
sprintf( label, "*.%s%u", ( const char *)&off_6F972E, ( unsigned int)++labelno_17); 
sprintf( label, "*.%s%u", ( const char *)&off_6F972E, ( unsigned int)++labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_6F972E, ( unsigned int)labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_6F972E, ( unsigned int)labelno_17); 
v2 = after_function_constants; 
after_function_constants = 0LL; 
fprintf( asm_out_file, off_6F973A, 6514846LL); 
v11 = byte_6F9A58[*( unsigned __int8 *)v7]; 
v9 = byte_6F9A58[( unsigned int)j]; 
if ( v25 != ( tree_node *)global_trees ) 
if ( !v12 || v12 == ( tree_node *)global_trees ) 
fprintf( v29, off_6F973A, "object"); 
if ( v12 == ( tree_node *)global_trees ) 
if ( in_section_0 == in_text ) 
fprintf( asm_out_file, off_6F973A, "object"); 
if ( in_section_0 == in_text ) 
fancy_abort( ( const char *)&stru_665A39, 9850, "assign_386_stack_local"); 
tree v53; // rdx 
tree v66; // rdx 
rtx *x_regno_reg_rtx; // rdx 
rtx v81; // rsi 
tree result; // rbp 
v9 = promote_mode( type, ( machine_mode)v8, unsignedp, 0); 
rtx start; // rbp 
rtx nonnote_insn; // rax 
rtx v10; // rax 
start = loop->start; 
nonnote_insn = prev_nonnote_insn( end); 
v6 = nonnote_insn; 
if ( *( _WORD *)nonnote_insn == 35 ) 
v6 = (  struct rtx_def *)nonnote_insn[1]; 
if ( start != rtx ) 
if ( start != v9 ) 
v10 = start; 
v10 = start; 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
if ( v10 == rtx ) 
return mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_FLOAT; 
v1 = off_666031; 
v2 = ( tree_node *)*( &global_trees + 19); 
if ( *( _OWORD *)v6->bits != 0LL ) 
if ( *( _OWORD *)object_base->bits == 0LL ) 
induction_1 *biv; // rbx 
induction_1 *biv; // rbx 
biv = bl_0->biv; 
if ( biv ) 
v4 = *( ( _BYTE *)biv + 100); 
if ( biv->mult_val != const_int_rtx[65] ) 
v2 = fold_rtx_mult_add( v2, const_int_rtx[65], biv->add_val, biv->mode); 
v2 = fold_rtx_mult_add( v2, const_int_rtx[65], biv->add_val, biv->mode); 
biv = biv->next_iv; 
biv = biv->next_iv; 
if ( !biv ) 
rtx nonnote_insn; // rax 
rtx end; // rbx 
nonnote_insn = prev_nonnote_insn( *( rtx *)v19); 
rtx = nonnote_insn ? ( rtx)nonnote_insn[1].fld[0].rtwint : get_insns( ); 
rtx = nonnote_insn ? ( rtx)nonnote_insn[1].fld[0].rtwint : get_insns( ); 
ignore_next_note_3 = 1; 
if ( !ignore_next_note_3 ) 
ignore_next_note_3 = 0; 
return force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
return force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5, v6); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5, v6); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5, v6); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5, v6); 
if ( in_section_0 != in_bss ) 
in_section_0 = in_bss; 
v4 = ( tree_node *)ggc_alloc( 0x28uLL); 
v8 = ( const char *)&unk_6F6114; 
v8 = ( const char *)&unk_6F6128; 
v8 = ( const char *)&unk_6F613E; 
v8 = ( const char *)&unk_6F6150; 
v13 = *( tree_node **)( low + 8); 
v6 = ( tree_node *)global_trees; 
if ( v13 == ( tree_node *)global_trees ) 
sprintf( v9, "%s.%d", "__compound_literal", ( unsigned int)var_labelno); 
++var_labelno; 
section_name = ( tree_node *)( ( unsigned int)v10 - 6); 
section_name = ( tree_node *)( unsigned int)( v11 - 6); 
node->int_cst.int_cst = *( $A887AD9C3C6C8CC7716950D571F57C9D *)&v4->block.vars; 
reg_dies( *( _DWORD *)( v10 + 8), ( machine_mode)*( unsigned __int8 *)( v10 + 2), v9); 
reg_dies( *( _DWORD *)( v12 + 8), ( machine_mode)*( unsigned __int8 *)( v12 + 2), v9); 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
p_int_cst = &node->int_cst.int_cst; 
p_int_cst->low = *v6; 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
while ( p_int_cst != ( $A887AD9C3C6C8CC7716950D571F57C9D *)( &v3->block.subblocks + ( unsigned int)( v4 - 1)) ); 
while ( p_int_cst != ( $A887AD9C3C6C8CC7716950D571F57C9D *)( &v3->block.subblocks + ( unsigned int)( v4 - 1)) ); 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
p_int_cst = &node->int_cst.int_cst; 
p_int_cst->low = *v5; 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
while ( p_int_cst != ( $A887AD9C3C6C8CC7716950D571F57C9D *)( &node->block.subblocks + ( unsigned int)( v3 - 1)) ); 
while ( p_int_cst != ( $A887AD9C3C6C8CC7716950D571F57C9D *)( &node->block.subblocks + ( unsigned int)( v3 - 1)) ); 
v23 = ( tree_node *)*( &global_trees + 12); 
v37 = build( ( tree_code)( 59 - ( ( ( ( code - 130) & 0xFFFFFFFD) == 0) - 1)), v22, v36, v24); 
v23 = ( tree_node *)splay_tree_lookup( cases, ( splay_tree_key)low_value); 
duplicatea = *( tree_node **)( low_bound->value + 48); 
|| ( v21 = *( tree_node **)( v20->value + 40)) == 0LL 
v2 = ( tree_node *)*( &global_trees + 16); 
v2 = ( tree_node *)*( &global_trees + 15); 
v6 = ( tree_node *)*( &global_trees + 16); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_EXPAND_0); 
timevar_pop( TV_EXPAND_0); 
v0 = &if_stack_0[--if_stack_pointer]; 
if ( ( tree_node *)global_trees != v5 ) 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * ( v4 + 10)); 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * ( v4 + 10)); 
if_stack_0 = ( if_elt *)xmalloc( 0x140uLL); 
v6 = &if_stack_0[if_stack_pointer]; 
v1 = &if_stack_0[v0 - 2]; 
if ( if_stack_0[v0 - 1].compstmt_count == v1->compstmt_count ) 
v2 = &if_stack_0[if_stack_pointer - 1]; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
timevar_push( TV_CPP_0); 
timevar_pop( TV_CPP_0); 
if ( ( sch_istable[c] & 0xAC) != 0 ) 
v3 = ( tree_node *)*( &global_trees + 16); 
v3 = ( tree_node *)*( &global_trees + 16); 
v3 = ( tree_node *)*( &global_trees + 16); 
v3 = ( tree_node *)*( &global_trees + 15); 
if ( *( _OWORD *)&idom != 0LL ) 
return general_operand( op, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
return general_operand( op, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
rtl_op = first_rtl_op( ( tree_code)v3); 
v19 = ( tree_node *)v9[13]; 
reg_fusage = ix86_hard_regno_mode_ok( v31, ( machine_mode)*( unsigned __int8 *)( v21.rtwint + 2)); 
reg_fusage = ix86_hard_regno_mode_ok( v32, ( machine_mode)*( unsigned __int8 *)( v22 + 2)); 
v15 = *( ( unsigned int *)uid_cuid_1 + v14); 
v16 = reaching_defs[v13]->elms[*( ( _DWORD *)uid_cuid_1 + v14) >> 6]; 
if ( v13 == *( _DWORD *)( basic_block_for_insn->data.l[v14] + 88) && ( int)v15 < *( ( _DWORD *)uid_cuid_1 + rtint) ) 
while ( v2 != ( change_t_0 *)v3 ); 
|| !global_regs[rtuint] && ( fixed_regs[rtuint] || mode_class_0[*( ( unsigned __int8 *)rtx + 2)] == MODE_CC) ) 
|| insn_data_0[rtint].n_dups > 0) ) 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v6, v7); 
v7 = base_alias_check( addr, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), mem_mode); 
rtx v9; // r14 
rtx nonnote_insn; // rax 
rtx v16; // rax 
rtx v17; // r12 
v9 = ( rtx)cond[1]; 
if ( rtx_class[v10] == 60 && const_tiny_rtx[0][*( ( unsigned __int8 *)rtx + 2)] == v9 && rtx != want_reg ) 
v9 = ( rtx)rtx[1]; 
if ( rtx_class[v10] != 60 || const_tiny_rtx[0][*( ( unsigned __int8 *)rtx + 2)] != v9 || rtx == want_reg ) 
nonnote_insn = prev_nonnote_insn( v5); 
v5 = nonnote_insn; 
if ( !nonnote_insn || *( _WORD *)nonnote_insn != 32 ) 
if ( !nonnote_insn || *( _WORD *)nonnote_insn != 32 ) 
v16 = set_of( rtx, nonnote_insn); 
rtx v14; // rdx 
v14 = function_tail_eff_head; 
if ( v14 ) 
*( _QWORD *)&v14[1] = rtx; 
if ( reg_note ) 
if ( *( __int64 *)( reg_note->fld[0].rtwint + 8) <= 4999 ) 
mode_alignment = get_mode_alignment( ( machine_mode)v4); 
*( _QWORD *)&v3[1] = get_mem_attrs( v8, 0LL, 0LL, v6, mode_alignment, ( machine_mode)v4); 
rtx v6; // rdx 
if ( !rtx_equal_p( rtx, memref->fld[0].rtx) || ( v6 = memref, *( ( unsigned __int8 *)memref + 2) != v4) ) 
v6 = gen_rtx_MEM( v4, rtx); 
v7 = *( ( _BYTE *)memref + 3) & 8 | *( ( _BYTE *)v6 + 3) & 0xF7; 
*( ( _BYTE *)v6 + 3) = v7; 
*( ( _BYTE *)v6 + 3) = v8; 
*( ( _BYTE *)v6 + 3) = v9; 
*( ( _BYTE *)v6 + 3) = v10; 
*( ( _BYTE *)v6 + 3) = *( ( _BYTE *)memref + 3) & 1 | v10 & 0xFE; 
*( _QWORD *)&v6[1] = memref[1]; 
return v6; 
if ( ( sch_istable[*( unsigned __int8 *)v10] & 4) != 0 && !v10[1] ) 
rtx *v15; // rax 
rtx v20; // rax 
rtx *v26; // r14 
rtx v27; // rax 
rtx v33; // rax 
rtx *clobber_reg; // [rsp+8h] [rbp-D8h] 
rtx insna; // [rsp+20h] [rbp-C0h] 
insna = insn; 
n_operands = recog_data_0.n_operands; 
rtwint = ( rtx *)( unsigned int)( recog_data_0.n_operands - asm_operand_n_inputs); 
n_outputs = recog_data_0.n_operands - asm_operand_n_inputs; 
*( _QWORD *)&insna[2] = gen_rtx_fmt_e( USE, VOIDmode, const_int_rtx[64]); 
v1 = *( tree_node **)( v7 + 8); 
v4 = ( tree_node *)global_trees; 
if ( ( sch_istable[( unsigned __int8)v132[1]] & 4) == 0 ) 
if ( ( sch_istable[( unsigned __int8)*format[0]] & 4) != 0 ) 
while ( ( sch_istable[( unsigned __int8)*v38] & 4) != 0 ); 
if ( ( flags & 0x40) == 0 && ( sch_istable[( unsigned __int8)v134[1]] & 4) == 0 ) 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
rtx v13; // rax 
induction_1 *v; // [rsp+8h] [rbp-70h] 
induction_1 *v; // [rsp+8h] [rbp-70h] 
rtx src_reg; // [rsp+18h] [rbp-60h] BYREF 
rtx add_val; // [rsp+20h] [rbp-58h] BYREF 
rtx mult_val; // [rsp+28h] [rbp-50h] BYREF 
rtx ext_val; // [rsp+30h] [rbp-48h] BYREF 
rtx last_consec_insn[8]; // [rsp+38h] [rbp-40h] BYREF 
v5 = ( ( unsigned int)( mode_class_0[v2] - 5) < 2) + 1; 
v9 = ( ( unsigned int)( mode_class_0[v7] - 5) < 2) + 1; 
v13 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v17 = ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
v22 = ( ( unsigned int)( mode_class_0[v21 + 52] - 5) < 2) + 1; 
v21 = subreg_regno_offset( rtint, ( machine_mode)*( ( unsigned __int8 *)v19 + 2), nr, v18) + rtint; 
v22 = smallest_mode_for_size( nr + mode_size[v18], mode_class_0[v18]); 
if ( !ix86_hard_regno_mode_ok( v21, *( ( machine_mode *)&rld + 26 * v12 + 7)) ) 
nre = ix86_register_move_cost( v18, ( reg_class)j, ( reg_class)bad_for_class); 
if ( nre >= ix86_memory_move_cost( v18, ( reg_class)bad_for_class, 1) 
|| ix86_secondary_memory_needed( ( reg_class)j, ( reg_class)bad_for_class, v18, 1) ) 
*( reload_type *)( v7 + 64), 
*( machine_mode *)v7); 
fancy_abort( ( const char *)&stru_665A39, 1912, "classify_argument"); 
( machine_mode)( *( _BYTE *)( i->fld[0].rtwint + 61) >> 1), 
( machine_mode)( *( _BYTE *)( v21 + 61) >> 1), 
fancy_abort( ( const char *)&stru_665A39, 1809, "classify_argument"); 
( machine_mode)( *( _BYTE *)( v42 + 61) >> 1), 
( machine_mode)( *( _BYTE *)( rtl->fld[0].rtwint + 61) >> 1), 
( machine_mode)( BYTE5( type->common.type->block.abstract_origin) >> 1), 
if ( ( sch_istable[i] & 0x8C) == 0 && i != 46 ) 
rtx head; // rax 
rtx nonnote_insn; // rdi 
rtx v126; // [rsp+48h] [rbp-70h] 
timevar_push( TV_CLEANUP_CFG_0); 
nonnote_insn = next_nonnote_insn( *( rtx *)( v5 + 8)); 
if ( *( _WORD *)nonnote_insn != 35 ) 
delete_insn( nonnote_insn); 
if ( recog_data_0.n_operands > 0 ) 
v3 = recog_data_0.operand_loc[v1]; 
recog_data_0.operand[v1] = alter_subreg( v3); 
else if ( ( unsigned __int16)( *( _WORD *)recog_data_0.operand[v1] - 66) <= 0xCu 
&& _bittest64( &v2, ( unsigned int)*( _WORD *)recog_data_0.operand[v1] - 66) ) 
recog_data_0.operand[v1] = walk_alter_subreg( v3); 
while ( recog_data_0.n_operands > ( int)v1 ); 
if ( recog_data_0.n_dups > 0 ) 
v6 = recog_data_0.dup_loc[v4]; 
*v6 = alter_subreg( recog_data_0.dup_loc[v4]); 
*v6 = walk_alter_subreg( recog_data_0.dup_loc[v4]); 
while ( recog_data_0.n_dups > ( int)v4 ); 
v11 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v12.rtwint + 2)] - 5) < 2) + 1; 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v14 = ( ( unsigned int)( mode_class_0[*v17] - 5) < 2) + 1; 
tree v13; // rbx 
tree v19; // rax 
tree v20; // rax 
tree v35; // rdi 
htab_empty( hash_table_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
|| ( v11 = ix86_hard_regno_mode_ok( rtuint, ( machine_mode)*( ( unsigned __int8 *)v15 + 2))) != 0 ) 
induction_1 *giv; // rax 
induction_1 *giv; // rax 
induction_1 *v3; // rdx 
induction_1 *v3; // rdx 
induction_1 **v10; // r15 
induction_1 **v10; // r15 
induction_1 *v12; // rbx 
induction_1 *v12; // rbx 
induction_1 *v15; // r13 
induction_1 *v15; // r13 
induction_1 *v19; // rax 
induction_1 *v19; // rax 
induction_1 *v23; // r12 
induction_1 *v23; // r12 
induction_1 *v32; // r14 
induction_1 *v32; // r14 
induction_1 **v39; // r15 
induction_1 **v39; // r15 
rtx v4; // rbx 
rtx v6; // rbx 
rtx v8; // rax 
reg_last_set_mode = ( machine_mode *)xmalloc( 4LL * nregs); 
v4 = f; 
*( ( _DWORD *)uid_cuid + v4->fld[0].rtint) = ++v5; 
subst_insn = v4; 
if ( rtx_class[*( _WORD *)v4] == 105 ) 
note_stores( *( rtx *)&v4[2], set_nonzero_bits_and_sign_copies, 0LL); 
record_dead_and_set_regs( v4); 
if ( *( _WORD *)v4 == 36 ) 
rtx v11; // rcx 
rtx v24; // rcx 
v11 = rtx; 
v10 += *( _DWORD *)&v11[1] / ( ( target_flags & 0x2000000) == 0 ? 4 : 8); 
( machine_mode)v12, 
*( _DWORD *)&v11[1], 
( machine_mode)*( ( unsigned __int8 *)v11 + 2)); 
( machine_mode)*( ( unsigned __int8 *)v11 + 2)); 
usize = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
v24 = setreg; 
v10 -= subreg_regno_offset( v26, ( machine_mode)v25, *( _DWORD *)&v24[1], ( machine_mode)*( ( unsigned __int8 *)v24 + 2)); 
if ( mode_class_0[*( unsigned __int8 *)( v3.rtwint + 2)] == MODE_CC ) 
( rtx_code)*( _WORD *)exp, 
rtx v70; // rbx 
rtx v72; // rcx 
rtx v83; // rbx 
rtx v92; // rax 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), global_rtl[2]) ) 
rtx end; // rsi 
end = dest->end; 
end = dest->end; 
if ( *( _WORD *)end != 33 ) 
head = end; 
end = ( rtx)end[1]; 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
while ( *( _WORD *)end == 37 && end[2].fld[0].rtint == -96 ); 
end = ( rtx)rtx[1]; 
nonnote_insn = emit_insns_after( insns, end); 
v22 = lang_hooks_0.expand_constant( exp); 
change_stack( src->end, &tmpstack, v5, ( emit_where)( *( _WORD *)src->end == 33)); 
i = ( tree_node *)high[3]; 
v18 = ( tree_node *)*( ( _QWORD *)v2 + 1); 
v19 = ( tree_node *)*( ( _QWORD *)rtl + 1); 
v22 = ( tree_node *)*( ( _QWORD *)v2 + 3); 
v23 = ( tree_node *)*( ( _QWORD *)rtl + 3); 
rtx v5; // rax 
rtx v6; // r12 
rtx v7; // rax 
v5 = group_leader( *( rtx *)( i + 8)); 
v6 = v5; 
v6 = v5; 
if ( *( rtx *)( i + 8) == v5 ) 
v7 = alloc_INSN_LIST( v2, h_i_d[v5->fld[0].rtint].depend); 
v7 = alloc_INSN_LIST( v2, h_i_d[v5->fld[0].rtint].depend); 
*( ( _BYTE *)v7 + 2) = *( _BYTE *)( i + 2); 
h_i_d[v6->fld[0].rtint].depend = v7; 
h_i_d[v6->fld[0].rtint].depend = v7; 
reg_avail_info_0 = (  struct reg_avail_info *)v2; 
free( reg_avail_info_0); 
reg_avail_info_0 = 0LL; 
rtx insn; // [rsp+18h] [rbp-20h] BYREF 
insn = insns; 
for_each_rtx( &insn, insns_for_mem_walk, &ifmwi); 
rtx = insn[1].fld[0].rtx; 
insn = rtx; 
reg_set_0 *v15; // rax 
reg_set_0 *v15; // rax 
reg_set_0 *v23; // rdx 
reg_set_0 *v23; // rdx 
rtx v26; // rax 
v15 = reg_set_table[rtuint]; 
if ( v15 ) 
v17 = bmap[*( int *)( v16->data.l[v15->insn->fld[0].rtint] + 88)]; 
v15 = v15->next; 
v15 = v15->next; 
while ( v15 ); 
v23 = reg_set_table[v18]; 
if ( v23 ) 
v25 = bmap[*( int *)( v24->data.l[v23->insn->fld[0].rtint] + 88)]; 
v23 = v23->next; 
v23 = v23->next; 
while ( v23 ); 
v26 = canon_modify_mem_list[v9]; 
v6 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v11] + 2)] - 5) < 2) + 1; 
rtx v26; // rax 
rtx v29; // [rsp+32h] [rbp-D0h] 
rtx v30; // [rsp+3Ah] [rbp-C8h] 
rtx *add_vala; // [rsp+B2h] [rbp-50h] 
rtx src_rega[2]; // [rsp+BAh] [rbp-48h] BYREF 
src_rega[0] = src_reg; 
add_vala = add_val; 
v28 = src_rega[0]; 
v29 = *mult_val; 
v30 = *add_val; 
v16 = ( tree_node *)i[4]; 
v5 = mode_class_0[mode]; 
v5 = mode_class_0[mode]; 
*( _OWORD *)&v20.r[1] = __PAIR128__( v23, v14); 
rtx v13; // rdi 
rtx v14; // rsi 
rtx v37; // rdi 
if ( recog_data_0.n_operands && recog_data_0.n_alternatives ) 
if ( recog_data_0.n_operands && recog_data_0.n_alternatives ) 
n_operands = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
constraints[v3] = recog_data_0.constraints[v3]; 
while ( recog_data_0.n_operands > 0 ) 
rtx = recog_data_0.operand[v30]; 
( machine_mode)*( unsigned __int8 *)( v4.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)); 
v13 = recog_data_0.operand[v11]; 
v13 = recog_data_0.operand[v11]; 
fwrite( ( char *)&stru_665A39._IO_read_end + 7, 1uLL, 0xDuLL, stderr); 
fwrite( ( char *)&stru_665A39._IO_write_base + 5, 1uLL, 8uLL, stderr); 
fprintf( stderr, off_661611, x86_64_reg_class_name[*( unsigned int *)v10++]); 
fancy_abort( ( const char *)&stru_665A39, 2086, "construct_container"); 
fancy_abort( ( const char *)&stru_665A39, 2019, "construct_container"); 
if ( *( tree_node **)( *( _QWORD *)( low + 8) + 8LL) != v14 ) 
rtx resume; // rsi 
rtx label; // rsi 
rtx continue_label; // rdx 
rtx insns; // [rsp+8h] [rbp-20h] BYREF 
insns = get_insns( ); 
convert_from_eh_region_ranges_1( &insns, v11, 0); 
rtx = insns; 
resume = v35->resume; 
if ( resume ) 
v37 = &v30[resume->fld[0].rtint]; 
label = v35->label; 
if ( label ) 
v39 = &v30[label->fld[0].rtint]; 
continue_label = v35->u.try.continue_label; 
rtx j; // rdi 
rtx x[2]; // [rsp+30h] [rbp-58h] BYREF 
x[0] = *( rtx *)( v9 + 16); 
if ( *( _WORD *)x[0] == 61 ) 
bitmap_set_bit( &head, x[0]->fld[0].rtint); 
else if ( *( _WORD *)x[0] == 152 ) 
for_each_rtx( x, mark_reg_in_phi, &head); 
x[0] = ( rtx)v1; 
x[1] = ( rtx)v5; 
for_each_successor_phi( v14, coalesce_reg_in_phi, x); 
for ( j = *( rtx *)basic_block_info->data.l[v16]; ; j = j[1].fld[0].rtx ) 
if ( mode_class_0[mode] != MODE_INT ) 
if ( mode_class_0[oldmode] != MODE_INT 
if ( mode_class_0[mode] != MODE_INT ) 
v5 = mode_class_0[v3]; 
v57 = mode_class_0[v58]; 
v9 = gen_lowpart( ( machine_mode)v3, v7); 
v9 = simplify_gen_subreg( ( machine_mode)v3, v9, ( machine_mode)*( ( unsigned __int8 *)v9 + 2), 0); 
v9 = simplify_gen_subreg( ( machine_mode)v3, v9, ( machine_mode)*( ( unsigned __int8 *)v9 + 2), 0); 
v6 = simplify_gen_subreg( ( machine_mode)v58, v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), 0); 
v6 = simplify_gen_subreg( ( machine_mode)v58, v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), 0); 
v18 = can_extend_p( ( machine_mode)v3, ( machine_mode)v58, 0); 
v18 = can_extend_p( ( machine_mode)v3, ( machine_mode)v58, 0); 
v52 = can_extend_p( v8, ( machine_mode)v58, unsignedp); 
rtx end; // rax 
rtx *v19; // rbp 
fprintf( file, off_6376D2, ( unsigned int)v15); 
end = v34->end; 
v18 = end; 
if ( *( _WORD *)end == 33 ) 
v18 = (  struct rtx_def *)end[1]; 
v19 = ( rtx *)( FP_mode_reg + 120); 
v22 = gen_rtx_fmt_ee( SET, VOIDmode, *v19, nan); 
v19 += 59; 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
result = build1( ( tree_code)( ( flag_float_store == 0) + 114), type, expr); 
return copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), x); 
src = operand_sub*(short *)0xforce( v3, i / v16, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)); 
src = operand_sub*(short *)0xforce( v3, i / v16, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)); 
return build( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v10, v9); 
return build1( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v5); 
return build1( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v11); 
rtx v4; // rbp 
if ( reg_note ) 
v4 = reg_note; 
v4 = reg_note; 
rtx[3].fld[0].rtwint = ( __int64)gen_rtx_fmt_ee( EXPR_LIST, XCmode, v4->fld[0].rtx, rtx[3].fld[0].rtx); 
rtvec v12; // r15 
rtx result; // rax 
v4 = rtx_alloc( ( rtx_code)v2); 
v12 = rtvec_alloc( rtvec->num_elem); 
v4->fld[v9].rtwint = ( __int64)v12; 
if ( v12->num_elem > 0 ) 
v12->elem[j] = copy_insn_1( *( rtx *)( orig->fld[v9].rtwint + 8LL * j + 8)); 
v12 = v4->fld[v9].rtvec; 
while ( v12->num_elem > j ); 
return result; 
rtx v8; // r12 
rtx v10; // rax 
rtx v13; // r12 
rtx v15; // r15 
rtx v35; // rax 
rtx sequence[3]; // [rsp+8h] [rbp-58h] 
v8 = 0LL; 
&& *( _WORD *)v8->fld[0].rtwint == 61 
&& rtx_equal_p( *( rtx *)&v8[1], static_chain_incoming_rtx->fld[0].rtx) ) 
( machine_mode)*( ( unsigned __int8 *)static_chain_incoming_rtx + 2), 
v8->fld[0].rtx); 
rtx note; // [rsp+10h] [rbp-40h] BYREF 
note = copy_rtx_and_substitute( rtx, map, 0); 
subst_constants( &note, 0LL, map, 0); 
v6 = note; 
for ( v10[3].fld[0].rtwint = ( __int64)note; v6; note = v6 ) 
for ( v10[3].fld[0].rtwint = ( __int64)note; v6; note = v6 ) 
rtx last_insn; // rbp 
rtx v18; // rax 
rtx v19; // rbx 
rtx *v23; // rbp 
induction_1 *v33; // rax 
induction_1 *v33; // rax 
rtx v35; // rax 
induction_1 *v36; // r13 
induction_1 *v36; // r13 
rtx v38; // rax 
rtx new_reg; // rax 
rtx *reg_map; // [rsp+8h] [rbp-60h] 
rtx temp; // [rsp+20h] [rbp-48h] 
temp = ( rtx)v1[1]; 
reg_map = 0LL; 
reg_map = 0LL; 
if ( !reg_map ) 
reg_map = ( rtx *)xcalloc( nregs, 8uLL); 
v12 = &reg_map[*( unsigned int *)( v8.rtwint + 8)]; 
*v12 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v8.rtwint + 2)); 
if ( reg_map ) 
replace_regs( *( rtx *)&v26[2], reg_map, nregs, 1); 
v2 = rtx_alloc( ( rtx_code)*( _WORD *)orig); 
v3 = ( tree_node *)ggc_alloc( v2); 
rtx result; // rax 
return result; 
v61 = gen_rtx_MEM( ( machine_mode)*( unsigned __int8 *)( orig->fld[0].rtwint + 2), v60); 
return gen_rtx_fmt_ee( CALL, ( machine_mode)*( ( unsigned __int8 *)orig + 2), v61, v66); 
if ( mode_class_0[v5] != MODE_FLOAT ) 
v9 = rtx_alloc( ( rtx_code)v2); 
v2 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
n_operands = recog_data_0.n_operands; 
v20 = ( reg_class *)( 32LL * v66 + 9844808); 
if ( *recog_data_0.constraints[v21] ) 
if ( v67 >= 0 && ( v27 = recog_data_0.operand[v21], *( _WORD *)v27 == 61) ) 
if ( v27->fld[0].rtint != v27[1] && recog_data_0.operand_type[v21] == OP_IN ) 
v22 = replace_oldest_value_addr( recog_data_0.operand_loc[v21], *v20, VOIDmode, ( rtx)head, v59); 
v22 = replace_oldest_value_reg( recog_data_0.operand_loc[v21], *v20, ( rtx)head, v59); 
v23 = recog_data_0.operand_loc[v21]; 
recog_data_0.operand[v21] = *v23; 
if ( recog_data_0.n_dups <= 0 ) 
*recog_data_0.dup_loc[v25] = v24; 
while ( recog_data_0.n_dups > ( int)v25 ); 
if ( warning_message_3 ) 
warning_message_3 = 1; 
v12 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v5.rtwint + 2)] - 5) < 2) + 1; 
v5 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v3 + 2)] - 5) < 2) + 1; 
v4 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[reg] + 2)] - 5) < 2) + 1; 
v7 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v4] + 2)] - 5) < 2) + 1; 
while ( v12 != ( int *)( ( char *)&unk_9DF25C + 4 * ( v11 - ( unsigned int)( v7 - 1))) ); 
while ( v4 != ( const  struct named_op *)&unk_64D130 ); 
return ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, str, len, HT_ALLOC); 
while ( ( sch_istable[*v7] & 0x100) != 0 ) 
v14 = hex_value[*v7]; 
if ( ( sch_istable[( _QWORD)v6] & 0x100) == 0 ) 
v18 = hex_value[v16]; 
if ( ( sch_istable[v8] & 0xAC) != 0 ) 
object_base = ( cpp_buffer_0 *)pfile->buffer_ob.object_base; 
else if ( ( sch_istable[v6] & 0x10) != 0 ) 
rtx v20; // rax 
rtx v23; // rbx 
rtx v25; // rax 
rtx nonnote_insn; // rax 
rtx v28; // rax 
nonnote_insn = prev_nonnote_insn( to); 
v23 = to; 
return v23; 
if ( *( _WORD *)nonnote_insn != 33 ) 
v29 = ( __int64)nonnote_insn[4]; 
rtx *v23; // rax 
rtx q; // [rsp+20h] [rbp-48h] 
v6 = *( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint); 
v22 = *( ( _DWORD *)uid_cuid_0 + rtint); 
v23 = ( rtx *)( ( char *)data + 16 * v13); 
if ( v23[4] != rtx ) 
if ( *( ( _DWORD *)v23 + 10) != 1 ) 
q = ( rtx)v27; 
q = ( rtx)v27; 
if ( !skip_blocksb || !v30 || *( _WORD *)q == 36 ) 
if ( next == next_real_insn( q) ) 
rtx v27; // r15 
rtx v28; // rbx 
rtx v34; // r12 
rtx v36; // rax 
rtx v40; // rbx 
rtx v41; // r15 
rtx v67; // r12 
rtx v73; // rax 
rtx v13; // rdx 
uid_cuid_0 = v7; 
v13 = cse_basic_block( last, val.last, val.path, after_loop == 0); 
last = v13; 
free( uid_cuid_0); 
&& ( v19 = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)v2 + 2), const_rtx)) != 0LL ) 
invalidate( *( rtx *)( v7.rtwint + 8), ( machine_mode)*( unsigned __int8 *)( v7.rtwint + 2)); 
htab_delete( hash_table_0); 
reg_values = varray_init( ( unsigned int)cselib_nregs, 8uLL, ( const char *)&insn.fld[0].rtwint + 1); 
hash_table_0 = htab_create( 0x1FuLL, get_value_hash, entry_and_rtx_equal_p, 0LL); 
fancy_abort( ( const char *)&insn, 968, "cselib_invalidate_regno"); 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v12 = ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)elt->u.val_rtx + 2)] - 5) <= 1; 
cselib_invalidate_regno( rtx->fld[0].rtuint, ( machine_mode)*( ( unsigned __int8 *)rtx + 2)); 
htab_traverse( hash_table_0, cselib_invalidate_mem_1, rtx); 
if ( push_operand( rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2)) ) 
v18 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
v8 = new_cselib_val( ++next_unknown_value, ( machine_mode)v3); 
*htab_find_slot_with_hash( hash_table_0, x, v8->value, INSERT) = v8; 
slot_with_hash = htab_find_slot_with_hash( hash_table_0, v9, v7, ( insert_option)( create != 0)); 
slot_with_hash = htab_find_slot_with_hash( hash_table_0, v9, v7, ( insert_option)( create != 0)); 
if ( ( ( mode_class_0[v2] & 0xFFFFFFFB) == 2 || mode_class_0[v2] == MODE_VECTOR_FLOAT) && flag_float_store ) 
if ( ( ( mode_class_0[v2] & 0xFFFFFFFB) == 2 || mode_class_0[v2] == MODE_VECTOR_FLOAT) && flag_float_store ) 
v4 = cselib_lookup( x->fld[0].rtx, ( machine_mode)v2, create); 
elt = new_cselib_val( ++next_unknown_value, ( machine_mode)v2); 
*htab_find_slot_with_hash( hash_table_0, v9, value, INSERT) = elt; 
htab_traverse( hash_table_0, cselib_invalidate_mem_1, callmem); 
htab_traverse( hash_table_0, discard_useless_locs, 0LL); 
htab_traverse( hash_table_0, discard_useless_values, 0LL); 
set_0 *v7; // rbp 
set_0 *v7; // rbp 
set_0 sets[106]; // [rsp+10h] [rbp-D78h] BYREF 
sets[0].src = *( rtx *)( v1 + 16); 
sets[0].dest = *( rtx *)( v1 + 8); 
sets[v6].src = *( rtx *)( v5 + 16); 
sets[v6].dest = *( rtx *)( v5 + 8); 
v7 = sets; 
v7 = sets; 
dest = v7->dest; 
v7->dest = dest; 
src = v7->src; 
src = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)src + 2), cond, v7->src, dest); 
src = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)src + 2), cond, v7->src, dest); 
v7->src_elt = cselib_lookup( src, ( machine_mode)*( ( unsigned __int8 *)dest + 2), 1); 
v7->src_elt = cselib_lookup( src, ( machine_mode)*( ( unsigned __int8 *)dest + 2), 1); 
v7->dest_addr_elt = cselib_lookup( dest->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1); 
v7->dest_addr_elt = cselib_lookup( dest->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1); 
fancy_abort( ( const char *)&insn, 806, "cselib_subst_to_values"); 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
fprintf( asmfile, &off_6376D2[1], ( unsigned int)current_sym_value); 
rtx homea; // [rsp+8h] [rbp-30h] BYREF 
homea = home; 
homea = alter_subreg( &homea); 
homea = alter_subreg( &homea); 
v7 = *( _WORD *)homea; 
if ( *( _WORD *)homea == 61 ) 
rtint = homea->fld[0].rtint; 
if ( *( _WORD *)homea->fld[0].rtwint == 68 ) 
current_sym_addr = homea->fld[0].rtx; 
if ( !initial || !strcmp( lang_hooks_0.name, "GNU C++") && initial == ( tree)global_trees ) 
v8.rtwint = ( __int64)homea->fld[0]; 
dbxout_symbol_location( decl, v25, "$real", homea->fld[0].rtx); 
dbxout_symbol_location( decl, v25, "$imag", *( rtx *)&homea[1]); 
v60 = ( tree_node *)i[4]; 
fwrite( &unk_64F820, 1uLL, 2uLL, asmfile); 
v34 = ( unsigned int)anonymous_type_number_2++; 
if ( ( *( _BYTE *)( v38 + 18) & 4) != 0 && !strcmp( lang_hooks_0.name, "GNU C++") ) 
rtx v35; // rax 
rtx earliest; // [rsp+B8h] [rbp-50h] BYREF 
rtx end; // [rsp+C0h] [rbp-48h] BYREF 
rtx head; // [rsp+C8h] [rbp-40h] BYREF 
head = v8; 
end = v9; 
head = v8[1].fld[0].rtx; 
if ( *( _WORD *)head == 37 ) 
if ( v9 == head ) 
end = 0LL; 
head = 0LL; 
head = head[1].fld[0].rtx; 
head = head[1].fld[0].rtx; 
if ( v9 != head ) 
end = ( rtx)v9[1]; 
v6 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v18 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v12 + 2)] - 5) < 2) + 1; 
v23 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v22 + 2)] - 5) < 2) + 1; 
*( ( reload_type *)&rld + 26 * r + 23), 
*( ( machine_mode *)&rld + 26 * r + 7)); 
fprintf( sched_dump, asc_661610, v4); 
fprintf( v1, "%s, ", reg_class_names_0[*( ( int *)v2 + 4)]); 
fprintf( v1, "%ssecondary_in_icode = %s", "\n\t", insn_data_0[v8].name); 
fprintf( v1, "%ssecondary_out_icode = %s", v9, insn_data_0[v10].name); 
bitmap_element *v8; // r13 
bitmap_element *v8; // r13 
v8 = ( bitmap_element *)attribute_tables; 
v8 = ( bitmap_element *)attribute_tables; 
next = ( const char *)v8->next->next; 
next = *( const char **)( ( char *)&v8->next->next + v10); 
v7 = ( char *)v8->next + v10; 
v12 = *( tree_node **)v10; 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
if ( ( sch_istable[*( unsigned __int8 *)v3] & 4) == 0 ) 
if ( !strcmp( v1, table_21[i].name) ) 
return table_21[( int)i].number; 
v5 = mode_class_0[mode]; 
rtx v14; // r12 
v14 = rtx->fld[0].rtx; 
if ( ( unsigned __int16)( *( _WORD *)v14 - 54) <= 0xEu ) 
v15 = ( ( 0x6017uLL >> ( ( unsigned __int8)*( _WORD *)v14 - 54)) ^ 1) & 1; 
if ( *( _WORD *)v14 == 140 || *( _WORD *)v14 == 134 || !v15 ) 
if ( *( _WORD *)v14 == 140 || *( _WORD *)v14 == 134 || !v15 ) 
v14 = v25; 
if ( *( _WORD *)v14 == 58 ) 
v14 = v14->fld[0].rtx; 
v14 = v14->fld[0].rtx; 
if ( *( _WORD *)v14 != 75 ) 
if ( *( _WORD *)v14 == 54 ) 
rtwint = v14->fld[0].rtwint; 
v27 = v14->fld[0].rtx; 
warning_with_file_and_line( filename, line, ( const char *)&stru_634008.block + 88, name->int_cst.int_cst.low); 
rtx reg; // rdx 
reg = defs->ref->reg; 
if ( *( _WORD *)reg == 63 ) 
rtuint = *( _DWORD *)( reg->fld[0].rtwint + 8); 
rtuint = reg->fld[0].rtuint; 
rtx reg; // rdx 
reg = defs->ref->reg; 
if ( *( _WORD *)reg != 63 ) 
rtuint = *( _DWORD *)( reg->fld[0].rtwint + 8); 
rtuint = reg->fld[0].rtuint; 
if ( reg_note ) 
v4.rtwint = ( __int64)reg_note->fld[0]; 
rtx v5; // r14 
rtx real_insn; // r15 
rtx retval_note; // [rsp+0h] [rbp-40h] 
v5 = reg_note; 
v5 = reg_note; 
if ( reg_note ) 
if ( reg_note->fld[0].rtx != v2 ) 
real_insn = next_real_insn( v2); 
retval_note = find_reg_note( v5->fld[0].rtx, REG_RETVAL, 0LL); 
retval_note = find_reg_note( v5->fld[0].rtx, REG_RETVAL, 0LL); 
v5->fld[0].rtx, 
real_insn[3].fld[0].rtx); 
rtx v25; // rsi 
rtx v28; // rsi 
rtx output_reload_insn; // [rsp+8h] [rbp-50h] 
output_reload_insn = spill_reg_store[last_reload_reg]; 
v12.rtwint = ( __int64)output_reload_insn[1].fld[0]; 
v16 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)i + 2)] - 5) < 2) + 1; 
delete_address_reloads( output_reload_insn, insn); 
delete_insn( output_reload_insn); 
|| ( v25 = ( rtx)*( ( _QWORD *)v24 + 4), *( _WORD *)v25 != 47) && ( v25 = single_set_2( ( rtx)v24, v25)) == 0LL 
rtx nonnote_insn; // rax 
nonnote_insn = next_nonnote_insn( ( rtx)v6); 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
delete_related_insns( nonnote_insn); 
rtx v143; // rax 
rtx v145; // rax 
rtx v161; // rax 
rtx v164; // rax 
v143 = i30->ref->reg; 
if ( *( _WORD *)v143 == 63 ) 
v143 = v143->fld[0].rtx; 
v143 = v143->fld[0].rtx; 
v141 = v143->fld[0].rtint; 
v145 = i31->ref->reg; 
if ( *( _WORD *)v145 == 63 ) 
v145 = v145->fld[0].rtx; 
v145 = v145->fld[0].rtx; 
bitmap_set_bit( *( bitmap *)( v148 + 72), v145->fld[0].rtint); 
df_uses_record( df_0, ( rtx *)( v5.rtwint + 8), DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)( v9 + 8), DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)v7->fld, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)v10->fld, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)&insn[2], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
v13 = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), v12); 
v15 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
return gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1); 
rtx *v19; // rbp 
rtx v21; // rax 
df_uses_record( df_0, ( rtx *)&v13[2 * v14 + 2], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)&rtx[1], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)( v9.rtwint + 8), DF_REF_REG_MEM_STORE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)( v9.rtwint + 16), DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
if ( ( sch_istable[v17] & 0x88) != 0 ) 
if ( !displayed_4 ) 
displayed_4 = 1; 
v13 = build( ( tree_code)*( ( unsigned __int8 *)&arg0->block.common + 16), type, low, v12); 
rtx *v59; // rax 
rtx v60; // rax 
rtx note; // [rsp+38h] [rbp-40h] 
v2 = ( tree_node *)switch_stack; 
if ( ( tree_node *)global_trees == v2 ) 
if ( mode_class_0[mode] != MODE_INT || can_compare_p( op, mode, ccp_jump) ) 
do_compare_rtx_and_jump( op0, op1, unsigned_code, v14, ( machine_mode)v13, v15, if_false_label, if_true_label); 
if ( !if_true_label && ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
if ( !if_true_label && ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
v9 = operand_sub*(short *)0xforce( op1, i, ( machine_mode)v4); 
v9 = operand_sub*(short *)0xforce( op1, i, ( machine_mode)v4); 
v8 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)v4); 
v8 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)v4); 
v5 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v5 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v7 = operand_sub*(short *)0xforce( op0, v6, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v7 = operand_sub*(short *)0xforce( op0, v6, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v12 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v12 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( exp->int_cst.int_cst.low + 8) + 61LL) >> 1), 
v8 = operand_sub*(short *)0xforce( op0, v6 - v7, mode); 
v9 = operand_sub*(short *)0xforce( op1, v6 - v7, mode); 
v9 = expand_shift( RSHIFT_EXPR, ( machine_mode)v8, v9, v24, subtargeta, 1); 
if ( !can_compare_p( v14, ( machine_mode)v8, ccp_store_flag) ) 
if ( !only_cheap || *( ( unsigned __int16 *)insn_data_0[v15].operand + 8) == mode ) 
v9 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
if ( mode_class_0[v4] == MODE_INT && *( _WORD *)newval == 54 ) 
if ( rtwint != trunc_int_for_mode( rtwint, ( machine_mode)v4) ) 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
if ( !warned_11 && do_warn ) 
warned_11 = 1; 
( machine_mode)*( unsigned __int8 *)( v12.rtwint + 2), 
v15 = swap_condition( ( rtx_code)aux[22]); 
( machine_mode)*( ( unsigned __int8 *)v39 + 2), 
( machine_mode)*( ( unsigned __int8 *)v53 + 2), 
emit_cmp_and_jump_insns( v55, v58, ( rtx_code)( v57 == 0 ? EQ : LEU), 0LL, op1a, 0, v56); 
( machine_mode)*( ( unsigned __int8 *)unsignedpa + 2), 
fwrite( &unk_6378FD, 1uLL, 0x11uLL, outf); 
fprintf( file, off_6376D2, ( unsigned int)dest->index); 
fprintf( file, &off_6376D2[1], ( unsigned int)v6); 
fputs( bitnames_8[v6], file); 
fprintf( file, "; pref %s", reg_class_names_9[v10]); 
fprintf( file, "; pref %s, else %s", reg_class_names_9[v10], reg_class_names_9[v11]); 
fprintf( file, "; pref %s, else %s", reg_class_names_9[v10], reg_class_names_9[v11]); 
fprintf( file, "; %s or none", reg_class_names_9[v10]); 
fwrite( &unk_636F04, 1uLL, 9uLL, file); 
fprintf( file, off_6376D2, ( unsigned int)i); 
fprintf( di_0->stream, asc_6F7DF3, 25LL, 6489631LL); 
fprintf( di_0->stream, off_6F7DF4, 15 - v2, 6489631LL); 
v12 = *( tree_node **)( v6 + 72); 
v13 = *( tree_node **)( v6 + 120); 
if ( v13 && v13 != *( tree_node **)( v6 + 72) ) 
v13 = *( tree_node **)( v6 + 120); 
v28 = *( tree_node **)v6; 
v14 = lang_hooks_0.tree_dump.type_quals( ( tree)v6); 
v15 = *( tree_node **)( v6 + 128); 
predictor_info_0[predictor].name, 
fprintf( outf, off_6376D2, ( unsigned int)v5); 
fwrite( ( char *)&to.current + 5, 1uLL, 6uLL, outf); 
fprintf( file, &off_6376D2[1], ( bmap->elms[v6] >> v4++) & 1); 
lang_hooks_0.print_statistics( ); 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), label); 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), lab2); 
v6 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), lab1); 
v7 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v6, v5); 
v9 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4, global_rtl[0]); 
if ( ( sch_istable[( unsigned __int8)v10] & 0x10) != 0 ) 
v15 = byte_6551A0[*( unsigned __int8 *)v3]; 
v14 = byte_6551A0[( unsigned int)j]; 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), label); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4441, "AT_unsigned"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
args_size_0 = 0LL; 
v0 = label_num_59++; 
sprintf( label_58, "*.%s%u", "LCFI", v0); 
assemble_name( asm_out_file, label_58); 
return label_58; 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
&& ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
sprintf( label, "*.%s%u", ( const char *)&a.dw_attr_next + 4, current_funcdef_number); 
fancy_abort( ( const char *)&a, 1626, "dwarf2out_frame_debug"); 
fancy_abort( ( const char *)&a, 1009, "dwarf2out_stack_adjust"); 
v7 = -args_size_0; 
v9 = args_size_0 + v7; 
args_size_0 = v9; 
dwarf2out_args_size( v10, args_size_0); 
fancy_abort( ( const char *)&a, 1309, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1603, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1479, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1528, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1549, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1513, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1555, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1490, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1495, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1538, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1588, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1561, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1457, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1386, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1399, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1404, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1442, "dwarf2out_frame_debug_expr"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
while ( v2 != ( _WORD *)&unk_963802 ); 
while ( v3 != ( _WORD *)&unk_963802 ); 
if ( ( unsigned int)format > 0xFF || ( result = format_names_3[format]) == 0LL ) 
&& ( v8 = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, v3), 
v6 = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, tem[0]); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v4, v5); 
y = gen_reg_rtx( ( machine_mode)( *( unsigned __int8 **)( ( char *)nodes + v62))[2]); 
rtx v42; // rax 
rtx v50; // r12 
rtx v55; // rdx 
rtx v56; // r13 
rtx v59; // rdx 
v3 = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)v37, v36, *( rtx *)&v3[1]); 
( rtx_code)*( _WORD *)v3, 
rtx new_body; // [rsp+10h] [rbp-248h] 
rtx old_set; // [rsp+20h] [rbp-238h] 
rtx orig_operand[30]; // [rsp+40h] [rbp-218h] 
rtx substed_operand[30]; // [rsp+130h] [rbp-128h] 
new_body = ( rtx)insn[2]; 
v4 = asm_noperands( new_body); 
old_set = 0LL; 
old_set = v8; 
old_set = single_set_2( insn, v8); 
if ( !old_set ) 
elimination_effects( new_body, VOIDmode); 
if ( recog_data_0.n_operands <= 0 ) 
v27 = recog_data_0.operand[v11]; 
orig_operand[v11] = v27; 
rtx rtwint; // rax 
elimination_effects( v27, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
rtwint = ( rtx)fld->rtwint; 
elimination_effects( rtwint->fld[v33++].rtx, mem_mode); 
rtwint = ( rtx)fld->rtwint; 
tree v16; // rbx 
tree v23; // rax 
tree v24; // rax 
v16 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v15, v6); 
v16 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v15, v6); 
v19 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v18, v6); 
v19 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v18, v6); 
emit_cmp_and_jump_insns( index, v19, GT, 0LL, ( machine_mode)v7, v6, highd); 
v21 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v20, v6); 
v21 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v20, v6); 
emit_cmp_and_jump_insns( index, v21, LT, 0LL, ( machine_mode)v7, v6, highe); 
v23 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v22, v6); 
v23 = convert_modes( ( machine_mode)v7, ( machine_mode)( unsigned __int8)v8, v22, v6); 
v9 = mode_class_0[pmode]; 
v19 = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
operand = insn_data_0[v13].operand; 
if ( !operand->predicate( v14, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)operand + 8)); 
if ( !operand[2].predicate( op2a, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8), op2a); 
if ( !operand[3].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8), x); 
v17 = insn_data_0[v13].genfun( subtarget, v16); 
( machine_mode)*( ( unsigned __int8 *)v12 + 2), 
v12 = gen_reg_rtx( ( machine_mode)v11); 
rtx v19; // r15 
rtx dst; // [rsp+8h] [rbp-68h] 
rtx dest; // [rsp+18h] [rbp-58h] 
rtx *tmps; // [rsp+28h] [rbp-48h] 
rtx srca; // [rsp+30h] [rbp-40h] 
dst = orig_dst; 
srca = src; 
rtwint = ( int *)srca->fld[0].rtwint; 
tmps = ( rtx *)&v25; 
v9 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v8 + 2)); 
tmps[v7] = v9; 
rtwint = ( int *)srca->fld[0].rtwint; 
if ( !insn_data_0[1159].operand->predicate( loc, ( ( target_flags & 0x2000000) != 0) + 4) ) 
v1 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), loc); 
rtx v4; // rax 
v4 = first; 
v4 = first; 
v4 = first; 
rtx = v4; 
v4 = v4[1].fld[0].rtx; 
v4 = v4[1].fld[0].rtx; 
while ( v4 ); 
rtx v12; // r12 
rtx i; // rbx 
rtx v20; // rbp 
rtx v22; // rbx 
rtx targeta; // [rsp+8h] [rbp-50h] 
targeta = target; 
targeta = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
targeta = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
for ( i = insns; ; i = ( rtx)v17.rtwint ) 
for ( i = insns; ; i = ( rtx)v17.rtwint ) 
v12 = 0LL; 
if ( rtx_class[*( _WORD *)i] == 105 ) 
v12 = ( rtx)i[2]; 
rtx *overflow_arg_area; // rax 
rtx v20; // rdi 
rtx v22; // rax 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v3->fld[0].rtx) 
&& !push_operand( v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v5->fld[0].rtx) 
v6 = insn_data_0[insn_code].genfun( x, y); 
v9 = mode_class_0[*( ( unsigned __int8 *)x + 2)]; 
if ( push_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
genfun = (  struct rtx_def *(  *)( rtx, rtx))insn_data_0[optab_table[30]->handlers[v19].insn_code].genfun; 
v25 = (  struct rtx_def *(  *)( rtx, rtx))insn_data_0[optab_table[30]->handlers[v19].insn_code].genfun; 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v35 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v34); 
v39 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v38); 
v52 = insn_data_0[optab_table[30]->handlers[v51].insn_code].genfun( v48, v49); 
rtx v9; // rbp 
rtx v10; // rbx 
rtx v16; // rbx 
rtx last_insn; // rbp 
rtx v23; // rbp 
v9 = insns; 
v16 = v9; 
v16 = v9; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
reg_note = find_reg_note( v16, REG_LIBCALL, 0LL); 
remove_note( v16, reg_note); 
v18 = find_reg_note( v16, REG_RETVAL, 0LL); 
remove_note( v16, v18); 
if ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) <= 1 ) 
induction_1 *giv; // rbx 
induction_1 *giv; // rbx 
induction_1 *biv; // r12 
induction_1 *biv; // r12 
induction_1 *v14; // rbx 
induction_1 *v14; // rbx 
induction_1 *v42; // r13 
induction_1 *v42; // r13 
induction_1 **p_giv; // rbx 
induction_1 **p_giv; // rbx 
biv = v2->biv; 
if ( biv ) 
v14 = v2->biv; 
if ( *( _WORD *)biv->add_val != 54 ) 
biv->src_reg->fld[0].rtuint, 
biv->insn->fld[0].rtuint); 
print_rtl( loop_dump_stream, biv->add_val); 
if ( ( *( ( _BYTE *)biv + 100) & 0x20) != 0 ) 
v13 += v14->add_val->fld[0].rtint; 
v25 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), args_addr, args_so_far); 
( machine_mode)*( ( unsigned __int8 *)size + 2), 
operand = insn_data_0[v39].operand; 
v37 = insn_data_0[v39].genfun( v30, froma); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
&& mode_class_0[*( ( unsigned __int8 *)xinner + 2)] != MODE_INT ) 
v22 = operand_sub*(short *)0xforce( xinner, v18, mode); 
v45 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), args_addr, args_so_far); 
v14 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( 4 - ( ( v6 == 0) - 1)), global_rtl[2]); 
v18 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v17); 
v14 = gen_rtx_fmt_ee( PRE_MODIFY, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v18); 
predicate = insn_data_0[insn_code].operand->predicate; 
v13 = insn_data_0[insn_code].genfun( x, ( rtx)v7); 
v5 = assign_stack_local( ( machine_mode)v6, mode_size[v6], 0); 
v5 = gen_reg_rtx( ( machine_mode)v6); 
if ( v61 == ( ( target_flags & 0x2000000) == 0 ? 64 : 128) && mode_class_0[mode] == MODE_INT ) 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
operand = insn_data_0[icode].operand; 
if ( !operand->predicate( v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)) || flag_force_mem && *( _WORD *)v8 == 66 ) 
v12 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
v11 = insn_data_0[icode].genfun( v12, v9); 
v10 = insn_data_0[icode].genfun( v8, v9); 
( machine_mode)*( ( unsigned __int8 *)dest_reg + 2), 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), name); 
v6 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), name); 
( machine_mode)*( ( unsigned __int8 *)var + 2), 
exp = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)exp + 2), const_rtx); 
if ( mode_class_0[mode] != MODE_FLOAT ) 
if ( mode_class_0[mode] != MODE_FLOAT ) 
v2 = rndprc; 
wstring[0] = 0; 
strcpy( wstring, " NaN "); 
rndprc = 80; 
strcpy( wstring, " -Infinity "); 
strcpy( wstring, " Infinity "); 
*( _DWORD *)wstring = ( _DWORD)&loc_4E614E; 
*( _DWORD *)wstring = ( _DWORD)&loc_4E614E; 
emul( etens[12], &b, &b); 
v30 = etens[0]; 
for ( i = emtens[0]; ecmp( eone, c) > 0; i += 6 ) 
v19 = etens[8]; 
*v22 &= bmask[v21]; 
while ( v19 != ( const unsigned __int16 *)&unk_6E35BC ); 
for ( j = etens[0]; ecmp( etens[12], &y) <= 0; j += 6 ) 
for ( j = etens[0]; ecmp( etens[12], &y) <= 0; j += 6 ) 
v5 = equot[8]; 
v6 = equot[8]; 
rtx earliest; // [rsp+48h] [rbp-40h] BYREF 
predict_edge_def( v2, PRED_LOOP_BRANCH, TAKEN_0); 
predict_edge_def( k, PRED_NORETURN, NOT_TAKEN_0); 
predict_edge_def( m, PRED_ERROR_RETURN, NOT_TAKEN_0); 
predict_edge_def( m, PRED_CALL, NOT_TAKEN_0); 
condition_0 = get_condition_0( v17, &earliest); 
predict_insn_def( v17, PRED_POINTER, NOT_TAKEN_0); 
predict_insn_def( v17, PRED_POINTER, TAKEN_0); 
predict_insn_def( v17, PRED_UNCONDITIONAL, ( prediction)( const_int_rtx[64] != condition_0)); 
if ( ( mode_class_0[*( unsigned __int8 *)( v31.rtwint + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( unsigned __int8 *)( v31.rtwint + 2)] != MODE_VECTOR_FLOAT 
predict_insn_def( v17, PRED_OPCODE_NONEQUAL, TAKEN_0); 
*( _OWORD *)&v6.r[1] = *( unsigned int *)&einv[4]; 
fancy_abort( ( const char *)&stru_665A39, 1953, "examine_argument"); 
v31 = ( ( unsigned int)( mode_class_0[v29] - 5) < 2) + 1; 
v11 = mode_class_0[mode]; 
( machine_mode)( ( BYTE5( to->common.type->block.abstract_origin) >> 1) & 0x7F), 
( machine_mode)( BYTE5( to->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( from->common.type->block.abstract_origin) >> 1), 
v20 = ( tree_node *)v14[1]; 
v34 = expand_expr( from, 0LL, ( machine_mode)*( ( unsigned __int8 *)v18 + 2), EXPAND_NORMAL); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
v6 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), arguments); 
v24 = adjust_address_1( v11, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v18, 1, 1); 
v9 = adjust_address_1( v1, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 0LL, 1, 1); 
v12 = adjust_address_1( v1, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v10, 1, 1); 
v5 = *( tree_node **)( *high + 32LL); 
v8 = ( tree_node *)high[4]; 
predict_insn_def( v12, PRED_BUILTIN_EXPECT, ( prediction)taken); 
return expand_expr( addr_tree, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
v8 = adjust_address_1( v3, ( machine_mode)v1, v6, 1, 1); 
v5 = force_reg( ( machine_mode)v4, buf_addr); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5); 
v8 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v7); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v6 = expand_expr( elements, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
if ( !insn_data_0[1316].operand->predicate( v6, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
if ( !insn_data_0[1316].operand->predicate( v6, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
v6 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v6); 
v7 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), result); 
v8 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v7); 
return gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v10); 
return gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4); 
v2 = gen_reg_rtx( ( machine_mode)( BYTE5( integer_types[5]->block.abstract_origin) >> 1)); 
v4 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3); 
v5 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v6); 
v8 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), receiver_label); 
v9 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8); 
stack_save = gen_rtx_MEM( ( machine_mode)v2, v11); 
if ( !gave_help_9 ) 
gave_help_9 = 1; 
v6 = gen_rtx_MEM( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), v5); 
tree rttree; // rbx 
tree v46; // rdi 
tree v60; // rcx 
rtx v91; // r14 
v5 = mode_class_0[mode]; 
operand = insn_data_0[v8].operand; 
v13 = insn_data_0[v8].genfun( v10, xop0_0); 
v15 = gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v11.rtx); 
v16 = nonzero_bits( x->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v18 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)x + 2), v17.rtx); 
v32 = nonzero_bits( *( rtx *)( v1->fld[0].rtwint + 8), ( machine_mode)v21); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
rtx v20; // rbp 
rtx v25; // rax 
rtx v27; // rax 
v13 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v6 = promote_mode( type, ( machine_mode)supercontext, unsignedp, 0); 
v27 = decl->decl.rtl; 
if ( !v27 ) 
v27 = decl->decl.rtl; 
regno_decl[*( unsigned int *)( *( _QWORD *)&v27[1] + 8LL)] = decl; 
v20 = assign_temp( decl, 1, 1, 1); 
set_mem_attributes( v20, decl, 1); 
decl->decl.rtl = v20; 
if ( !v20 ) 
v20 = decl->decl.rtl; 
v21 = force_operand( v20->fld[0].rtx, rtx); 
v4 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v0 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 2); 
v7 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
emit_stack_restore( ( save_level)( x_block_stack->next == 0LL), next_label, 0LL); 
rtx v32; // r12 
rtx v35; // rbx 
rtx j; // r12 
rtx *p_table_label; // rbx 
rtx *v42; // r12 
rtx v35; // rax 
rtx v36; // rax 
rtx v38; // rax 
rtx v40; // rax 
rtx v41; // rax 
rtx v42; // rax 
rtx v14; // r13 
v14 = gen_rtx_CONST_INT( VOIDmode, v13); 
v28 = gen_lowpart_for_combine( ( machine_mode)v8, *( rtx *)&x[1]); 
v14 = *( rtx *)( v2.rtwint + 24); 
if ( *( _WORD *)v14 == 54 && v14->fld[0].rtwint + ( int)v16 > mode_bitsize[*( ( unsigned __int8 *)rtx + 2)] ) 
if ( *( _WORD *)v14 == 54 && v14->fld[0].rtwint + ( int)v16 > mode_bitsize[*( ( unsigned __int8 *)rtx + 2)] ) 
rtx = gen_rtx_fmt_e( USE, ( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), *( rtx *)( v2.rtwint + 8)); 
&& can_fix_p( ( machine_mode)v14, v7, 0, must_trunc) != CODE_FOR_nothing ) 
emit_cmp_and_jump_insns( v20, v16, GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v20 + 2), 0, v17); 
( machine_mode)*( ( unsigned __int8 *)v20 + 2), 
v23 = trunc_int_for_mode( 1LL << v15, ( machine_mode)*( ( unsigned __int8 *)v18 + 2)); 
( machine_mode)*( ( unsigned __int8 *)v18 + 2), 
v28 = gen_rtx_fmt_e( UNSIGNED_FIX, ( machine_mode)*( ( unsigned __int8 *)v18 + 2), v27); 
( machine_mode)*( ( unsigned __int8 *)v9 + 2), 
( rtx_code)( unsignedp == 0 ? FIX : UNSIGNED_FIX), 
( machine_mode)*( ( unsigned __int8 *)v9 + 2), 
v12 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v11 + 2)); 
v11 = expand_unop( ( machine_mode)*( ( unsigned __int8 *)v11 + 2), optab_table[17], v11, v12, 0); 
emit_unop_insn( fixed, v3, v11, ( rtx_code)( lab2 == 0 ? FIX : UNSIGNED_FIX)); 
emit_cmp_and_jump_insns( v12, const_int_rtx[64], GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), 0, v9); 
if ( significand_size( ( machine_mode)tempa) + 1 >= mode_bitsize[*( ( unsigned __int8 *)v12 + 2)] ) 
v4 = gen_reg_rtx( ( machine_mode)tempa); 
( machine_mode)*( ( unsigned __int8 *)v10 + 2), 
v30 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)v10 + 2), v23); 
emit_unop_insn( v6, v4, v8, ( rtx_code)( temp == 0 ? FLOAT : UNSIGNED_FLOAT)); 
rtx k; // rbx 
rtx x_nonlocal_goto_handler_slots; // rbp 
rtx v25; // rax 
rtx v28; // rax 
rtx v30; // rbp 
rtx return_rtx; // r12 
rtx v34; // rbp 
for ( k = get_insns( ); k; k = k[1].fld[0].rtx ) 
v37 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v38 = gen_rtx_MEM( ( machine_mode)LOBYTE( subr->decl.result->block.supercontext), v37); 
v24->decl.rtl = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v23 + 2)); 
v30 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v29); 
v31 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v30); 
rtx last_insn; // rbx 
v4 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3); 
last_insn = get_last_insn( ); 
if ( last_insn ) 
while ( *( _WORD *)last_insn != 33 ) 
if ( *( _WORD *)last_insn != 34 ) 
last_insn = ( rtx)last_insn[1]; 
if ( last_insn ) 
last_insn[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], last_insn[3].fld[0].rtx); 
last_insn[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 27, const_int_rtx[64], last_insn[3].fld[0].rtx); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
operand = insn_data_0[insn_code].operand; 
if ( operand->predicate( v8, ( machine_mode)v6) ) 
if ( operand[1].predicate( v8, ( machine_mode)v6) ) 
( machine_mode)v6, 
( tree_code)( ( ( *( ( _BYTE *)&exp->block.common + 16) & 0xFD) == 0x81) + 59), 
v15 = insn_data_0[v14].operand; 
if ( v15->predicate( v8, ( machine_mode)v6) && v15[1].predicate( v8, ( machine_mode)v6) ) 
if ( v15->predicate( v8, ( machine_mode)v6) && v15[1].predicate( v8, ( machine_mode)v6) ) 
if ( !v15[2].predicate( tempa, ( machine_mode)v6) ) 
force_reg( ( machine_mode)v6, tempa); 
v16 = insn_data_0[v14].genfun( v8, v8); 
if ( general_operand( v8->fld[0].rtx, ( machine_mode)v6) ) 
v17 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8->fld[0].rtx); 
v19 = force_reg( ( machine_mode)*( ( unsigned __int8 *)v18 + 2), v18); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( i->int_cst.int_cst.low + 8) + 61LL) >> 1), 
*v20 = expand_expr( v26, 0LL, ( machine_mode)v28, EXPAND_SUM); 
pmode = promote_mode( v27, ( machine_mode)v28, ( int *)&unsignedp, 0); 
v30 = expand_expr( v26, 0LL, ( machine_mode)v28, EXPAND_SUM); 
( machine_mode)( BYTE5( v26->common.type->block.abstract_origin) >> 1), 
v25 = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int8 *)v29 + 2), v25); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)temp + 2), temp->fld[0].rtx) ) 
v96 = gen_rtx_SUBREG( ( machine_mode)v98, target, 0); 
v96 = gen_reg_rtx( ( machine_mode)v98); 
|| ( target = gen_reg_rtx( ( machine_mode)v66), *( _WORD *)target != 65) ) 
v85 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), temp); 
temp = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v85); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v4 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), const_int_rtx[64]); 
if ( mode_class_0[*( ( unsigned __int8 *)op1 + 2)] != MODE_INT ) 
variant = basic_variant; 
variant = basic_variant; 
variant = basic_variant; 
variant = basic_variant; 
variant = negate_variant; 
tree v14; // r12 
tree v15; // rax 
tree v17; // rax 
v12 = type_for_mode( ( machine_mode)v11, unsignedp); 
v14 = make_tree( v10, mult); 
v15 = make_tree( v10, x); 
v16 = build( MULT_EXPR, v10, v15, v14); 
v16 = build( MULT_EXPR, v10, v15, v14); 
v17 = fold( v16); 
v18 = build( PLUS_EXPR, v10, v17, tree); 
wide_op1 = immed_double_const( cnst1, v11, ( machine_mode)v6); 
v15 = convert_to_mode( ( machine_mode)v6, op0, unsignedp); 
v16 = expand_mult( ( machine_mode)v6, v15, wide_op1, 0LL, 0); 
v26 = expand_binop( ( machine_mode)v6, v19, op0, wide_op1, 0LL, unsignedp, OPTAB_WIDEN); 
v28 = expand_shift( RSHIFT_EXPR, ( machine_mode)v6, v13, v27, 0LL, 1); 
return convert_modes( mode, ( machine_mode)v6, v28, unsignedp); 
v13 = gen_rtx_fmt_ee( ( rtx_code)v8, mode, adj_operand, v12); 
v18 = gen_rtx_fmt_ee( ( rtx_code)v8, mode, v14, v17); 
v3 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v2); 
v15 = expand_expr( ( tree)high, v14, ( machine_mode)*( ( unsigned __int8 *)v14 + 2), EXPAND_NORMAL); 
tmpmode = operand_sub*(short *)0xforce( result_val, v30 / v18, BLKmode); 
v4 = ( tree_node *)*( &global_trees + 11); 
v4 = ( tree_node *)*( &global_trees + 11); 
v4 = ( tree_node *)*( &global_trees + 11); 
v4 = ( tree_node *)*( &global_trees + 11); 
v4 = ( tree_node *)global_trees; 
v4 = ( tree_node *)global_trees; 
op1a = mode_class_0[v10]; 
operand = insn_data_0[insn_code].operand; 
t0 = convert_to_mode( ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8), v11, unsignedp); 
v19 = insn_data_0[insn_code].genfun( targ0a, t0); 
classa = mode_class_0[mode]; 
operand = insn_data_0[insn_code].operand; 
operand = insn_data_0[v51].operand; 
v15 = insn_data_0[icode].genfun( v9, xop0); 
v30 = operand_sub*(short *)0xforce( v8, v27, mode); 
rtx v4; // rax 
rtx v5; // rax 
v4 = pc_set( rtx); 
v5 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v4[1] + 8LL), 0, 0LL, v2); 
v5 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v4[1] + 8LL), 0, 0LL, v2); 
if ( v5 ) 
if ( v5->fld[0].rtx == v2 ) 
v6 = (  struct rtx_def *)v5[1]; 
v7 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v5, VOIDmode, *( rtx *)( v3 + 16), v6); 
v7 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v5, VOIDmode, *( rtx *)( v3 + 16), v6); 
predict_insn_def( rtx, PRED_BUILTIN_EXPECT, ( prediction)( const_true_rtx == v8)); 
return expand_expr( size_unit, 0LL, ( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), EXPAND_NORMAL); 
v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)add_val + 2), add_val->fld[0].rtx, v15)) 
: ( v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)add_val + 2), g1->add_val, v6)), 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v11, result); 
( rtx_code)*( _WORD *)ext_dependent, 
( machine_mode)*( ( unsigned __int8 *)ext_dependent + 2), 
( rtx_code)*( _WORD *)ext_dependent, 
( machine_mode)*( ( unsigned __int8 *)ext_dependent + 2), 
rtx v13; // rax 
rtx fixed_bit_field; // r14 
fatal_insn_not_found( insn, "recog.c", 2063, "extract_constrain_insn_cached"); 
v7 = expand_shift( RSHIFT_EXPR, ( machine_mode)v11, v7, v22, v23, 1); 
v24 = mask_rtx( ( machine_mode)*( ( unsigned __int8 *)v7 + 2), 0, bitsize, 0); 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
v25 = force_reg( ( machine_mode)v11, v7); 
recog_data_0.insn = 0LL; 
recog_data_0.n_operands = 0; 
recog_data_0.n_alternatives = 0; 
recog_data_0.n_dups = 0; 
recog_data_0.n_operands = v7; 
fatal_insn_not_found( insn, "recog.c", 2139, "extract_insn"); 
recog_data_0.operand, 
recog_data_0.operand_loc, 
recog_data_0.constraints, 
recog_data_0.operand_mode); 
v8 = recog_data_0.constraints[0]; 
recog_data_0.n_alternatives = 1; 
for ( i = *recog_data_0.constraints[0]; *v8; i = *v8 ) 
recog_data_0.n_alternatives += i == 44; 
fatal_insn_not_found( insn, "recog.c", 2148, "extract_insn"); 
if ( recog_data_0.insn != insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
v15 = operand_sub*(short *)0xforce( op0, v21, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, v21, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
v15 = operand_sub*(short *)0xforce( 
fancy_abort( ( const char *)&a, 8430, "field_byte_offset"); 
imag = ( tree_node *)*( &global_trees + 17); 
rtx v9; // rax 
rtx i; // rdi 
v9 = first; 
if ( *( _WORD *)v9 == 37 ) 
v10 = v9[2].fld[0].rtint; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
while ( v9 ); 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
if ( i->fld[0].rtuint < insn_addresses_->num_elements ) 
v12 = insn_addresses_->data.i[i->fld[0].rtint]; 
if ( mode_class_0[bl_0->biv->mode] == MODE_INT ) 
( machine_mode)*( ( unsigned __int8 *)v5 + 2), 
rtx v37; // rax 
rtx v38; // [rsp+0h] [rbp-40h] BYREF 
if ( ( unsigned int)( debug_info_level_0 - 2) <= 1 
if ( ( unsigned int)( debug_info_level_0 - 2) <= 1 
output_asm_insn( v33, &v38); 
type->type.align = get_mode_alignment( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
rtx base_term; // rbx 
base_term = find_base_term( rtx); 
if ( !base_term ) 
if ( ( unsigned __int16)( *( _WORD *)base_term - 67) <= 1u ) 
return base_term; 
if ( *( _WORD *)base_term == 25 && *( ( _BYTE *)base_term + 2) ) 
if ( *( _WORD *)base_term == 25 && *( ( _BYTE *)base_term + 2) ) 
return base_term; 
rtx v5; // rbp 
rtx base_value; // rax 
rtx v10; // rax 
v5 = ( rtx)src[1]; 
if ( ( *( _DWORD *)v5 & 0x8000FFFF) == -2147483587 ) 
base_value = find_base_value( src->fld[0].rtx); 
if ( base_value ) 
v1 = base_value; 
if ( *( _WORD *)v5 == 61 ) 
v10 = find_base_value( v5); 
v10 = find_base_value( v5); 
if ( v10 ) 
v5 = v10; 
v5 = v10; 
if ( !v5 ) 
rtx v13; // r12 
rtx nonnote_insn; // rax 
timevar_push( TV_CFG_0); 
v13 = f[1].fld[0].rtx; 
v13 = delete_insn( f); 
nonnote_insn = next_nonnote_insn( v23); 
|| *( _WORD *)nonnote_insn != 33 
if ( ( !nonnote_insn 
|| ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) > 1u) 
if ( v13 ) 
v12 = *( _WORD *)v13; 
v11 = safe_hash( v6, ( machine_mode)v8); 
v12 = lookup( v6, v11 & 0x1F, ( machine_mode)v8); 
if ( mode_class_0[v17] == MODE_INT && mode_bitsize[v17] == 1 ) 
if ( code == GE && mode_class_0[v17] == MODE_INT && mode_bitsize[v17] == 1 ) 
rtx v16; // rbx 
rtx v17; // rbp 
( machine_mode)*( ( unsigned __int8 *)rtx + 2), 
( machine_mode)*( ( unsigned __int8 *)v13 + 2)); 
v16 = real_in; 
v17 = v16->fld[0].rtx; 
v17 = v16->fld[0].rtx; 
if ( *( _WORD *)v17 == 61 ) 
v18 = v17->fld[0].rtuint; 
( machine_mode)*( ( unsigned __int8 *)v17 + 2), 
( machine_mode)*( ( unsigned __int8 *)v17 + 2), 
*( _DWORD *)&v16[1], 
rtx v19; // r12 
rtx v26; // rax 
rtx v46; // rsi 
rtx *v50; // rcx 
rtx v63; // rax 
rtx value; // [rsp+28h] [rbp-70h] 
rtx tem; // [rsp+30h] [rbp-68h] 
if ( flag_float_store && mode_class_0[*( ( unsigned __int8 *)goal + 2)] == MODE_FLOAT ) 
if ( ( *( ( _BYTE *)cfun + 425) & 1) != 0 && qty_0[qtyno].n_calls_crossed > 0 ) 
if ( !qty_0[qtyno].n_calls_crossed ) 
if ( ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
if ( &unk_939B74 == ( _UNKNOWN *)++v17 ) 
v19 = &qty_0[qtyno]; 
LODWORD( v3) = recog_data_0.n_operands - 1; 
if ( recog_data_0.n_operands <= 0 ) 
v8 = recog_data_0.constraints[v4]; 
while ( recog_data_0.n_operands > ( int)v4 ); 
induction_1 *v7; // rbp 
induction_1 *v7; // rbp 
( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
v7 = ( induction_1 *)xmalloc( 0xA8uLL); 
v7 = ( induction_1 *)xmalloc( 0xA8uLL); 
v7, 
v7->mem = x; 
if ( ( unsigned int)( mode_class_0[v6] - 5) <= 1 ) 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
v18 = mode_class_0[mode] - 5; 
result = gen_rtx_fmt_i0( REG, ( machine_mode)v6, oldest_regno); 
&& *( tree_node **)( *( _QWORD *)( v9.rtwint + 8) + 128LL) == section_name ) 
v5 = reg_alternate_class( allocno_0[( __int64)num].reg); 
v5 = reg_preferred_class( allocno_0[( __int64)num].reg); 
v6 = ( char *)allocno_0 + v84; 
v92 = *( ( _BYTE *)cfun->emit->x_regno_reg_rtx[*( int *)( ( char *)&allocno_0->reg + v84)] + 2); 
if ( _bittest64( ( const __int64 *)&v8, v80) || !ix86_hard_regno_mode_ok( v80, ( machine_mode)v92) ) 
if ( ( unsigned int)( mode_class_0[v92] - 5) > 1 ) 
v14 = ( char *)allocno_0 + v84; 
v15 = *( HARD_REG_ELT_TYPE *)( ( _BYTE *)&allocno_0->hard_reg_copy_preferences + v84) & ~v8; 
*( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->hard_reg_copy_preferences + v84) = v15; 
v38 = *( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->hard_reg_preferences + v84); 
v11 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)datum + 2)] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v12 + 2)] - 5) < 2) + 1; 
v8 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v9 + 2)] - 5) < 2) + 1; 
rtx v28; // rax 
rtx v29; // r12 
rtx v36; // rbx 
rtx v39; // rax 
rtx v40; // r12 
rtx v42; // rax 
rtx v47; // rbx 
rtx memloc; // rbx 
rtx equiva; // [rsp+10h] [rbp-68h] 
rtx op0; // [rsp+18h] [rbp-60h] 
rtx op1; // [rsp+20h] [rbp-58h] 
tem[0] = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)v7 + 2), *( rtx *)&v7[1]); 
v7 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v7 + 2), v7->fld[0].rtx, tem[0]); 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
if ( x != recog_data_0.operand[opnum] ) 
if ( replace_reloads && recog_data_0.operand[opnum] != arg0 ) 
( machine_mode)*( ( unsigned __int8 *)memloc + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v20); 
&& ( !strict_memory_address_p( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v24->fld[0].rtx) 
( machine_mode)*( unsigned __int8 *)( arg0->fld[0].rtwint + 2)); 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v22); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v12, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), replacement, v11); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v12, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), replacement, v11); 
( machine_mode)*( unsigned __int8 *)( ( *loc)->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)*loc + 2)); 
return gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*loc + 2), v5 + v6); 
( machine_mode)v7, 
rtx *v29; // r12 
rtx *v30; // rax 
rtx *v31; // rax 
rtx *v61; // rax 
rtx *v71; // rax 
rtx *v76; // rax 
rtx *single_use; // rax 
rtx v85; // rax 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v11.rtx) ) 
&& memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), *( rtx *)( v24 + 16)) ) 
v7 = ix86_register_move_cost( m1, ( reg_class)v3, dest_class); 
v4 = ix86_register_move_cost( m1, ( reg_class)v3, dest_class); 
v40 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), j); 
v43 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 0); 
elements = ( tree_node *)*( &global_trees + 11); 
v5 = ( tree_node *)*( &global_trees + 11); 
v0 = initializer_stack_0; 
for ( i = constructor_stack_0; constructor_stack_0; i = constructor_stack_0 ) 
for ( i = constructor_stack_0; constructor_stack_0; i = constructor_stack_0 ) 
for ( i = constructor_stack_0; constructor_stack_0; i = constructor_stack_0 ) 
constructor_stack_0 = i->next; 
if ( constructor_range_stack_0 ) 
constructor_stack_0 = v0->constructor_stack; 
constructor_range_stack_0 = v0->constructor_range_stack; 
spelling_0 = v0->spelling; 
initializer_stack_0 = v0->next; 
v44 = ( tree_node *)*j; 
v44 = ( tree_node *)j; 
fancy_abort( ( const char *)&to, 400, "first_insn_after_basic_block_note"); 
v12 = memory_address( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), fixed); 
v13 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v12); 
error( "can't use '%s' as a %s register", name, what_option_2[fixed][call_used]); 
&& !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)x + 2), v6.rtx) ) 
rtx v53; // rbx 
rtx v67; // rbx 
rtx v76; // rax 
rtx v79; // rax 
rtx v83; // rax 
rtx v84; // rax 
rtx v87; // rax 
fprintf( file, asc_6376CF, ( unsigned int)loop->num_nodes); 
add_dependence_list_and_free( insn, &deps->pending_write_insns, ( reg_note)v5); 
add_dependence_list_and_free( insn, &deps->last_pending_memory_flush, ( reg_note)v5); 
lhs_type = ( tree_node *)*( &global_trees + 27); 
rhs_type = ( tree_node *)*( &global_trees + 27); 
rtx v57; // rax 
rtx v58; // rbx 
rtx const_rtx; // rax 
rtx v123; // rdx 
rtx v134; // rbx 
rtx v161; // r15 
rtx scan_start; // rax 
rtx exit_labels; // rax 
rtx v14; // rax 
rtx v15; // r12 
v14 = fncall( loop, insn_in_loop, v7, v4); 
v15 = v14; 
v15 = v14; 
if ( *( _WORD *)v14 == 36 ) 
rtx = v14[1].fld[0].rtx; 
scan_start = loop->scan_start; 
if ( rtx != scan_start ) 
if ( rtx == scan_start || !rtx ) 
if ( v11 && v11 != loop->scan_start && !loop_insn_first_p( v15, v11) ) 
scan_start = loop->scan_start; 
sprintf( label, "*.%s%u", ( const char *)&a.dw_attr_val, v13); 
v18 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v17); 
rtx v15; // r13 
edge succ; // rax 
edge v21; // rdx 
succ = entry_exit_blocks[0].succ; 
v21 = succ; 
v21 = succ; 
succ = succ->succ_next; 
succ = succ->succ_next; 
if ( !succ ) 
if ( e == succ ) 
p_succ_next = &v21->succ_next; 
v15 = block_label( target); 
v17 = gen_jump( v15); 
*( _QWORD *)&src->end[4] = v15; 
++*( _DWORD *)&v15[2]; 
v3 = gen_reg_rtx( ( machine_mode)v2); 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2)); 
v19 = negate_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2), *( rtx *)&value[1]); 
v17 = expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v5, v23, v19, subtarget, 0, OPTAB_LIB_WIDEN); 
return expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v5, v17, v18, target, 0, OPTAB_LIB_WIDEN); 
return expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v5, v24, v25, target, 0, OPTAB_LIB_WIDEN); 
return expand_mult( ( machine_mode)*( ( unsigned __int8 *)value + 2), v15, v16, target, 1); 
v10 = force_reg( ( machine_mode)*( unsigned __int8 *)( value->fld[0].rtwint + 2), v9); 
return simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)value + 2), v10, ( machine_mode)v7, v8); 
return simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)value + 2), v10, ( machine_mode)v7, v8); 
rtx v25; // rax 
rtx v82; // rax 
if ( mode_class_0[mode] != mode_class_0[*( ( unsigned __int8 *)x + 2)] 
if ( mode_class_0[mode] != mode_class_0[*( ( unsigned __int8 *)x + 2)] 
|| ( v10 = mode, !have_insn_for( ( rtx_code)v8, mode)) ) 
v95 = gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), v94); 
v97 = gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), v96); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v3, y, x); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v3, y, x); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v3, y, x); 
v10 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v3, y, x); 
v9 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v19 = ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v21 + 2)] - 5) <= 1; 
free( uid_cuid_1); 
v17 = immediate_operand( recog_data_0.operand[1], VOIDmode); 
if ( immediate_operand( recog_data_0.operand[1], VOIDmode) || ( unsigned int)attr_memory <= MEMORY_STORE ) 
|| ( v27 = general_operand( recog_data_0.operand[0], QImode), v28 = 1024, !v27) ) 
rtx v85; // rbx 
rtx v110; // r12 
rtx v119; // rsi 
rtx v153; // r12 
if ( mode_class_0[i] == MODE_CC ) 
v4 = gen_rtx_REG( ( machine_mode)i, 58); 
if ( *( ( _DWORD *)uid_cuid_1 + *( ( int *)v54 + 2)) < *( ( _DWORD *)uid_cuid_1 + rtint) ) 
operand = insn_data_0[insn_code].operand; 
if ( !operand->predicate( x, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
|| !operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
|| !operand[2].predicate( y, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[insn_code].genfun( x, x); 
operand = insn_data_0[insn_code].operand; 
if ( !operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
if ( !operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) ) 
if ( operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[insn_code].genfun( r0, r1); 
v6 = expand_mult_add( b, reg, m, a, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
v17 = ( tree_node *)rtl[7]; 
if ( !compiled_from_record_1++ ) 
rtx v6; // r12 
rtx result; // rax 
v6 = op1; 
rtx = v6; 
v6 = v10; 
result = simplify_binary_operation( code, mode, rtx, v6); 
result = simplify_binary_operation( code, mode, rtx, v6); 
if ( !result ) 
if ( swap_commutative_operands_p( rtx, v6) ) 
return gen_rtx_fmt_ee( code, mode, v6, rtx); 
result = simplify_binary_operation( code, mode, op0, op1); 
if ( result ) 
return result; 
v6 = ( rtx)op0[1]; 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
if ( !call_insn_operand( operand0->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
if ( !call_insn_operand( operand0->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
if ( !call_insn_operand( operand1->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
if ( !call_insn_operand( operand1->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v8 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operand1->fld[0].rtx); 
v9 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operand2->fld[0].rtx); 
v9 = insn_data_0[optab_table[41]->handlers[v7].insn_code].genfun( op1, op2); 
v2 = ix86_expand_compare( ( rtx_code)*( _WORD *)operand0, 0LL, 0LL); 
v2 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[5], operand0); 
v4 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 10025, "gen_formal_parameter_die"); 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
v9 = ( tree_node *)i[4]; 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
v4 = force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
v15 = mode_class_0[mode]; 
v15 = mode_class_0[mode]; 
return gen_rtx_fmt_e( ( rtx_code)v17, mode, x->fld[0].rtx); 
return simplify_gen_subreg( mode, x, ( machine_mode)v3, 0); 
if ( mode_class_0[v3] == MODE_FLOAT ) 
*( _OWORD *)&r_0.r[1] = __PAIR128__( u.d.r[2], v22.rtwint); 
rtx result; // rax 
result = x; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)v3, const_int_rtx[64]); 
result = x->fld[0].rtx; 
if ( *( _WORD *)result == 66 ) 
if ( *( ( unsigned __int8 *)result + 2) == mode ) 
return result; 
result = gen_lowpart_common( mode, rtx); 
if ( result ) 
return result; 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), const_int_rtx[64]); 
return gen_rtx_fmt_ee( ( rtx_code)v7, mode, rtx->fld[0].rtx, *( rtx *)&rtx[1]); 
v9 = subreg_lowpart_offset( mode, ( machine_mode)v8); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v9); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v9); 
if ( !result ) 
v3 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
v4 = gen_rtx_fmt_eit( ADDRESSOF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3, rtint, decl); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
fixup_var_refs( reg, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0, reg, 0LL); 
if ( optab_table[30]->handlers[v2].insn_code == CODE_FOR_nothing && mode_class_0[v2] == MODE_CC ) 
return insn_data_0[optab_table[30]->handlers[v6].insn_code].genfun( v8, v9); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v10, v4); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v10, v4); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v4, v10); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v4, v10); 
v3 = gen_rtx_REG( ( machine_mode)( ( *( ( _BYTE *)*operands + 2) == 5) + 4), v2); 
v3 = gen_rtx_REG( ( machine_mode)( ( *( ( _BYTE *)*operands + 2) == 5) + 4), v2); 
v1 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2]); 
v2 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v1); 
if ( generating_concat_p && ( v2 = mode_class_0[mode], ( unsigned int)( v2 - 5) <= 1) ) 
rtx last_insn; // r12 
rtx v15; // rax 
rtx v19; // r15 
rtx v22; // rax 
rtx v26; // rax 
rtx v28; // rbp 
rtx secondary_mem; // r13 
last_insn = get_last_insn( ); 
v13 = gen_lowpart_common( ( machine_mode)v9, out); 
if ( last_insn ) 
if ( !MEMORY[0x10096D8DF] ) 
rtx v5; // rdi 
rtx v6; // rax 
v5 = gen_rtx_fmt_E( SEQUENCE, VOIDmode, v4); 
v6 = cfun->emit->x_first_insn; 
if ( v6 ) 
*( _QWORD *)( v5->fld[0].rtwint + 8LL * v7 + 8) = v6; 
*( _QWORD *)( v5->fld[0].rtwint + 8LL * v7 + 8) = v6; 
v6 = v6[1].fld[0].rtx; 
v6 = v6[1].fld[0].rtx; 
while ( v6 ); 
return v5; 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
v1 = trunc_int_for_mode( 1 << operands[2]->fld[0].rtwint, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v3 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1], v2); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
v1 = trunc_int_for_mode( 1 << operands[2]->fld[0].rtwint, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v2 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v1); 
v2 = reverse_condition( ( rtx_code)*( _WORD *)v1); 
v2 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v1); 
v2 = reverse_condition( ( rtx_code)*( _WORD *)v1); 
v2 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v1); 
v2 = reverse_condition( ( rtx_code)*( _WORD *)v1); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], 0LL); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], operands[5]); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)*( _WORD *)operands[3], 
( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2), operands[2]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
( rtx_code)*( _WORD *)operands[3], 
( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2)); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v4, const_int_rtx[64]); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v4, const_int_rtx[64]); 
v13 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v12, v11); 
v13 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v12, v11); 
v3 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v9 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v8, v6); 
v9 = gen_rtx( ( rtx_code)*( _WORD *)v2, ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v8, v6); 
*( _WORD *)operands[1] = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
if ( const0_operand( operands[2], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)) ) 
v8 = gen_rtx( ( rtx_code)*( _WORD *)v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v7, v4); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v7, v4); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)v4, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v2, v3); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)v4, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v2, v3); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[2]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
v2 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1], operands[2]); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v2, v1); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[2]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
v2 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1], operands[2]); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v2, v1); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[4]); 
v3 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1], operands[2]); 
v4 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3, v2); 
v5 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4, v1); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
operands[3] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[3]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[4]); 
operands[1] = gen_lowpart( ( machine_mode)v3, operands[1]); 
operands[2] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[2]); 
v4 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1], operands[2]); 
operands[1] = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[1]); 
v1 = gen_lowpart( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), operands[2]); 
v12 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v12 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
operand = insn_data_0[insn_code].operand; 
if ( !operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
if ( !operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) ) 
if ( operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
return insn_data_0[insn_code].genfun( r0, r1); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 10204, "gen_subprogram_die"); 
fancy_abort( ( const char *)&a, 10210, "gen_subprogram_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 4441, "AT_unsigned"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4387, "AT_flag"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4441, "AT_unsigned"); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v14 = concat( ret_val, &off_631D1E, 0LL); 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // r15 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // r15 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
p_int_cst = &size_unit->int_cst.int_cst; 
low = p_int_cst->low; 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
while ( ( $A887AD9C3C6C8CC7716950D571F57C9D *)v86 != p_int_cst ); 
fancy_abort( ( const char *)&a, 10121, "gen_type_die_for_member"); 
fancy_abort( ( const char *)&a, 9553, "pop_decl_scope"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4387, "AT_flag"); 
if ( *( ( _BYTE *)op + 2) || v3 == VOIDmode || ( result = 0, ( mode_class_0[v3] & 0xFFFFFFFD) == 1) ) 
if ( mode_class_0[v12] == MODE_FLOAT ) 
v17 = legitimate_address_p( ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v16, 0); 
if ( !explained_1 ) 
explained_1 = 1; 
v1 = lang_hooks_0.get_alias_set( i); 
v1 = lang_hooks_0.get_alias_set( placeholder->decl.section_name); 
result = ( alias_set_entry_0)splay_tree_lookup( alias_sets, alias_set); 
return ( alias_set_entry_0)result->children; 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
rtx v9; // rdi 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
v9 = ( rtx)rtx[1]; 
if ( !v9 ) 
v10 = *( _DWORD *)v9; 
if ( attr_kind == *( _DWORD *)v9 ) 
die_attr = ( dw_attr_ref)v9; 
if ( v9[1] != 10 ) 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
die_attr = ( dw_attr_ref)v9[1].fld[0].rtwint; 
fatal_insn_not_found( insn, "insn-attrtab.c", 12189, "get_attr_athlon_decode"); 
result = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
result = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 13438, "get_attr_i387"); 
v15 = mult_operator( recog_data_0.operand[3], SFmode); 
v13 = mult_operator( recog_data_0.operand[3], SFmode); 
v11 = mult_operator( recog_data_0.operand[3], DFmode); 
v9 = mult_operator( recog_data_0.operand[3], DFmode); 
v7 = mult_operator( recog_data_0.operand[3], XFmode); 
v5 = mult_operator( recog_data_0.operand[3], TFmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 13072, "get_attr_imm_disp"); 
v47 = memory_displacement_operand( recog_data_0.operand[0], VOIDmode); 
return immediate_operand( recog_data_0.operand[1], VOIDmode) != 0; 
if ( !flag_pic || ( v45 = symbolic_operand( recog_data_0.operand[1], SImode), result = IMM_DISP_FALSE, !v45) ) 
v46 = memory_displacement_operand( recog_data_0.operand[0], VOIDmode); 
return immediate_operand( recog_data_0.operand[1], VOIDmode) != 0; 
v44 = memory_displacement_operand( recog_data_0.operand[0], VOIDmode); 
return immediate_operand( recog_data_0.operand[1], VOIDmode) != 0; 
v40 = memory_displacement_operand( recog_data_0.operand[0], VOIDmode); 
return immediate_operand( recog_data_0.operand[1], VOIDmode) != 0; 
v36 = q_regs_operand( recog_data_0.operand[0], QImode); 
v38 = memory_displacement_operand( recog_data_0.operand[0], VOIDmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 13642, "get_attr_length_address"); 
v4 = constant_call_address_operand( recog_data_0.operand[1], VOIDmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 14632, "get_attr_length_immediate"); 
v3 = symbolic_operand( recog_data_0.operand[1], SImode); 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
v3 = symbolic_operand( recog_data_0.operand[1], DImode); 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
else if ( flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], SImode) ) 
v3 = incdec_operand( recog_data_0.operand[2], HImode); 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
v3 = incdec_operand( recog_data_0.operand[2], QImode); 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 15861, "get_attr_memory"); 
v123 = memory_operand( recog_data_0.operand[0], VOIDmode); 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return 2 - ( ( memory_operand( recog_data_0.operand[1], VOIDmode) == 0) - 1); 
return memory_operand( recog_data_0.operand[0], VOIDmode) == 0 ? 1 : 3; 
v122 = memory_operand( recog_data_0.operand[1], VOIDmode); 
return 2 * ( memory_operand( recog_data_0.operand[0], VOIDmode) != 0); 
|| ( v121 = symbolic_operand( recog_data_0.operand[1], SImode), result = MEMORY_NONE, !v121) ) 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) 
|| ( v118 = memory_operand( recog_data_0.operand[1], VOIDmode), result = MEMORY_BOTH, !v118) ) 
v119 = memory_operand( recog_data_0.operand[0], VOIDmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 17669, "get_attr_mode"); 
v13 = aligned_operand( recog_data_0.operand[1], HImode); 
if ( aligned_operand( recog_data_0.operand[1], HImode) || ( v16 = x86_movx, !_bittest( &v16, ix86_cpu)) ) 
v4 = q_regs_operand( recog_data_0.operand[0], QImode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 16766, "get_attr_modrm"); 
return memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
return memory_operand( recog_data_0.operand[0], VOIDmode) != 0; 
if ( ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) 
&& register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
&& ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode)) ) 
if ( register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
if ( register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
if ( get_attr_type( insn) == TYPE_IMOV && register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
if ( get_attr_type( insn) == TYPE_IMOV && register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
if ( register_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 19810, "get_attr_pent_prefix"); 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
v4 = q_regs_operand( recog_data_0.operand[0], QImode); 
rtx v12; // rdx 
rtx v14; // rdx 
rtx v16; // rdx 
fatal_insn_not_found( insn, "insn-attrtab.c", 20323, "get_attr_prefix_0f"); 
v7 = aligned_operand( recog_data_0.operand[1], HImode); 
v5 = q_regs_operand( recog_data_0.operand[0], QImode); 
rtx = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
rtx = recog_data_0.operand[0]->fld[0].rtx; 
v12 = recog_data_0.operand[0]; 
v12 = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
v12 = recog_data_0.operand[0]->fld[0].rtx; 
v12 = recog_data_0.operand[0]->fld[0].rtx; 
fatal_insn_not_found( insn, "insn-attrtab.c", 20460, "get_attr_prefix_data16"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 20358, "get_attr_prefix_rep"); 
rtx v48; // rdx 
fatal_insn_not_found( insn, "insn-attrtab.c", 21978, "get_attr_type"); 
return symbolic_operand( recog_data_0.operand[1], SImode) == 0 ? 7 : 9; 
v14 = aligned_operand( recog_data_0.operand[1], HImode); 
v15 = register_operand( recog_data_0.operand[0], QImode); 
v16 = q_regs_operand( recog_data_0.operand[0], QImode); 
v17 = register_operand( recog_data_0.operand[0], QImode); 
v18 = q_regs_operand( recog_data_0.operand[0], QImode); 
v19 = register_operand( recog_data_0.operand[0], QImode); 
v20 = q_regs_operand( recog_data_0.operand[0], QImode); 
v21 = q_regs_operand( recog_data_0.operand[0], QImode); 
return symbolic_operand( recog_data_0.operand[1], DImode) == 0 ? 7 : 9; 
v6 = pic_symbolic_operand( recog_data_0.operand[2], DImode); 
return incdec_operand( recog_data_0.operand[2], DImode) == 0 ? 4 : 10; 
v6 = reverse_condition( ( rtx_code)*( _WORD *)result); 
v7 = swap_condition( ( rtx_code)*v3); 
result = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
if ( !value_2 ) 
value_2 = v14; 
v11 = value_2; 
v12 = value_2 / 0x3EuLL; 
*v10 = letters_1[value_2 % 0x3EuLL]; 
*v10 = letters_1[value_2 % 0x3EuLL]; 
v10[1] = letters_1[v12 
v10[2] = letters_1[( ( unsigned __int64)( ( 0x8421084210842109LL * ( unsigned __int128)( v11 / 0x7C)) >> 64) >> 4) 
v10[3] = letters_1[( ( unsigned __int64)( ( 0x8421084210842109LL 
v10[4] = letters_1[( ( unsigned __int64)( ( 0x8421084210842109LL 
*( _WORD *)( v10 + 5) = ( unsigned __int8)letters_1[( ( unsigned __int64)( ( 0x8421084210842109LL 
if ( set_2 == -1 ) 
set_2 = new_alias_set( ); 
return set_2; 
hard_reg_initial_vals->entries = ( initial_value_pair_0 *)xmalloc( 0x50uLL); 
hard_reg_initial_vals->entries = ( initial_value_pair_0 *)xrealloc( hard_reg_initial_vals->entries, 16LL * v7); 
*( _QWORD *)( v5 + 8) = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
v8 = ( tree_node *)*( &global_trees + 15); 
v9 = ( tree_node *)*( &global_trees + 17); 
return insn_data_0[code].name; 
output = ( __int64 (  *)( _QWORD))insn_data_0[code].output; 
output_format = insn_data_0[code].output_format; 
return ( const char *)output( &recog_data_0); 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), last_value); 
v12 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v5 + 2)] - 5) < 2) + 1; 
*loc = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), const_int_rtx[64]); 
if ( ( unsigned int)( mode_class_0[mode] - 5) <= 1 ) 
v11 = *( tree_node **)( elements->int_cst.int_cst.high + 40); 
v7 = mode_class_0[mode]; 
v8 = mode_class_0[v4] & 0xFFFFFFFD; 
find_reloads_address( v4, 0LL, v9->fld[0].rtx, ( rtx *)v9->fld, opnum, ( reload_type)v11, 0, 0LL); 
v7 = *( tree_node **)( high + 32); 
v8 = *( tree_node **)( high + 24); 
( machine_mode)*( unsigned __int8 *)( v4.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)v2 + 2))] 
v15 = *( tree_node **)( high + 40); 
if ( set_3 == -1 ) 
set_3 = new_alias_set( ); 
return set_3; 
v0 = pwd_1; 
if ( !pwd_1 ) 
v3 = failure_errno_0; 
*v2 = failure_errno_0; 
v4 = getenv( off_660C72); 
failure_errno_0 = v6; 
pwd_1 = v0; 
v7 = ( page_entry_0 *)( &G + 2640); 
group = ( page_group_0 *)&v9[v8 - v14]; 
group = ( page_group_0 *)( ( char *)group + v11); 
v16 = ( page_group_0 *)&v9[v8 - v14]; 
group = ( page_group_0 *)( page - 32); 
if ( length == 1 && ( sch_istable[*( unsigned __int8 *)contents] & 4) != 0 ) 
timevar_push( TV_GC_0); 
timevar_pop( TV_GC_0); 
rtl_op = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)v22 + 16)); 
v1 = ( page_entry_0 **)( &G + 16); 
fprintf( stream, "\n%-17s%10s %16s %10s\n", ( const char *)&off_660CF0, "Number", "Bytes", "% Total"); 
from = eliminables_2[i].from; 
allocno_0 = v28; 
v38 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v31->emit->x_regno_reg_rtx[v43] + 2)] - 5) < 2) + 1; 
v110 = allocno_0; 
v111 = &allocno_0[( __int64)v98]; 
v125 = allocno_0; 
v117 = allocno_0; 
v118 = &allocno_0[v115]; 
v148 = &allocno_0[v146]; 
v143 = allocno_0; 
v7 = ( tree_node *)( ( unsigned __int64)width | ( unsigned __int64)declarator); 
v7 = grokdeclarator( declarator, declspecs, ( decl_context)v9, 0); 
reg_set_0 *v3; // rax 
reg_set_0 *v3; // rax 
v3 = reg_set_table[regno]; 
if ( v3 ) 
v8 = uid_cuid_1; 
rtint = v3->insn->fld[0].rtint; 
v3 = v3->next; 
v3 = v3->next; 
while ( v3 ); 
v10 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v4.rtwint + 2)] - 5) < 2) + 1; 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rbp 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rbp 
rtl_op = first_rtl_op( ( tree_code)v3); 
p_int_cst = &exp->int_cst.int_cst; 
low = p_int_cst->low; 
if ( p_int_cst->low ) 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v7 ) 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v7 ) 
v7 += hash_rtx( ( rtx)v12, ( machine_mode)*( unsigned __int8 *)( v12 + 2), 0); 
v8 = cselib_lookup( x, ( machine_mode)v6, create); 
fancy_abort( ( const char *)&insn, 688, "hash_rtx"); 
operand = insn_data_0[insn_code].operand; 
result = operand->predicate( x, ( machine_mode)*( ( unsigned __int16 *)operand + 8)); 
result = operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)); 
v2 = ( unsigned __int64 *)primes_0; 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)( 5 - ( ( target_flags & 0x2000000) == 0)), v7, result); 
rtx end; // rdi 
rtx nonnote_insn; // rax 
rtx cond_earliest; // rbx 
rtx v25; // rax 
rtx alt_condition; // rax 
rtx v35; // rax 
rtx i; // rbx 
rtx v38; // rax 
rtx v40; // rsi 
rtx last_value; // rax 
rtx cond1; // [rsp+18h] [rbp-70h] 
rtx false1; // [rsp+30h] [rbp-58h] BYREF 
rtx false0; // [rsp+38h] [rbp-50h] BYREF 
rtx true1; // [rsp+40h] [rbp-48h] BYREF 
rtx true0[8]; // [rsp+48h] [rbp-40h] BYREF 
rtx = if_then_else_cond( x->fld[0].rtx, true0, &false0); 
rtx = if_then_else_cond( x->fld[0].rtx, true0, &false0); 
( rtx_code)( unsigned __int16)v5, 
if ( ( mode_class_0[mode] & 0xFFFFFFFD) != 1 ) 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
return immed_real_const_1( ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), v2); 
rtx[1] = ( rtx_def)_mm_loadu_si128( ( const __m128i *)&u); 
if ( *( ( _BYTE *)op + 2) || mode == VOIDmode || ( result = 0, ( mode_class_0[mode] & 0xFFFFFFFD) == 1) ) 
rtx *v24; // rbp 
rtx *v29; // rsi 
rtx v32; // rdx 
rtx src; // [rsp+8h] [rbp-40h] 
v4 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), i); 
v6[7] = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2]); 
v7[16] = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[5]); 
v8[20] = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[3]); 
v9[6] = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[4]); 
&& ix86_hard_regno_mode_ok( i, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
profiler_label = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8); 
profiler_label = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8); 
ggc_add_rtx_root( &profiler_label, 1); 
while ( v1 != ( const  struct builtin *)&unk_64D290 ); 
v29 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5); 
address = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v29, v10); 
*( __m128i *)&cum->words = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
*( __m128i *)&cum->words = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
*( __m128i *)&cum->words = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
v11 = mode_class_0[5]; 
v11 = mode_class_0[4]; 
global_rtl[2] = gen_raw_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 7); 
v22 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)v34, v31); 
v23 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)v34, v31); 
v24 = gen_rtx_fmt_ee( MULT, ( machine_mode)v34, v23, v22); 
v26 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)v34, v31); 
v27 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)v34, v31); 
v28 = gen_rtx_fmt_ee( MULT, ( machine_mode)v34, v27, v26); 
v29 = gen_rtx_fmt_ee( LSHIFTRT, ( machine_mode)v34, v28, v25); 
if ( ix86_hard_regno_mode_ok( v5, ( machine_mode)i) ) 
v6 = gen_rtx_REG( ( machine_mode)i, v5); 
if ( initialized_12 ) 
initialized_12 = 1; 
optab_0 optablea; // [rsp+8h] [rbp-38h] 
optab_0 optablea; // [rsp+8h] [rbp-38h] 
optablea = optable; 
*v13++ = sch_tolower[i]; 
v18 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v17); 
optablea->handlers[v9++].libfunc = v18; 
rtx v18; // rsi 
rtx v19; // rax 
v18 = ( rtx)i[2]; 
if ( *( _WORD *)v18 == 47 || ( v18 = single_set_2( i, v18)) != 0LL ) 
if ( *( _WORD *)v18 == 47 || ( v18 = single_set_2( i, v18)) != 0LL ) 
if ( *( _WORD *)v18 == 47 || ( v18 = single_set_2( i, v18)) != 0LL ) 
rtx = v18->fld[0].rtx; 
v19 = canon_rtx( rtx); 
if ( ( *( ( _BYTE *)v19 + 3) & 4) == 0 ) 
v20.rtwint = ( __int64)v19->fld[0]; 
add_to_mem_set_list( v10, v19); 
reg_class ( *v16)[25]; // rdx 
reg_class ( *v19)[25]; // rbx 
reg_class ( *v57)[25]; // rdx 
reg_class ( *v60)[25]; // rdx 
reg_class ( *v67)[25]; // r14 
reg_class ( *v84)[25]; // [rsp+30h] [rbp-98h] 
v1 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 58); 
v2 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v1, v0); 
v3 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v2); 
v3 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3); 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), off_6E782A); 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), off_6E782A); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v5); 
v7 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4); 
v8 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 6); 
v9 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8, v7); 
ident_hash->alloc_node = alloc_node_0; 
v2 = rtx_alloc( ( rtx_code)*( _WORD *)notes); 
fancy_abort( ( const char *)&a, 900, "initial_return_save"); 
fancy_abort( ( const char *)&a, 906, "initial_return_save"); 
fancy_abort( ( const char *)&a, 911, "initial_return_save"); 
fancy_abort( ( const char *)&a, 894, "initial_return_save"); 
fancy_abort( ( const char *)&a, 926, "initial_return_save"); 
fancy_abort( ( const char *)&a, 921, "initial_return_save"); 
v3 = lang_hooks_0.expand_constant( value); 
v27 = mode_class_0[( *( _BYTE *)( *( _QWORD *)( v26 + 8) + 61LL) >> 1) & 0x7F] & 0xFFFFFFFD; 
v30 = mode_class_0[( *( _BYTE *)( *( _QWORD *)( v29 + 8) + 61LL) >> 1) & 0x7F] & 0xFFFFFFFD; 
if ( ( tree_node *)*( &global_trees + 14) != v7 ) 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
&& ( lang_hooks_0.tree_inlining.disregard_inline_limits( fn) || 10 * fnp->decl.u1.i <= compiler_params->value / 2) ) 
if ( lang_hooks_0.tree_inlining.disregard_inline_limits( v16) ) 
v5 = lang_hooks_0.tree_inlining.disregard_inline_limits( v4); 
v2 = lang_hooks_0.tree_inlining.cannot_inline_tree_fn( &fnp); 
p_int_cst = &inlined_fns->int_cst.int_cst; 
while ( p_int_cst->low != fns->data.l[0] ) 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
v30 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v41->const_rtx = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)x + 2), first_same_value->exp); 
i = ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v11 + 2)] - 5) <= 1; 
v27 = *( ( _DWORD *)uid_cuid_0 + v26[1]); 
if ( v27 <= cse_basic_block_end && *( ( _DWORD *)uid_cuid_0 + *v26) >= cse_basic_block_start 
|| v27 <= *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[first_reg] + 4)) ) 
v16 = ( ( unsigned int)( mode_class_0[v18] - 5) < 2) + 1; 
v20 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)v17 + 2), v7); 
rtint = MEMORY[8]; 
if ( MEMORY[8] > max_uid_cuid ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 29, "insn_current_length"); 
if ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v10.rtwint + 2)] - 5) <= 1 ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 356, "insn_default_length"); 
v7 = register_operand( recog_data_0.operand[0], DImode); 
v6 = register_operand( recog_data_0.operand[0], SImode); 
v5 = register_operand( recog_data_0.operand[0], VOIDmode); 
memset( &recog_data_0, 0, 0xF0uLL); 
memset( recog_data_0.operand_loc, 0, sizeof( recog_data_0.operand_loc)); 
memset( recog_data_0.operand_loc, 0, sizeof( recog_data_0.operand_loc)); 
fatal_insn_not_found( insn, "insn-extract.c", 26, "insn_extract"); 
recog_data_0.operand_loc[0] = ( rtx *)v1[2]->fld; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand_loc[1] = ( rtx *)&v1[2][1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand_loc[0] = ( rtx *)( v1[2]->fld[0].rtwint + 8); 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand_loc[1] = ( rtx *)( v1[2]->fld[0].rtwint + 16); 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand_loc[0] = ( rtx *)v1[2]->fld; 
fatal_insn_not_found( insn, "insn-attrtab.c", 46, "insn_variable_length_p"); 
rtx s1; // [rsp+0h] [rbp-48h] 
rtx s2; // [rsp+8h] [rbp-40h] 
s1 = 0LL; 
s1 = v26; 
s1 = single_set_2( i1, v26); 
s2 = v24; 
s2 = single_set_2( i2, v24); 
result = s1 != 0LL && s2 != 0LL; 
rtx addr[4]; // [rsp+0h] [rbp-20h] BYREF 
addr[0] = rtx; 
addr[0] = copy_rtx( rtx); 
instantiate_virtual_regs_1( addr, 0LL, 0); 
if ( !memory_address_p( v8, addr[0]) ) 
if ( !memory_address_p( v10, addr[0]) ) 
instantiate_virtual_regs_1( addr, 0LL, 0); 
x->fld[0].rtx = addr[0]; 
rtx *v7; // rdi 
v7 = &v5->x_parm_reg_stack_loc[v6]; 
if ( *v7 ) 
instantiate_virtual_regs_1( v7, 0LL, 0); 
rtx *v48; // rbx 
rtx v50; // rax 
rtx old; // [rsp+8h] [rbp-50h] 
rtx src; // [rsp+10h] [rbp-48h] BYREF 
src = ( rtx)v3[1]; 
instantiate_virtual_regs_1( &src, 0LL, 0); 
if ( *( _WORD *)src != 61 && *( _WORD *)src != 75 ) 
if ( *( _WORD *)src != 61 && *( _WORD *)src != 75 ) 
v9 = src; 
if ( *( _WORD *)src != 61 ) 
v9 = force_operand( src, 0LL); 
if ( v8 && ( v13 & 8) == 0 && *( _OWORD *)&v11->block.vars != __PAIR128__( hi, *( ( unsigned __int64 *)&hi + 1)) ) 
if ( *( _OWORD *)&abstract_origin->block.vars >= *( _OWORD *)&c->block.vars ) 
if ( *( _OWORD *)&abstract_origin->block.vars >= *( _OWORD *)&c->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&abstract_origin->block.vars >= *( _OWORD *)&c->block.vars ) 
if ( *( _OWORD *)&abstract_origin->block.vars >= *( _OWORD *)&c->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
v9 = canon_hash( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) & 0x1F; 
v18 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v24 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)exp + 2)] - 5) < 2) + 1; 
v6 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)exp + 2)] - 5) < 2) + 1; 
invalidate( *( rtx *)( v2.rtwint + 8), ( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2)); 
invalidate( v6->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)v6 + 2)); 
v6 = gen_rtx_fmt_ee( v4, ( machine_mode)*( unsigned __int8 *)( v3 + 2), *( rtx *)( v3 + 8), *( rtx *)( v3 + 16)); 
return build1( ( tree_code)*( ( unsigned __int8 *)&arg->block.common + 16), type, v27); 
fancy_abort( ( const char *)&stru_665A39, 4601, "ix86_address_cost"); 
LODWORD( v1) = recog_data_0.n_operands - 1; 
v2 = recog_data_0.operand[v1]; 
LODWORD( v4) = recog_data_0.n_operands - 1; 
v7 = recog_data_0.operand[v4]; 
fancy_abort( ( const char *)&stru_665A39, 9933, "ix86_attr_length_immediate_default"); 
fatal_insn( 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_FLOAT ) 
fancy_abort( ( const char *)&stru_665A39, 7200, "ix86_cc_mode"); 
ix86_fp_comparison_codes( ( rtx_code)v2, &bypass_code, code, &second_code); 
fancy_abort( ( const char *)&stru_665A39, 4048, "ix86_compute_frame_layout"); 
fancy_abort( ( const char *)&stru_665A39, 4050, "ix86_compute_frame_layout"); 
fancy_abort( ( const char *)&stru_665A39, 4052, "ix86_compute_frame_layout"); 
fancy_abort( ( const char *)&stru_665A39, 4054, "ix86_compute_frame_layout"); 
v7 = gen_rtx_MEM( ( machine_mode)v6, pointer); 
v8 = adjust_address_1( v7, ( machine_mode)v6, offset, 1, 1); 
v9 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), i); 
v4 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), i); 
v6 = gen_rtx_MEM( ( machine_mode)v5, pointer); 
v7 = adjust_address_1( v6, ( machine_mode)v5, offset, 1, 1); 
fancy_abort( ( const char *)&stru_665A39, 6945, "ix86_expand_binary_operator"); 
fancy_abort( ( const char *)&stru_665A39, 6754, "ix86_expand_clear"); 
if ( mode_class_0[*( ( unsigned __int8 *)v3 + 2)] == MODE_FLOAT ) 
fancy_abort( ( const char *)&stru_665A39, 4396, "ix86_expand_epilogue"); 
v17 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 2); 
v19 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[4], v17); 
v22 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[4]); 
v24 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v17); 
fancy_abort( ( const char *)&stru_665A39, 4445, "ix86_expand_epilogue"); 
fancy_abort( ( const char *)&stru_665A39, 7655, "ix86_expand_fp_compare"); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v4 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v4); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v4 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v4); 
v21 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v25 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)operands[1]); 
fancy_abort( ( const char *)&stru_665A39, 8532, "ix86_expand_fp_movcc"); 
v31 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v32 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v8 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v6, operands[2], operands[3]); 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
|| ( v7 = operands[1], !symbolic_operand( v7, ( machine_mode)v5)) ) 
if ( ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
if ( ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
operands[1] = force_reg( ( machine_mode)v5, v7); 
v8 = gen_reg_rtx( ( machine_mode)v5); 
v8 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), i); 
fancy_abort( ( const char *)&stru_665A39, 4235, "ix86_expand_prologue"); 
v17 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), "_alloca"); 
fancy_abort( ( const char *)&stru_665A39, 7980, "ix86_expand_setcc"); 
fancy_abort( ( const char *)&stru_665A39, 7997, "ix86_expand_setcc"); 
*( _WORD *)v7 = reverse_condition_maybe_unordered( ( rtx_code)*( unsigned __int16 *)bypass_test); 
fancy_abort( ( const char *)&stru_665A39, 12178, "ix86_force_to_memory"); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v2); 
fancy_abort( ( const char *)&stru_665A39, 12244, "ix86_force_to_memory"); 
v19 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)operanda + 2), v18); 
fancy_abort( ( const char *)&stru_665A39, 12204, "ix86_force_to_memory"); 
fancy_abort( ( const char *)&stru_665A39, 7422, "ix86_fp_comparison_arithmetics_cost"); 
fancy_abort( ( const char *)&stru_665A39, 7379, "ix86_fp_comparison_codes"); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v2); 
( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), 
return gen_rtx_REG( ( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), 0); 
v4 = mode_class_0[v3 & 0x7F]; 
return gen_rtx_REG( ( machine_mode)v3, v2); 
LODWORD( v4) = mode_class_0[mode] == MODE_CC; 
v2 = mode_class_0[mode]; 
fancy_abort( ( const char *)&stru_665A39, 4013, "ix86_initial_elimination_offset"); 
fancy_abort( ( const char *)&stru_665A39, 4017, "ix86_initial_elimination_offset"); 
v3 = mode_class_0[mode]; 
fancy_abort( ( const char *)&stru_665A39, 7084, "ix86_match_ccmode"); 
fancy_abort( ( const char *)&stru_665A39, 7086, "ix86_match_ccmode"); 
fancy_abort( ( const char *)&stru_665A39, 7113, "ix86_match_ccmode"); 
v4 = force_reg( ( machine_mode)v6, v4); 
v5 = force_reg( ( machine_mode)v6, v5); 
if ( ( unsigned int)( mode_class_0[mode] - 5) <= 1 ) 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
if ( ( unsigned int)( mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] - 7) <= 1 
return ( unsigned int)( mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] - 7) > 1; 
fancy_abort( ( const char *)&stru_665A39, 12336, "ix86_secondary_memory_needed"); 
v37 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v36); 
v38 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), x86_64_int_parameter_registers[regno]); 
v11 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v10); 
v12 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v13 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v17 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v13, v16); 
v23 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
rtx v28; // r14 
rtx v31; // rax 
rtx v32; // rbx 
rtx i; // [rsp+0h] [rbp-58h] 
rtx bypass; // [rsp+10h] [rbp-48h] BYREF 
rtx second; // [rsp+18h] [rbp-40h] BYREF 
v11 = ix86_expand_fp_compare( code, op1, op2, tmp, &second, &bypass); 
v11 = ix86_expand_fp_compare( code, op1, op2, tmp, &second, &bypass); 
v13 = bypass; 
if ( !bypass ) 
v13 = bypass; 
if ( !bypass ) 
rtx v11; // rax 
rtx v22; // rsi 
rtx part[2][3]; // [rsp+0h] [rbp-68h] BYREF 
v5 = ix86_split_to_parts( operands[1], part[1], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v5 = ix86_split_to_parts( operands[1], part[1], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, part[0], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, part[0], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v22 = operands[1]; 
if ( *( _WORD *)v22 == 66 && reg_overlap_mentioned_p( global_rtl[2], v22) ) 
if ( *( _WORD *)v22 == 66 && reg_overlap_mentioned_p( global_rtl[2], v22) ) 
part[1][1] = change_address( 
( machine_mode)*( ( unsigned __int8 *)part[1][1] + 2), 
( machine_mode)*( ( unsigned __int8 *)part[1][1] + 2), 
part[1][1], 
part[1][2]->fld[0].rtx); 
part[1][0] = change_address( 
rtx operanda; // [rsp+8h] [rbp-60h] BYREF 
operanda = operand; 
v5 = operanda; 
if ( *( _WORD *)operanda != 61 ) 
if ( *( _WORD *)operanda != 66 ) 
fancy_abort( ( const char *)&stru_665A39, 8593, "ix86_split_to_parts"); 
fancy_abort( ( const char *)&stru_665A39, 8595, "ix86_split_to_parts"); 
v5 = operanda; 
if ( *( _WORD *)operanda == 61 ) 
if ( *( _WORD *)operanda == 66 ) 
if ( !push_operand( operanda, VOIDmode) ) 
fancy_abort( ( const char *)&stru_665A39, 8609, "ix86_split_to_parts"); 
operanda = copy_rtx( operanda); 
v62 = construct_container( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, v13, v12, intreg_43, 0); 
v62 = construct_container( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, v13, v12, intreg_43, 0); 
addr_rtx = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
examine_argument( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, &needed_intregs, needed_sseregs); 
v33 = expand_expr( v32, int_addr_rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
v35 = expand_expr( v34, v16, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
int_addr_rtx = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v16 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v25 = expand_expr( v24, addr_rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
tree v22; // rax 
tree v23; // rax 
tree v24; // rax 
tree v25; // rax 
tree fpr; // [rsp+8h] [rbp-40h] 
fpr = build( COMPONENT_REF, ( tree)v4[1], v7, v4); 
v20 = build( MODIFY_EXPR, fpr->common.type, fpr, v19); 
v20 = build( MODIFY_EXPR, fpr->common.type, fpr, v19); 
return force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), exp); 
return copy_to_mode_reg( ( machine_mode)v3, exp); 
v4 = gen_reg_rtx( ( machine_mode)v3); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
v4 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
&& ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[*( ( unsigned __int8 *)val + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)val + 2)] != MODE_VECTOR_FLOAT ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v21 = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v19, ( machine_mode)v18, *( _DWORD *)&v4[1]); 
v21 = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v19, ( machine_mode)v18, *( _DWORD *)&v4[1]); 
v26 = simplify_unary_operation( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v25, ( machine_mode)v24); 
v26 = simplify_unary_operation( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v25, ( machine_mode)v24); 
if ( comparison_dominates_p( v5, ( rtx_code)v6) ) 
|| mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] != MODE_INT ) 
elements = ( tree_node *)*( &global_trees + 12); 
v20 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), x->fld[0].rtx); 
v3 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v20, v19); 
v24 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), *( rtx *)( v3->fld[0].rtwint + 8)); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v28 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), *( rtx *)( *( _QWORD *)&v3[1] + 8LL)); 
*( _QWORD *)&v3[1] = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v28, v27); 
v32 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v10.rtx, *( rtx *)( v30 + 8)); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v32, v31); 
rtx v16; // rbx 
rtx v20; // rbx 
rtx v31; // rbx 
v29 = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v28, 15); 
v30 = gen_rtx_fmt_e( CONST, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v29); 
v31 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v30); 
v31 = gen_rtx_MEM( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v30); 
*( ( _BYTE *)v31 + 3) |= 4u; 
if ( set_31 == -1 ) 
set_31 = new_alias_set( ); 
set_mem_alias_set( v31, set_31); 
set_mem_alias_set( v31, set_31); 
v3 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
v32 = gen_movsi( v3, v31); 
v9 = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v8, 7); 
v5 = NOT_FLOAT; 
v5 = NOT_FLOAT; 
if ( v5 == AFTER_POINT ) 
if ( v5 == AFTER_POINT ) 
v5 = AFTER_POINT; 
v5 = AFTER_POINT; 
v19 = sch_istable[v17]; 
v20 = hex_value[v17]; 
v5 = AFTER_EXPON; 
v5 = AFTER_EXPON; 
rtx insns; // rbx 
v11 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 2); 
diddle_return_value( mark_reg_0, global_live_at_start); 
insns = get_insns( ); 
if ( insns ) 
v12.rtwint = ( __int64)insns[1].fld[0]; 
if ( *( _WORD *)insns == 36 && insns[2] == ( ( *( ( _BYTE *)insns + 3) & 0x10) != 0) ) 
if ( *( _WORD *)insns == 36 && insns[2] == ( ( *( ( _BYTE *)insns + 3) & 0x10) != 0) ) 
if ( *( _WORD *)insns == 36 && insns[2] == ( ( *( ( _BYTE *)insns + 3) & 0x10) != 0) ) 
fprintf( rtl_dump_file, ( const char *)&to.indx + 4, insns->fld[0].rtuint); 
fprintf( rtl_dump_file, ( const char *)&to.indx + 4, insns->fld[0].rtuint); 
delete_insn( insns[1].fld[0].rtx); 
delete_insn( insns); 
insns = ( rtx)v12.rtwint; 
if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v6->fld[0].rtwint + 8)) < uid_limit ) 
else if ( *( ( _DWORD *)uid_cuid_1 + *( int *)( v6->fld[0].rtwint + 8)) > uid_limit ) 
fancy_abort( ( const char *)&stru_665A39, 3916, "load_pic_register"); 
v2 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), pic_label_name); 
return mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtl + 2)); 
fancy_abort( ( const char *)&a, 7976, "loc_descriptor"); 
fancy_abort( ( const char *)&a, 8292, "loc_descriptor_from_tree"); 
rtx init_insns; // rax 
rtx v20; // rax 
rtx v40; // rax 
rtx v42; // rax 
rtx v74; // r12 
rtx hard_reg_initial_reg; // rax 
rtx v86; // rax 
rtx v90; // rax 
v12 = ( tree_node *)*( ( _QWORD *)&v15->stmt + v11++); 
if ( strcmp( file_name, ( const char *)&a.dw_attr_val.val_class + 3) ) 
last_lookup_index = file_table_0.last_lookup_index; 
if ( !file_table_0.last_lookup_index || strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
if ( !file_table_0.last_lookup_index || strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
if ( !file_table_0.last_lookup_index || strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
last_lookup_index = file_table_0.in_use; 
v2 = ( const char **)( file_table_0.table + 1); 
if ( file_table_0.in_use <= 1 ) 
if ( file_table_0.allocated == last_lookup_index ) 
file_table_0.allocated = last_lookup_index + 64; 
file_table_0.table = ( char **)xrealloc( file_table_0.table, 8LL * ( last_lookup_index + 64)); 
file_table_0.table = ( char **)xrealloc( file_table_0.table, 8LL * ( last_lookup_index + 64)); 
v4 = &file_table_0.table[last_lookup_index]; 
file_table_0.in_use = last_lookup_index + 1; 
file_table_0.last_lookup_index = last_lookup_index; 
fprintf( asm_out_file, ( const char *)&a.dw_attr_val.v.val_unsigned + 6, last_lookup_index, file_name); 
file_table_0.last_lookup_index = v3; 
error( ( const char *)&stru_634008, id->int_cst.int_cst.low); 
induction_1 *biv; // r14 
induction_1 *biv; // r14 
rtx v34; // rax 
rtx v35; // r15 
rtx v37; // rax 
rtx v38; // rax 
rtx const2; // [rsp+8h] [rbp-60h] 
rtx increment; // [rsp+10h] [rbp-58h] 
rtx v14; // rbx 
rtx j; // rax 
rtx nonnote_insn; // rax 
rtx v23; // rax 
rtx v24; // rax 
rtx v25; // rax 
rtx k; // rax 
rtx m; // rax 
v15 = gen_rtx_REG( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), i); 
rtx *fld; // rbp 
rtx compound_operation; // r14 
compound_operation = make_compound_operation( x->fld[0].rtx, in_code); 
if ( *( _WORD *)compound_operation == *( _WORD *)x->fld[0].rtwint 
|| mode_size[v6] >= mode_size[*( ( unsigned __int8 *)compound_operation + 2)] 
if ( ( unsigned __int16)( *( _WORD *)compound_operation - 120) > 1u || !subreg_lowpart_p( x) ) 
if ( v51 <= mode_size[*( ( unsigned __int8 *)compound_operation + 2)] 
&& ( v52.rtwint = ( __int64)compound_operation->fld[0], v51 <= mode_size[*( unsigned __int8 *)( v52.rtwint + 2)]) ) 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)compound_operation, v6, compound_operation->fld[0].rtx); 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)compound_operation, v6, compound_operation->fld[0].rtx); 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)compound_operation, v6, compound_operation->fld[0].rtx); 
v53 = force_to_mode( compound_operation, v6, 0xFFFFFFFFFFFFFFFFLL, 0LL, 0); 
decl->decl.rtl = adjust_address_1( rtl, ( machine_mode)supercontext, 0LL, 0, 1); 
v22 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), low); 
v23 = gen_rtx_MEM( ( machine_mode)LOBYTE( decl->block.supercontext), v22); 
if ( !ix86_hard_regno_mode_ok( v10, ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)) ) 
v13 = gen_rtx_fmt_i0( REG, ( machine_mode)LOBYTE( decl->block.supercontext), v10); 
v16 = ( ( unsigned int)( mode_class_0[LOBYTE( decl->block.supercontext)] - 5) < 2) + 1; 
rtx v13; // rbx 
rtx v31; // rax 
v13 = pos_rtx; 
v13 = pos_rtx; 
v13 = pos_rtx; 
v43 = v13 == 0LL; 
v14 = ( unsigned __int64)v13 | pos; 
if ( ( unsigned __int64)v13 | pos ) 
rtx result; // rax 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
if ( reg_equiv_memory_loc[regno] == result ) 
return copy_rtx( result); 
return result; 
v3 = ( tree_node *)ggc_alloc( v2); 
v5 = transp_0[src->index]; 
n_low = range_binop( ( tree_code)v17, type, v5, 0, low, 0); 
v18 = range_binop( ( tree_code)v17, type, high, 1, low, 0); 
abstract_origin = type_for_mode( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 1)->decl.abstract_origin; 
tree v8; // r12 
tree v9; // rax 
tree v11; // r12 
tree v12; // rax 
tree v16; // r12 
tree v17; // rax 
if ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v3.rtwint + 2)] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v11.rtwint + 2)] - 5) > 1 ) 
v3 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno] + 2)] - 5) < 2) + 1; 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx v19; // rdx 
v12 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
v19 = reg_equiv_mem[rtint]; 
if ( v19 ) 
mark_referenced_regs( v19->fld[0].rtx); 
fancy_abort( ( const char *)&to, 918, "mark_reg"); 
if ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) > 1 ) 
v7 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) < 2) + 1; 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx ya; // [rsp+8h] [rbp-70h] 
rtx rega; // [rsp+38h] [rbp-40h] 
v12 = ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) <= 1; 
v27 = v24 + subreg_regno_offset( v24, ( machine_mode)v23, *( _DWORD *)&rtx[1], ( machine_mode)v22); 
v27 = v24 + subreg_regno_offset( v24, ( machine_mode)v23, *( _DWORD *)&rtx[1], ( machine_mode)v22); 
v29 = ( ( unsigned int)( mode_class_0[v22] - 5) < 2) + 1; 
rega = rtx; 
rtx = rega; 
ya = pbi->reg_next_use[v49]; 
ya = 0LL; 
ya = 0LL; 
&& ya 
&& *( _DWORD *)( basic_block_for_insn->data.l[ya->fld[0].rtint] + 88) == blocknuma 
&& ( v9 > 52 || asm_noperands( *( rtx *)&ya[2]) < 0) ) 
mark_set_1( pbi, ( rtx_code)v8, v3->fld[0].rtx, v7, insn, pbi->flags); 
fancy_abort( ( const char *)&to, 2468, "mark_set_regs"); 
mark_set_1( pbi, ( rtx_code)v11, *( ( rtx *)v10 + 1), v7, insn, pbi->flags); 
v9 = ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) <= 1; 
v10 = __CFADD__( ( _DWORD)rtuint, v9); 
rtx mem_set_list; // r14 
rtx *listp; // [rsp+10h] [rbp-48h] 
listp = &pbi->mem_set_list; 
fancy_abort( ( const char *)&to, 3893, "mark_used_regs"); 
free_EXPR_LIST_list( listp); 
free_EXPR_LIST_list( listp); 
v7 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT ) 
if ( mode_class_0[*( unsigned __int8 *)( x->fld[0].rtwint + 2)] != MODE_FLOAT ) 
if ( mode_class_0[*( unsigned __int8 *)( *( _QWORD *)&x[1] + 2LL)] != MODE_FLOAT ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT || v5 == 54 && !*( ( _QWORD *)v4 + 1) ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT ) 
v16 = ( const char *)&off_6E0C7E; 
induction_1 *giv; // rax 
induction_1 *giv; // rax 
induction_1 *j; // rax 
induction_1 *j; // rax 
induction_1 *v20; // rbx 
induction_1 *v20; // rbx 
rtx mult_val; // rax 
rtx v25; // rax 
rtx v26; // rdx 
induction_1 *i; // rax 
induction_1 *i; // rax 
rtx *fmta; // [rsp+18h] [rbp-50h] 
induction_1 *tem; // [rsp+20h] [rbp-48h] 
induction_1 *tem; // [rsp+20h] [rbp-48h] 
decode_asm_operands( v20, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
decode_asm_operands( v20, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
if ( ( sch_istable[*( unsigned __int8 *)*format] & 4) != 0 ) 
if ( ( sch_istable[v13] & 4) == 0 ) 
rtx pool_constant_mark; // rax 
pool_constant_mark = get_pool_constant_mark( rtx, marked); 
if ( *( _WORD *)pool_constant_mark != 68 ) 
rtx = pool_constant_mark; 
if ( ( *( ( _BYTE *)pool_constant_mark + 3) & 4) == 0 ) 
get_pool_constant_mark( pool_constant_mark, marked); 
v4 = mem_loc_descriptor( rtx->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2)); 
fancy_abort( ( const char *)&a, 7904, "mem_loc_descriptor"); 
rtx constant_term; // [rsp+8h] [rbp-30h] BYREF 
v3 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), x); 
constant_term = const_int_rtx[64]; 
v8 = eliminate_constant_term( v3, &constant_term); 
if ( const_int_rtx[64] != constant_term 
&& ( v9 = constant_term, 
v11 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v10, v9), 
v3 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v3); 
if ( general_operand( v3, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)) ) 
fancy_abort( ( const char *)&stru_665A39, 9877, "memory_address_length"); 
fancy_abort( ( const char *)&stru_665A39, 3460, "memory_displacement_operand"); 
rtx v11; // r13 
rtx v16; // r15 
rtx y1; // [rsp+18h] [rbp-40h] 
v11 = y->fld[0].rtx; 
v11 = ( rtx)y[1]; 
v11 = canon_rtx( v14); 
if ( rtx_equal_for_memref_p( rtx, v11) ) 
if ( *( _WORD *)v11 == 75 ) 
y0 = v11->fld[0].rtx; 
y1 = ( rtx)v11[1]; 
if ( rtx_equal_for_memref_p( v21, y1) ) 
return memrefs_conflict_p( xsize, v21, ysize, y1, c); 
if ( *( _WORD *)y1 == 54 ) 
return memrefs_conflict_p( xsize, rtx, ysize, y0, y1->fld[0].rtwint + c); 
v11 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 7381, "base_type_die"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
fancy_abort( ( const char *)&a, 7573, "modified_type_die"); 
fancy_abort( ( const char *)&a, 7461, "is_base_type"); 
v7 = operand_sub*(short *)0xforce( x, i, mode); 
rtx v21; // [rsp+10h] [rbp-68h] 
genfun = insn_data_0[insn_code].genfun; 
v21 = 0LL; 
v21 = adjust_automodify_address_1( to, v10, to_addr, v9, 1); 
v21 = adjust_address_1( to, v10, v9, 1, 1); 
v15 = genfun( v21, v14); 
rtx v21; // r14 
rtx oldnotes; // [rsp+38h] [rbp-40h] BYREF 
v21 = remove_death( regno, v13); 
v22 = regno <= 0x34 && v21 != 0LL; 
v23.rtwint = ( __int64)v21->fld[0]; 
v30 = ( ( unsigned int)( mode_class_0[v24] - 5) < 2) + 1; 
v34 = ( ( unsigned int)( mode_class_0[v26] - 5) < 2) + 1; 
if ( *( _BYTE *)( v21->fld[0].rtwint + 2) == *( ( _BYTE *)x + 2) ) 
*( _QWORD *)&v21[1] = *pnotes; 
*pnotes = v21; 
rtx v36; // rax 
rtx v37; // rax 
rtx v39; // rax 
rtx v40; // rax 
rtx v44; // r12 
rtx v46; // rax 
rtx set_dest; // rbp 
rtx v53; // rbp 
rtx v57; // rax 
v2 = ( const char *)&unk_6E2DA4; 
if ( in_section_0 != in_named || strcmp( name, in_named_name) ) 
in_section_0 = no_section; 
in_section_0 = in_named; 
return ++last_alias_set_5; 
fancy_abort( ( const char *)&insn, 710, "new_cselib_val"); 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
$B50C8071A5A789E219D5EDC319094081 *handlers; // rax 
$B50C8071A5A789E219D5EDC319094081 *handlers; // rax 
handlers = v0->handlers; 
handlers->insn_code = CODE_FOR_nothing; 
handlers->libfunc = 0LL; 
++handlers; 
while ( handlers != ( $B50C8071A5A789E219D5EDC319094081 *)&v0[1] ); 
while ( handlers != ( $B50C8071A5A789E219D5EDC319094081 *)&v0[1] ); 
result = ( cpp_context_0 *)xmalloc( 0x38uLL); 
v2 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v13 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)if_info->cond + 2), cmp_a, cmp_b); 
v14 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v13, vtrue, vfalse); 
v11 = general_operand( cmp_a, ( machine_mode)*( ( unsigned __int8 *)cmp_a + 2)); 
if ( general_operand( cmp_b, ( machine_mode)*( ( unsigned __int8 *)cmp_b + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
v10 = gen_rtx_fmt_ee( v8, ( machine_mode)*( ( unsigned __int8 *)x + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
v5 = gen_rtx_fmt_ee( v12, ( machine_mode)*( unsigned __int8 *)( v9 + 2), tmp, op_b); 
rtx v14; // rbx 
if ( *( _WORD *)v7 == 61 && mode_class_0[*( unsigned __int8 *)( v7 + 2)] == MODE_INT ) 
v12 = reverse_condition( ( rtx_code)*v6); 
if ( *( _WORD *)v13.rtwint == 61 && mode_class_0[*( unsigned __int8 *)( v13.rtwint + 2)] == MODE_INT ) 
v14 = *earliest; 
while ( rtx_class[*( _WORD *)v14] != 105 || !modified_in_p( v2, v14) ) 
while ( rtx_class[*( _WORD *)v14] != 105 || !modified_in_p( v2, v14) ) 
v14 = v14[1].fld[0].rtx; 
v4 = mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_VECTOR_FLOAT 
|| ( mode_class_0[*( ( unsigned __int8 *)op + 2)] & 0xFFFFFFFB) == 2; 
if ( ( mode_class_0[mode] & 0xFFFFFFFD) != 1 ) 
rtx v16; // rax 
rtx v17; // rax 
rtx v37; // rax 
rtx v40; // rax 
rtx v44; // rax 
rtx v47; // rax 
rtx basex; // [rsp+8h] [rbp-50h] 
if ( ( mode_class_0[v4] & 0xFFFFFFFB) != 2 ) 
if ( mode_class_0[v4] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[mode] & 0xFFFFFFFB) != 2 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
return v3 & nonzero_bits( x, ( machine_mode)v4) | mode_mask_array[v2] & ~mode_mask_array[*( ( unsigned __int8 *)x 
|| mode_class_0[v12] == MODE_INT && mode_class_0[v2] == MODE_INT) 
|| mode_class_0[v12] == MODE_INT && mode_class_0[v2] == MODE_INT) 
v3 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v4) & v38; 
if ( mode_class_0[v2] == MODE_INT ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_INT ) 
if ( mode_class_0[v4] != MODE_INT ) 
if ( ( mode_class_0[v3] & 0xFFFFFFFB) == 2 || mode_class_0[v3] == MODE_VECTOR_FLOAT ) 
if ( ( mode_class_0[v3] & 0xFFFFFFFB) == 2 || mode_class_0[v3] == MODE_VECTOR_FLOAT ) 
if ( ( mode_class_0[v6] & 0xFFFFFFFB) == 2 || mode_class_0[v6] == MODE_VECTOR_FLOAT ) 
if ( ( mode_class_0[v6] & 0xFFFFFFFB) == 2 || mode_class_0[v6] == MODE_VECTOR_FLOAT ) 
LODWORD( v4) = num_sign_bit_copies( x, ( machine_mode)v6) 
if ( *( _OWORD *)&t1 == 0LL ) 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4.rtx, offset); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), v5) 
v12 = force_reg( ( machine_mode)*( unsigned __int8 *)( v4.rtwint + 2), v4.rtx); 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v12, offset); 
v9 = *( tree_node **)( v8 + 8); 
v9 = ( tree_node *)memref[1]; 
*( _QWORD *)&v6[1] = get_mem_attrs( v10, v9, 0LL, 0LL, v7, ( machine_mode)*( ( unsigned __int8 *)v6 + 2)); 
v11 = gen_rtx_fmt_ee( LO_SUM, ( machine_mode)*( ( unsigned __int8 *)y + 2), y->fld[0].rtx, v14); 
return offsettable_address_p( 1, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx) != 0; 
return offsettable_address_p( 0, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx) != 0; 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
( machine_mode)*( unsigned __int8 *)( v7.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)) 
( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2)); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
v6 = &reg_avail_info_0[x->fld[0].rtuint]; 
return v6->last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
return v6->first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
rtx v15; // r12 
rtx v21; // rdx 
v15 = adjust_address_1( rtx, mode, v13, 1, 1); 
validate_change( insn, ( rtx *)body->fld, v15, 1); 
if ( v20 && v20 != *( ( _BYTE *)v15 + 2) ) 
v21 = ( rtx)body[1]; 
if ( v21[1] ) 
v21 = v21->fld[0].rtx; 
v21 = v21->fld[0].rtx; 
while ( *( _WORD *)v21 == 63 ); 
v22 = *( ( _BYTE *)v15 + 2); 
lang_hooks_0.tree_inlining.add_pending_fn_decls( &id, v5); 
v8 = *( tree_node **)( low + 40); 
transp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
comp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
sbitmap_vector_ones( transp_0, n_basic_blocks); 
note_stores( *( ( rtx *)v11 + 4), reg_becomes_live_0, live_at_edge); 
transp_0[v2]->elms[0] &= ~1uLL; 
sbitmap_vector_zero( comp_0, n_basic_blocks); 
v31 = comp_0; 
sbitmap_not( kill[v17], transp_0[v17]); 
v18 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
v18 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
v18 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
if ( ( insert_0[v20 / 8]->elms[0] & 1) != 0 ) 
transp_0[index]->elms[0] &= ~1uLL; 
free( transp_0); 
free( comp_0); 
free( insert_0); 
rtx v33; // rax 
rtx v34; // rsi 
rtx v38; // rax 
rtx v39; // rsi 
rtx i; // rbx 
rtx j; // rbx 
rtx rtl; // rax 
rtx orig_insn; // [rsp+0h] [rbp-68h] 
rtx orig_insna; // [rsp+0h] [rbp-68h] 
rtx v7; // rax 
v7 = simplify_subtraction( x); 
x = v7; 
if ( *( _WORD *)v7 != 76 ) 
output_addr_const( file, v7->fld[0].rtx); 
v1 = lang_hooks_0.expand_constant( exp); 
v9 = ( tree_node *)high[4]; 
fprintf( asm_out_file, &off_6376D2[1], ( unsigned int)insn_counter); 
v10 = sch_istable[( unsigned __int8)v8]; 
if ( ( sch_istable[*( ( unsigned __int8 *)v2 + 2)] & 4) != 0 ) 
if ( ( sch_istable[*( ( unsigned __int8 *)v2 + 2)] & 4) != 0 ) 
while ( ( sch_istable[*( unsigned __int8 *)v14] & 4) != 0 ); 
if ( ( sch_istable[*( unsigned __int8 *)v3] & 4) != 0 ) 
while ( ( sch_istable[*( unsigned __int8 *)v3] & 4) != 0 ); 
fprintf( asm_out_file, "\t%s %d\t%s", "#", debug_insn->fld[0].rtuint, insn_data_0[rtint].name); 
if ( insn_data_0[rtint].n_alternatives > 1 ) 
fprintf( asm_out_file, off_65D071, ( unsigned int)( which_alternative + 1)); 
v17 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v16->dw_fde_begin); 
v21 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), l1); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
fancy_abort( ( const char *)&a, 1772, "output_cfi"); 
v4 = lang_hooks_0.expand_constant( exp); 
sprintf( label, "*.%s%u", ( const char *)&a.dw_attr_val, v6); 
v10 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), object_base->label); 
rtl = gen_rtx_MEM( ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), v10); 
mergeable_constant_section( ( machine_mode)LOBYTE( v3->block.supercontext), v5, 0); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&a.dw_attr_val, ( unsigned int)labelno); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&a.dw_attr_val, ( unsigned int)k->labelno); 
v23 = ( tree_node *)v22[7]; 
v23 = ( tree_node *)v25; 
v23 = ( tree_node *)v25; 
sprintf( buffer->digit_buffer, &off_6376D2[1], ( unsigned int)i); 
sprintf( buffer->digit_buffer, off_6544E1, *v12); 
sprintf( buffer->digit_buffer, off_6544E5, *v18); 
v11 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v10); 
table_address = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v11); 
v12 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)identifier, "__bb_init_func"); 
v18 = ( tree_node *)*( &global_trees + 11); 
v18 = ( tree_node *)*( ( _QWORD *)*htab_find_slot_with_hash( 
if ( ( tree_node *)global_trees == v11 ) 
fancy_abort( ( const char *)&a, 2778, "output_loc_operands"); 
fancy_abort( ( const char *)&a, 2789, "output_loc_operands"); 
fancy_abort( ( const char *)&stru_665A39, 5415, "output_pic_addr_const"); 
fwrite( ( char *)&stru_665A39._IO_buf_base + 6, 1uLL, 0xFuLL, file); 
output_operand_lossage( ( const char *)&stru_665A39._IO_save_base + 6); 
fprintf( file, ( const char *)&stru_665A39._IO_write_end + 3, v6.rtwint, *( _QWORD *)&x[1]); 
fancy_abort( ( const char *)&stru_665A39, 5343, "output_pic_addr_const"); 
fwrite( ( char *)&stru_665A39._IO_write_ptr + 6, 1uLL, 4uLL, file); 
fancy_abort( ( const char *)&stru_665A39, 5402, "output_pic_addr_const"); 
if ( ( sch_istable[( unsigned __int8)i] & 0x10) != 0 ) 
if ( !strcmp( v14, processor_alias_table_49[v15].name) ) 
ix86_arch = processor_alias_table_49[( int)v15].processor; 
flags = processor_alias_table_49[( int)v15].flags; 
flags = processor_alias_table_49[( int)v15].flags; 
if ( ( flags & 4) != 0 ) 
if ( ( flags & 0x10) != 0 && ( target_flags & 0x200000) == 0 ) 
if ( ( flags & 0x40) != 0 && ( target_flags & 0x800000) == 0 ) 
if ( ( flags & 1) != 0 && ( target_flags & 0x20000) == 0 ) 
if ( ( flags & 2) != 0 && ( target_flags & 0x80000) == 0 ) 
if ( ( flags & 8) != 0 ) 
if ( !strcmp( v17, processor_alias_table_49[v18].name) ) 
ix86_cpu = processor_alias_table_49[( int)v18].processor; 
if ( ( processor_alias_table_49[v19].flags & 8) != 0 ) 
cost = processor_target_table_48[ix86_cpu].cost; 
if ( !already_0 ) 
already_0 = 1; 
if ( ( sch_istable[( unsigned __int8)v15] & 0x88) == 0 ) 
if ( ( sch_istable[*v12] & 0x204) == 0 
if ( ( sch_istable[( unsigned __int8)v4] & 0x204) == 0 
if ( ( sch_istable[( unsigned __int8)v14] & 0x88) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v10] & 0x400) != 0 ) 
if ( !peep2_insn_data_0[v8].insn ) 
reg_set_to_hard_reg_set( live, peep2_insn_data_0[v8].live_before); 
if ( !peep2_insn_data_0[v8].insn ) 
reg_set_to_hard_reg_set( &this_live, peep2_insn_data_0[v8].live_before); 
v21 = search_ofs_1 + v12; 
if ( search_ofs_1 + v12 > 52 ) 
v21 = search_ofs_1 + v12 - 53; 
v14 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
search_ofs_1 = 0; 
v16 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
search_ofs_1 = v18; 
result = peep2_insn_data_0[v1].insn; 
if ( !peep2_insn_data_0[v2].insn ) 
v5 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) < 2) + 1; 
if ( bitmap_bit_p( peep2_insn_data_0[v2].live_before, v7--) ) 
if ( !peep2_insn_data_0[v2].insn ) 
return bitmap_bit_p( peep2_insn_data_0[v2].live_before, regno) == 0; 
recog_data_0.insn = 0LL; 
return gen_peephole2_1277( insn, recog_data_0.operand); 
result = gen_peephole2_1278( insn, recog_data_0.operand); 
return gen_peephole2_1279( insn, recog_data_0.operand); 
return gen_peephole2_1274( insn, recog_data_0.operand); 
return gen_peephole2_1273( insn, recog_data_0.operand); 
return gen_peephole2_1292( insn, recog_data_0.operand); 
result = gen_peephole2_1293( insn, recog_data_0.operand); 
return gen_peephole2_1294( insn, recog_data_0.operand); 
return gen_peephole2_1289( insn, recog_data_0.operand); 
return gen_peephole2_1288( insn, recog_data_0.operand); 
recog_data_0.operand[6] = v97; 
recog_data_0.operand[4] = v102; 
recog_data_0.operand[5] = v104; 
recog_data_0.operand[3] = v107; 
recog_data_0.operand[0] = v114; 
recog_data_0.operand[1] = v116; 
recog_data_0.operand[2] = v118; 
peep2_insn_data_0[0].insn = 0LL; 
peep2_insn_data_0[1].insn = 0LL; 
peep2_insn_data_0[2].insn = 0LL; 
peep2_insn_data_0[3].insn = 0LL; 
peep2_insn_data_0[4].insn = global_rtl[0]; 
bitmap_copy( peep2_insn_data_0[4].live_before, live); 
peep2_insn_data_0[v25].insn = ( rtx)v23; 
bitmap_copy( peep2_insn_data_0[peep2_current].live_before, live); 
insn = peep2_insn_data_0[v27].insn; 
( machine_mode)v15, 
if ( *( _WORD *)peep2_insn_data_0[v30].insn == 34 ) 
note = find_reg_note( peep2_insn_data_0[v6].insn, REG_EH_REGION, 0LL); 
v7 = emit_insn_after( v26, peep2_insn_data_0[v6].insn); 
delete_insn_chain( ( rtx)v23, peep2_insn_data_0[v6].insn); 
bitmap_copy( live, peep2_insn_data_0[v9].live_before); 
( const char *)&stru_634008.block.supercontext, 
rtx *constant_term_loc; // rbx 
rtx copy; // [rsp+10h] [rbp-38h] BYREF 
rtx y; // [rsp+18h] [rbp-30h] BYREF 
y = rtx; 
add_double( *( _QWORD *)&rtx[1], rtx[1].fld[0].rtwint, v4, v4 >> 63, &lv, ( __int64 *)&copy); 
return immed_double_const( lv, ( __int64)copy, VOIDmode); 
v2 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v2 + 2), v2->fld[0].rtx) ) 
v4 = trunc_int_for_mode( v4, ( machine_mode)v13); 
if ( find_constant_term_loc( &y) ) 
copy = copy_rtx( rtx); 
constant_term_loc = find_constant_term_loc( &copy); 
constant_term_loc = find_constant_term_loc( &copy); 
v4 = build_binary_op( ( tree_code)subcode, v4, v20, 1); 
while ( constructor_stack_0->implicit ) 
if ( constructor_range_stack_0 ) 
v2 = constructor_stack_0; 
spelling_0 = &spelling_base[constructor_depth]; 
replacement_value = ( tree_node *)global_trees; 
replacement_value = ( tree_node *)global_trees; 
constructor_range_stack_0 = v2->range_stack; 
spelling_0 = &spelling_base[depth]; 
constructor_stack_0 = v2->next; 
if ( !replacement_value && !constructor_stack_0 ) 
warning_with_decl( ( tree)low, ( const char *)&stru_634008.block + 200); 
error_with_decl( ( tree)low, ( const char *)&stru_634008.block + 168); 
warning_with_decl( j->vector.elements, ( const char *)&stru_634008.block + 200); 
error_with_decl( j->vector.elements, ( const char *)&stru_634008.block + 168); 
v9 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
if ( mode_class_0[*( unsigned __int8 *)( *( ( _QWORD *)aux + 6) + 2LL)] == MODE_FLOAT 
|| ( v13 = *( ( _QWORD *)aux + 4), mode_class_0[*( unsigned __int8 *)( v13 + 2)] == MODE_FLOAT) ) 
hitrate = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
hitrate = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
v12 = &insn_data_0[icode].operand[opnum]; 
if ( !v12->predicate( v11, ( machine_mode)*( ( unsigned __int16 *)v12 + 8)) ) 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)v12 + 8), v11); 
if ( recog_data_0.n_operands > 0 ) 
v6 = recog_data_0.constraints[v1]; 
if ( recog_data_0.n_alternatives > 0 ) 
while ( recog_data_0.n_alternatives > v2 ); 
while ( recog_data_0.n_operands > ( int)v1 ); 
sprintf( tmp, &off_6376D2[1], *( _DWORD *)&x[1]); 
v7 = off_6BAD95; 
fprintf( outfile, off_661611, name->int_cst.int_cst.low); 
fwrite( &unk_6E1B77, 1uLL, 0xCuLL, outfile); 
fancy_abort( ( const char *)&stru_665A39, 6027, "print_operand"); 
*( _OWORD *)&v18.r[1] = __PAIR128__( *( _QWORD *)&x[2], v15.rtwint); 
*( _OWORD *)&v19.r[1] = __PAIR128__( u.d.r[2], v17.rtwint); 
fancy_abort( ( const char *)&stru_665A39, 5776, "print_operand"); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 0, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 0, file); 
fwrite( &off_66705A, 1uLL, 3uLL, file); 
fwrite( &off_6BD75B, 1uLL, 3uLL, file); 
fancy_abort( ( const char *)&stru_665A39, 5919, "print_operand"); 
fancy_abort( ( const char *)&stru_665A39, 6126, "print_operand_address"); 
v2 = *( _OWORD *)&scale.base; 
if ( *( _OWORD *)&scale.base == 0LL ) 
fprintf( file, off_66644D, v4); 
fprintf( file, off_666451, v4); 
fancy_abort( ( const char *)&stru_665A39, 5640, "print_reg"); 
fancy_abort( ( const char *)&stru_665A39, 5715, "print_reg"); 
fancy_abort( ( const char *)&stru_665A39, 5665, "print_reg"); 
fprintf( file, off_6663DA, ( unsigned int)( v9 - 29)); 
in_bb_p = ( print_rtl_graph_with_bb::bb_state *)rtx_first; 
memcpy( &in_bb_p, fp, v3); 
memcpy( ( char *)&in_bb_p + v3, end, ( size_t)start); 
memcpy( ( char *)&in_bb_p + ( _QWORD)v8, v5, v7); 
v10 = fopen( ( const char *)&in_bb_p, "a"); 
if ( in_bb_p ) 
v15 = ( print_rtl_graph_with_bb::bb_state *)xmalloc( v12); 
for ( i = 0LL; i != max_uid; v15[i++] = NOT_IN_BB_0 ) 
for ( i = 0LL; i != max_uid; v15[i++] = NOT_IN_BB_0 ) 
v24 = &v15[*( int *)( v22 + 8)]; 
v24 = &v15[*( int *)( v22 + 8)]; 
*v24 = 1 - ( ( *v24 == NOT_IN_BB_0) - 1); 
fwrite( ( char *)&to.current + 6, 1uLL, 5uLL, outfile); 
fprintf( outfile, off_6376D2, *( _DWORD *)&in_rtx[2]); 
fprintf( outfile, off_6376D2, ( unsigned int)v22, v11); 
fputs( hi_name_2[v24], outfile); 
fprintf( outfile, off_6663DA, ( unsigned int)( v24 - 29)); 
fputs( hi_name_2[in_rtx->fld[0].rtuint], outfile); 
fputs( hi_name_2[in_rtx->fld[0].rtuint], outfile); 
fputs( qi_name_1[v24], outfile); 
fprintf( outfile, off_6376D2, *( _DWORD *)&in_rtx[3], v11); 
fprintf( outfile, off_6376D2); 
fprintf( outfile, off_661611, note_insn_name[v28]); 
fprintf( outfile, off_6376D2, LODWORD( v29->current)); 
if ( spelling_base >= spelling_0 ) 
while ( spelling_0 > v1 ); 
while ( &unk_6F4758 != ( _UNKNOWN *)v18 ); 
sprintf( t, off_6ECBFD); 
if ( ( sch_istable[*( unsigned __int8 *)reg_names[rtuint]] & 4) != 0 ) 
sprintf( t, off_6FAD63, *( _DWORD *)&x[1]); 
safe_concat( buf, v16, ( const char *)&off_631D1E + 2); 
sprintf( t, off_6ECBEC, *( unsigned int *)( x->fld[0].rtwint + 8)); 
lang_hooks_0.name, 
v3 = convert_to_mode( ( machine_mode)v5, size, 1); 
v7 = gen_rtx( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v6); 
v12 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v11); 
v14 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v13); 
v16 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v15); 
v19 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), global_rtl[2], v18); 
v17 = force_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v17); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
emit_cmp_and_jump_insns( v17, v20, GTU, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1, v22); 
if ( !constructor_stack_0->replacement_value ) 
if ( constructor_stack_0->replacement_value ) 
constructor_stack_0->replacement_value = value; 
v2 = constructor_stack_0; 
if ( !constructor_stack_0->replacement_value ) 
v2 = constructor_stack_0; 
if ( constructor_stack_0->replacement_value ) 
while ( constructor_stack_0->implicit ); 
if ( general_operand( v2, ( machine_mode)*( ( unsigned __int8 *)reaching_reg + 2)) ) 
v4 = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int8 *)loc + 2), copy); 
fatal_insn( "Attempt to delete prologue/epilogue insn:", insn, ( const char *)&to, 1615, "propagate_one_insn"); 
rtx v6; // rax 
rtx v12; // r12 
rtx v13; // rax 
rtx v14; // r13 
v15 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v6 = replace_equiv_address_nv( x, *( rtx *)( v3.rtwint + 8)); 
v7 = v6; 
rtx = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v10 = copy_to_reg( v6->fld[0].rtx); 
v12 = protect_from_queue( x->fld[0].rtx, 0); 
rtx note; // [rsp+8h] [rbp-90h] BYREF 
for ( note = ( rtx)v3.rtwint; v3.rtwint; note = ( rtx)v3.rtwint ) 
for ( note = ( rtx)v3.rtwint; v3.rtwint; note = ( rtx)v3.rtwint ) 
if ( for_each_rtx( &note, is_addressof, 0LL) ) 
remove_note( rtx, note); 
v3.rtwint = ( __int64)note[1]; 
rtx v35; // rbx 
rtx v36; // rax 
rtx *fld; // rbp 
rtx v42; // rax 
rtx insna; // [rsp+0h] [rbp-58h] 
insna = insn; 
rtx v2; // rbp 
v2 = 0LL; 
v2 = 0LL; 
if ( v2 ) 
if ( rtx[2] == v2[2] ) 
if ( rtint == v2[2].fld[0].rtint ) 
v2 = rtx; 
v2 = rtx; 
v2 = rtx; 
( machine_mode)*( unsigned __int8 *)( v5 + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2)); 
v1 = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[( int)v1]; 
v3 = spelling_0; 
spelling_0->kind = 3; 
spelling_0 = v3 + 1; 
v4 = convert_modes( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), ptr_mode, size, 1); 
v10 = copy_to_mode_reg( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v4); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
while ( constructor_stack_0->implicit ) 
v6->next = constructor_stack_0; 
constructor_stack_0 = v6; 
constructor_depth = spelling_0 - spelling_base; 
v6->range_stack = constructor_range_stack_0; 
constructor_range_stack_0 = 0LL; 
v24 = ( tree_node *)*( &global_trees + 17); 
v3 = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[( int)v3]; 
v5 = spelling_0; 
spelling_0->kind = 2; 
spelling_0 = v5 + 1; 
v1->prev = constructor_range_stack_0; 
v1->stack = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
constructor_range_stack_0->next = v1; 
constructor_range_stack_0 = v1; 
rtx v116; // rax 
rtx ina; // [rsp+8h] [rbp-90h] 
v4 = *( tree_node **)( v3.rtwint + 8); 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
fancy_abort( ( const char *)&stru_665A39, 5554, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5600, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5571, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5610, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5587, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5605, "put_condition_code"); 
p_chain = ( char *)&stru_665A39._chain + 3; 
p_chain = ( char *)&stru_665A39._chain + 6; 
fancy_abort( ( const char *)&stru_665A39, 5578, "put_condition_code"); 
p_chain = ( char *)&stru_665A39._fileno + 1; 
fancy_abort( ( const char *)&stru_665A39, 5615, "put_condition_code"); 
fancy_abort( ( const char *)&stru_665A39, 5591, "put_condition_code"); 
p_chain = ( const char *)&stru_665A39._chain; 
put_reg_into_stack( v6, rtl, decl->common.type, v5, ( machine_mode)supercontext_low, volatile_p, 0, v2, 0LL); 
v3 = ( int)( ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)) 
v3 = ( int)( ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)) 
v3 = ( int)( ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)) 
/ ( double)( qty_0[v2].death - qty_0[v2].birth) 
/ ( double)( qty_0[v2].death - qty_0[v2].birth) 
- ( int)( ( double)( qty_0[v4].size * qty_0[v4].freq * floor_log2_wide( qty_0[v4].n_refs)) 
- ( int)( ( double)( qty_0[v4].size * qty_0[v4].freq * floor_log2_wide( qty_0[v4].n_refs)) 
- ( int)( ( double)( qty_0[v4].size * qty_0[v4].freq * floor_log2_wide( qty_0[v4].n_refs)) 
/ ( double)( qty_0[v4].death - qty_0[v4].birth) 
/ ( double)( qty_0[v4].death - qty_0[v4].birth) 
LODWORD( v5) = ( int)( ( double)( *( int *)( ( char *)&qty_0->size + v5) 
* *( int *)( ( char *)&qty_0->freq + v5) 
* floor_log2_wide( *( int *)( ( char *)&qty_0->n_refs + v5))) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
v17 = ( tree_node *)*( &global_trees + 12); 
v17 = ( tree_node *)*( &global_trees + 11); 
aka = ( tree_node *)prev_try->aka; 
v8 = ( tree_node *)prev_try->aka; 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
if ( v6 == -1 || ( sch_istable[( unsigned __int8)v6] & 0xC00) != 0 ) 
while ( ( sch_istable[v3] & 4) != 0 ) 
if ( ( sch_istable[( unsigned __int8)v9] & 0xC00) == 0 ) 
while ( v10 != -1 && ( sch_istable[( unsigned __int8)v10] & 1) != 0 ); 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
constructor_stack_0 = v2; 
constructor_depth = spelling_0 - spelling_base; 
rtx i; // rax 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
v6.rtwint = ( __int64)i->fld[0]; 
rtx op; // [rsp+0h] [rbp-48h] 
rtx opa; // [rsp+0h] [rbp-48h] 
rtx opb; // [rsp+0h] [rbp-48h] 
rtx opc; // [rsp+0h] [rbp-48h] 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = v528; 
recog_data_0.operand[0] = v528; 
recog_data_0.operand[0] = v53; 
recog_data_0.operand[1] = ( rtx)v54; 
recog_data_0.operand[0] = v17; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v5; 
recog_data_0.operand[1] = v5; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = ( rtx)v21; 
recog_data_0.operand[2] = v30; 
recog_data_0.operand[1] = ( rtx)v21; 
recog_data_0.operand[2] = v27; 
recog_data_0.operand[1] = ( rtx)v21; 
recog_data_0.operand[1] = v38; 
recog_data_0.operand[2] = v39; 
recog_data_0.operand[1] = v6; 
recog_data_0.operand[2] = v16; 
recog_data_0.operand[2] = v62; 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[1] = v52; 
recog_data_0.operand[2] = v53; 
recog_data_0.operand[1] = v55; 
recog_data_0.operand[2] = v56; 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v73; 
recog_data_0.operand[2] = v85; 
recog_data_0.operand[2] = v83; 
recog_data_0.operand[2] = ( rtx)v51; 
recog_data_0.operand[1] = v24; 
recog_data_0.operand[2] = v25; 
if ( !rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
recog_data_0.operand[0] = v5.rtx; 
recog_data_0.operand[1] = v278; 
recog_data_0.operand[2] = v282; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)v282 != 66) 
recog_data_0.operand[1] = v277; 
recog_data_0.operand[2] = v280; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)v280 != 66) 
recog_data_0.operand[0] = ( rtx)v5; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[0] = v15; 
recog_data_0.operand[1] = v31; 
recog_data_0.operand[2] = v58; 
recog_data_0.operand[2] = v58; 
recog_data_0.operand[2] = v53; 
recog_data_0.operand[2] = ( rtx)v34; 
recog_data_0.operand[1] = v38; 
recog_data_0.operand[2] = v42; 
recog_data_0.operand[1] = v21; 
recog_data_0.operand[2] = ( rtx)v24; 
recog_data_0.operand[2] = ( rtx)v24; 
recog_data_0.operand[2] = v47; 
recog_data_0.operand[0] = v5; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[2] = v35; 
recog_data_0.operand[3] = v38; 
if ( rtx_equal_p( *( rtx *)( v39 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v39 + 16), recog_data_0.operand[2]) 
recog_data_0.operand[0] = v5; 
recog_data_0.operand[1] = v41; 
recog_data_0.operand[2] = v42; 
result = -( ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand) == 0); 
v94 = ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand); 
recog_data_0.operand[1] = v46; 
recog_data_0.operand[2] = v47; 
result = -( ix86_binary_operator_ok( MINUS, HImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v62; 
return ix86_unary_operator_ok( NEG, HImode, recog_data_0.operand) == 0 ? -1 : 0x15F; 
recog_data_0.operand[1] = v50; 
recog_data_0.operand[2] = v51; 
recog_data_0.operand[0] = v4.rtx; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[0] = v8; 
recog_data_0.operand[1] = v39; 
recog_data_0.operand[1] = v27; 
recog_data_0.operand[2] = v45; 
recog_data_0.operand[2] = v45; 
recog_data_0.operand[2] = v42; 
recog_data_0.operand[2] = ( rtx)v30; 
recog_data_0.operand[1] = v73; 
recog_data_0.operand[2] = v74; 
result = -( ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = ( rtx)v15; 
recog_data_0.operand[2] = v16; 
recog_data_0.operand[2] = v16; 
result = -( ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v21; 
recog_data_0.operand[2] = v81; 
result = -( ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand) == 0); 
recog_data_0.operand[2] = ( rtx)v22; 
recog_data_0.operand[2] = ( rtx)v22; 
result = -( ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v39; 
|| ( v86 = ix86_unary_operator_ok( NEG, DImode, recog_data_0.operand), result = 344, !v86) ) 
recog_data_0.operand[1] = ( rtx)v5; 
if ( rtx_equal_p( *( rtx *)( v51 + 16), recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = v126; 
recog_data_0.operand[2] = v128; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 ) 
recog_data_0.operand[1] = v121; 
recog_data_0.operand[2] = v123; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 ) 
recog_data_0.operand[1] = ( rtx)v8; 
recog_data_0.operand[2] = v10; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 ) 
recog_data_0.operand[2] = v13; 
recog_data_0.operand[3] = v14; 
recog_data_0.operand[1] = v16; 
if ( rtx_equal_p( *( rtx *)( v17 + 8), recog_data_0.operand[2]) ) 
if ( rtx_equal_p( v18, recog_data_0.operand[3]) 
else if ( rtx_equal_p( v18, recog_data_0.operand[3]) ) 
recog_data_0.operand[1] = v19; 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v59; 
recog_data_0.operand[0] = v82; 
recog_data_0.operand[2] = v59; 
recog_data_0.operand[0] = v63; 
if ( rtx_equal_p( *( rtx *)( v64 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v64 + 16), recog_data_0.operand[2]) ) 
result = -( ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v5; 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = v65; 
if ( rtx_equal_p( *( rtx *)( v66 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v66 + 16), recog_data_0.operand[2]) ) 
if ( ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) ) 
return pic_symbolic_operand( recog_data_0.operand[2], VOIDmode) == 0 ? 203 : -1; 
recog_data_0.operand[0] = v67; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
if ( *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v75; 
recog_data_0.operand[0] = v194; 
if ( recog_data_0.operand[2]->fld[0].rtint != 0x80000000 ) 
recog_data_0.operand[2] = v75; 
recog_data_0.operand[0] = ( rtx)v79; 
if ( rtx_equal_p( *( rtx *)( v195 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v195 + 16), recog_data_0.operand[2]) ) 
result = -( ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) == 0); 
recog_data_0.operand[0] = ( rtx)v79; 
if ( rtx_equal_p( *( rtx *)( v197 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v197 + 16), recog_data_0.operand[2]) ) 
result = -( ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v5; 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = ( rtx)v81; 
if ( rtx_equal_p( *( rtx *)( v84 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v84 + 16), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = ( rtx)v4; 
recog_data_0.operand[2] = v59; 
recog_data_0.operand[0] = v82; 
if ( LOWORD( recog_data_0.operand[2]->fld[0].rtwint) != 0x8000 ) 
recog_data_0.operand[2] = v59; 
recog_data_0.operand[0] = v63; 
if ( rtx_equal_p( *( rtx *)( v64 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v64 + 16), recog_data_0.operand[2]) ) 
result = -( ix86_binary_operator_ok( MINUS, HImode, recog_data_0.operand) == 0); 
recog_data_0.operand[1] = v5; 
recog_data_0.operand[2] = v6; 
recog_data_0.operand[0] = v65; 
if ( rtx_equal_p( *( rtx *)( v66 + 8), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v66 + 16), recog_data_0.operand[2]) ) 
result = -( ix86_binary_operator_ok( PLUS, HImode, recog_data_0.operand) == 0); 
recog_data_0.operand[0] = v67; 
if ( *( _WORD *)recog_data_0.operand[1] == 66 ) 
if ( *( _WORD *)recog_data_0.operand[2] != 66 ) 
recog_data_0.operand[1] = ( rtx)v387; 
recog_data_0.operand[2] = v389; 
recog_data_0.operand[0] = v395; 
if ( !rtx_equal_p( *( rtx *)( v396 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = ( rtx)v387; 
recog_data_0.operand[2] = v392; 
recog_data_0.operand[0] = v401; 
if ( !rtx_equal_p( *( rtx *)( v402 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = ( rtx)v268; 
recog_data_0.operand[2] = v273; 
recog_data_0.operand[0] = v276; 
if ( rtx_equal_p( *( rtx *)( v277 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = ( rtx)v268; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v12; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v17; 
recog_data_0.operand[1] = ( rtx)v13; 
if ( *( _WORD *)recog_data_0.operand[0] != 66 ) 
recog_data_0.operand[0] = v14; 
recog_data_0.operand[1] = v15; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v21; 
recog_data_0.operand[1] = v20; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[2] = ( rtx)v102; 
recog_data_0.operand[3] = v106; 
recog_data_0.operand[0] = v109; 
if ( rtx_equal_p( *( rtx *)( v110 + 8), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = v114; 
if ( rtx_equal_p( *( rtx *)( v115 + 8), recog_data_0.operand[3]) ) 
recog_data_0.operand[2] = ( rtx)v102; 
recog_data_0.operand[3] = v120; 
recog_data_0.operand[0] = v123; 
if ( rtx_equal_p( *( rtx *)( v124 + 8), recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = v128; 
if ( rtx_equal_p( *( rtx *)( v129 + 8), recog_data_0.operand[3]) ) 
recog_data_0.operand[0] = ( rtx)v4; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v10; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v11; 
recog_data_0.operand[1] = v11; 
recog_data_0.operand[0] = rtx; 
recog_data_0.operand[1] = v21; 
recog_data_0.operand[1] = ( rtx)v19; 
if ( ( ( mode_class_0[v20] & 0xFFFFFFFB) == 2 || mode_class_0[v20] == MODE_VECTOR_FLOAT) 
if ( ( ( mode_class_0[v20] & 0xFFFFFFFB) == 2 || mode_class_0[v20] == MODE_VECTOR_FLOAT) 
recog_data_0.operand[1] = v28; 
recog_data_0.operand[1] = v21; 
recog_data_0.operand[1] = v22; 
recog_data_0.operand[1] = ( rtx)v25; 
recog_data_0.operand[2] = v35; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
recog_data_0.operand[1] = ( rtx)v25; 
recog_data_0.operand[2] = v36; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = ( rtx)v25; 
recog_data_0.operand[2] = v26; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
recog_data_0.operand[1] = ( rtx)v23; 
recog_data_0.operand[2] = v33; 
recog_data_0.operand[1] = v27; 
recog_data_0.operand[1] = ( rtx)v25; 
recog_data_0.operand[1] = v28; 
recog_data_0.operand[1] = ( rtx)v26; 
recog_data_0.operand[1] = ( rtx)v31; 
recog_data_0.operand[2] = v41; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
recog_data_0.operand[1] = ( rtx)v31; 
recog_data_0.operand[2] = v42; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = ( rtx)v31; 
recog_data_0.operand[2] = v32; 
if ( rtx_equal_p( *( rtx *)( v3 + 16), recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)( v3 + 24), recog_data_0.operand[2]) 
reg_dead_regno = v27; 
reg_dead_endregno = v27 + 1; 
reg_dead_flag = 0; 
v24 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v30 + 2)] - 5) < 2) + 1; 
reg_dead_endregno = v25; 
reg_dead_flag = 0; 
if ( reg_dead_flag ) 
if ( reg_dead_flag == 1 ) 
if ( find_regno_note( nonnote_insn, REG_DEAD, reg_dead_regno) ) 
v28 = reg_dead_regno; 
if ( reg_dead_regno < reg_dead_endregno ) 
if ( reg_dead_regno < reg_dead_endregno ) 
if ( ++v28 >= reg_dead_endregno ) 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
frees->next = undobuf_0.undos; 
undobuf_0.undos = frees; 
v14 = &costs_0[x->fld[0].rtuint]; 
v14->mem_cost += scale * ix86_memory_move_cost( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), a2, 1) / 2; 
alias_set_entry_0 v3; // rax 
v28 = ( tree_node *)i[4]; 
v30 = lang_hooks_0.expand_constant( exp); 
v7 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v4 + 2)] - 5) < 2) + 1; 
rtx v33; // rax 
rtx mult_valb; // [rsp+8h] [rbp-50h] 
rtx set; // [rsp+10h] [rbp-48h] 
v->next_iv = *( induction_1 **)( v36 + 24); 
v->mode = *( unsigned __int8 *)( set->fld[0].rtwint + 2); 
v->next_iv = *( induction_1 **)( v21 + 24); 
mult_valb = ( rtx)reg_n_info; 
v16 = gen_lowpart_if_possible( ( machine_mode)v14, op1); 
v13 = gen_lowpart_if_possible( ( machine_mode)v11, op0); 
v19 = gen_lowpart_if_possible( ( machine_mode)v17, v7); 
v22 = gen_lowpart_if_possible( ( machine_mode)v20, op0); 
|| ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] & 0xFFFFFFFB) == 2 
|| mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_VECTOR_FLOAT ) 
|| ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT) 
|| ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT) 
v3 = &reg_avail_info_0[regno]; 
v4 = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
allocno_0[( __int64)v8].hard_reg_conflicts |= hard_regs_live; 
v3 = allocno_0; 
reg_set_0 **v5; // rax 
reg_set_0 **v5; // rax 
reg_set_table = ( reg_set_0 **)xrealloc( reg_set_table, ( unsigned int)( 8 * ( regno + 100))); 
v5 = &reg_set_table[regno]; 
*( _QWORD *)object_base = *v5; 
*v5 = ( reg_set_0 *)object_base; 
*v5 = ( reg_set_0 *)object_base; 
v9 = address_operand( v55, ( machine_mode)*( ( unsigned __int8 *)v55 + 2)); 
if ( recog_data_0.operand_type[v54] == OP_OUT 
|| ( alt_cost += copy_cost_0( v55, mode, v45, 1), recog_data_0.operand_type[v54]) ) 
if ( v9 || reg_fits_class_p( v55, *v88, 0, ( machine_mode)*( ( unsigned __int8 *)v55 + 2)) ) 
v47 = recog_data_0.operand_type[v54]; 
*v12 = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v11); 
rtx v31; // rax 
rtx valuea[8]; // [rsp+8h] [rbp-40h] BYREF 
valuea[0] = value; 
v6 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) < 2) + 1; 
if ( valuea[0] && insn && reg_overlap_mentioned_p( reg, valuea[0]) ) 
if ( valuea[0] && insn && reg_overlap_mentioned_p( reg, valuea[0]) ) 
v23 = copy_rtx( valuea[0]); 
valuea[0] = replace_rtx( v23, reg, rtx); 
if ( valuea[0] ) 
update_table_tick( valuea[0]); 
v27[v28] = valuea[0] && v25 == v26[v28]; 
*( _QWORD *)v25 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v21); 
v20 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v4 + 2)] - 5) < 2) + 1; 
v13 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v4 + 2)] - 5) < 2) + 1; 
rtx *v26; // r13 
v16 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v4 + 2)] - 5) < 2) + 1; 
v13 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v4 + 2)] - 5) < 2) + 1; 
v26 = ( rtx *)*v10 + v25; 
v28 = ( __int64)&v26[-( v25 - 1) - 1]; 
while ( v26 == loc || !refers_to_regno_p( regno, endregno, *v26, loc) ) 
while ( v26 == loc || !refers_to_regno_p( regno, endregno, *v26, loc) ) 
if ( reg_pref_0 ) 
return reg_pref_0[regno].altclass; 
v11 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
v16 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v10 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
v10 = next_qty_0++; 
v12 = &qty_0[v11]; 
v14 = &qty_0[v11]; 
v15 = &qty_0[v11]; 
qty_0[v6].death = -1; 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
post_mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1, birth, 2 * this_insn_number); 
fancy_abort( ( const char *)&a, 7617, "reg_number"); 
( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)); 
v14 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
v10 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) < 2) + 1; 
if ( reg_pref_0 ) 
return reg_pref_0[regno].prefclass; 
if ( !reg_note ) 
v30 = *( _WORD *)reg_note->fld[0].rtwint; 
v33 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v29 + 2)] - 5) < 2) + 1; 
costs_0 = (  struct costs *)xmalloc( 104LL * nregs); 
memset( costs_0, 0, 104LL * nregs); 
reg_pref_0 = reg_pref_buffer; 
fprintf( dump, " %s:%i", reg_class_names_0[m], ( unsigned int)costs_0->cost[( unsigned int)m + v6 / 4]); 
fprintf( dump, " %s:%i", reg_class_names_0[m], ( unsigned int)costs_0->cost[( unsigned int)m + v6 / 4]); 
fprintf( dump, " MEM:%i\n", ( unsigned int)costs_0[v6 / 0x68].mem_cost); 
v23 = &costs_0[n]; 
v24 = &reg_pref_0[n]; 
fprintf( dump, " pref %s\n", reg_class_names_1[v16]); 
fprintf( dump, " pref %s, else %s\n", reg_class_names_1[v16], reg_class_names_1[v21]); 
fprintf( dump, " pref %s, else %s\n", reg_class_names_1[v16], reg_class_names_1[v21]); 
fprintf( dump, " pref %s or none\n", reg_class_names_1[v16]); 
v22 = &reg_pref_0[n]; 
free( costs_0); 
if ( !reg_class_subset_p( ( reg_class)class0, ( reg_class)class1) || ( result = 1, ( unsigned int)( class0 - 1) <= 6) ) 
result = reg_class_subset_p( ( reg_class)class1, ( reg_class)class0); 
reg_pref_0 = 0LL; 
if ( mode_class_0[v2] != MODE_FLOAT || ( result = 0, mode_size[v2] <= mode_size[*( unsigned __int8 *)( v4.rtwint + 2)]) ) 
rtx v55; // rax 
rtx real_insn; // r12 
rtx v58; // rbx 
rtx v68; // rax 
rtx v71; // rsi 
rtx v84; // r12 
rtx v85; // r13 
rtx v90; // rax 
rtx *v105; // rax 
rtx v109; // rsi 
v6 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
closed_chains = 0LL; 
open_chains = 0LL; 
unavailable = recog_data_0.n_operands; 
n_operands = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
v2 = ( reg_class *)( 32LL * which_alternative + 9844808); 
else if ( *( ( int *)v2 + 3) < 0 && ( v31 != 38 || recog_data_0.operand_type[v1] != OP_OUT) ) 
recog_data_0.operand_type[v1] = OP_INOUT; 
recog_data_0.operand_loc[v4], 
recog_data_0.operand_type[v4], 
to[v5] = ( HARD_REG_ELT_TYPE)recog_data_0.operand[v5]; 
if ( *recog_data_0.constraints[v5] ) 
*recog_data_0.operand_loc[v5] = global_rtl[1]; 
if ( recog_data_0.n_dups > 0 ) 
v8 = ( HARD_REG_ELT_TYPE *)recog_data_0.dup_loc[v6]; 
page_group_0 *v3; // rbx 
page_group_0 *v3; // rbx 
v1 = ( page_entry_0 *)( &G + 2640); 
v3 = ( page_group_0 *)( &G + 2648); 
v3 = ( page_group_0 *)( &G + 2648); 
v3 = page_groups; 
v3->next = page_groups->next; 
page_groups = v3->next; 
while ( v3->next ); 
rtx v14; // r12 
rtx *v20; // r15 
rtx *v21; // rbp 
rtx *v22; // r15 
rtx *v25; // rbp 
rtx k; // rbx 
rtx m; // rbx 
rtx v44; // r12 
rtx v53; // rax 
rtx v55; // rsi 
rtx v240; // [rsp+58h] [rbp-80h] 
rtx arg0; // [rsp+60h] [rbp-78h] 
rtx arg0a; // [rsp+60h] [rbp-78h] 
rtx ya; // [rsp+68h] [rbp-70h] 
rtx yb; // [rsp+68h] [rbp-70h] 
rtx next; // [rsp+70h] [rbp-68h] 
rtx v6; // rdi 
rtx *v11; // rbp 
v6 = const_int_rtx[64]; 
v15 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v12.rtwint + 2)] - 5) < 2) + 1; 
v6 = ( rtx)rtx[1]; 
if ( *( _WORD *)v6 != 54 ) 
if ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] - 5) <= 1 ) 
reg_state[v24].offset = v6; 
if ( rtx_equal_p( v6, reg_state[( int)rtuint].offset) ) 
v11 = ( rtx *)rtx + v8; 
reload_combine_note_use( v11, insn); 
v33 = *( _DWORD *)*v11; 
$46E27178171750CEF28E8B43DEBEAD96 *v26; // r8 
$46E27178171750CEF28E8B43DEBEAD96 *v26; // r8 
rtx v75; // rax 
rtx v76; // r14 
rtx ptra; // [rsp+8h] [rbp-90h] 
rtx newa; // [rsp+20h] [rbp-78h] 
$46E27178171750CEF28E8B43DEBEAD96 *v100; // [rsp+28h] [rbp-70h] 
$46E27178171750CEF28E8B43DEBEAD96 *v100; // [rsp+28h] [rbp-70h] 
rtx arg1; // [rsp+38h] [rbp-60h] 
rtx orig; // [rsp+40h] [rbp-58h] 
rtx insn; // [rsp+48h] [rbp-50h] 
if ( !recog_data_0.n_alternatives ) 
if ( recog_data_0.n_operands ) 
fatal_insn_not_found( insna, "reload1.c", 8371, "reload_cse_simplify_operands"); 
v2 = 4LL * recog_data_0.n_alternatives; 
if ( recog_data_0.n_operands > 0 ) 
v9 = recog_data_0.operand[v6]; 
if ( v10 != 140 && v10 != 134 && v11 || recog_data_0.operand_mode[v6] ) 
v12 = cselib_lookup( v9, recog_data_0.operand_mode[v6], 0); 
while ( recog_data_0.n_operands > ( int)v6 ); 
if ( recog_data_0.n_operands > 0 ) 
n_alternatives = recog_data_0.n_alternatives; 
v28 = alloca( 16 * ( ( 4LL * recog_data_0.n_alternatives + 23) / 0x10uLL)); 
v15 = recog_data_0.constraints[i]; 
mode = recog_data_0.operand_mode[i]; 
if ( true_regnum( recog_data_0.operand[i]) < 0 && *p != 43 && *p != 61 ) 
v23 = recog_data_0.operand[i]; 
v9 = ix86_memory_move_cost( ( machine_mode)*( ( unsigned __int8 *)v5 + 2), dclass, 1); 
( machine_mode)*( ( unsigned __int8 *)v5 + 2), 
v10 = cselib_lookup( v5, ( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)loc + 2), 
v15 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v15 = *( tree_node **)( v10 + 64); 
v15 = ( tree_node *)v10; 
if ( use == sibcall_use_tail_recursion_0 ) 
else if ( use == sibcall_use_sibcall_0 ) 
if ( use != sibcall_use_normal_0 ) 
( machine_mode)*( ( unsigned __int8 *)v7 + 2), 
*loc = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v12 + 2), v15); 
replace_pseudos_in_call_usage( ( rtx *)v4->fld, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), usage); 
if ( ( mode_class_0[*( ( unsigned __int8 *)v2 + 2)] & 0xFFFFFFFB) != 2 ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
rtx last_insn; // rbx 
rtx j; // rbp 
rtx v10; // r14 
last_insn = get_last_insn( ); 
if ( last_insn ) 
j = 0LL; 
v10 = 0LL; 
if ( *( _WORD *)last_insn == 37 ) 
if ( last_insn[2].fld[0].rtint == -89 ) 
j = last_insn; 
j = last_insn; 
else if ( contains( last_insn, v8) ) 
v10 = last_insn; 
v10 = last_insn; 
v10 = last_insn; 
v10 = last_insn; 
for ( ; ( sch_istable[*( unsigned __int8 *)v2] & 4) != 0; ++v2 ) 
sprintf( p, &off_6376D2[1], v6); 
v6 = prefixes_18[v3][( BYTE2( decl->block.supercontext) & 8) != 0]; 
timevar_push( TV_REST_OF_COMPILATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_TO_SSA_0); 
timevar_pop( TV_TO_SSA_0); 
timevar_push( TV_SSA_CCP_0); 
timevar_pop( TV_SSA_CCP_0); 
timevar_push( TV_SSA_DCE_0); 
timevar_pop( TV_SSA_DCE_0); 
timevar_push( TV_FROM_SSA_0); 
timevar_pop( TV_FROM_SSA_0); 
timevar_push( TV_VARCONST_0); 
timevar_pop( TV_VARCONST_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
rtx v4; // rax 
rtx line_note; // r13 
rtx v10; // rax 
v4 = head; 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
v4 = ( rtx)v4[1]; 
while ( v4 ); 
v4 = 0LL; 
v4 = v2; 
line_note = h_i_d[rtint].line_note; 
if ( line_note != v4 
if ( line_note != v4 
&& line_note 
&& ( !v4 || line_note[2].fld[0].rtint != v4[2].fld[0].rtint || line_note[2] != v4[2]) ) 
&& ( !v4 || line_note[2].fld[0].rtint != v4[2].fld[0].rtint || line_note[2] != v4[2]) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 1990, "result_ready_cost"); 
return memory_operand( recog_data_0.operand[1], VOIDmode) == 0 ? 1 : 3; 
if ( ix86_cpu != PROCESSOR_PENTIUMPRO || ( v3 = 3, !memory_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
return 1 - ( ( symbolic_operand( recog_data_0.operand[1], SImode) == 0) - 1); 
return memory_operand( recog_data_0.operand[1], VOIDmode) == 0 ? 1 : 3; 
return 1 - ( ( symbolic_operand( recog_data_0.operand[1], DImode) == 0) - 1); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( which_alternative || pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
( rtx_code)*( _WORD *)comparison, 
v7 = mode_class_0[v6]; 
rtx v7; // rdx 
rtx v10; // rax 
v7 = head; 
if ( *( _WORD *)v7 == 37 ) 
v8 = (  struct rtx_def *)v7[1]; 
if ( rtx == v7 ) 
v10 = v7; 
v10 = v7; 
v10 = v7; 
v10 = v7; 
v9 = v10; 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
v8[1].fld[0].rtwint = ( __int64)v10; 
if ( v10 ) 
*( _QWORD *)&v10[1] = v8; 
rtx v5; // rsi 
rtx v10; // rax 
v5 = head; 
if ( *( _WORD *)v5 == 37 ) 
v11 = ( __int64)v5[1]; 
if ( rtx == v5 ) 
v10 = v5; 
v10 = v5; 
v10 = v5; 
v10 = v5; 
v9.rtwint = ( __int64)v10; 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
*( _QWORD *)( v11 + 24) = v10; 
if ( v10 ) 
*( _QWORD *)&v10[1] = v11; 
while ( rtx != v10 && *( _WORD *)v10 == 37 ); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
v9 = expand_divmod( 0, TRUNC_DIV_EXPR, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v7, v8, 0LL, 1); 
return expand_mult( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v9, v10, 0LL, 1); 
v1 = gen_reg_rtx( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4)); 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
return expand_simple_binop( ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), AND, v4, v3, v4, 0, OPTAB_LIB_WIDEN); 
if ( mode_class_0[( BYTE5( type->common.type->block.abstract_origin) >> 1) & 0x7F] != MODE_INT ) 
fancy_abort( ( const char *)&a, 8957, "rtl_for_decl_location"); 
v5 += rtx_cost( x->fld[v6].rtx, ( rtx_code)v4); 
v5 += rtx_cost( *( rtx *)&rtwint[2 * v47++ + 2], ( rtx_code)v4); 
v26 = mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFD; 
v11 = cselib_lookup( x, ( machine_mode)*( ( unsigned __int8 *)x + 2), 0); 
v12 = cselib_lookup( y, ( machine_mode)*( ( unsigned __int8 *)y + 2), 0); 
fancy_abort( ( const char *)&insn, 530, "rtx_equal_for_cselib_p"); 
v6 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( v5.rtwint + 2), x); 
v4 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2), y); 
if ( *( _OWORD *)&x == 0LL ) 
rtint = subreg_regno_offset( v14, ( machine_mode)*( unsigned __int8 *)( v13.rtwint + 2), v9, ( machine_mode)v6); 
rtint = subreg_regno_offset( v14, ( machine_mode)*( unsigned __int8 *)( v13.rtwint + 2), v9, ( machine_mode)v6); 
( machine_mode)*( unsigned __int8 *)( v15.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2)); 
save_expr_list_5 = 0LL; 
for ( i = save_expr_list_5; i; i = i->common.chain ) 
rtl_op = first_rtl_op( ( tree_code)*( unsigned __int8 *)( v4 + 16)); 
v10 = lang_hooks_0.safe_from_p( v3, ( tree)v4); 
save_expr_list_5 = tree_cons( exp, 0LL, save_expr_list_5); 
save_expr_list_5 = tree_cons( exp, 0LL, save_expr_list_5); 
v2 = ( machine_mode *)( regno_save_mode + 4); 
if ( ( unsigned int)( mode_class_0[v10] - 5) > 1 ) 
v33 = ( ( unsigned int)( mode_class_0[v31] - 5) < 2) + 1; 
v34 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)v30 + 2), v25); 
v13 = gen_realpart( ( machine_mode)*( unsigned __int8 *)( rtl->fld[0].rtwint + 2), rtl); 
v14 = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)v13 + 2), rtl); 
( save_level)( x_block_stack->next == 0LL), 
rtx start; // r13 
rtx v10; // r12 
rtx v11; // rax 
rtx v15; // rax 
rtx v17; // rax 
rtx scan_start; // rax 
rtx v20; // rax 
rtx cont; // rax 
rtx insn_in_loop; // r13 
v11 = ix86_memory_move_cost( ( machine_mode)*( unsigned __int8 *)( v3->fld[0].rtwint + 2), GENERAL_REGS, 1); 
v13 = &costs_0[*( unsigned int *)( v3->fld[0].rtwint + 8)]; 
&& recog_data_0.n_operands > 2 
&& *recog_data_0.constraints[1] == 48 
&& !*( ( _BYTE *)recog_data_0.constraints[1] + 1) ) 
if ( ( unsigned __int16)( *( _WORD *)recog_data_0.operand[1] - 54) <= 0xEu ) 
v15 = ( ( 0x6017uLL >> ( ( unsigned __int8)*( _WORD *)recog_data_0.operand[1] - 54)) ^ 1) & 1; 
if ( ( *( _WORD *)recog_data_0.operand[1] == 140 || *( _WORD *)recog_data_0.operand[1] == 134 || !v15) 
if ( ( *( _WORD *)recog_data_0.operand[1] == 140 || *( _WORD *)recog_data_0.operand[1] == 134 || !v15) 
&& !rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[1]) ) 
&& !rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[1]) ) 
v16 = rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[2]); 
v16 = rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[2]); 
if ( !v16 && *( _WORD *)recog_data_0.operand[0] == 61 ) 
v17 = *( ( _BYTE *)recog_data_0.operand[0] + 2); 
if ( v17 == recog_data_0.operand_mode[1] ) 
v19 = gen_lowpart( recog_data_0.operand_mode[1], recog_data_0.operand[0]); 
scan_rtx_address( insn, ( rtx *)v9->fld, GENERAL_REGS, action, ( machine_mode)*( ( unsigned __int8 *)v9 + 2)); 
scan_rtx_address( insn, ( rtx *)v7->fld, GENERAL_REGS, action, ( machine_mode)*( ( unsigned __int8 *)v7 + 2)); 
v11 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
v20 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v22 + 2)] - 5) < 2) + 1; 
cselib_lookup( t->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1); 
v12 = ( ( unsigned int)( mode_class_0[*( unsigned __int8 *)( v3.rtwint + 2)] - 5) < 2) + 1; 
v8 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
cselib_lookup( v13->fld[0].rtx, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 1); 
add_dependence( insn, pending_write_insns->fld[0].rtx, ( reg_note)0); 
add_dependence_list( insn, v39->sets, ( reg_note)0); 
add_dependence_list( insn, v39->clobbers, ( reg_note)0); 
add_dependence_list_and_free( insn, &v42->sets, ( reg_note)0); 
add_dependence_list_and_free( insn, &v42->clobbers, ( reg_note)0); 
add_dependence_list( insn, v48->sets, ( reg_note)0); 
add_dependence_list( insn, v48->clobbers, ( reg_note)0); 
rtx j; // rbx 
rtx v25; // [rsp+0h] [rbp-38h] BYREF 
rtx tailp; // [rsp+8h] [rbp-30h] BYREF 
get_block_head_tail( v9, &v25, &tailp); 
get_block_head_tail( v9, &v25, &tailp); 
v24.rtwint = ( __int64)tailp[1].fld[0]; 
for ( j = v25; v24.rtx != j; j = j[1].fld[0].rtx ) 
for ( j = v25; v24.rtx != j; j = j[1].fld[0].rtx ) 
for ( j = v25; v24.rtx != j; j = j[1].fld[0].rtx ) 
for ( j = v25; v24.rtx != j; j = j[1].fld[0].rtx ) 
for ( j = v25; v24.rtx != j; j = j[1].fld[0].rtx ) 
if ( rtx_class[*( _WORD *)j] == 105 ) 
v23 = ( __int64)j[2]; 
rtx v11; // rbx 
rtx *v16; // rbx 
rtx nonnote_insn; // r13 
rtx v121; // r12 
rtx v122; // rbx 
rtx v125; // rbx 
rtx v127; // rbp 
deps_0 *v129; // rax 
deps_0 *v129; // rax 
rtx *p_pending_read_insns; // rbx 
rtx *v191; // rax 
deps_0 *old_insns_pa; // [rsp+20h] [rbp-138h] 
deps_0 *old_insns_pa; // [rsp+20h] [rbp-138h] 
rtx *old_insns_pb; // [rsp+20h] [rbp-138h] 
fancy_abort( ( const char *)&a, 9575, "scope_die_for"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE && ( *( ( _BYTE *)&rtl[1] + 1) & 0x40) == 0 ) 
fancy_abort( ( const char *)&a, 9604, "scope_die_for"); 
if ( ( tree_node *)v4 != initial ) 
initial = ( tree_node *)v4; 
rtx v4; // rbp 
v4 = rtx; 
if ( active_insn_p( v4) && ( unsigned __int16)( **( _WORD **)&v4[2] - 44) > 1u ) 
if ( active_insn_p( v4) && ( unsigned __int16)( **( _WORD **)&v4[2] - 44) > 1u ) 
insn_scopes->data.l[v4->fld[0].rtint] = v3; 
else if ( *( _WORD *)v4 == 37 ) 
rtint = v4[2].fld[0].rtint; 
v3 = ( __int64)v4[2]; 
delete_insn( v4); 
delete_insn( v4); 
v2 = ( tree_node *)*( &global_trees + 27); 
v3 = ( tree_node *)*( &global_trees + 24); 
if ( initial != ( tree_node *)global_trees ) 
if ( initial != ( tree_node *)global_trees ) 
if ( constructor_range_stack_0 ) 
while ( constructor_stack_0->implicit ) 
if ( ( unsigned __int64)constructor_range_stack_0 | ( unsigned __int64)elements ) 
if ( constructor_range_stack_0 ) 
rtx nonnote_insn; // rax 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
if ( rtx == insn && ( nonnote_insn = prev_nonnote_insn( insn)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
v9 = ( tree_node *)v6[1]; 
v6 = *( tree_node **)( v5 + 8); 
v6 = ( tree_node *)ref[1]; 
if ( !lang_hooks_0.honor_readonly 
( machine_mode)*( ( unsigned __int8 *)ref + 2)); 
v18 = ( tree_node *)*( &global_trees + 15); 
mem_attrs = get_mem_attrs( alias, v6, offseta, size_unit, align, ( machine_mode)*( ( unsigned __int8 *)ref + 2)); 
v9 = *( tree_node **)( v6 + 8); 
G.lookup[BYTE3( p)] = ( page_entry_0 **)xcalloc( 1LL << ( 24 - LOBYTE( G.lg_pagesize)), 8uLL); 
v2 = gen_rtx_REG( ( machine_mode)*( ( _DWORD *)&rld + 26 * r + 7), spill_regs[i]); 
result = ix86_hard_regno_mode_ok( v3, *( ( machine_mode *)&rld + 26 * r + 7)); 
|| ( result = ix86_hard_regno_mode_ok( v3, ( machine_mode)*( unsigned __int8 *)( v5 + 2))) != 0 ) 
if ( !v6 || ( result = ix86_hard_regno_mode_ok( v3, ( machine_mode)*( unsigned __int8 *)( v6 + 2))) != 0 ) 
*( ( reload_type *)&rld + 26 * r + 23), 
*( ( machine_mode *)&rld + 26 * r + 7)); 
while ( &unk_6F4758 != ( _UNKNOWN *)v4 ); 
reg_note = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, datum, insn[3].fld[0].rtx); 
v5 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v7 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v3] + 2)] - 5) < 2) + 1; 
v21 = *( machine_mode *)( ( char *)&regno_save_mode[0][v14] + v11); 
v25 = ( machine_mode *)( v11 + 9707172); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x, c); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, v6); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, rtx); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v4, v2); 
rtx v61; // rbx 
rtx align_tab[16]; // [rsp+20h] [rbp-B8h] BYREF 
v20 = &align_tab[15]; 
while ( v21 != align_tab ); 
*v27 = align_tab[0]; 
*v27 = align_tab[v26]; 
align_tab[v28--] = last_insn; 
v23[rtint] = align_tab[0]; 
if ( ( tree_node *)*( &global_trees + 10) == section_name ) 
if ( ( tree_node *)*( &global_trees + 9) == section_name ) 
if ( ( tree_node *)*( &global_trees + 8) == section_name ) 
if ( ( tree_node *)*( &global_trees + 7) == section_name ) 
if ( ( tree_node *)*( &global_trees + 6) == section_name ) 
v15 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), *( rtx *)&rtx[1], v8); 
v16 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), rtx->fld[0].rtx, v8); 
v17 = gen_binary( ( rtx_code)*( _WORD *)rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v16, v15); 
v17 = gen_binary( ( rtx_code)*( _WORD *)rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v16, v15); 
rtx v48; // rax 
rtx trueop1; // [rsp+8h] [rbp-90h] 
rtx trueop1b; // [rsp+8h] [rbp-90h] 
rtx rhs; // [rsp+10h] [rbp-88h] 
rhs = op1; 
trueop1 = avoid_constant_pool_reference( op0); 
v12 = trueop1; 
if ( swap_commutative_operands_p( trueop1, v8) ) 
trueop1 = v8; 
rtx i; // r12 
rtx v43; // rax 
rtx v45; // rax 
rtx v47; // rax 
rtx v50; // rax 
rtx v57; // rax 
rtx v60; // rax 
rtx v66; // rsi 
rtx result; // rax 
rtx arg1; // [rsp+0h] [rbp-48h] 
if ( mode_class_0[v8] != MODE_INT ) 
if ( !reg_note ) 
v62 = reg_note->fld[0].rtx; 
rtx compound_operation; // rbp 
rtx v60; // rsi 
rtx zb; // [rsp+8h] [rbp-70h] 
rtx cond_op0a; // [rsp+10h] [rbp-68h] 
return gen_binary( v6, ( machine_mode)v2, *( ( rtx *)rtwint + 1), *( ( rtx *)rtwint + 2)); 
rtx v43; // rsi 
ops[v42++] = ( simplify_plus_minus_op_data)_mm_loadu_si128( ( const __m128i *)v41); 
v22 = gen_rtx_fmt_ee( ( rtx_code)( 75 - ( ( v51->neg == 0) - 1)), mode, v22, v51->op); 
v43 = ops[v42 - 1].op; 
if ( *( _WORD *)v43 == 54 ) 
v43 = neg_const_int( mode, v43); 
v43 = neg_const_int( mode, v43); 
rtx v7; // r13 
rtx v8; // rbx 
rtx result; // rax 
v7 = avoid_constant_pool_reference( rtx); 
v8 = avoid_constant_pool_reference( v6); 
if ( mode_class_0[*( ( unsigned __int8 *)rtx + 2)] == MODE_CC ) 
if ( swap_commutative_operands_p( v7, v8) ) 
if ( swap_commutative_operands_p( v7, v8) ) 
v12 = v7; 
v7 = v8; 
result = simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), v13, v12, v10); 
return simplify_relational_operation( ( rtx_code)*( _WORD *)x, v9, v8.rtx, ( rtx)v7); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( rtx_code)*( _WORD *)x, 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( rtx_code)*( _WORD *)x, 
varop = gen_rtx_fmt_e( ( rtx_code)( ( v13 != ASHIFTRT) + 120), shift_mode, v21); 
varop = gen_rtx_fmt_e( ( rtx_code)( ( v13 != ASHIFTRT) + 120), shift_mode, v18); 
if ( v8 == v12 && v9 > v12 && mode_class_0[outermode] == MODE_INT ) 
if ( mode_class_0[outermode] == MODE_INT ) 
res = simplify_subreg( outermode, v26.rtx, ( machine_mode)*( unsigned __int8 *)( v26.rtwint + 2), v27); 
res = simplify_subreg( outermode, res, ( machine_mode)v18, v20); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, &val0); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)v1 + 2), *( rtx *)&v1[1], &val1); 
|| ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
|| ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
|| ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
|| ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
v21 = simplify_relational_operation( ( rtx_code)*( _WORD *)op0, op0_mode, v19.rtx, *( rtx *)&op0[1]); 
*( _OWORD *)v28.r = *( _OWORD *)&i0[8]; 
v12 = ( rtx_def)v9->fld[0].rtwint; 
*( _OWORD *)v29.r = *( _OWORD *)&i0[8]; 
*( _OWORD *)i0 = ~*( _OWORD *)&v12; 
v25 = mode_class_0[mode]; 
if ( mode_class_0[v11] != MODE_FLOAT || v25 != MODE_INT || ( unsigned int)v8 - 1 > 0x3F ) 
if ( !size_htab_11 ) 
size_htab_11 = htab_create( 0x400uLL, size_htab_hash, size_htab_eq, 0LL); 
ggc_add_deletable_htab( size_htab_11, 0LL, 0LL); 
new_const_10 = make_node( INTEGER_CST); 
ggc_add_tree_root( &new_const_10, 1); 
v3 = new_const_10; 
*( _OWORD *)&new_const_10->block.vars = number; 
*( _OWORD *)&new_const_10->block.vars = number; 
v5 = new_const_10; 
*( ( _BYTE *)&new_const_10->block.common + 18) = ( 8 * ( v4 & 1)) | ( 4 * ( v4 & 1)) | *( ( _BYTE *)&new_const_10->block.common 
*( ( _BYTE *)&new_const_10->block.common + 18) = ( 8 * ( v4 & 1)) | ( 4 * ( v4 & 1)) | *( ( _BYTE *)&new_const_10->block.common 
slot = htab_find_slot( size_htab_11, v5, INSERT); 
v7 = ( tree_node *)*slot; 
v7 = new_const_10; 
*slot = new_const_10; 
new_const_10 = make_node( INTEGER_CST); 
v7 = cpp_trigraph_map[v6]; 
v3 = cpp_trigraph_map[*( ( unsigned __int8 *)buffer->cur + 1)]; 
v14 = sch_istable[*v12]; 
v1 = spelling_0; 
if ( spelling_base >= spelling_0 ) 
v6 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[v2] + 2)] - 5) < 2) + 1; 
rtx v9; // rax 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
v9 = die_attr->dw_attr_val.v.val_addr; 
if ( !v9 ) 
die_parent = (  struct die_struct *)v9[1].fld[0].rtwint; 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 5055, "splice_child_die"); 
recog_data_0.operand[0] = v3.rtx; 
recog_data_0.operand[1] = ( rtx)v83; 
return gen_split_1133( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v84; 
rtx v5; // rax 
v5 = split_insn( i); 
if ( v5 ) 
for ( ; *( _WORD *)v5 == 35; v5 = ( rtx)v5[1] ) 
for ( ; *( _WORD *)v5 == 35; v5 = ( rtx)v5[1] ) 
i = v5; 
lo_half[v6 / 8] = simplify_gen_subreg( SImode, operands[v6 / 8], ( machine_mode)v8, 0); 
hi_half[v6 / 8] = simplify_gen_subreg( SImode, v7, ( machine_mode)v9, 4u); 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v631; 
return gen_split_1178( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v631; 
return gen_split_1179( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v19; 
recog_data_0.operand[1] = v589; 
recog_data_0.operand[2] = v592; 
recog_data_0.operand[3] = v595; 
recog_data_0.operand[4] = v598; 
return gen_split_944( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v19; 
recog_data_0.operand[1] = v599; 
rtx v6; // rax 
rtx v11; // rdx 
v6 = *startp; 
v11 = v6; 
v11 = v6; 
v6 = v6[1].fld[0].rtx; 
v6 = v6[1].fld[0].rtx; 
if ( *( _WORD *)v11 == 37 ) 
rtint = v11[2].fld[0].rtint; 
v7 = v11; 
else if ( v4 == v11 ) 
v4 = v6; 
v9 = ( __int64)v11[1]; 
*( _QWORD *)&v11[1] = v10; 
v11[1].fld[0].rtwint = ( __int64)v4; 
edge_info_0 = ( edge *)xmalloc( 8LL * edges->num_edges); 
for ( flow_edges = entry_exit_blocks[0].succ; succ; edge_info_0[edge_index] = succ ) 
v11 = edge_info_0; 
v23 = edge_info_0; 
( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), 
free( edge_info_0); 
edge_info_0 = 0LL; 
fancy_abort( ( const char *)&a, 972, "stack_adjust_offset"); 
if ( ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT ) 
if ( name == ( tree_node *)*( &global_trees + 50) ) 
if ( name != ( tree_node *)*( &global_trees + 50) ) 
if ( name != ( tree_node *)*( &global_trees + 50) ) 
v5->constructor_stack = constructor_stack_0; 
v5->constructor_range_stack = constructor_range_stack_0; 
v5->spelling = spelling_0; 
v5->next = initializer_stack_0; 
initializer_stack_0 = v5; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
spelling_0 = v9 + 1; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
result = lang_hooks_0.staticp( arg); 
v5 = ( tree_node *)*( &global_trees + 15); 
v6 = expand_expr( valist, 0LL, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), EXPAND_NORMAL); 
tree v9; // rax 
v9 = build( MODIFY_EXPR, valist->common.type, valist, tree); 
*( ( _BYTE *)&v9->block.common + 17) |= 1u; 
expand_expr( v9, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
rtx v12; // r12 
rtx v28; // r14 
v12 = protect_from_queue( value, 0); 
v12 = force_not_mem( v12); 
v12 = force_not_mem( v12); 
emit_move_insn( rtx, v12); 
return v12; 
tree v45; // r12 
v13 = bitpos % get_mode_alignment( ( machine_mode)v12) != 0 ? 0x33 : 0; 
v8 = adjust_address_1( v8, ( machine_mode)v13, v11, 1, 1); 
rtx v40; // r15 
rtx v44; // r14 
rtx v45; // r15 
v10 = expand_expr( exp, 0LL, ( machine_mode)v8, EXPAND_NORMAL); 
v9 = gen_reg_rtx( ( machine_mode)v8); 
v10 = expand_expr( exp, v9, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
v10 = expand_expr( exp, target, ( machine_mode)v23, EXPAND_NORMAL); 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
( machine_mode)( BYTE5( v3->common.type->block.abstract_origin) >> 1), 
( machine_mode)*( unsigned __int8 *)( v4->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
if ( !direct_store[mode] && ( unsigned int)( mode_class_0[mode] - 5) > 1 || ( *( _WORD *)target & 0xFFFD) == 61 ) 
temp = convert_modes( mode, ( machine_mode)v16, temp, 1); 
v9 = gen_lowpart( ( machine_mode)v20, v9); 
v9 = convert_to_mode( ( machine_mode)v20, v9, 1); 
v8 = *( tree_node **)( v7->int_cst.int_cst.low + 32); 
v20 = ( tree_node *)*( &global_trees + 25); 
v29 = *( tree_node **)( rtl[4] + 128LL); 
if ( v29 == ( tree_node *)*( &global_trees + 27) ) 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
v15 = operand_sub*(short *)0xforce( 
v15 = operand_sub*(short *)0xforce( op0, v17, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v15 = operand_sub*(short *)0xforce( op0, v17, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
rtx condition_for_loop; // rax 
rtx v47; // rsi 
rtx v58; // rbp 
rtx v64; // rbp 
rtx v65; // rax 
rtx v76; // rsi 
rtx v86; // rax 
rtx v105; // rdx 
rtx last_insn; // rbx 
if ( check_mode && !ix86_hard_regno_mode_ok( v5, ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2)) ) 
( machine_mode)*( unsigned __int8 *)( v1.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
if ( ( unsigned int)( mode_class_0[xmode] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[ymode] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[ymode] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[xmode] - 5) <= 1 ) 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)x + 2), const_int_rtx[64]); 
( machine_mode)*( unsigned __int8 *)( v5->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)v5 + 2), 
( machine_mode)*( unsigned __int8 *)( v5->fld[0].rtwint + 2)); 
rtx v34; // rax 
rtx v41; // rsi 
rtx *v47; // r13 
rtx **v48; // r14 
rtx v55; // rax 
rtx *v57; // r15 
rtx v64; // rdx 
rtx v71; // rdx 
rtx v76; // rdx 
rtx **v80; // r14 
rtx **clobber_loc; // [rsp+10h] [rbp-90h] 
rtx inner; // [rsp+38h] [rbp-40h] BYREF 
if ( *( _WORD *)v20 == 74 && mode_class_0[*( unsigned __int8 *)( v20 + 2)] == MODE_CC ) 
v35 = gen_lowpart_if_possible( ( machine_mode)v33, v22); 
&& mode_class_0[*( ( unsigned __int8 *)v22 + 2)] == MODE_CC 
rtx *v47; // r13 
rtx regno_note; // rbp 
rtx *v50; // r14 
rtx *v51; // r15 
rtx v54; // rsi 
rtx v55; // rsi 
rtx *v56; // r13 
rtx v57; // r14 
rtx v59; // rbp 
rtx *src1_note; // [rsp+8h] [rbp-80h] 
rtx src2_note; // [rsp+10h] [rbp-78h] 
rtx flags_user; // rax 
rtx v10; // rax 
flags_user = next_flags_user( insn); 
rtx = flags_user; 
if ( !flags_user ) 
v2 = ( __int64)flags_user[2]; 
v10 = next_flags_user( rtx); 
rtx = v10; 
if ( v10 ) 
v2 = ( __int64)v10[2]; 
*( _WORD *)pat = swap_condition( ( rtx_code)v1); 
if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
rtx active_insn; // rax 
rtx end; // rbx 
rtx *loca; // [rsp+10h] [rbp-78h] 
rtx *loc; // [rsp+10h] [rbp-78h] 
end = src->end; 
if ( end ) 
if ( *( _WORD *)end == 36 ) 
if ( src->head == end ) 
if ( active_insn_p( end) ) 
end = ( rtx)end[1]; 
while ( end ); 
if ( src->head != end ) 
if ( *( _WORD *)end == 36 ) 
v1 = stack_0; 
if ( stack_0->timevar != &timevars[timevar] ) 
stack_0 = v1->next; 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, &now); 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, &now); 
v2->next = stack_0; 
stack_0 = v2; 
lang_hooks_0.init_options( ); 
decode_option = lang_hooks_0.decode_option; 
while ( &unk_939F0A != ( _UNKNOWN *)v66 ); 
( ( void (  *)( __int64, unsigned __int64))lang_hooks_0.set_yydebug)( 1LL, v63); 
while ( &unk_939F08 != ( _UNKNOWN *)v67 ); 
stack_limit_rtx = gen_rtx_REG( ( machine_mode)( 5 - ( ( target_flags & 0x2000000) == 0)), v48); 
stack_limit_rtx = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( 5 - ( ( target_flags & 0x2000000) == 0)), v49); 
if ( ( sch_istable[*( unsigned __int8 *)v56] & 4) == 0 ) 
level_3 = v57; 
if ( level_3 == 2 ) 
v59 = level_3; 
if ( !level_3 ) 
level_3 = v59; 
result = truth_value_p( ( tree_code)v2) != 0; 
v6 = base_alias_check( addr, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), v4); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
( tree_code)( ( *( ( _BYTE *)&expr->block.common + 17) & 1) == 0 ? TRUTH_ORIF_EXPR : TRUTH_OR_EXPR), 
( tree_code)( ( *( _BYTE *)( expr->int_cst.int_cst.high + 17) & 1) == 0 ? TRUTH_ORIF_EXPR : TRUTH_OR_EXPR), 
rtx v104; // rax 
rtx v107; // rbp 
rtx v108; // rax 
rtx v120; // rbp 
rtx v168; // rax 
rtx v186; // rax 
rtx v205; // rax 
rtx nonnote_insn; // rax 
rtx v220; // rbp 
rtx v17; // rax 
rtx x; // [rsp+18h] [rbp-60h] BYREF 
x = ( rtx)v6; 
for_each_rtx( &x, replace_loop_reg, &arg); 
v17 = find_reg_note( v9, REG_RETVAL, 0LL); 
if ( v17 ) 
rtx = v17->fld[0].rtx; 
&& ( v72 != swap_condition( ( rtx_code)nmatchb) 
( machine_mode)*( unsigned __int8 *)( v17.rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( v17.rtwint + 2), 
( machine_mode)( BYTE5( index_type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( range->common.type->block.abstract_origin) >> 1), 
emit_cmp_and_jump_insns( v14, v17, GTU, 0LL, ( machine_mode)v18, 1, default_label); 
v20 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)v18, table_label); 
v23 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v14, v22); 
v24 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( target_flags & 0x2000000) != 0) + 4), v23, v20); 
v26 = memory_address_noforce( ( machine_mode)v25, v24); 
v28 = gen_reg_rtx( ( machine_mode)v27); 
v30 = gen_rtx_MEM( ( machine_mode)v29, v26); 
if ( *( _OWORD *)&args1 == 0LL ) 
for ( i = undobuf_0.undos; i; undobuf_0.frees = v1 ) 
for ( i = undobuf_0.undos; i; undobuf_0.frees = v1 ) 
v1->next = undobuf_0.frees; 
undobuf_0.undos = 0LL; 
rtx v10; // rdx 
rtx v15; // rax 
rtx v17; // rax 
rtx v34; // rdx 
rtx v39; // rbx 
rtx v64; // rbx 
rtx *v70; // rax 
rtx *v72; // rbp 
rtx v77; // rbx 
rtl_op = first_rtl_op( ( tree_code)v2); 
if ( ( tree_node *)*( &global_trees + 5) == section_name ) 
if ( ( tree_node *)*( &global_trees + 4) == section_name ) 
if ( ( tree_node *)*( &global_trees + 3) == section_name ) 
if ( ( tree_node *)*( &global_trees + 2) == section_name ) 
if ( ( tree_node *)*( &global_trees + 1) == section_name ) 
timevar_push( TV_LIFE_0); 
timevar = TV_LIFE_0; 
timevar = TV_LIFE_0; 
timevar_push( TV_LIFE_UPDATE_0); 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
v5 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
v7 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)x + 2)] - 5) < 2) + 1; 
changes = ( change_t_0 *)xrealloc( changes, 32LL * v8); 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
( machine_mode)*( ( unsigned __int8 *)v4 + 2)); 
v32 = simplify_gen_binary( PLUS, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v4->fld[0].rtx, v31); 
v35 = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v4->fld[0].rtx, op0_mode, *( _DWORD *)&v4[1]); 
&& ( v35 = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), const_int_rtx[64])) != 0LL ) 
v29 = simplify_gen_binary( PLUS, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v4->fld[0].rtx, v28); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)ref + 2), ref->fld[0].rtx) ) 
mergeable_constant_section( ( machine_mode)LOBYTE( decl->block.supercontext), decl->type.uid & 0xFFFFFF, 0); 
rtx x; // [rsp+10h] [rbp-48h] 
x = get_insns( ); 
fatal_insn( "wrong insn in the fallthru edge", rtx, "cfgrtl.c", 1717, "verify_flow_info"); 
fatal_insn( "flow control insn inside a basic block", v21, "cfgrtl.c", 1829, "verify_flow_info"); 
if ( x ) 
v29 = *( _WORD *)x; 
if ( *( _WORD *)x == 37 ) 
if ( x[2].fld[0].rtint == -80 ) 
if ( *( _DWORD *)( *( _QWORD *)&x[2] + 88LL) != ++v28 ) 
if ( !bb_info[x->fld[0].rtint] ) 
fancy_abort( ( const char *)&to, 604, "verify_local_live_at_start"); 
fancy_abort( ( const char *)&to, 557, "verify_wide_reg"); 
fwrite( ( char *)&to.first + 7, 1uLL, 5uLL, rtl_dump_file); 
fancy_abort( ( const char *)&to, 583, "verify_local_live_at_start"); 
rtx v9; // rdx 
rtx v11; // rax 
rtx v31; // rbp 
rtx const_value; // rdx 
rtx v43; // rcx 
edge_info_0[( int)v13] = flow_edges; 
edge_info_0[( int)v22] = flow_edges; 
v30 = gen_rtx( ( rtx_code)*v24, ( machine_mode)*( ( unsigned __int8 *)v24 + 2)); 
v8 = statement_code_p( ( tree_code)v9); 
if ( v9 != 2 && !v8 && !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v5) ) 
if ( v9 != 2 && !v8 && !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v5) ) 
v4 = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v5, walk_subtrees, func, data, htab_); 
v4 = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v5, walk_subtrees, func, data, htab_); 
if ( statement_code_p( ( tree_code)v9) && ( *( ( _BYTE *)*v5 + 19) & 4) == 0 ) 
rtl_op = first_rtl_op( ( tree_code)v9); 
v1 = general_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
if ( !test_insn_13 ) 
test_insn_13 = insn_raw; 
ggc_add_rtx_root( &test_insn_13, 1); 
*( _BYTE *)( *( _QWORD *)( *( _QWORD *)&test_insn_13[2] + 8LL) + 2LL) = *( ( _BYTE *)x + 2); 
v2 = test_insn_13; 
*( _QWORD *)( *( _QWORD *)&test_insn_13[2] + 16LL) = x; 
v11 = force_reg( ( machine_mode)v6, op); 
v9 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)op + 2), v7); 
if ( **( _WORD **)&this_insn_0[2] == 39 ) 
if ( multiple_sets( this_insn_0) ) 
v5 = **( _DWORD **)( *( _QWORD *)&this_insn_0[2] + 8LL) - 1; 
v6 = *( _QWORD *)( *( _QWORD *)( *( _QWORD *)&this_insn_0[2] + 8LL) + 8LL * v5 + 8); 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
if ( find_regno_note( this_insn_0, REG_INC, rtint) ) 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
qty_0[v4].death = output_p + 2 * this_insn_number; 
fancy_abort( ( const char *)&insn, 548, "wrap_constant"); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)mem + 2)) ) 
if ( ( v4 == 16 || v4 == 22 || ( mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] & 0xFFFFFFFB) == 1) 
fancy_abort( ( const char *)&stru_665A39, 10894, "x86_initialize_trampoline"); 
if ( xexit_cleanup ) 
sprintf( xstrerror_buf, aUndocumentedEr, ( unsigned int)errnum); 
if ( ( unsigned int)v2 <= 0xFF && ( sch_istable[( unsigned __int8)v2] & 0xAC) != 0 ) 
timevar_push( TV_LEX_0); 
v7 = cpp_type2name( ( cpp_ttype)v0); 
timevar_pop( TV_LEX_0); 
