for ( p = &pfile->free_buffs; ; p = ( _cpp_buff_0 **)*p ) 
run->base = ( cpp_token_0 *)xmalloc( 24LL * count); 
else if ( ( sch_istable[( unsigned __int8)ce] & 4) != 0 ) 
parse_number_0( pfile, ( cpp_string_0 *)&result->val, ce, 1); 
parse_number_0( pfile, ( cpp_string_0 *)&result->val, c, 0); 
loc = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)loc + 2), new_addr); 
tree_node *v3; // rax 
v3 = field_type( tree_node); 
size = simple_type_size_in_bits( v3) >> 3; 
if ( mode_class_0[mode] != MODE_FLOAT ) 
note = gen_rtx_fmt_e( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v7); 
note = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v9, v8); 
compiler_params = ( param_info_0 *)xrealloc( compiler_params, 24 * ( n + num_compiler_params)); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
upper = ( tree_node *)domain[7]; 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)addr + 2), addr->fld[0].rtx, v5); 
|| get_mode_alignment( ( machine_mode)*( ( unsigned __int8 *)memref + 2)) >> 3 <= ( unsigned __int64)offset ) 
v12 = *( tree_node **)( *( _QWORD *)&memref[1] + 8LL); 
*( _QWORD *)&newa[1] = get_mem_attrs( v13, v12, memoffset, size, memalign, ( machine_mode)*( ( unsigned __int8 *)newa + 2)); 
else if ( mode_class_0[BYTE5( type->block.abstract_origin) >> 1] == MODE_COMPLEX_INT 
|| mode_class_0[BYTE5( type->block.abstract_origin) >> 1] == MODE_COMPLEX_FLOAT ) 
if ( initialized_6 ) 
initialized_6 = 1; 
if ( initialized_2 ) 
initialized_2 = 1; 
return gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, val, next); 
max_uid_0 = get_max_uid( ); 
n = 4 * ( max_uid_0 + 1); 
uid_cuid_1 = gmalloc( n); 
memset( uid_cuid_1, 0, n); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) = v1; 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) = i; 
group = ( page_group_0 *)enda; 
group = ( page_group_0 *)( page - 32); 
v4 = next_qty_0++; 
qty_0[v4].first_reg = regno; 
qty_0[v4].size = size; 
qty_0[v4].mode = mode; 
qty_0[v4].birth = birth; 
qty_0[v4].n_calls_crossed = *( _DWORD *)( reg_n_info->data.l[regno] + 32); 
v5 = &qty_0[v4]; 
v6 = &qty_0[qtyno]; 
qty_0[qtyno].n_refs = *( _DWORD *)( reg_n_info->data.l[regno] + 16); 
qty_0[qtyno].freq = *( _DWORD *)( reg_n_info->data.l[regno] + 20); 
qty_0[qtyno].changes_mode = *( _BYTE *)( reg_n_info->data.l[regno] + 40); 
reg_set_table = ( reg_set_0 **)gmalloc( 8 * ( n_regs + 100)); 
mode = *( ( unsigned __int16 *)&insn_data_0[1234].operand[1] + 8); 
pred = insn_data_0[1234].operand[1].predicate; 
free( reg_pref_0); 
if ( reg_pref_0 ) 
reg_pref_0 = reg_pref_buffer; 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
x = assign_stack_local( ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2), v3, v4); 
xa = adjust_address_1( x, ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2), 0LL, 0, 1); 
*xp = adjust_address_1( y, ( machine_mode)*( ( unsigned __int8 *)x + 2), *( _DWORD *)&x[1], 1, 1); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2), 
verbatim( off_76BE8C, v1); 
if ( !value_2 ) 
value_2 = st.st_ino ^ st.st_dev ^ st.st_mtim.tv_sec; 
value_2 = 1LL; 
v = value_2; 
*templatea = letters_1[value_2 % 0x3E]; 
*templatea = letters_1[value_2 % 0x3E]; 
templatea[1] = letters_1[v % 0x3E]; 
templatea[2] = letters_1[v % 0x3E]; 
templatea[3] = letters_1[v % 0x3E]; 
templatea[4] = letters_1[v % 0x3E]; 
templatea[5] = letters_1[v % 0x3E]; 
if ( size_10 < 0 ) 
size_10 = mode_size[v0]; 
size_10 += mode_size[v1]; 
v2 = mode_class_0[mode] != MODE_COMPLEX_INT && mode_class_0[mode] != MODE_COMPLEX_FLOAT; 
v2 = mode_class_0[mode] != MODE_COMPLEX_INT && mode_class_0[mode] != MODE_COMPLEX_FLOAT; 
if ( size_10 % align ) 
size_10 = align * ( ( size_10 + align - 1) / align); 
size_10 = align * ( ( size_10 + align - 1) / align); 
apply_args_reg_offset[regno] = size_10; 
size_10 += mode_size[best_mode]; 
return size_10; 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)object + 2), object->fld[0].rtx) ) 
r->new_reg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)r->old_reg + 2)); 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT ) 
|| mode_class_0[*( ( unsigned __int8 *)lhsa + 2)] != mode_class_0[*( unsigned __int8 *)( lhsa->fld[0].rtwint + 2)] 
|| mode_class_0[*( ( unsigned __int8 *)lhsa + 2)] != mode_class_0[*( unsigned __int8 *)( lhsa->fld[0].rtwint + 2)] 
( machine_mode)*( unsigned __int8 *)( lhsa->fld[0].rtwint + 2), 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), tema); 
v3 = gen_binary( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&lhsa[1], *( rtx *)&rhsa[1]); 
v3 = gen_binary( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&lhsa[1], rhsa->fld[0].rtx); 
v3 = gen_binary( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), lhsa->fld[0].rtx, *( rtx *)&rhsa[1]); 
v3 = gen_binary( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), lhsa->fld[0].rtx, rhsa->fld[0].rtx); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
if ( size_8 < 0 ) 
size_8 = 0; 
if ( size_8 % align ) 
size_8 = align * ( ( size_8 + align - 1) / align); 
size_8 = align * ( ( size_8 + align - 1) / align); 
size_8 += mode_size[best_mode]; 
size_8 = 116; 
return size_8; 
k = hex_value[( unsigned __int8)*s]; 
( sch_istable[( unsigned __int8)*sp_0] & 4) != 0 
|| base == 16 && ( sch_istable[( unsigned __int8)*sp_0] & 0x100) != 0; 
if ( ( sch_istable[( unsigned __int8)*s] & 4) == 0 ) 
destination = asm_dest_local; 
destination = asm_dest_local; 
destination = ( BYTE2( decl->block.supercontext) & 2) == 0; 
if ( destination == asm_dest_bss ) 
if ( destination == asm_dest_bss ) 
if ( destination == asm_dest_local ) 
if ( destination == asm_dest_local ) 
if ( ( unsigned int)destination > asm_dest_local ) 
if ( ( unsigned int)destination > asm_dest_local ) 
if ( destination ) 
while ( ( sch_istable[( unsigned __int8)c] & 4) != 0 || c == 46 ) 
while ( ( sch_istable[*( unsigned __int8 *)constraint] & 4) != 0 ) 
return tcmalloc::HugePageAwareAllocator::AllocEnormous( buf, fmt, ap); 
sprintf( label, "*.%s%u", ( const char *)&off_818574, ( unsigned int)++labelno_17); 
sprintf( label, "*.%s%u", ( const char *)&off_818574, ( unsigned int)++labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_818574, ( unsigned int)labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_818574, ( unsigned int)labelno_17); 
v8 = byte_8185A8[*( unsigned __int8 *)v2]; 
v6 = byte_8185A8[*v10]; 
ttypes = htab_create( 0x1FuLL, ( htab_hash)ttypes_filter_hash, ( htab_eq)has_key, free); 
tree *regno_decl; // rbx 
tree *v47; // rbx 
tree *v48; // rbx 
tree result; // [rsp+90h] [rbp-170h] 
tree inc; // [rsp+100h] [rbp-100h] 
ca = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), c, cmode, 0); 
return new_loc_descr( ( dwarf_location_atom)( reg + 112), offset, 0LL); 
return mode_class_0[*( ( unsigned __int8 *)a1 + 2)] == MODE_FLOAT; 
return mode_class_0[*( ( unsigned __int8 *)a1 + 2)] == MODE_FLOAT; 
error( "invalid operands to binary %s", ( const char *)&off_74A67D); 
error( "invalid operands to binary %s", ( _BYTE *)&off_74A69F + 2); 
error( "invalid operands to binary %s", ( const char *)&off_74A69F); 
v2 = ( tree_node *)*( &global_trees + 19); 
*( _OWORD *)to_elt->bits = *( _OWORD *)from_ptr->bits; 
return *( _OWORD *)element->bits == 0LL; 
comma = ( const char *)&unk_748822; 
induction_1 *v; // [rsp+18h] [rbp-8h] 
induction_1 *v; // [rsp+18h] [rbp-8h] 
for ( v = bl_0->biv; v; v = v->next_iv ) 
for ( v = bl_0->biv; v; v = v->next_iv ) 
for ( v = bl_0->biv; v; v = v->next_iv ) 
for ( v = bl_0->biv; v; v = v->next_iv ) 
if ( ( *( ( _BYTE *)v + 100) & 8) == 0 || v->mult_val != const_int_rtx[65] || ( *( ( _BYTE *)v + 100) & 0x20) != 0 ) 
if ( ( *( ( _BYTE *)v + 100) & 8) == 0 || v->mult_val != const_int_rtx[65] || ( *( ( _BYTE *)v + 100) & 0x20) != 0 ) 
if ( ( *( ( _BYTE *)v + 100) & 8) == 0 || v->mult_val != const_int_rtx[65] || ( *( ( _BYTE *)v + 100) & 0x20) != 0 ) 
result = fold_rtx_mult_add( result, const_int_rtx[65], v->add_val, v->mode); 
result = fold_rtx_mult_add( result, const_int_rtx[65], v->add_val, v->mode); 
this_insn_0 = insna; 
&& recog_data_0.n_operands > 1 
&& *recog_data_0.constraints[0] == 61 
&& *( ( _BYTE *)recog_data_0.constraints[0] + 1) != 38 ) 
for ( i_0 = 1; i_0 < recog_data_0.n_operands; ++i_0 ) 
v1 = requires_inout( recog_data_0.constraints[i_0]); 
if ( v1 == recog_data_0.n_alternatives ) 
r0 = recog_data_0.operand[0]; 
for ( i_0a = 1; i_0a < recog_data_0.n_operands; ++i_0a ) 
|| i_0a == must_match_0 + 1 && *( _BYTE *)recog_data_0.operand_loc[i_0a + 29] == 37 
|| i_0a == must_match_0 - 1 && *recog_data_0.constraints[i_0a] == 37) 
&& ( n_matching_alts != recog_data_0.n_alternatives || requires_inout( recog_data_0.constraints[i_0a])) ) 
&& ( n_matching_alts != recog_data_0.n_alternatives || requires_inout( recog_data_0.constraints[i_0a])) ) 
r1 = recog_data_0.operand[i_0a]; 
if ( *recog_data_0.constraints[i_0a] == 112 ) 
v2 = r1 == recog_data_0.operand[i_0a] && must_match_0 >= 0; 
edge_info_0 *inf; // [rsp+18h] [rbp-88h] 
edge_info_0 *inf; // [rsp+18h] [rbp-88h] 
edge_info_0 *i_1; // [rsp+28h] [rbp-78h] 
edge_info_0 *i_1; // [rsp+28h] [rbp-78h] 
ignore_next_note_1 = 1; 
if ( ignore_next_note_1 ) 
ignore_next_note_1 = 0; 
inf = ( edge_info_0 *)e_1->aux; 
inf = ( edge_info_0 *)e_1->aux; 
if ( ( e_1->flags & 0x10) != 0 && ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
if ( ( e_1->flags & 0x10) != 0 && ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
*( _BYTE *)inf |= 4u; 
i_1 = ( edge_info_0 *)e_2a->aux; 
return force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, v1, op0, op1); 
if ( in_section_0 != in_bss ) 
in_section_0 = in_bss; 
head = new_loc_descr( ( dwarf_location_atom)( cfa->reg + 112), cfa->base_offset, 0LL); 
head = new_loc_descr( ( dwarf_location_atom)( cfa->reg + 80), 0LL, 0LL); 
sprintf( ( char *)&inita, "%s.%d", "__compound_literal", ( unsigned int)var_labelno); 
++var_labelno; 
n_ops = recog_data_0.n_operands; 
if ( matches >= 0 || recog_op_alt[i][alt].matched >= 0 || predicated && recog_data_0.operand_type[i] == OP_OUT ) 
recog_data_0.operand_type[i] = OP_INOUT; 
recog_data_0.operand_loc[i], 
recog_data_0.operand_type[i], 
old_operands[i] = recog_data_0.operand[i]; 
if ( *recog_data_0.constraints[i] ) 
*recog_data_0.operand_loc[i] = global_rtl[1]; 
for ( i = 0; i < recog_data_0.n_dups; ++i ) 
dup_num = recog_data_0.dup_num[i]; 
old_dups[i] = *recog_data_0.dup_loc[i]; 
*recog_data_0.dup_loc[i] = global_rtl[1]; 
if ( icode >= 0 && !insn_data_0[icode].operand[dup_num].eliminable ) 
old_dups[i] = recog_data_0.operand[dup_num]; 
for ( i = 0; i < recog_data_0.n_dups; ++i ) 
( machine_mode)*( unsigned __int8 *)( link->fld[0].rtwint + 2), 
duplicate = *( tree_node **)( node->value + 48); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_EXPAND_0); 
if ( fndecl->decl.name && *( _OWORD *)&fndecl->block.fragment_chain == *( &global_trees + 50) ) 
timevar_pop( TV_EXPAND_0); 
if ( if_stack_0[--if_stack_pointer].needs_warning ) 
if_stack_0[if_stack_pointer].file, 
if_stack_0[if_stack_pointer].line, 
if ( t == ( tree_node *)global_trees ) 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * if_stack_space); 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * if_stack_space); 
if_stack_0 = ( if_elt *)xmalloc( 0x140uLL); 
if_stack_0[if_stack_pointer].compstmt_count = compstmt_count; 
if_stack_0[if_stack_pointer].file = input_filename; 
if_stack_0[if_stack_pointer].line = lineno; 
if_stack_0[if_stack_pointer].needs_warning = 0; 
if_stack_0[if_stack_pointer++].if_stmt = if_stmt; 
&& if_stack_0[if_stack_pointer - 1].compstmt_count == if_stack_0[if_stack_pointer - 2].compstmt_count ) 
&& if_stack_0[if_stack_pointer - 1].compstmt_count == if_stack_0[if_stack_pointer - 2].compstmt_count ) 
if_stack_0[if_stack_pointer - 2].needs_warning = 1; 
if_stack_0[if_stack_pointer - 1].needs_warning = 0; 
--if_stack_0[if_stack_pointer - 1].compstmt_count; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
timevar_push( TV_CPP_0); 
timevar_pop( TV_CPP_0); 
if ( ( sch_istable[tok->val.c] & 0xAC) != 0 ) 
&& !ix86_hard_regno_mode_ok( dest->fld[0].rtint, ( machine_mode)*( ( unsigned __int8 *)dest + 2)) 
&& !ix86_hard_regno_mode_ok( src->fld[0].rtint, ( machine_mode)*( ( unsigned __int8 *)src + 2))) ) 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( *( _QWORD *)&x[2] + 8LL * ib + 8) + 2LL)); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( x->fld[0].rtwint + 8LL * ia + 8) + 2LL)); 
record = mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_CC; 
rtint < 0 || insn_data_0[rtint].n_dups > 0)) ) 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x0, x1); 
if ( !base_alias_check( x_addr, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), mem_mode) ) 
&& mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_INT 
&& ( ( mode_class_0[mode] != MODE_CC) != ( mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_CC) 
&& ( ( mode_class_0[mode] != MODE_CC) != ( mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_CC) 
|| mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] != MODE_INT 
|| ( mode_class_0[mode] != MODE_CC) == ( mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_CC) 
|| ( mode_class_0[mode] != MODE_CC) == ( mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_CC) 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_CC ) 
if ( ( sch_istable[*( unsigned __int8 *)c] & 4) != 0 && !c[1] ) 
n_outputs = recog_data_0.n_operands - n_inputs; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( *( _WORD *)recog_data_0.operand[i] == 63 && *( _WORD *)recog_data_0.operand[i]->fld[0].rtwint == 61 ) 
if ( *( _WORD *)recog_data_0.operand[i] == 63 && *( _WORD *)recog_data_0.operand[i]->fld[0].rtwint == 61 ) 
recog_data_0.operand[i] = recog_data_0.operand[i]->fld[0].rtx; 
recog_data_0.operand[i] = recog_data_0.operand[i]->fld[0].rtx; 
if ( *( _WORD *)recog_data_0.operand[i] == 61 
&& recog_data_0.operand[i]->fld[0].rtint > 7u 
&& recog_data_0.operand[i]->fld[0].rtint <= 0xFu ) 
if ( recog_data_0.operand[i]->fld[0].rtint == clobber_reg[j]->fld[0].rtint ) 
reg_used_as_output[recog_data_0.operand[i]->fld[0].rtuint] = 1; 
if ( *( _WORD *)recog_data_0.operand[i] == 61 
&& recog_data_0.operand[i]->fld[0].rtint > 7u 
&& recog_data_0.operand[i]->fld[0].rtint <= 0xFu ) 
for ( j_0 = 0; j_0 < n_clobbers && !operands_match_p( clobber_reg[j_0], recog_data_0.operand[i]); ++j_0 ) 
implicitly_dies[recog_data_0.operand[i]->fld[0].rtuint] = 1; 
if ( operands_match_p( recog_data_0.operand[j_1], recog_data_0.operand[i]) ) 
if ( operands_match_p( recog_data_0.operand[j_1], recog_data_0.operand[i]) ) 
valuec = ( tree_node *)global_trees; 
induction_1 *v; // [rsp+110h] [rbp-50h] 
induction_1 *v; // [rsp+110h] [rbp-50h] 
v = bl_0->giv; 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
induction_1 *v; // [rsp+70h] [rbp-30h] 
induction_1 *v; // [rsp+70h] [rbp-30h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( v->ext_dependent ) 
code = *( _WORD *)v->ext_dependent; 
max = mode_mask_array[*( ( unsigned __int8 *)v->ext_dependent + 2)] >> 1; 
fprintf( loop_dump_stream, "Verified ext dependent giv at %d of reg %d\n", v->insn->fld[0].rtuint, bl_0->regno); 
v->insn->fld[0].rtuint, 
v->insn->fld[0].rtuint, 
v->insn->fld[0].rtuint, 
*( ( _BYTE *)v + 100) |= 4u; 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
induction_1 *v; // [rsp+58h] [rbp-38h] 
induction_1 *v; // [rsp+58h] [rbp-38h] 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
v, 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modea] == MODE_COMPLEX_INT || mode_class_0[modea] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modea] == MODE_COMPLEX_INT || mode_class_0[modea] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modeb] == MODE_COMPLEX_INT || mode_class_0[modeb] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modeb] == MODE_COMPLEX_INT || mode_class_0[modeb] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modec] == MODE_COMPLEX_INT || mode_class_0[modec] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[modec] == MODE_COMPLEX_INT || mode_class_0[modec] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[m] == MODE_COMPLEX_INT || mode_class_0[m] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[m] == MODE_COMPLEX_INT || mode_class_0[m] == MODE_COMPLEX_FLOAT ) 
if ( v19 == nregs && ix86_hard_regno_mode_ok( regno, ( machine_mode)m) ) 
i += subreg_regno_offset( i, ( machine_mode)*( ( unsigned __int8 *)last_reg + 2), byte, mode); 
need_mode = byte ? smallest_mode_for_size( mode_size[mode] + byte, mode_class_0[mode]) : mode; 
v3 = mode_class_0[rld[r].mode] == MODE_COMPLEX_INT 
|| mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[r_2].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r_2].mode] == MODE_COMPLEX_FLOAT ) 
( machine_mode)( BYTE5( type_0->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( field->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( type->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( type_1->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( field->common.type->block.abstract_origin) >> 1), 
if ( ( sch_istable[( unsigned __int8)*p] & 0x8C) == 0 && *p != 46 ) 
timevar_push( TV_CLEANUP_CFG_0); 
timevar_pop( TV_CLEANUP_CFG_0); 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( **( _WORD **)recog_data_0.operand_loc[i] == 63 ) 
recog_data_0.operand[i] = alter_subreg( recog_data_0.operand_loc[i]); 
recog_data_0.operand[i] = alter_subreg( recog_data_0.operand_loc[i]); 
else if ( *( _WORD *)recog_data_0.operand[i] == 75 
|| *( _WORD *)recog_data_0.operand[i] == 78 
|| *( _WORD *)recog_data_0.operand[i] == 66 ) 
recog_data_0.operand[i] = walk_alter_subreg( recog_data_0.operand_loc[i]); 
recog_data_0.operand[i] = walk_alter_subreg( recog_data_0.operand_loc[i]); 
for ( ia = 0; ia < recog_data_0.n_dups; ++ia ) 
if ( **( _WORD **)recog_data_0.dup_loc[ia] == 63 ) 
v1 = recog_data_0.dup_loc[ia]; 
else if ( **( _WORD **)recog_data_0.dup_loc[ia] == 75 
|| **( _WORD **)recog_data_0.dup_loc[ia] == 78 
|| **( _WORD **)recog_data_0.dup_loc[ia] == 66 ) 
v2 = recog_data_0.dup_loc[ia]; 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[i].mode] == MODE_COMPLEX_INT || mode_class_0[rld[i].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[i].mode] == MODE_COMPLEX_INT || mode_class_0[rld[i].mode] == MODE_COMPLEX_FLOAT ) 
tree v16; // rax 
tree call_expr; // [rsp+30h] [rbp-50h] 
tree v29; // [rsp+38h] [rbp-48h] 
mode_alignment = get_mode_alignment( ( machine_mode)*( ( unsigned __int8 *)object + 2)); 
htab_empty( hash_table_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
args = ( macro_arg_0 *)buff->base; 
&& !ix86_hard_regno_mode_ok( inner_dest->fld[0].rtint, ( machine_mode)*( ( unsigned __int8 *)inner_dest + 2)) 
induction_1 *g2; // [rsp+30h] [rbp-60h] 
induction_1 *g2; // [rsp+30h] [rbp-60h] 
induction_1 **giv_array; // [rsp+50h] [rbp-40h] 
induction_1 **giv_array; // [rsp+50h] [rbp-40h] 
induction_1 *g1; // [rsp+78h] [rbp-18h] 
induction_1 *g1; // [rsp+78h] [rbp-18h] 
for ( g1 = bl_0->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0->giv; g1; g1 = g1->next_iv ) 
if ( ( *( ( _BYTE *)g1 + 100) & 4) == 0 ) 
giv_array = ( induction_1 **)&bl_0a; 
giv_array = ( induction_1 **)&bl_0a; 
for ( g1 = bl_0a->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0a->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0a->giv; g1; g1 = g1->next_iv ) 
for ( g1 = bl_0a->giv; g1; g1 = g1->next_iv ) 
if ( ( *( ( _BYTE *)g1 + 100) & 4) == 0 ) 
if ( ret && g2->giv_type == DEST_ADDR && memory_address_p( ( machine_mode)*( ( unsigned __int8 *)g2->mem + 2), ret) ) 
rtx nextlinks; // [rsp+38h] [rbp-28h] 
rtx links; // [rsp+40h] [rbp-20h] 
rtx next; // [rsp+50h] [rbp-10h] 
rtx insn; // [rsp+58h] [rbp-8h] 
reg_last_set_mode = ( machine_mode *)xmalloc( 4LL * nregs); 
insn = f; 
while ( insn ) 
if ( i < insn->fld[0].rtint ) 
i = insn->fld[0].rtint; 
insn = insn[1].fld[0].rtx; 
*( machine_mode *)mode = class_narrowest_mode[1]; 
rtx prob_note; // [rsp+28h] [rbp-38h] 
rtx note; // [rsp+40h] [rbp-20h] 
rtx *pnote; // [rsp+48h] [rbp-18h] 
prob_note = find_reg_note( insn, REG_BR_PROB, 0LL); 
pnote = ( rtx *)insn[3].fld; 
for ( note = insn[3].fld[0].rtx; note; note = ( rtx)note[1] ) 
for ( note = insn[3].fld[0].rtx; note; note = ( rtx)note[1] ) 
for ( note = insn[3].fld[0].rtx; note; note = ( rtx)note[1] ) 
if ( *( ( _BYTE *)note + 2) == 20 ) 
probability = *( _QWORD *)( *( _QWORD *)( note->fld[0].rtwint + 16) + 8LL); 
if ( best_predictor > ( int)*( _QWORD *)( *( _QWORD *)( note->fld[0].rtwint + 8) + 8LL) ) 
( machine_mode)*( ( unsigned __int8 *)subreg + 2), 
( machine_mode)*( ( unsigned __int8 *)usedreg + 2)); 
else if ( mode_class_0[*( ( unsigned __int8 *)usedreg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)usedreg + 2)] == MODE_COMPLEX_FLOAT ) 
( machine_mode)*( ( unsigned __int8 *)subreg_0 + 2), 
( machine_mode)*( ( unsigned __int8 *)setreg + 2)); 
else if ( mode_class_0[*( ( unsigned __int8 *)setreg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)setreg + 2)] == MODE_COMPLEX_FLOAT ) 
|| ssize > usize && ureg > 52 && usize < qty_0[*( ( int *)reg_qty + ureg)].size 
&& reg_meets_class_p( sreg, qty_0[*( ( int *)reg_qty + ureg)].min_class) ) 
*( ( _DWORD *)reg_next_in_qty + sreg) = qty_0[sqty].first_reg; 
qty_0[sqty].first_reg = sreg; 
qty_0[sqty].n_calls_crossed += *( _DWORD *)( reg_n_info->data.l[sreg] + 32); 
qty_0[sqty].n_refs += *( _DWORD *)( reg_n_info->data.l[sreg] + 16); 
qty_0[sqty].freq += *( _DWORD *)( reg_n_info->data.l[sreg] + 20); 
for ( i = qty_0[sqty].first_reg; i >= 0; i = *( ( _DWORD *)reg_next_in_qty + i) ) 
qty_0[sqty].size = ssize; 
qty_0[sqty].mode = *( ( unsigned __int8 *)setreg + 2); 
if ( this_insn_1[2].fld[0].rtint != -1 ) 
for ( ic = 1; ic < insn_data_0[this_insn_1[2].fld[0].rtint].n_operands; ++ic ) 
for ( ic = 1; ic < insn_data_0[this_insn_1[2].fld[0].rtint].n_operands; ++ic ) 
if ( *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 61 
if ( *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 61 
|| *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 43 ) 
|| *insn_data_0[this_insn_1[2].fld[0].rtint].operand[ic].constraint == 43 ) 
for ( note = this_insn_1[3].fld[0].rtx; note; note = ( rtx)note[1] ) 
v14 = mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_INT 
|| mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_FLOAT 
v18 = mode_class_0[*( unsigned __int8 *)( note->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( note->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
v0 = mode_class_0[rld[ib].inmode] == MODE_COMPLEX_INT || mode_class_0[rld[ib].inmode] == MODE_COMPLEX_FLOAT 
v0 = mode_class_0[rld[ib].inmode] == MODE_COMPLEX_INT || mode_class_0[rld[ib].inmode] == MODE_COMPLEX_FLOAT 
v6 = mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_INT 
|| mode_class_0[rld[output_reload].outmode] == MODE_COMPLEX_FLOAT 
if ( code1 || mode_class_0[*( unsigned __int8 *)( exp->fld[0].rtwint + 2)] != MODE_CC ) 
return reversed_comparison_code_parts( ( rtx_code)*( _WORD *)exp, x->fld[0].rtx, *( rtx *)&x[1], 0LL); 
|| ( mode_class_0[mode] != MODE_INT 
&& mode_class_0[mode] != MODE_PARTIAL_INT 
&& mode_class_0[mode] != MODE_COMPLEX_INT 
&& mode_class_0[mode] != MODE_VECTOR_INT 
|| mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT) 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)dest + 2), global_rtl[2]) ) 
newa = lang_hooks_0.expand_constant( expa); 
bi = ( block_info_0)block->aux; 
change_stack( block->end, &tmpstack, target_stack, ( emit_where)( *( _WORD *)block->end == 33)); 
timevar_push( TV_PARSE_0); 
lang_hooks_0.clear_binding_stack( ); 
timevar_pop( TV_PARSE_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
deps_0 *v1; // rax 
deps_0 *v1; // rax 
deps_0 tmp_deps; // [rsp+10h] [rbp-90h] BYREF 
v1 = &bb_deps[bb]; 
pending_read_mems = v1->pending_read_mems; 
tmp_deps.pending_read_insns = v1->pending_read_insns; 
tmp_deps.pending_read_insns = v1->pending_read_insns; 
tmp_deps.pending_read_mems = pending_read_mems; 
pending_write_mems = v1->pending_write_mems; 
tmp_deps.pending_write_insns = v1->pending_write_insns; 
tmp_deps.pending_write_insns = v1->pending_write_insns; 
tmp_deps.pending_write_mems = pending_write_mems; 
last_pending_memory_flush = v1->last_pending_memory_flush; 
*( _QWORD *)&tmp_deps.pending_lists_length = *( _QWORD *)&v1->pending_lists_length; 
*( _QWORD *)&tmp_deps.pending_lists_length = *( _QWORD *)&v1->pending_lists_length; 
tmp_deps.last_pending_memory_flush = last_pending_memory_flush; 
sched_before_next_call = v1->sched_before_next_call; 
tmp_deps.last_function_call = v1->last_function_call; 
tmp_deps.last_function_call = v1->last_function_call; 
rtx end; // r12 
bb_info_1 *bi; // [rsp+78h] [rbp-C8h] 
bb_info_1 *bi; // [rsp+78h] [rbp-C8h] 
rtx note; // [rsp+90h] [rbp-B0h] 
bi = ( bb_info_1 *)v2->aux; 
bi = ( bb_info_1 *)v2->aux; 
if ( ( *( _BYTE *)bi & 1) == 0 ) 
if ( bi->succ_count ) 
if ( !bi->pred_count ) 
*( _BYTE *)bi |= 1u; 
*( _BYTE *)bi |= 1u; 
if ( ( *( _BYTE *)bi & 1) != 0 ) 
if ( bi->succ_count == 1 ) 
--bi->succ_count; 
if ( bi->pred_count == 1 ) 
--bi->pred_count; 
if ( mode_class_0[i] == MODE_CC ) 
reg = gen_rtx_REG( ( machine_mode)i, 58); 
reg_avail_info_0 = (  struct reg_avail_info *)gmalloc( 12 * max_gcse_regno); 
reg_avail_info_0[i].last_bb = -1; 
free( reg_avail_info_0); 
reg_avail_info_0 = 0LL; 
edge_list_0 = pre_edge_lcm( gcse_file, n_exprs, transp, comp, antloc, ae_kill, &pre_insert_map, &pre_delete_map); 
mode = ( machine_mode)field[3]; 
reg_set_0 *r; // [rsp+48h] [rbp-18h] 
reg_set_0 *r; // [rsp+48h] [rbp-18h] 
reg_set_0 *ra; // [rsp+48h] [rbp-18h] 
reg_set_0 *ra; // [rsp+48h] [rbp-18h] 
for ( r = reg_set_table[x->fld[0].rtuint]; r; r = r->next ) 
for ( r = reg_set_table[x->fld[0].rtuint]; r; r = r->next ) 
for ( r = reg_set_table[x->fld[0].rtuint]; r; r = r->next ) 
for ( r = reg_set_table[x->fld[0].rtuint]; r; r = r->next ) 
bmap[*( int *)( basic_block_for_insn->data.l[r->insn->fld[0].rtint] + 88)]->elms[( unsigned int)indx >> 6] |= 1LL << ( indx & 0x3F); 
for ( ra = reg_set_table[x->fld[0].rtuint]; ra; ra = ra->next ) 
for ( ra = reg_set_table[x->fld[0].rtuint]; ra; ra = ra->next ) 
for ( ra = reg_set_table[x->fld[0].rtuint]; ra; ra = ra->next ) 
for ( ra = reg_set_table[x->fld[0].rtuint]; ra; ra = ra->next ) 
bmap[*( int *)( basic_block_for_insn->data.l[ra->insn->fld[0].rtint] + 88)]->elms[( unsigned int)indx >> 6] &= ~( 1LL << ( indx & 0x3F)); 
( machine_mode)*( ( unsigned __int8 *)dest + 2), 
v2 = mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno] + 2)] == MODE_COMPLEX_FLOAT 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) < *( ( _DWORD *)uid_cuid_1 + occr->insn->fld[0].rtint) 
if ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) < *( ( _DWORD *)uid_cuid_1 + occr->insn->fld[0].rtint) 
if ( v2 == reverse_condition( ( rtx_code)*( _WORD *)cond2) 
induction_1 *v; // [rsp+50h] [rbp-20h] 
induction_1 *v; // [rsp+50h] [rbp-20h] 
v = ( induction_1 *)&add_vala; 
v = ( induction_1 *)&add_vala; 
LODWORD( v) = first_benefita; 
*( ( _BYTE *)v + 100) &= ~0x40u; 
v->derive_adjustment = 0LL; 
v->ext_dependent = 0LL; 
ivs->regs[dest_rega->fld[0].rtuint].iv.class = (  struct iv_class *)v; 
&& v->src_reg == src_rega) ) 
v->mult_val = *mult_val; 
v->add_val = *add_vala; 
v->benefit += benefit; 
v3 = ( tree_node *)*( &global_trees + 12); 
v3 = ( tree_node *)*( &global_trees + 11); 
if ( mode_class_0[mode] == MODE_INT ) 
if ( mode_class_0[mode] == MODE_FLOAT && mode_bitsize[mode] == 64 && *( _WORD *)op == 55 ) 
else if ( mode_class_0[mode] == MODE_FLOAT && mode_bitsize[mode] > 0x40u && *( _WORD *)op == 55 ) 
else if ( mode_class_0[mode] == MODE_FLOAT && mode_bitsize[mode] == 32 && *( _WORD *)op == 55 ) 
else if ( mode_class_0[mode] == MODE_INT && ( *( _WORD *)op == 54 || *( _WORD *)op == 55) ) 
if ( !recog_data_0.n_operands || !recog_data_0.n_alternatives ) 
if ( !recog_data_0.n_operands || !recog_data_0.n_alternatives ) 
for ( c = 0; c < recog_data_0.n_operands; ++c ) 
constraints[c] = recog_data_0.constraints[c]; 
for ( opno = 0; opno < recog_data_0.n_operands; ++opno ) 
( machine_mode)*( unsigned __int8 *)( op->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)op + 2)); 
op1 = recog_data_0.operand[match]; 
op2 = recog_data_0.operand[opno]; 
if ( strict <= 0 || strict_memory_address_p( recog_data_0.operand_mode[opno], op) ) 
for ( eopno = 0; eopno < recog_data_0.n_operands; ++eopno ) 
if ( earlyclobber[eopno] && *( _WORD *)recog_data_0.operand[eopno] == 61 ) 
for ( opno_0 = 0; opno_0 < recog_data_0.n_operands; ++opno_0 ) 
fprintf( stderr, off_77B517, x86_64_reg_class_name[classa[i]]); 
rtx insn; // [rsp+40h] [rbp-20h] 
for ( insn = *pinsns; insn; insn = next ) 
for ( insn = *pinsns; insn; insn = next ) 
for ( insn = *pinsns; insn; insn = next ) 
next = insn[1].fld[0].rtx; 
if ( *( _WORD *)insn == 37 ) 
kind = insn[2].fld[0].rtint; 
cur = ( int)insn[2]; 
if ( insn == *pinsns ) 
remove_insn( insn); 
else if ( rtx_class[*( _WORD *)insn] == 105 ) 
&& !find_reg_note( insn, REG_EH_REGION, 0LL) 
&& ( *( _WORD *)insn == 34 
&& **( _WORD **)&insn[2] != 49 
&& **( _WORD **)&insn[2] != 48 
&& may_trap_p( *( rtx *)&insn[2])) ) 
rtx = insn[3].fld[0].rtx; 
&& mode_class_0[mode] == MODE_INT 
|| mode_class_0[mode] == MODE_INT 
&& mode_class_0[oldmode] == MODE_INT 
to_real = mode_class_0[*( ( unsigned __int8 *)to + 2)] == MODE_FLOAT; 
from_real = mode_class_0[*( ( unsigned __int8 *)from + 2)] == MODE_FLOAT; 
if ( mode_class_0[to_mode] == MODE_VECTOR_INT 
|| mode_class_0[to_mode] == MODE_VECTOR_FLOAT 
|| mode_class_0[from_mode] == MODE_VECTOR_INT 
|| mode_class_0[from_mode] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[to_mode] == MODE_VECTOR_INT || mode_class_0[to_mode] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[to_mode] == MODE_VECTOR_INT || mode_class_0[to_mode] == MODE_VECTOR_FLOAT ) 
fromb = simplify_gen_subreg( to_mode, froma, ( machine_mode)*( ( unsigned __int8 *)froma + 2), 0); 
tob = simplify_gen_subreg( from_mode, toa, ( machine_mode)*( ( unsigned __int8 *)toa + 2), 0); 
bi = ( block_info_0)b->aux; 
bi = ( block_info_0)block->aux; 
fprintf( file, off_803B1B, ( unsigned int)reg); 
bi = ( block_info_0)block->aux; 
bi_0 = ( block_info_0)e->dest->aux; 
else if ( mode_class_0[*( ( unsigned __int8 *)retvalue + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)retvalue + 2)] == MODE_COMPLEX_FLOAT ) 
src = operand_sub*(short *)0xforce( srcrega, xbitpos / v8, ( machine_mode)*( ( unsigned __int8 *)srcrega + 2)); 
src = operand_sub*(short *)0xforce( srcrega, xbitpos / v8, ( machine_mode)*( ( unsigned __int8 *)srcrega + 2)); 
return build( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v7, v6); 
return build1( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v2); 
new_set->fld[0].rtwint = ( __int64)gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( new_set->fld[0].rtwint + 2)); 
( machine_mode)*( ( unsigned __int8 *)static_chain_incoming_rtx + 2), 
induction_1 *v; // [rsp+50h] [rbp-C0h] 
induction_1 *v; // [rsp+50h] [rbp-C0h] 
induction_1 *tv; // [rsp+C0h] [rbp-50h] 
induction_1 *tv; // [rsp+C0h] [rbp-50h] 
v = addr_combined_regs[*( unsigned int *)( v11->fld[0].rtwint + 8)]; 
bl_0 = ivs->regs[v->src_reg->fld[0].rtuint].iv.class; 
for ( tv = bl_0->giv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->giv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->giv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->giv; tv; tv = tv->next_iv ) 
if ( tv->giv_type == DEST_ADDR && v == tv->same && *tv->location == tv->dest_reg ) 
if ( tv->giv_type == DEST_ADDR && v == tv->same && *tv->location == tv->dest_reg ) 
if ( tv->giv_type == DEST_ADDR && v == tv->same && *tv->location == tv->dest_reg ) 
if ( tv->giv_type == DEST_ADDR && v == tv->same && *tv->location == tv->dest_reg ) 
if ( tv->giv_type == DEST_ADDR && v == tv->same && *tv->location == tv->dest_reg ) 
if ( tv->mult_val != v->mult_val ) 
copy = rtx_alloc( ( rtx_code)*( _WORD *)orig); 
rtx equiv_loc; // [rsp+68h] [rbp-D8h] 
rtx equiv_reg; // [rsp+70h] [rbp-D0h] 
rtx copy_0; // [rsp+78h] [rbp-C8h] 
rtx seq; // [rsp+80h] [rbp-C0h] 
rtx loc; // [rsp+98h] [rbp-A8h] 
rtx seq_0; // [rsp+A8h] [rbp-98h] 
rtx loc_0; // [rsp+C0h] [rbp-80h] 
temp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v3 = mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT 
v7 = mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[vd->e[sr].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[sr].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[vd->e[sr].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[sr].mode] == MODE_COMPLEX_FLOAT ) 
n_ops = recog_data_0.n_operands; 
if ( matches >= 0 || recog_op_alt[i][alt].matched >= 0 || predicated && recog_data_0.operand_type[i] == OP_OUT ) 
recog_data_0.operand_type[i] = OP_INOUT; 
kill_value( recog_data_0.operand[ia], vd); 
kill_value( recog_data_0.operand[ib], vd); 
v3 = mode_class_0[*( ( unsigned __int8 *)src + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)src + 2)] == MODE_COMPLEX_FLOAT 
v7 = mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_FLOAT 
v7 = mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_FLOAT 
if ( *recog_data_0.constraints[ic] ) 
|| *( _WORD *)recog_data_0.operand[ic] != 61 
|| recog_data_0.operand[ic]->fld[0].rtint != recog_data_0.operand[ic][1] ) 
|| recog_data_0.operand[ic]->fld[0].rtint != recog_data_0.operand[ic][1] ) 
if ( recog_data_0.operand_type[ic] ) 
if ( !warning_message_1 ) 
warning_message_1 = 1; 
v5 = mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[reg] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[reg] + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[reg] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[reg] + 2)] == MODE_COMPLEX_FLOAT ) 
return ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, str, len, HT_ALLOC); 
if ( ( sch_istable[( unsigned __int8)c] & 0x100) == 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 0xAC) != 0 ) 
value = ( cpp_buffer_0 *)pfile->buffer_ob.object_base; 
if ( value == ( cpp_buffer_0 *)pfile->buffer_ob.next_free ) 
memset( value, 0, sizeof( cpp_buffer_0)); 
else if ( ( sch_istable[c] & 0x10) != 0 ) 
invalidate( p->exp->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)p->exp + 2)); 
low_cuid = *( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint); 
if ( p->fld[0].rtint <= max_uid && high_cuid < *( ( _DWORD *)uid_cuid_0 + p->fld[0].rtint) ) 
high_cuid = *( ( _DWORD *)uid_cuid_0 + p->fld[0].rtint); 
if ( p->fld[0].rtint <= max_uid && low_cuid > *( ( _DWORD *)uid_cuid_0 + p->fld[0].rtint) ) 
low_cuid = *( ( _DWORD *)uid_cuid_0 + p->fld[0].rtint); 
invalidate( clobbered->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)clobbered + 2)); 
( insn_code = rtint, rtint < 0) || insn_data_0[insn_code].n_dups > 0) ) 
rtx temp; // [rsp+E8h] [rbp-18h] 
rtx insn; // [rsp+F8h] [rbp-8h] 
uid_cuid_0 = xcalloc( max_uid + 1, 4uLL); 
insn = f; 
while ( insn ) 
if ( *( _WORD *)insn == 37 && insn[2].fld[0].rtint >= 0 ) 
if ( *( _WORD *)insn == 37 && insn[2].fld[0].rtint >= 0 ) 
*( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint) = i; 
*( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint) = i; 
*( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint) = ++i; 
*( ( _DWORD *)uid_cuid_0 + insn->fld[0].rtint) = ++i; 
insn = insn[1].fld[0].rtx; 
insn = insn[1].fld[0].rtx; 
insn = f; 
while ( insn ) 
cse_end_of_basic_block( insn, &val, flag_cse_follow_jumps, after_loop, flag_cse_skip_blocks); 
if ( val.nsets && *( ( _BYTE *)insn + 2) != 2 ) 
&& ( new_0 = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)x + 2), ent->const_rtx)) != 0LL ) 
v5 = canon_hash( *( rtx *)&x[1], ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)) & 0x1F; 
invalidate( *( rtx *)( x->fld[0].rtwint + 8), ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
htab_delete( hash_table_0); 
hash_table_0 = htab_create( 0x1FuLL, ( htab_hash)get_value_hash, ( htab_eq)entry_and_rtx_equal_p, 0LL); 
htab_traverse_noresize( hash_table_0, ( htab_trav)cselib_invalidate_mem_1, mem_rtx); 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
v6 = mode_class_0[*( ( unsigned __int8 *)v->u.val_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)v->u.val_rtx + 2)] == MODE_COMPLEX_FLOAT; 
cselib_invalidate_regno( dest->fld[0].rtuint, ( machine_mode)*( ( unsigned __int8 *)dest + 2)); 
if ( push_operand( dest, ( machine_mode)*( ( unsigned __int8 *)dest + 2)) ) 
v4 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v4 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
*htab_find_slot_with_hash( hash_table_0, x, e->value, INSERT) = e; 
slot = htab_find_slot_with_hash( hash_table_0, v12, hashval, ( insert_option)( create != 0)); 
slot = htab_find_slot_with_hash( hash_table_0, v12, hashval, ( insert_option)( create != 0)); 
|| ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT) 
*htab_find_slot_with_hash( hash_table_0, v4, value, INSERT) = mem_elt; 
else if ( mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT ) 
set_0 sets[106]; // [rsp+10h] [rbp-D80h] 
sets[0].src = ( rtx)body[1]; 
sets[0].dest = body->fld[0].rtx; 
sets[n_sets].src = ( rtx)x[1]; 
sets[n_sets++].dest = x->fld[0].rtx; 
dest = sets[i].dest; 
if ( *( _WORD *)sets[i].dest == 64 ) 
sets[i].dest = dest; 
src = sets[i].src; 
src = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)src + 2), cond, src, dest); 
v1 = cselib_lookup( src, ( machine_mode)*( ( unsigned __int8 *)dest + 2), 1); 
sets[i].src_elt = v1; 
sets[i].dest_addr_elt = v3; 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
if ( !decla->decl.initial || !strcmp( lang_hooks_0.name, "GNU C++") && decla->decl.initial == ( tree)global_trees ) 
v3 = ( const char *)&unk_76B59B; 
if ( ( *( ( _BYTE *)&child->block.common + 18) & 4) != 0 && !strcmp( lang_hooks_0.name, "GNU C++") ) 
v16 = anonymous_type_number_3++; 
rttree = ( tree_node *)tem[6]; 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT ) 
v23 = mode_class_0[*( ( unsigned __int8 *)dest_0 + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest_0 + 2)] == MODE_COMPLEX_FLOAT 
fprintf( file, off_74881A, j + ( i << 6) + ( ptr->indx << 7)); 
fwrite( &unk_74881E, 1uLL, 3uLL, file); 
fprintf( fa, "%s, ", reg_class_names_0[rld[r].class]); 
fprintf( fa, "%ssecondary_in_icode = %s", "\n\t", insn_data_0[rld[r].secondary_in_icode].name); 
fprintf( fa, "%ssecondary_out_icode = %s", prefixa, insn_data_0[rld[r].secondary_out_icode].name); 
v6 = ( tree_node *)( *( __int64 (  **)( tree *, tree, tree, _QWORD, bool *))( *( _QWORD *)&i[4] + 24LL))( 
lang_hooks_0.set_yydebug( 1); 
if ( !*p || ( sch_istable[*( unsigned __int8 *)p] & 4) != 0 ) 
level_3 = read_integral_parameter( p, 0LL, max_debug_level_4 + 1); 
level_3 = read_integral_parameter( p, 0LL, max_debug_level_4 + 1); 
if ( level_3 ) 
v1 = level_3; 
level_3 = v1; 
error( "use -gdwarf -g%d for DWARF v1, level %d", level_3, level_3); 
error( "use -gdwarf -g%d for DWARF v1, level %d", level_3, level_3); 
if ( level_3 == 2 ) 
if ( level_3 > max_debug_level_4 ) 
if ( level_3 > max_debug_level_4 ) 
level_3 = debug_info_level_0; 
level_3 = debug_info_level_0; 
if ( type_explicitly_set_p_2 && da->debug_type && type != selected_debug_type_1 ) 
if ( type_explicitly_set_p_2 && da->debug_type && type != selected_debug_type_1 ) 
for ( i = strlen( asmspeca) - 1; i >= 0 && ( sch_istable[( unsigned __int8)asmspeca[i]] & 4) != 0; --i ) 
if ( !strcmp( asmspeca, table_20[ic].name) ) 
return table_20[ic].number; 
memset( value, 0, sizeof( rtx_const)); 
if ( mode_class_0[mode] == MODE_VECTOR_INT ) 
if ( mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
rtx addr; // [rsp+30h] [rbp-20h] 
rtx offset; // [rsp+38h] [rbp-18h] 
rtx base; // [rsp+40h] [rbp-10h] 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
base = 0LL; 
offset = 0LL; 
addr = x->fld[0].rtx; 
if ( *( _WORD *)addr == 96 || *( _WORD *)addr == 97 || *( _WORD *)addr == 98 || *( _WORD *)addr == 99 ) 
if ( *( _WORD *)addr == 96 || *( _WORD *)addr == 97 || *( _WORD *)addr == 98 || *( _WORD *)addr == 99 ) 
if ( *( _WORD *)addr == 96 || *( _WORD *)addr == 97 || *( _WORD *)addr == 98 || *( _WORD *)addr == 99 ) 
if ( *( _WORD *)addr == 96 || *( _WORD *)addr == 97 || *( _WORD *)addr == 98 || *( _WORD *)addr == 99 ) 
if ( ( ( reaching_defs[*( int *)( basic_block_for_insn->data.l[insn->fld[0].rtint] + 88)]->elms[*( ( _DWORD *)uid_cuid_1 
+ def_insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * def_insn->fld[0].rtint) & 0x3F)) & 1) != 0 ) 
if ( *( ( _DWORD *)uid_cuid_1 + def_insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) ) 
if ( *( ( _DWORD *)uid_cuid_1 + def_insn->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) ) 
rtx reg; // rax 
rtx v4; // rax 
rtx v5; // rax 
reg = currdef->ref->reg->fld[0].rtx; 
reg = currdef->ref->reg; 
v3 = ( unsigned int)reg->fld[0].rtint >> 6; 
v4 = currdef->ref->reg->fld[0].rtx; 
v4 = currdef->ref->reg; 
ssa_edges->elms[v3] |= 1LL << ( v4->fld[0].rtint & 0x3F); 
v5 = currdef->ref->reg->fld[0].rtx; 
v5 = currdef->ref->reg; 
values[v5->fld[0].rtuint].lattice_val = UNDEFINED; 
rtx reg; // rax 
rtx v4; // rax 
rtx v5; // rax 
reg = currdef->ref->reg->fld[0].rtx; 
reg = currdef->ref->reg; 
v3 = ( unsigned int)reg->fld[0].rtint >> 6; 
v4 = currdef->ref->reg->fld[0].rtx; 
v4 = currdef->ref->reg; 
ssa_edges->elms[v3] |= 1LL << ( v4->fld[0].rtint & 0x3F); 
v5 = currdef->ref->reg->fld[0].rtx; 
v5 = currdef->ref->reg; 
values[v5->fld[0].rtuint].lattice_val = VARYING; 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
quals = lang_hooks_0.tree_dump.type_quals( t); 
if ( !lang_hooks_0.tree_dump.dump_tree( di_0, t) ) 
queue_and_dump_index( di_0, off_816A46, t->decl.abstract_origin, 0); 
dump_int( di_0, off_816AF1, t->int_cst.int_cst.low); 
queue_and_dump_index( di_0, off_816AE8, t->block.abstract_origin, 0); 
queue_and_dump_index( di_0, &off_816AE8[4], t->decl.size_unit, 0); 
queue_and_dump_index( di_0, off_816AF1, t->vector.elements, 0); 
rtx insn; // [rsp+68h] [rbp-8h] 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
uid = insn->fld[0].rtuint; 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
rtx reg; // rax 
rtx insn; // [rsp+48h] [rbp-8h] 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
uid = insn->fld[0].rtuint; 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
reg = use->reg->fld[0].rtx; 
reg = use->reg; 
bitmap_set_bit( bb_info->lr_use, reg->fld[0].rtint); 
rtx insn; // [rsp+48h] [rbp-8h] 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
for ( def_link = df_0->insns[insn->fld[0].rtuint].defs; def_link; def_link = def_link->next ) 
rtx insn; // [rsp+38h] [rbp-18h] 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
for ( link = df_0->insns[insn->fld[0].rtuint].defs; link; link = link->next ) 
rtx reg; // rax 
rtx insn; // [rsp+88h] [rbp-8h] 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
uid = insn->fld[0].rtuint; 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
reg = use->reg->fld[0].rtx; 
reg = use->reg; 
uregno = reg->fld[0].rtuint; 
rtx insn; // [rsp+38h] [rbp-18h] 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
for ( link = df_0->insns[insn->fld[0].rtuint].uses; link; link = link->next ) 
rtx insn; // [rsp+58h] [rbp-8h] 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
for ( insn = bb->end; insn && insn != ( rtx)bb->head[1]; insn = ( rtx)insn[1] ) 
uid = insn->fld[0].rtuint; 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
rtx reg; // rax 
rtx insn; // [rsp+68h] [rbp-8h] 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
for ( insn = bb->head; insn && insn != bb->end[1].fld[0].rtx; insn = insn[1].fld[0].rtx ) 
uid = insn->fld[0].rtuint; 
if ( rtx_class[*( _WORD *)insn] == 105 ) 
reg = def_0->reg->fld[0].rtx; 
reg = def_0->reg; 
reg_def_last[reg->fld[0].rtint] = def_0; 
df_uses_record( df_0, ( rtx *)note->fld, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)( note_0->fld[0].rtwint + 8), DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)fld, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)v4, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)&insn[2], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
rtx rega; // [rsp+20h] [rbp-20h] 
rega = reg; 
rega = reg->fld[0].rtx; 
if ( *( _WORD *)rega == 63 ) 
rtx = rega->fld[0].rtx; 
rtx = rega; 
df_ref_record_1( df_0, rega, loc, insn, ref_type, ref_flags); 
if ( *( ( _BYTE *)rega + 2) == 18 ) 
else if ( *( ( _BYTE *)rega + 2) == 24 ) 
v9 = mode_size[*( ( unsigned __int8 *)rega + 2)] + v8 - 1; 
else if ( mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_INT 
else if ( mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_FLOAT ) 
|| mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_FLOAT ) 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1); 
return gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1); 
df_uses_record( df_0, ( rtx *)( *( _QWORD *)&x[2] + 8LL * j + 8), DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)&x[1], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)dst->fld, DF_REF_REG_MEM_STORE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)&dst[1], DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
df_uses_record( df_0, ( rtx *)dst[1].fld, DF_REF_REG_USE, bb, insn, ( df_ref_flags)0); 
memset( context, 0, sizeof( diagnostic_context_0)); 
if ( !displayed_5 ) 
displayed_5 = 1; 
v7 = build( ( tree_code)*( ( unsigned __int8 *)&arg0->block.common + 16), type, common, v6); 
v13 = mode_class_0[*( unsigned __int8 *)( notes->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( notes->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT; 
v17 = mode_class_0[*( unsigned __int8 *)( notes->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( notes->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[reg_raw_mode[ia]] == MODE_COMPLEX_INT 
|| mode_class_0[reg_raw_mode[ia]] == MODE_COMPLEX_FLOAT ) 
( rtx_code)*( _WORD *)notes, 
( machine_mode)*( ( unsigned __int8 *)notes + 2), 
if ( label == ( tree_node *)global_trees ) 
if ( mode_class_0[mode] != MODE_INT || can_compare_p( op, mode, ccp_jump) ) 
do_compare_rtx_and_jump( op0, op1, code, unsignedp, ( machine_mode)mode, v6, if_false_label, if_true_label); 
&& mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
timevar_start( TV_TOTAL_0); 
timevar_stop( TV_TOTAL_0); 
v6 = operand_sub*(short *)0xforce( op1, i, ( machine_mode)mode); 
v6 = operand_sub*(short *)0xforce( op1, i, ( machine_mode)mode); 
v7 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)mode); 
v7 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)mode); 
v4 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v4 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v5 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v5 = operand_sub*(short *)0xforce( op0, i, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v8 = operand_sub*(short *)0xforce( op0, ia, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v8 = operand_sub*(short *)0xforce( op0, ia, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( exp->int_cst.int_cst.low + 8) + 61LL) >> 1), 
op0_word = operand_sub*(short *)0xforce( op0, nwords - 1 - i, mode); 
op1_word = operand_sub*(short *)0xforce( op1, nwords - 1 - i, mode); 
notea->fld[0].rtwint = ( __int64)gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)old + 2), rl->reg_rtx); 
*loc = gen_raw_REG( ( machine_mode)*( ( unsigned __int8 *)*loc + 2), reg); 
op0 = expand_shift( RSHIFT_EXPR, ( machine_mode)operand_mode, op0, v11, subtarget, 1); 
else if ( can_compare_p( code, ( machine_mode)operand_mode, ccp_store_flag) ) 
if ( icode != CODE_FOR_nothing && ( !only_cheap || mode == *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
result = emit_store_flag( targeta, code, v13, v12, ( machine_mode)operand_mode, unsignedp, 1); 
targeta = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)targeta + 2)); 
resulta = compare_from_rtx( op0a, op1, code, unsignedp, ( machine_mode)operand_mode, 0LL); 
if ( mode_class_0[*( ( unsigned __int8 *)oldval + 2)] == MODE_INT && *( _WORD *)newval == 54 ) 
if ( rtwint != trunc_int_for_mode( rtwint, ( machine_mode)*( ( unsigned __int8 *)oldval + 2)) ) 
if ( undobuf_0.frees ) 
buf = undobuf_0.frees; 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
buf->next = undobuf_0.undos; 
undobuf_0.undos = buf; 
if ( undobuf_0.frees ) 
buf = undobuf_0.frees; 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
buf->next = undobuf_0.undos; 
undobuf_0.undos = buf; 
if ( !warned_11 ) 
warned_11 = 1; 
( machine_mode)*( ( unsigned __int8 *)counter_reg + 2), 
( machine_mode)*( ( unsigned __int8 *)diff + 2), 
( machine_mode)*( ( unsigned __int8 *)iterations + 2), 
( machine_mode)*( ( unsigned __int8 *)iterations + 2), 
color = ( const char *)&unk_779750; 
if ( reg_renumber[allocno_0[( __int64)*( int *)&allocno_order[4 * i]].reg] < 0 ) 
if ( reg_renumber[allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg] < 0 ) 
fprintf( file, off_779681, ( unsigned int)allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg); 
fprintf( file, off_779681, ( unsigned int)allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg); 
&& j != allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].reg ) 
if ( allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].size != 1 ) 
fprintf( file, " ( %d)", ( unsigned int)allocno_0[( __int64)*( int *)&allocno_order[4 * ia]].size); 
fprintf( file, ";; %d conflicts:", ( unsigned int)allocno_0[( __int64)ib].reg); 
fprintf( file, off_779681, ( unsigned int)allocno_0[( __int64)j_0].reg); 
fprintf( file, off_779681, ( unsigned int)allocno_0[( __int64)j_0].reg); 
if ( ( ( allocno_0[( __int64)ib].hard_reg_conflicts >> j_0a) & 1) != 0 ) 
fprintf( file, off_779681, ( unsigned int)j_0a); 
if ( ( ( allocno_0[( __int64)ib].hard_reg_preferences >> j_0b) & 1) != 0 ) 
fprintf( file, ";; %d preferences:", ( unsigned int)allocno_0[( __int64)ib].reg); 
if ( ( ( allocno_0[( __int64)ib].hard_reg_preferences >> j_0c) & 1) != 0 ) 
fprintf( file, off_779681, ( unsigned int)j_0c); 
else if ( mode_class_0[*( ( unsigned __int8 *)*chains->loc + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*chains->loc + 2)] == MODE_COMPLEX_FLOAT ) 
fprintf( file, off_74F495, ( unsigned int)dest->index); 
fputs( bitnames_8[i], file); 
v1 = ( const char *)&unk_74F330; 
fprintf( file, "; pref %s", reg_class_names_9[classa]); 
fprintf( file, "; pref %s, else %s", reg_class_names_9[classa], reg_class_names_9[altclass]); 
fprintf( file, "; pref %s, else %s", reg_class_names_9[classa], reg_class_names_9[altclass]); 
fprintf( file, "; %s or none", reg_class_names_9[classa]); 
fprintf( file, off_779681, ( unsigned int)ia); 
fprintf( di_0->stream, off_816959, ( unsigned int)( 15 - extra), &unk_816953); 
fprintf( di_0->stream, off_816959, ( unsigned int)( 15 - extra), &unk_816953); 
fprintf( di_0->stream, "\n%*s", 25, ( const char *)&unk_816953); 
v4 = ( const char *)&unk_7FF2EA; 
predictor_info_0[predictor].name, 
fprintf( dump, " %s:%i", reg_class_names_1[classa], ( unsigned int)costs_0[i].cost[classa]); 
fprintf( dump, " %s:%i", reg_class_names_1[classa], ( unsigned int)costs_0[i].cost[classa]); 
fprintf( dump, " MEM:%i\n", ( unsigned int)costs_0[i].mem_cost); 
fprintf( outf, off_775F97, ( unsigned int)i); 
fwrite( &unk_80A560, 1uLL, 2uLL, file); 
lang_hooks_0.print_statistics( ); 
*( ( _OWORD *)&newdecl->block + 10) = *( ( _OWORD *)&olddecl->block + 10); 
*( ( _OWORD *)&newdecl->block + 10) = *( ( _OWORD *)&olddecl->block + 10); 
*v4 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
( machine_mode)*( ( unsigned __int8 *)link + 2), 
( machine_mode)*( ( unsigned __int8 *)link + 2), 
predict_insn_def( copy, PRED_LOOP_HEADER, TAKEN_0); 
predict_insn_def( copy, PRED_LOOP_HEADER, NOT_TAKEN_0); 
if ( ( sch_istable[( unsigned __int8)c] & 0x10) != 0 ) 
v12 = byte_76C668[*( unsigned __int8 *)v6]; 
v10 = byte_76C668[*v14]; 
v4 = gen_rtx_fmt_s( ASM_INPUT, VOIDmode, &byte_7735B0); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
sprintf( label, "*.%s%u", ( const char *)&off_76E313, current_funcdef_number); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_76E313, current_funcdef_number); 
args_size_0 = 0LL; 
v0 = label_num_60++; 
sprintf( label_59, "*.%s%u", "LCFI", v0); 
assemble_name( asm_out_file, label_59); 
return label_59; 
&& ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
*( _QWORD *)&i[4] = -args_size_0; 
args_size_0 += *( _QWORD *)&i[4]; 
if ( args_size_0 < 0 ) 
args_size_0 = 0LL; 
dwarf2out_args_size( label, args_size_0); 
if ( ( unsigned int)format > 0xFF || !format_names_3[format] ) 
return format_names_3[format]; 
&& ( tem = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, *( rtx *)&x[1])) != 0LL 
tem = simplify_binary_operation( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), *constptr, tem); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x0, x1); 
xa = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)*( ( unsigned __int8 *)x + 2), newc, *( rtx *)&x[1]); 
( rtx_code)*( _WORD *)xa, 
( machine_mode)*( ( unsigned __int8 *)xa + 2), 
return gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)x + 2), newg); 
return adjust_address_1( newf, ( machine_mode)*( ( unsigned __int8 *)x + 2), *( _DWORD *)&x[1], 0, 1); 
return gen_rtx_SUBREG( ( machine_mode)*( ( unsigned __int8 *)x + 2), newf, *( _DWORD *)&x[1]); 
return gen_rtx_fmt_e( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), newe); 
v11 = eliminate_regs( x->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)x + 2), insn); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), newb, const_int_rtx[64]); 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
orig_operand[i] = recog_data_0.operand[i]; 
substed_operand[i] = recog_data_0.operand[i]; 
if ( insn_is_asm || insn_data_0[icode].operand[i].eliminable ) 
if ( recog_data_0.operand_type[i] && *( _WORD *)orig_operand[i] == 61 ) 
v10 = eliminate_regs( recog_data_0.operand[i], VOIDmode, v9); 
*recog_data_0.operand_loc[i] = 0LL; 
if ( recog_data_0.operand_type[i] 
for ( i = 0; i < recog_data_0.n_dups; ++i ) 
*recog_data_0.dup_loc[i] = *recog_data_0.operand_loc[recog_data_0.dup_num[i]]; 
elimination_effects( x->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
tree v20; // rax 
tree call_expr; // [rsp+40h] [rbp-50h] 
tree v37; // [rsp+48h] [rbp-48h] 
v28 = convert_modes( mode, ( machine_mode)imode, v27, unsignedp); 
v31 = convert_modes( mode, ( machine_mode)imode, v30, unsignedp); 
v33 = convert_modes( mode, ( machine_mode)imode, v32, unsignedp); 
v36 = convert_modes( mode, ( machine_mode)imode, v35, unsignedp); 
v38 = convert_modes( mode, ( machine_mode)imode, v37, unsignedp); 
v41 = convert_modes( mode, ( machine_mode)imode, v40, unsignedp); 
v45 = convert_modes( mode, ( machine_mode)imode, v44, unsignedp); 
v43 = convert_modes( mode, ( machine_mode)imode, v42, unsignedp); 
v6 = convert_modes( mode, ( machine_mode)imode, v5, unsignedp); 
v9 = convert_modes( mode, ( machine_mode)imode, v8, unsignedp); 
v12 = convert_modes( mode, ( machine_mode)imode, v11, unsignedp); 
v15 = convert_modes( mode, ( machine_mode)imode, v14, unsignedp); 
classa = mode_class_0[mode]; 
if ( insn_data_0[icode].operand->predicate( test, wider_mode) ) 
v6 = insn_data_0[icode].genfun( test, xa, ya, label); 
v7 = insn_data_0[icodea].genfun( xb); 
v9 = insn_data_0[icodeb].genfun( xc, yb); 
if ( !insn_data_0[icode].operand->predicate( targeta, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
if ( !insn_data_0[icode].operand->predicate( targeta, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) ) 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)insn_data_0[icode].operand + 8)); 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)insn_data_0[icode].operand + 8)); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
if ( !insn_data_0[icode].operand[2].predicate( 
op2b = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8), op2b); 
op2b = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8), op2b); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[3] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[3] + 8)) ) 
if ( !insn_data_0[icode].operand[3].predicate( 
op3a = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[3] + 8), op3a); 
src = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)orig_srca + 2)); 
( machine_mode)*( ( unsigned __int8 *)src + 2), 
*v4 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
temp = assign_stack_temp( ( machine_mode)*( ( unsigned __int8 *)dst + 2), ssizea, 0); 
dst = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)orig_dsta + 2)); 
if ( !insn_data_0[1159].operand->predicate( loc, v1) ) 
if ( constraint_accepts_reg_p( insn_data_0[v6].operand->constraint, reloadreg) 
rtx v6; // rax 
rtx targeta; // [rsp+10h] [rbp-70h] 
rtx insnsa; // [rsp+18h] [rbp-68h] 
rtx set; // [rsp+28h] [rbp-58h] 
rtx next; // [rsp+30h] [rbp-50h] 
rtx nexta; // [rsp+30h] [rbp-50h] 
rtx last; // [rsp+38h] [rbp-48h] 
rtx prev; // [rsp+40h] [rbp-40h] 
rtx note_0; // [rsp+48h] [rbp-38h] 
&& ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)xa + 2), xa->fld[0].rtx) 
&& !push_operand( xa, ( machine_mode)*( ( unsigned __int8 *)xa + 2)) 
&& ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)ya + 2), ya->fld[0].rtx) 
classa = mode_class_0[*( ( unsigned __int8 *)x + 2)]; 
v2 = insn_data_0[optab_table[30]->handlers[*( ( unsigned __int8 *)x + 2)].insn_code].genfun( x, y); 
if ( !push_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
ypart = operand_sub*(short *)0xforce( ya, i, mode); 
stack = push_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
fatal_insn( "VOIDmode on an output", insn, "reload1.c", 6651, "emit_output_reload_insns"); 
tem = gen_lowpart_common( ( machine_mode)*( unsigned __int8 *)( real_old->fld[0].rtwint + 2), reloadreg); 
v4 = insn_data_0[tertiary_icode].genfun( real_old, reloadreg, third_reloadreg); 
v3 = insn_data_0[rl->secondary_out_icode].genfun( real_old, second_reloadreg, reloadreg); 
if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
induction_1 *biv; // [rsp+1630h] [rbp-B0h] 
induction_1 *biv; // [rsp+1630h] [rbp-B0h] 
induction_1 *biv1; // [rsp+16A8h] [rbp-38h] 
induction_1 *biv1; // [rsp+16A8h] [rbp-38h] 
induction_1 *iv; // [rsp+16B0h] [rbp-30h] 
induction_1 *iv; // [rsp+16B0h] [rbp-30h] 
biv = bl_0->biv; 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
for ( biv1 = biv; biv1; biv1 = biv1->next_iv ) 
if ( *( _WORD *)biv->add_val != 54 ) 
biv->src_reg->fld[0].rtuint, 
( machine_mode)*( ( unsigned __int8 *)size + 2), 
pred = insn_data_0[code].operand->predicate; 
preda = insn_data_0[code].operand[1].predicate; 
predb = insn_data_0[code].operand[3].predicate; 
predc = insn_data_0[code].operand[2].predicate; 
pat = insn_data_0[code].genfun( target, xinner, op2, opalign); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
if ( *( _WORD *)xa == 61 && xa->fld[0].rtint <= 0x34u && mode_class_0[*( ( unsigned __int8 *)xa + 2)] != MODE_INT ) 
v38 = operand_sub*(short *)0xforce( xa, i, mode); 
else if ( mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rld[r].reg_rtx + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)rld[r].out + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rld[r].out + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[rld[r].mode] == MODE_COMPLEX_INT || mode_class_0[rld[r].mode] == MODE_COMPLEX_FLOAT ) 
pred = insn_data_0[icode].operand->predicate; 
v5 = insn_data_0[icode].genfun( xa); 
&& mode_class_0[mode] == MODE_INT 
if ( op1a == const_int_rtx[64] && ( codea == LT || codea == GE) && mode_class_0[mode] == MODE_INT ) 
targeta = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
if ( !insn_data_0[icode].operand[1].predicate( op0a, mode0) ) 
if ( !insn_data_0[icode].operand->predicate( targeta, *( ( unsigned __int8 *)targeta + 2)) 
temp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)targeta + 2)); 
pat = insn_data_0[icode].genfun( temp, op0a); 
( machine_mode)*( ( unsigned __int8 *)dest_reg + 2), 
( machine_mode)*( ( unsigned __int8 *)var + 2), 
replace_args_0( pfile, node, ( macro_arg_0 *)buff->base); 
xa = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)x + 2), x_ent->const_rtx); 
if ( mode_class_0[mode] != MODE_FLOAT ) 
if ( mode_class_0[mode] != MODE_FLOAT ) 
if ( ( sch_istable[( unsigned __int8)i] & 0x8C) != 0 ) 
else if ( ( sch_istable[( unsigned __int8)i] & 0x20) != 0 ) 
else if ( ( sch_istable[( unsigned __int8)i] & 2) != 0 ) 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&min_ascii->block.vars 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&min_ascii->block.vars 
|| *( _OWORD *)&max_ascii->block.vars < *( _OWORD *)&n->high->block.vars ) 
|| *( _OWORD *)&max_ascii->block.vars < *( _OWORD *)&n->high->block.vars ) 
predict_edge_def( e, PRED_LOOP_BRANCH, TAKEN_0); 
predict_edge_def( e_0, PRED_NORETURN, NOT_TAKEN_0); 
predict_edge_def( e_0, PRED_ERROR_RETURN, NOT_TAKEN_0); 
predict_edge_def( e_0, PRED_CALL, NOT_TAKEN_0); 
predict_insn_def( last_insn, PRED_POINTER, NOT_TAKEN_0); 
predict_insn_def( last_insn, PRED_POINTER, TAKEN_0); 
predict_insn_def( last_insn, PRED_UNCONDITIONAL, ( prediction)( cond != const_int_rtx[64])); 
if ( mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_VECTOR_FLOAT 
predict_insn_def( last_insn, PRED_OPCODE_NONEQUAL, TAKEN_0); 
if ( mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( cond->fld[0].rtwint + 2)] != MODE_VECTOR_FLOAT 
predict_insn_def( last_insn, PRED_OPCODE_NONEQUAL, NOT_TAKEN_0); 
v0 = edge_info_0; 
v6 = edge_info_0; 
else if ( mode_class_0[*( ( unsigned __int8 *)y + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)y + 2)] == MODE_COMPLEX_FLOAT ) 
if ( mode_class_0[mode] != MODE_INT || ix86_branch_cost <= 1 ) 
if ( mode_class_0[mode] != MODE_INT || can_compare_p( GE, mode, ccp_jump) ) 
tree clobbersa; // [rsp+10h] [rbp-150h] 
tree inputsa; // [rsp+18h] [rbp-148h] 
tree outputsa; // [rsp+20h] [rbp-140h] 
tree stringa; // [rsp+28h] [rbp-138h] 
tree type; // [rsp+78h] [rbp-E8h] 
tree val; // [rsp+80h] [rbp-E0h] 
tree type_0; // [rsp+88h] [rbp-D8h] 
v8 = to_rtx[1] ? *( tree_node **)( *( _QWORD *)&to_rtx[1] + 8LL) : 0LL; 
v9 = to_rtx[1] ? *( tree_node **)( *( _QWORD *)&to_rtx[1] + 8LL) : 0LL; 
( machine_mode)v13, 
( machine_mode)( BYTE5( to->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( from->common.type->block.abstract_origin) >> 1), 
temp = expand_expr( from, 0LL, ( machine_mode)*( ( unsigned __int8 *)to_rtx + 2), EXPAND_NORMAL); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
return gen_rtx_fmt_e( CONSTANT_P_RTX, ( machine_mode)value_mode, v2); 
targeta = force_reg( ( machine_mode)*( ( unsigned __int8 *)targeta + 2), targeta); 
rtx_c = expand_expr( c, 0LL, ( machine_mode)*( ( unsigned __int8 *)targeta + 2), EXPAND_NORMAL); 
predict_insn_def( insn, PRED_BUILTIN_EXPECT, ( prediction)taken); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 61LL) >> 1), 
v4 = adjust_address_1( mem, ( machine_mode)mode, offset, 1, 1); 
targeta = gen_reg_rtx( ( machine_mode)( BYTE5( expa->common.type->block.abstract_origin) >> 1)); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 61LL) >> 1), 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 61LL) >> 1), 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( arglist->int_cst.int_cst.low + 8) + 61LL) >> 1), 
emit_cmp_and_jump_insns( targetb, targetb, EQ, 0LL, ( machine_mode)*( ( unsigned __int8 *)targetb + 2), 0, lab1); 
insn_mode = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( integer_types[5]->block.abstract_origin) >> 1), 
return convert_to_mode( ( machine_mode)modeb, result_0, 0); 
if ( !insn_data_0[1316].operand->predicate( op0, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
if ( !insn_data_0[1316].operand->predicate( op0, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
targeta = gen_reg_rtx( ( machine_mode)( BYTE5( integer_types[5]->block.abstract_origin) >> 1)); 
for ( i = 0LL; i <= 3 && ( elim_regs_12[i].from != 16 || *(int *)0x749B24[2 * i] != 6); ++i ) 
v6 = gen_rtx_fmt_s( ASM_INPUT, VOIDmode, arg0); 
char_mode = *( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
if ( !insn_data_0[icode].operand[2].predicate( 
genfun = insn_data_0[icode].genfun; 
return convert_to_mode( ( machine_mode)value_mode, result, 0); 
if ( !gave_help_3 ) 
gave_help_3 = 1; 
result = gen_rtx_MEM( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), addr); 
tree expa; // [rsp+18h] [rbp-238h] 
tree nt; // [rsp+B0h] [rbp-1A0h] 
tree var; // [rsp+120h] [rbp-130h] 
tree funtype; // [rsp+140h] [rbp-110h] 
tree fndecl; // [rsp+180h] [rbp-D0h] 
classa = mode_class_0[mode]; 
if ( !unsignedp && flag_trapv && mode_class_0[mode] == MODE_INT ) 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
if ( !insn_data_0[icode].operand[1].predicate( xop0, mode0) ) 
if ( !insn_data_0[icode].operand->predicate( temp, submode) ) 
pat = insn_data_0[icode].genfun( temp, xop0); 
v4 = gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx); 
&& ( nonzero_bits( x->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)) & ~( mode_mask_array[*( unsigned __int8 *)( x->fld[0].rtwint + 2)] >> 1)) == 0 ) 
temp = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx); 
&& ( nonzero_bits( *( rtx *)( x->fld[0].rtwint + 8), ( machine_mode)*( ( unsigned __int8 *)x + 2)) & ~mode_mask_array[*( unsigned __int8 *)( x->fld[0].rtwint + 2)]) == 0 ) 
&& ( nonzero_bits( *( rtx *)( x->fld[0].rtwint + 8), ( machine_mode)*( ( unsigned __int8 *)x + 2)) & ~mode_mask_array[*( unsigned __int8 *)( x->fld[0].rtwint + 2)]) == 0 ) 
v7 = simplify_shift_const( 0LL, LSHIFTRT, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, pos); 
tem = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, ( 1LL << len) - 1); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
tem = simplify_shift_const( 0LL, v6, ( machine_mode)*( ( unsigned __int8 *)x + 2), v5, modewidth - ( unsigned int)len); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
x_1 = gen_rtx_MEM( ( machine_mode)LOBYTE( decl->block.supercontext), address); 
reg_mode = promote_mode( type, ( machine_mode)LOBYTE( decl->block.supercontext), &unsignedp, 0); 
emit_stack_restore( ( save_level)( thisblock->next == 0LL), thisblock->data.cond.next_label, 0LL); 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&minval->block.vars ) 
if ( *( _OWORD *)&n->low->block.vars < *( _OWORD *)&minval->block.vars ) 
if ( *( _OWORD *)&maxval->block.vars < *( _OWORD *)&n->high->block.vars ) 
rtx insn; // [rsp+38h] [rbp-28h] 
rtx etc_note; // [rsp+50h] [rbp-10h] 
rtx start_label; // [rsp+58h] [rbp-8h] 
start_label = cfun->stmt->x_loop_stack->data.cond.endif_label; 
if ( start_label == cfun->stmt->x_loop_stack->data.loop.continue_label ) 
emit_note_before( -94, start_label); 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
for ( etc_note = start_label; etc_note; etc_note = etc_note[1].fld[0].rtx ) 
if ( *( _WORD *)etc_note == 37 ) 
switch ( etc_note[2].fld[0].rtint ) 
etc_note = 0LL; 
if ( etc_note && optimize && !eh_regions && ( !debug_blocks || optimize > 1) ) 
inner = gen_rtx_fmt_e( USE, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), inner); 
if ( mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_INT 
&& mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_PARTIAL_INT 
&& mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_COMPLEX_INT 
&& mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_VECTOR_INT ) 
if ( mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_VECTOR_FLOAT ) 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( x->fld[0].rtwint + 8) + 2LL), 
&& can_fix_p( ( machine_mode)*( ( unsigned __int8 *)to + 2), fmode, 0, &must_trunc) != CODE_FOR_nothing ) 
emit_cmp_and_jump_insns( fromb, limit, GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)fromb + 2), 0, lab1); 
( machine_mode)*( ( unsigned __int8 *)fromb + 2), 
v5 = trunc_int_for_mode( 1LL << ( ( unsigned __int8)bitsize - 1), ( machine_mode)*( ( unsigned __int8 *)toc + 2)); 
( machine_mode)*( ( unsigned __int8 *)toc + 2), 
v8 = gen_rtx_fmt_e( UNSIGNED_FIX, ( machine_mode)*( ( unsigned __int8 *)toc + 2), v7); 
( machine_mode)*( ( unsigned __int8 *)toa + 2), 
v22 = gen_rtx_fmt_e( v21, ( machine_mode)*( ( unsigned __int8 *)toa + 2), fromc); 
|| can_float_p( fmode, ( machine_mode)*( ( unsigned __int8 *)fromb + 2), 0) == CODE_FOR_nothing); 
( machine_mode)*( ( unsigned __int8 *)fromb + 2), 
( machine_mode)*( ( unsigned __int8 *)tob + 2), 
v7 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)tob + 2), fromc); 
last_ptr = assign_stack_local( ( machine_mode)v7, v6, 0); 
x = gen_rtx_MEM( ( machine_mode)LOBYTE( subr->decl.result->block.supercontext), value_address); 
result->decl.rtl = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)hard_reg + 2)); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
&& insn_data_0[icode].operand->predicate( op0, mode) 
&& insn_data_0[icode].operand[1].predicate( op0, ( machine_mode)mode) 
&& insn_data_0[icode].operand[1].predicate( op0, ( machine_mode)mode) 
&& insn_data_0[icode].operand[2].predicate( op1, ( machine_mode)mode) ) 
&& insn_data_0[icode].operand[2].predicate( op1, ( machine_mode)mode) ) 
&& insn_data_0[icodea].operand->predicate( op0, mode) 
&& insn_data_0[icodea].operand[1].predicate( op0, ( machine_mode)mode) ) 
&& insn_data_0[icodea].operand[1].predicate( op0, ( machine_mode)mode) ) 
if ( !insn_data_0[icodea].operand[2].predicate( op1, ( machine_mode)mode) ) 
if ( !insn_data_0[icodea].operand[2].predicate( op1, ( machine_mode)mode) ) 
op1 = force_reg( ( machine_mode)mode, op1); 
v10 = insn_data_0[icodea].genfun( op0, op0, op1); 
rtx *v10; // r12 
rtx *v11; // rbx 
rtx *v12; // rbx 
rtx *v23; // rbx 
rtx temp; // [rsp+40h] [rbp-160h] BYREF 
rtx stack_save; // [rsp+48h] [rbp-158h] BYREF 
rtx stack_slot; // [rsp+68h] [rbp-138h] 
rtx copyimag; // [rsp+80h] [rbp-120h] 
rtx copyreal; // [rsp+88h] [rbp-118h] 
|| mode_class_0[*( ( unsigned __int8 *)op1 + 2)] != MODE_INT 
variant = basic_variant; 
variant = basic_variant; 
variant = negate_variant; 
variant = negate_variant; 
variant = add_variant; 
variant = add_variant; 
if ( opno != alg.ops - 1 || !target || variant == add_variant || preserve ) 
if ( opno != alg.ops - 1 || !target || variant == add_variant || preserve ) 
tree v8; // r12 
tree v9; // rax 
tree v11; // rax 
v6 = type_for_mode( ( machine_mode)*( ( unsigned __int8 *)add + 2), unsignedp); 
v8 = make_tree( type, mult); 
v9 = make_tree( type, x); 
v10 = build( MULT_EXPR, type, v9, v8); 
v10 = build( MULT_EXPR, type, v9, v8); 
v11 = fold( v10); 
v12 = build( PLUS_EXPR, type, v11, tree); 
for ( i = 0LL; i <= 3 && ( elim_regs_3[i].from != 16 || *(int *)0x80D4C4[2 * i] != 6); ++i ) 
allocno_0[( __int64)a1].hard_reg_copy_preferences |= allocno_0[( __int64)a2].hard_reg_copy_preferences; 
allocno_0[( __int64)a1].hard_reg_copy_preferences |= allocno_0[( __int64)a2].hard_reg_copy_preferences; 
allocno_0[( __int64)a2].hard_reg_copy_preferences |= allocno_0[( __int64)a1].hard_reg_copy_preferences; 
allocno_0[( __int64)a2].hard_reg_copy_preferences |= allocno_0[( __int64)a1].hard_reg_copy_preferences; 
allocno_0[( __int64)a1].hard_reg_preferences |= allocno_0[( __int64)a2].hard_reg_preferences; 
allocno_0[( __int64)a1].hard_reg_preferences |= allocno_0[( __int64)a2].hard_reg_preferences; 
allocno_0[( __int64)a2].hard_reg_preferences |= allocno_0[( __int64)a1].hard_reg_preferences; 
allocno_0[( __int64)a2].hard_reg_preferences |= allocno_0[( __int64)a1].hard_reg_preferences; 
allocno_0[( __int64)a1].hard_reg_full_preferences |= allocno_0[( __int64)a2].hard_reg_full_preferences; 
allocno_0[( __int64)a1].hard_reg_full_preferences |= allocno_0[( __int64)a2].hard_reg_full_preferences; 
allocno_0[( __int64)a2].hard_reg_full_preferences |= allocno_0[( __int64)a1].hard_reg_full_preferences; 
allocno_0[( __int64)a2].hard_reg_full_preferences |= allocno_0[( __int64)a1].hard_reg_full_preferences; 
src = operand_sub*(short *)0xforce( result_val, bitpos / v8, BLKmode); 
v17 = expand_expr( retval_rhs, val, ( machine_mode)*( ( unsigned __int8 *)val + 2), EXPAND_NORMAL); 
classa = mode_class_0[mode]; 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
mode1 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8); 
if ( !insn_data_0[icode].operand[1].predicate( xop0, mode0) ) 
if ( !insn_data_0[icode].operand[2].predicate( xop1, mode1) ) 
if ( !insn_data_0[icode].operand->predicate( targ0b, mode) || !insn_data_0[icode].operand[3].predicate( targ1b, mode) ) 
if ( !insn_data_0[icode].operand->predicate( targ0b, mode) || !insn_data_0[icode].operand[3].predicate( targ1b, mode) ) 
pat = insn_data_0[icode].genfun( targ0b, xop0, xop1, targ1b); 
classa = mode_class_0[mode]; 
mode0 = *( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8); 
if ( !insn_data_0[icode].operand[1].predicate( xop0, mode0) ) 
if ( !insn_data_0[icode].operand->predicate( temp, mode) ) 
pat = insn_data_0[icode].genfun( temp, xop0); 
v8 = operand_sub*(short *)0xforce( op0a, i, mode); 
v2 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)cond, VOIDmode, *( rtx *)&ev[1], *( rtx *)&cond[1]); 
predict_insn_def( insn, PRED_BUILTIN_EXPECT, ( prediction)( conda == const_true_rtx)); 
return expand_expr( size, 0LL, ( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), EXPAND_NORMAL); 
g1_add_vala = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)g1_add_val + 2), g1_add_val->fld[0].rtx, v4); 
g1_add_vala = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)g1_add_val + 2), g1_add_val, mult); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)ba + 2), rb, oba); 
memset( b, 0, sizeof( basic_block_def)); 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)ext_dep, ( machine_mode)*( ( unsigned __int8 *)ext_dep + 2), value); 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)ext_dep, ( machine_mode)*( ( unsigned __int8 *)ext_dep + 2), value); 
imode = int_mode_for_mode( ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
if ( mode_class_0[tmode] == MODE_VECTOR_INT || mode_class_0[tmode] == MODE_VECTOR_FLOAT ) 
if ( mode_class_0[tmode] == MODE_VECTOR_INT || mode_class_0[tmode] == MODE_VECTOR_FLOAT ) 
fatal_insn_not_found( insn, "recog.c", 2063, "extract_constrain_insn_cached"); 
v12 = mask_rtx( ( machine_mode)*( ( unsigned __int8 *)op0a + 2), 0, bitsize, 0); 
( machine_mode)*( ( unsigned __int8 *)op0a + 2), 
recog_data_0.insn = 0LL; 
recog_data_0.n_operands = 0; 
recog_data_0.n_alternatives = 0; 
recog_data_0.n_dups = 0; 
recog_data_0.n_operands = noperands; 
fatal_insn_not_found( insn, "recog.c", 2139, "extract_insn"); 
recog_data_0.operand, 
recog_data_0.operand_loc, 
recog_data_0.constraints, 
recog_data_0.operand_mode); 
p = recog_data_0.constraints[0]; 
recog_data_0.n_alternatives = 1; 
recog_data_0.n_alternatives += *v1 == 44; 
fatal_insn_not_found( insn, "recog.c", 2148, "extract_insn"); 
noperands = insn_data_0[rtint].n_operands; 
if ( insn != recog_data_0.insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
word = operand_sub*(short *)0xforce( 
worda = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
worda = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
fatal_insn( "could not find a spill register", insn, "reload1.c", 5051, "failed_reload"); 
fibonacci_heap<long, basic_block_def>::remove_root( heap, w); 
fibonacci_heap<long, basic_block_def>::insert_root( heap, a[i]); 
fibonacci_heap<long, basic_block_def>::insert_root( heap, x); 
fibonacci_heap<long, basic_block_def>::remove_root( heap, ret); 
fibonacci_heap<long, basic_block_def>::insert_root( heap, node); 
field_size_tree = ( tree_node *)*( &global_trees + 17); 
if ( mode_class_0[bl_0->biv->mode] != MODE_INT ) 
induction_1 *biv; // [rsp+48h] [rbp-28h] 
induction_1 *biv; // [rsp+48h] [rbp-28h] 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
if ( insn == biv->insn ) 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
biv->add_val, 
if ( debug_info_level_0 == DINFO_LEVEL_NORMAL 
|| debug_info_level_0 == DINFO_LEVEL_VERBOSE 
if ( debug_info_level_0 == DINFO_LEVEL_NORMAL 
|| debug_info_level_0 == DINFO_LEVEL_VERBOSE 
print_rtx_head = ( const char *)&unk_774FF3; 
fatal_insn_not_found( insna, "final.c", 2551, "final_scan_insn"); 
fatal_insn( "could not split insn", insna, "final.c", 2622, "final_scan_insn"); 
output_asm_insn( templatea, recog_data_0.operand); 
lang_hooks_0.finish( ); 
type->type.align = get_mode_alignment( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
timevar_push( TV_CFG_0); 
timevar_pop( TV_CFG_0); 
v9 = canon_hash( addr, ( machine_mode)v10) & 0x1F; 
v15 = canon_hash( ( *loc)->fld[0].rtx, ( machine_mode)v16) & 0x1F; 
elta = lookup( ( *loc)->fld[0].rtx, v15, ( machine_mode)v17); 
newa = simplify_gen_binary( ( rtx_code)*( _WORD *)*loc, ( machine_mode)v19, pc->exp, c); 
newa = simplify_gen_binary( ( rtx_code)*( _WORD *)*loc, ( machine_mode)v19, pc->exp, c); 
|| ( code == NE || code == LT && mode_class_0[inner_mode] == MODE_INT && mode_bitsize[inner_mode] == 1) 
if ( ( code == EQ || code == GE && mode_class_0[inner_mode] == MODE_INT && mode_bitsize[inner_mode] == 1) 
( machine_mode)*( unsigned __int8 *)( out->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)out + 2)); 
( machine_mode)*( unsigned __int8 *)( in->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)in + 2)); 
else if ( mode_class_0[outmode] == MODE_COMPLEX_INT || mode_class_0[outmode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[outmode] == MODE_COMPLEX_INT || mode_class_0[outmode] == MODE_COMPLEX_FLOAT ) 
&& !refers_to_regno_for_reload_p( regno, regno + nwords, *( rtx *)&this_insn_1[2], outloc) ) 
&& ( !value || find_reg_note( this_insn_1, REG_UNUSED, real_out)) 
&& find_reg_note( this_insn_1, REG_DEAD, real_in) 
if ( ix86_hard_regno_mode_ok( in->fld[0].rtint, ( machine_mode)v16) ) 
else if ( mode_class_0[inmode] == MODE_COMPLEX_INT || mode_class_0[inmode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[inmode] == MODE_COMPLEX_INT || mode_class_0[inmode] == MODE_COMPLEX_FLOAT ) 
&& !hard_reg_set_here_p( regno_0, nwords_0 + regno_0, *( rtx *)&this_insn_1[2]) 
&& ( !earlyclobber || !refers_to_regno_for_reload_p( regno_0, regno_0 + nwords_0, *( rtx *)&this_insn_1[2], inloc)) ) 
if ( flag_float_store && mode_class_0[*( ( unsigned __int8 *)goal + 2)] == MODE_FLOAT ) 
&& mode_class_0[*( unsigned __int8 *)( tem->fld[0].rtwint + 2)] == MODE_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( tema->fld[0].rtwint + 2)] == MODE_FLOAT 
v9 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v9 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v14 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v14 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v18 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v18 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v22 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v22 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
( htab_eq)tree_map_base_eq, 
if ( ( *( ( _BYTE *)cfun + 425) & 1) != 0 && qty_0[qtyno].n_calls_crossed > 0 ) 
else if ( qty_0[qtyno].n_calls_crossed ) 
v9 |= 1LL << eliminables_0[i].from; 
v13 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v13 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
|| !qty_0[qtyno].n_calls_crossed 
|| 4 * qty_0[qtyno].n_calls_crossed >= qty_0[qtyno].n_refs ) 
|| 4 * qty_0[qtyno].n_calls_crossed >= qty_0[qtyno].n_refs ) 
for ( op_no = recog_data_0.n_operands; --op_no >= 0; matchp->with[op_no] = matchp->commutative[op_no] ) 
for ( op_no = 0; op_no < recog_data_0.n_operands; ++op_no ) 
p = recog_data_0.constraints[op_no]; 
induction_1 *v; // [rsp+58h] [rbp-28h] 
induction_1 *v; // [rsp+58h] [rbp-28h] 
( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
v = ( induction_1 *)xmalloc( 0xA8uLL); 
v, 
v->mem = x; 
v3 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT 
v7 = mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_FLOAT 
v7 = mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[regno].mode] == MODE_COMPLEX_FLOAT 
v5 = reg_alternate_class( allocno_0[( __int64)num].reg); 
v5 = reg_preferred_class( allocno_0[( __int64)num].reg); 
mode = *( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[allocno_0[( __int64)num].reg] + 2); 
else if ( allocno_0[( __int64)num].calls_crossed ) 
v9 = allocno_0[( __int64)num].hard_reg_conflicts | v8; 
v10 = allocno_0[( __int64)num].regs_someone_prefers | ~regs_used_so_far | v9; 
v11 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v11 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
allocno_0[( __int64)num].hard_reg_copy_preferences &= ~v10; 
if ( ( allocno_0[( __int64)num].hard_reg_copy_preferences & ~reg_class_contents[0]) != 0 && best_reg >= 0 ) 
if ( ( ( allocno_0[( __int64)num].hard_reg_copy_preferences >> ia) & 1) != 0 
v15 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
v15 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ? 2 : 1; 
allocno_0[( __int64)num].hard_reg_preferences &= ~v10; 
else if ( mode_class_0[*( ( unsigned __int8 *)datum + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)datum + 2)] == MODE_COMPLEX_FLOAT ) 
v4 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT 
v4 = mode_class_0[*( unsigned __int8 *)( link->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( link->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[*( ( unsigned __int8 *)chain->rld[i].reg_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)chain->rld[i].reg_rtx + 2)] == MODE_COMPLEX_FLOAT ) 
if ( !strict_memory_address_p( ( machine_mode)*( ( unsigned __int8 *)tem + 2), tem->fld[0].rtx) ) 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
&& !regno_clobbered_p( regno, this_insn_1, mode, 0) ) 
( machine_mode)*( ( unsigned __int8 *)ada + 2), 
( machine_mode)*( ( unsigned __int8 *)v13 + 2), 
adb = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)ada + 2), v16, v15); 
( machine_mode)*( ( unsigned __int8 *)adb + 2), 
adc = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)ada + 2), *( rtx *)( ada->fld[0].rtwint + 8), v17); 
( machine_mode)*( ( unsigned __int8 *)adc + 2), 
( machine_mode)*( ( unsigned __int8 *)ada + 2), 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
rtx xa; // [rsp+10h] [rbp-E0h] BYREF 
rtx tem_0; // [rsp+28h] [rbp-C8h] BYREF 
tem_0 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&x[1]); 
xa = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, tem_0); 
( machine_mode)*( ( unsigned __int8 *)tem + 2), 
if ( replace_reloads && x != recog_data_0.operand[opnum] ) 
if ( replace_reloads && recog_data_0.operand[opnum] != xa ) 
( machine_mode)*( ( unsigned __int8 *)mem + 2), 
( machine_mode)*( ( unsigned __int8 *)xa + 2), 
tem_0 = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)xa + 2), reg_equiv_constant[regno_0]); 
( machine_mode)*( unsigned __int8 *)( xa->fld[0].rtwint + 2)); 
tem_0 = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)xa + 2), tem_0); 
&& ( !strict_memory_address_p( ( machine_mode)*( ( unsigned __int8 *)xa + 2), reg_equiv_mem[regno_0]->fld[0].rtx) 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)*loc, ( machine_mode)*( ( unsigned __int8 *)*loc + 2), x, y); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)*loc, ( machine_mode)*( ( unsigned __int8 *)*loc + 2), x, y); 
( machine_mode)*( unsigned __int8 *)( ( *loc)->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)*loc + 2)); 
return gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*loc + 2), rtint + v3); 
( machine_mode)*( ( unsigned __int8 *)*loc + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
v24 = gen_rtx_fmt_e( NOT, ( machine_mode)*( ( unsigned __int8 *)x + 2), v23); 
&& !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
if ( mode_class_0[*( ( unsigned __int8 *)inner + 2)] != MODE_PARTIAL_INT 
&& mode_class_0[*( unsigned __int8 *)( *( _QWORD *)&x[1] + 2LL)] != MODE_PARTIAL_INT ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
induction_1 *same; // [rsp+40h] [rbp-70h] 
induction_1 *same; // [rsp+40h] [rbp-70h] 
induction_1 *v2; // [rsp+A0h] [rbp-10h] 
induction_1 *v2; // [rsp+A0h] [rbp-10h] 
induction_1 *v2a; // [rsp+A0h] [rbp-10h] 
induction_1 *v2a; // [rsp+A0h] [rbp-10h] 
induction_1 *v2b; // [rsp+A0h] [rbp-10h] 
induction_1 *v2b; // [rsp+A0h] [rbp-10h] 
induction_1 *v; // [rsp+A8h] [rbp-8h] 
induction_1 *v; // [rsp+A8h] [rbp-8h] 
induction_1 *va; // [rsp+A8h] [rbp-8h] 
induction_1 *va; // [rsp+A8h] [rbp-8h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v2 = v->next_iv; v2; v2 = v2->next_iv ) 
for ( v2 = v->next_iv; v2; v2 = v2->next_iv ) 
induction_1 *v; // [rsp+50h] [rbp-10h] 
induction_1 *v; // [rsp+50h] [rbp-10h] 
for ( v = bl_0->biv; biv_splittable && v; v = v->next_iv ) 
for ( v = bl_0->biv; biv_splittable && v; v = v->next_iv ) 
for ( v = bl_0->biv; biv_splittable && v; v = v->next_iv ) 
for ( v = bl_0->biv; biv_splittable && v; v = v->next_iv ) 
if ( rtx_class[*( _WORD *)v->insn] == 105 ) 
if ( **( _WORD **)&v->insn[2] == 47 ) 
v3 = ( rtx)v->insn[2]; 
v3 = single_set_2( v->insn, *( rtx *)&v->insn[2]); 
v3 = single_set_2( v->insn, *( rtx *)&v->insn[2]); 
if ( ( cost = ix86_register_move_cost( m1, ( reg_class)classa, dest_class), best_size < reg_class_size[classa]) 
best_cost = ix86_register_move_cost( m1, ( reg_class)classa, dest_class); 
p = initializer_stack_0; 
while ( constructor_stack_0 ) 
q = constructor_stack_0; 
constructor_stack_0 = constructor_stack_0->next; 
constructor_stack_0 = constructor_stack_0->next; 
if ( constructor_range_stack_0 ) 
constructor_stack_0 = p->constructor_stack; 
constructor_range_stack_0 = p->constructor_range_stack; 
spelling_0 = p->spelling; 
initializer_stack_0 = p->next; 
error( "can't use '%s' as a %s register", name, what_option_2[fixed][call_used]); 
validate_change( insn, recog_data_0.operand_loc[match_number], src, 1); 
v2 = ( const char *)&unk_74FB08; 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)x + 2), ad) ) 
replacemente->new = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)var + 2)); 
temd = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v15 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)var + 2), temd); 
tem1a = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)temc + 2)); 
replacementf->new = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)var + 2)); 
v26 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)fixeddesta + 2)); 
v4 = ( const char *)&unk_74FBAF; 
v5 = ( const char *)&unk_74FBAF; 
v6 = ( const char *)&unk_74FBAF; 
v7 = ( const char *)&unk_74FBAF; 
return ( const char *)&unk_74A1BC; 
*( _OWORD *)v9.r = *( _OWORD *)&arg1a->block.vars; 
v2 = rhs ? rhs : ( tree_node *)*( &global_trees + 11); 
v4 = *( _OWORD *)&exp->block.vars; 
rtx xa; // [rsp+8h] [rbp-228h] 
rtx replacements[2]; // [rsp+20h] [rbp-210h] 
rtx folded_arg1; // [rsp+40h] [rbp-1F0h] BYREF 
rtx folded_arg0; // [rsp+48h] [rbp-1E8h] BYREF 
temp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2)); 
op2a = negate_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2), op2a); 
( machine_mode)*( ( unsigned __int8 *)value + 2), 
( machine_mode)*( ( unsigned __int8 *)value + 2), 
( machine_mode)*( ( unsigned __int8 *)value + 2), 
v9 = force_reg( ( machine_mode)*( unsigned __int8 *)( value->fld[0].rtwint + 2), v8); 
return simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)value + 2), v9, v7, v6); 
return expand_mult( ( machine_mode)*( ( unsigned __int8 *)value + 2), tmp, v3, target, 1); 
if ( mode_class_0[mode] == mode_class_0[*( ( unsigned __int8 *)x + 2)] && have_insn_for( code, mode) ) 
if ( mode_class_0[mode] == mode_class_0[*( ( unsigned __int8 *)x + 2)] && have_insn_for( code, mode) ) 
v38 = gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), v37); 
v40 = gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), v39); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
y = gen_binary( AND, ( machine_mode)*( ( unsigned __int8 *)xa + 2), xa->fld[0].rtx, v11); 
if ( ( v16 & ~nonzero_bits( x->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)x + 2))) == 0 ) 
( rtx_code)*( _WORD *)x, 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
fancy_abort( &off_76BD38[4], 858, "format_with_decl"); 
while ( ( sch_istable[*( ( unsigned __int8 *)p - 1)] & 0x88) == 0 ); 
memset( e, 0, sizeof( edge_def)); 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
free( uid_cuid_1); 
temp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
return expand_unop( ( machine_mode)*( ( unsigned __int8 *)x + 2), optab_table[17], x, temp, 0); 
immediate_operand( recog_data_0.operand[1], VOIDmode); 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) 
&& general_operand( recog_data_0.operand[0], QImode) 
v4 = &subtitle; 
if ( !insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
if ( !insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
|| !insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
|| !insn_data_0[icode].operand[2].predicate( 
return insn_data_0[icode].genfun( x, x, y); 
&& insn_data_0[icode].operand->predicate( r0, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
&& insn_data_0[icode].operand->predicate( r0, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
&& insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
&& insn_data_0[icode].operand[2].predicate( 
return insn_data_0[icode].genfun( r0, r1, c); 
result = expand_mult_add( b, reg, m, a, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
if ( !compiled_from_record_0++ ) 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
v5 = insn_data_0[optab_table[41]->handlers[mode].insn_code].genfun( op1, op2); 
v2 = ix86_expand_compare( ( rtx_code)*( _WORD *)operand0, 0LL, 0LL); 
else if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
formal_list = ( char *)&ret_val; 
formal_list = ( char *)&ret_val; 
this_type = gen_type( &ret_val, *( tree *)&formal_type[2], ansi); 
if ( formal_type == ( tree_node *)*( &global_trees + 27) ) 
if ( formal_type != ( tree_node *)*( &global_trees + 27) ) 
v3 = subreg_highpart_offset( mode, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
result = simplify_gen_subreg( mode, x, ( machine_mode)*( ( unsigned __int8 *)x + 2), v3); 
v4 = force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
if ( mode_class_0[mode] == MODE_FLOAT && *( ( _BYTE *)x + 2) && msize > xsize ) 
offset = subreg_lowpart_offset( mode, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
&& ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT) ) 
&& ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT) ) 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)x, mode, x->fld[0].rtx); 
return simplify_gen_subreg( mode, x, ( machine_mode)*( ( unsigned __int8 *)x + 2), offset); 
if ( ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT) 
if ( ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT) 
if ( mode_class_0[mode] == MODE_FLOAT && mode_bitsize[mode] == 32 && *( _WORD *)x == 54 ) 
if ( mode_class_0[mode] != MODE_FLOAT 
if ( mode_class_0[mode] != MODE_INT && mode_class_0[mode] != MODE_PARTIAL_INT 
if ( mode_class_0[mode] != MODE_INT && mode_class_0[mode] != MODE_PARTIAL_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT ) 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)xa + 2), const_int_rtx[64]); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)xa, mode, xa->fld[0].rtx, *( rtx *)&xa[1]); 
offset_0 = subreg_lowpart_offset( mode, ( machine_mode)*( ( unsigned __int8 *)xa + 2)); 
res = simplify_gen_subreg( mode, xa, ( machine_mode)*( ( unsigned __int8 *)xa + 2), offset_0); 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)xa + 2), const_int_rtx[64]); 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)xa + 2), const_int_rtx[64]); 
v3 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
fixup_var_refs( reg, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0, reg, 0LL); 
if ( mode_class_0[mode] == MODE_CC && optab_table[30]->handlers[mode].insn_code == CODE_FOR_nothing ) 
return insn_data_0[optab_table[30]->handlers[tmode].insn_code].genfun( xa, ya); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v7, v6); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v7, v6); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v7, v6); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v7, v6); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v6, operand1); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), v6, operand1); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), operand1, v6); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), operand1, v6); 
if ( generating_concat_p && ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT) ) 
if ( generating_concat_p && ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT) ) 
if ( mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
&& ( tem = gen_lowpart_common( ( machine_mode)*( unsigned __int8 *)( in->fld[0].rtwint + 2), out)) != 0LL ) 
tema = gen_lowpart_common( ( machine_mode)*( unsigned __int8 *)( out->fld[0].rtwint + 2), in); 
ina = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)ina + 2), op0, op1); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[code].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[code].operand[2] + 8)) ) 
&& !insn_data_0[code].operand[2].predicate( 
( machine_mode)*( ( unsigned __int8 *)outa + 2), 
loc = get_secondary_mem( ina, ( machine_mode)*( ( unsigned __int8 *)outa + 2), opnum, type); 
outa = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)loc + 2), outa->fld[0].rtint); 
ina = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)loc + 2), ina->fld[0].rtint); 
v1 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)new_op1); 
v1 = reverse_condition( ( rtx_code)*( _WORD *)new_op1); 
v1 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)new_op1); 
v1 = reverse_condition( ( rtx_code)*( _WORD *)new_op1); 
v1 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)new_op0); 
v1 = reverse_condition( ( rtx_code)*( _WORD *)new_op0); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], 0LL); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], operands[5]); 
operands[4] = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
operands[4] = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), operands[4]); 
( rtx_code)*( _WORD *)operands[3], 
( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
operands[4] = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2), operands[2]); 
operands[4] = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), operands[4]); 
( rtx_code)*( _WORD *)operands[3], 
( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2)); 
( rtx_code)*( _WORD *)operand1, 
( machine_mode)*( ( unsigned __int8 *)operand1 + 2), 
v6 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v5, v4); 
v6 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v5, v4); 
v3 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v2, operand5); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v2, operand5); 
*( _WORD *)operands[1] = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v2, operand5); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v2, operand5); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), operand1, operand2); 
v3 = gen_rtx( ( rtx_code)*( _WORD *)operand3, ( machine_mode)*( ( unsigned __int8 *)operand3 + 2), operand1, operand2); 
operands[2] = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
operands[2] = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), operands[2]); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v10 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v10 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
&& insn_data_0[icode].operand->predicate( r0, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
&& insn_data_0[icode].operand->predicate( r0, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
&& insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)) ) 
&& insn_data_0[icode].operand[2].predicate( 
return insn_data_0[icode].genfun( r0, r1, c); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
sprintf( label_id, "*.%s%u", ( const char *)&off_76E313, current_funcdef_number); 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
v7 = concat( ret_val, &off_749F5E, 0LL); 
if ( !*( ( _BYTE *)op + 2) && modea && mode_class_0[modea] != MODE_INT && mode_class_0[modea] != MODE_PARTIAL_INT ) 
if ( !*( ( _BYTE *)op + 2) && modea && mode_class_0[modea] != MODE_INT && mode_class_0[modea] != MODE_PARTIAL_INT ) 
if ( mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_FLOAT 
if ( !explained_1 ) 
explained_1 = 1; 
return ( alias_set_entry_0)sn->value; 
fatal_insn_not_found( insn, "insn-attrtab.c", 12189, "get_attr_athlon_decode"); 
result = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
result = which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode); 
result = which_alternative != 1 || memory_operand( recog_data_0.operand[1], VOIDmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 11973, "get_attr_athlon_fpunits"); 
&& ( register_operand( recog_data_0.operand[1], SImode) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode)) ) 
&& ( register_operand( recog_data_0.operand[1], SImode) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode)) ) 
else if ( register_operand( recog_data_0.operand[1], SImode) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
&& ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode)) ) 
&& ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode)) ) 
&& ( register_operand( recog_data_0.operand[1], SImode) 
|| immediate_operand( recog_data_0.operand[1], VOIDmode)) ) 
if ( mult_operator( recog_data_0.operand[3]) ) 
if ( which_alternative || mult_operator( recog_data_0.operand[3]) ) 
if ( which_alternative || !mult_operator( recog_data_0.operand[3]) ) 
if ( mult_operator( recog_data_0.operand[3]) ) 
if ( mult_operator( recog_data_0.operand[3]) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 13438, "get_attr_i387"); 
|| mult_operator( recog_data_0.operand[3]) 
|| which_alternative != 2 && mult_operator( recog_data_0.operand[3]) 
|| mult_operator( recog_data_0.operand[3]) 
|| which_alternative != 2 && mult_operator( recog_data_0.operand[3]) 
|| mult_operator( recog_data_0.operand[3]) 
|| mult_operator( recog_data_0.operand[3]) 
fatal_insn_not_found( insn, "insn-attrtab.c", 13072, "get_attr_imm_disp"); 
result = memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
&& ( !flag_pic || !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1])) 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
result = q_regs_operand( ( __int64)recog_data_0.operand[0], 2) 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
&& ( !flag_pic || !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1])) 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode); 
fatal_insn_not_found( insn, "insn-attrtab.c", 13642, "get_attr_length_address"); 
if ( !constant_call_address_operand( recog_data_0.operand[1], VOIDmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 14632, "get_attr_length_immediate"); 
&& symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
|| flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
if ( !q_regs_operand( ( __int64)recog_data_0.operand[0], 2) || ( ( x86_movx >> ix86_cpu) & 1) != 0 ) 
&& symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
|| flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
else if ( flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
|| ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2]) ) 
if ( !incdec_operand( recog_data_0.operand[2]) ) 
|| ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2]) ) 
|| ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2]) ) 
if ( !incdec_operand( recog_data_0.operand[2]) ) 
if ( !incdec_operand( recog_data_0.operand[2]) && which_alternative != 2 ) 
if ( !incdec_operand( recog_data_0.operand[2]) ) 
if ( !incdec_operand( recog_data_0.operand[2]) && which_alternative != 3 ) 
if ( !incdec_operand( recog_data_0.operand[2]) ) 
|| ( ( ( x86_double_with_add >> ix86_cpu) & 1) == 0 || !const1_operand( recog_data_0.operand[2])) 
fatal_insn_not_found( insn, "insn-attrtab.c", 15861, "get_attr_memory"); 
return memory_operand( recog_data_0.operand[0], VOIDmode) || memory_operand( recog_data_0.operand[1], VOIDmode); 
return memory_operand( recog_data_0.operand[0], VOIDmode) || memory_operand( recog_data_0.operand[1], VOIDmode); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
&& symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
return memory_operand( recog_data_0.operand[1], VOIDmode) 
|| flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1])) 
&& memory_operand( recog_data_0.operand[2], VOIDmode); 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 17669, "get_attr_mode"); 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
&& aligned_operand( recog_data_0.operand[1], HImode) 
if ( q_regs_operand( ( __int64)recog_data_0.operand[0], 2) && ( ( x86_movx >> ix86_cpu) & 1) == 0 ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 16766, "get_attr_modrm"); 
result = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
result = memory_operand( recog_data_0.operand[0], VOIDmode) != 0; 
result = flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
|| !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode); 
|| flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
|| !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode)); 
result = !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode); 
|| !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode); 
|| !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode)); 
result = !register_operand( recog_data_0.operand[0], VOIDmode) 
|| !immediate_operand( recog_data_0.operand[1], VOIDmode); 
|| !register_operand( recog_data_0.operand[0], VOIDmode) 
fatal_insn_not_found( insn, "insn-attrtab.c", 19258, "get_attr_pent_pair"); 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
&& symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
&& ( !flag_pic || !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1])) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
else if ( !q_regs_operand( ( __int64)recog_data_0.operand[0], 2) || ( ( x86_movx >> ix86_cpu) & 1) != 0 ) 
if ( which_alternative || memory_operand( recog_data_0.operand[1], VOIDmode) ) 
&& symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) 
&& ( !flag_pic || !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1])) ) 
if ( which_alternative != 1 || memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], v3) 
|| pic_symbolic_operand( recog_data_0.operand[2], v3) 
|| pic_symbolic_operand( recog_data_0.operand[2], v3) 
rtx v5; // rax 
rtx v7; // rax 
rtx v9; // rax 
fatal_insn_not_found( insn, "insn-attrtab.c", 20323, "get_attr_prefix_0f"); 
|| !aligned_operand( recog_data_0.operand[1], HImode)) 
result = !q_regs_operand( ( __int64)recog_data_0.operand[0], 2) || ( ( x86_movx >> ix86_cpu) & 1) != 0; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
rtx = recog_data_0.operand[0]->fld[0].rtx; 
rtx = recog_data_0.operand[0]; 
v5 = *( _WORD *)recog_data_0.operand[0] == 67 
v5 = *( _WORD *)recog_data_0.operand[0] == 67 
? ( rtx)recog_data_0.operand[0]->fld[0].rtwint 
v6 = insn_addresses_->data.i[v5->fld[0].rtint]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 20460, "get_attr_prefix_data16"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 20358, "get_attr_prefix_rep"); 
rtx v5; // rax 
fatal_insn_not_found( insn, "insn-attrtab.c", 21978, "get_attr_type"); 
else if ( flag_pic && symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
&& aligned_operand( recog_data_0.operand[1], HImode) ) 
rtx comparison; // [rsp+18h] [rbp-18h] 
comparison = get_condition_0( x, 0LL); 
if ( !comparison || !loop_invariant_p( loop, comparison->fld[0].rtx) || loop_invariant_p( loop, *( rtx *)&comparison[1]) ) 
if ( !comparison || !loop_invariant_p( loop, comparison->fld[0].rtx) || loop_invariant_p( loop, *( rtx *)&comparison[1]) ) 
if ( !comparison || !loop_invariant_p( loop, comparison->fld[0].rtx) || loop_invariant_p( loop, *( rtx *)&comparison[1]) ) 
return comparison; 
rtx = comparison->fld[0].rtx; 
v4 = (  struct rtx_def *)comparison[1]; 
v5 = swap_condition( ( rtx_code)*( _WORD *)comparison); 
v5 = swap_condition( ( rtx_code)*( _WORD *)comparison); 
name = ( const char *)&unk_816707; 
if ( set_2 == -1 ) 
set_2 = new_alias_set( ); 
return set_2; 
ivs->entries = ( initial_value_pair_0 *)xmalloc( 0x50uLL); 
ivs->entries = ( initial_value_pair_0 *)xrealloc( ivs->entries, 16LL * ivs->max_entries); 
*( _QWORD *)( v3 + 8) = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
&& ( v11 = ( tree_node *)*( &global_trees + 19), 
return insn_data_0[code].name; 
output = ( __int64 (  *)(  struct recog_data *, rtx))insn_data_0[code].output; 
output_format = insn_data_0[code].output_format; 
return ( const char *)output( &recog_data_0, insn); 
return ( const char *)insn_data_0[code].output; 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), value); 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
*loc = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)x + 2), const_int_rtx[64]); 
*loc = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)x + 2), const_int_rtx[64]); 
if ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT ) 
if ( mode_class_0[mode] == MODE_COMPLEX_FLOAT || mode_class_0[mode] == MODE_COMPLEX_INT ) 
&& ( mode_class_0[mode] == MODE_INT 
|| mode_class_0[mode] == MODE_PARTIAL_INT 
|| mode_class_0[mode] == MODE_COMPLEX_INT 
|| mode_class_0[mode] == MODE_VECTOR_INT) ) 
modea = mode_for_size( v5, mode_class_0[mode], 0); 
( machine_mode)*( ( unsigned __int8 *)subreg 
( machine_mode)*( ( unsigned __int8 *)*pat + 2))] 
if ( set_3 == -1 ) 
set_3 = new_alias_set( ); 
return set_3; 
p = pwd_1; 
if ( !pwd_1 ) 
*v0 = failure_errno_0; 
failure_errno_0 = e; 
*__errno_location( ) = failure_errno_0; 
pwd_1 = p; 
if ( lengtha == 1 && ( sch_istable[*( unsigned __int8 *)contents] & 4) != 0 ) 
timevar_push( TV_GC_0); 
timevar_pop( TV_GC_0); 
first_rtl = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&t->block.common + 16)); 
fprintf( stream, "\n%-17s%10s %16s %10s\n", ( const char *)&off_779511, "Number", "Bytes", "% Total"); 
eliminable_regset |= 1LL << eliminables_2[i].from; 
no_global_alloc_regs |= 1LL << eliminables_2[i].from; 
allocno_0 = (  struct allocno *)xcalloc( max_allocno, 0x40uLL); 
allocno_0[( __int64)num].reg = ie; 
allocno_0[( __int64)num].size = v4 / v5; 
allocno_0[( __int64)num].calls_crossed += *( _DWORD *)( reg_n_info->data.l[ie] + 32); 
allocno_0[( __int64)num].n_refs += *( _DWORD *)( reg_n_info->data.l[ie] + 16); 
allocno_0[( __int64)num].freq += *( _DWORD *)( reg_n_info->data.l[ie] + 20); 
if ( allocno_0[( __int64)num].live_length < *( _DWORD *)( reg_n_info->data.l[ie] + 28) ) 
allocno_0[( __int64)num].live_length = *( _DWORD *)( reg_n_info->data.l[ie] + 28); 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[ig] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[ig] + 2)] == MODE_COMPLEX_FLOAT ) 
allocno_0[ii].hard_reg_conflicts &= ~eliminable_regset; 
allocno_0[ii].hard_reg_copy_preferences &= ~eliminable_regset; 
allocno_0[ii].hard_reg_preferences &= ~eliminable_regset; 
if ( !allocno_0[ik].size ) 
allocno_0[ik].size = 1; 
mark_reg_live_nc( aa, ( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2)); 
if ( !already_1 && !pedantic ) 
already_1 = 1; 
v2 = *( _OWORD *)( ( char *)&parms_info->block + 24); 
to = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( expr_set->fld[0].rtwint + 2)); 
rd_kill[bb->index]->elms[*( ( _DWORD *)uid_cuid_1 + this_reg->insn->fld[0].rtint) >> 6] |= 1LL << ( *( ( _DWORD *)uid_cuid_1 + this_reg->insn->fld[0].rtint) & 0x3F); 
rd_kill[bb->index]->elms[*( ( _DWORD *)uid_cuid_1 + this_reg->insn->fld[0].rtint) >> 6] |= 1LL << ( *( ( _DWORD *)uid_cuid_1 + this_reg->insn->fld[0].rtint) & 0x3F); 
v3 = mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_COMPLEX_FLOAT 
nops = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16)); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( *( _QWORD *)&xa[2] + 8LL * ib + 8) + 2LL), 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( xa->fld[0].rtwint + 8LL * ia + 8) + 2LL), 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( x->fld[0].rtwint + 8LL * ia + 8) + 2LL), 
e = cselib_lookup( x, ( machine_mode)*( ( unsigned __int8 *)x + 2), create); 
if ( !std::allocator_traits<std::allocator<std::_Rb_tree_node<std::pair<std::string const, tcmalloc::MallocExtension::Property>>>>::allocate( 
insert_expr_in_table( src, ( machine_mode)*( ( unsigned __int8 *)dest + 2), insn, antic_p, v4); 
return insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
return insn_data_0[icode].operand->predicate( x, *( ( unsigned __int16 *)insn_data_0[icode].operand + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[1] + 8)) 
&& insn_data_0[icode].operand[1].predicate( 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[2] + 8)); 
&& insn_data_0[icode].operand[2].predicate( 
if ( hex_value[( unsigned __int8)c] == 99 ) 
return hex_value[( unsigned __int8)c]; 
low = primes_0; 
expr_0->reaching_reg = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v0->fld[0].rtwint + 2)); 
*ptrue = simplify_gen_unary( code, mode, true0, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
*pfalse = simplify_gen_unary( code, mode, false0, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
|| ( v7 = swap_condition( ( rtx_code)*( _WORD *)cond0), v7 == combine_reversed_comparison_code( cond1)) 
|| ( v11 = swap_condition( ( rtx_code)*( _WORD *)cond0), v11 == combine_reversed_comparison_code( cond1)) 
if ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT ) 
if ( mode_class_0[mode] == MODE_INT || mode_class_0[mode] == MODE_PARTIAL_INT ) 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
return immed_real_const_1( v2, ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1)); 
if ( !*( ( _BYTE *)op + 2) && mode && mode_class_0[mode] != MODE_INT && mode_class_0[mode] != MODE_PARTIAL_INT ) 
if ( !*( ( _BYTE *)op + 2) && mode && mode_class_0[mode] != MODE_INT && mode_class_0[mode] != MODE_PARTIAL_INT ) 
return in_section_0 == in_text; 
rtx incloc; // [rsp+50h] [rbp-10h] 
incloc = value->fld[0].rtx; 
if ( *( _WORD *)incloc == 61 ) 
reg_last_reload_reg[incloc->fld[0].rtuint] = 0LL; 
v7 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)incloc + 2), incloc, inc); 
v7 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)incloc + 2), incloc, inc); 
v7 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)incloc + 2), incloc, inc); 
v8 = gen_rtx_fmt_ee( SET, VOIDmode, incloc, v7); 
v10 = gen_move_insn( reloadreg, incloc); 
v16 = gen_move_insn( incloc, reloadreg); 
v14 = gen_move_insn( incloc, reloadreg); 
print_version( stderr, &sep); 
for ( b = builtin_array; b < ( const  struct builtin *)&unk_7628D0; ++b ) 
address = gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, addr_reg, v3); 
v3 = *( _QWORD *)&zero_cum_49.regno; 
*( _QWORD *)&cum->words = *( _QWORD *)&zero_cum_49.words; 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_49.sse_nregs; 
cum->maybe_vaarg = zero_cum_49.maybe_vaarg; 
ggc_add_root( &unused_expr_list, 1, 1, ( void ( *)( void *))json_end_group); 
if ( initialized_12 ) 
initialized_12 = 1; 
optab_0 optablea; // [rsp+18h] [rbp-48h] 
optab_0 optablea; // [rsp+18h] [rbp-48h] 
optablea = optable; 
v8 = sch_tolower[*( unsigned __int8 *)q]; 
optablea->handlers[mode].libfunc = v13; 
init_integral_libfuncs( optab_table[0], opname, 51); 
init_floating_libfuncs( optab_table[0], opname, 51); 
init_integral_libfuncs( optab_table[1], &opname[4], 51); 
init_floating_libfuncs( optab_table[1], opname, 51); 
init_integral_libfuncs( optab_table[10], off_7FEA13, 51); 
init_floating_libfuncs( optab_table[10], off_7FEA13, 51); 
init_integral_libfuncs( optab_table[19], off_7FEA44, 51); 
init_integral_libfuncs( optab_table[20], off_7FEA48, 51); 
init_integral_libfuncs( optab_table[21], &off_7FEA48[4], 51); 
init_integral_libfuncs( optab_table[27], off_7FEA5F, 51); 
init_floating_libfuncs( optab_table[27], off_7FEA5F, 51); 
for ( p = ( reg_class *)( 100LL * i + 11026976); *p != LIM_REG_CLASSES; ++p ) 
for ( p = ( reg_class *)( 100LL * j + 11029504); *p != LIM_REG_CLASSES; ++p ) 
if ( reg_classes_intersect_p( ( reg_class)i, GENERAL_REGS) ) 
else if ( mode_class_0[m] == MODE_COMPLEX_INT || mode_class_0[m] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[m] == MODE_COMPLEX_INT || mode_class_0[m] == MODE_COMPLEX_FLOAT ) 
if ( !fixed_regs[j] && ( ( reg_class_contents[i] >> j) & 1) != 0 && ix86_hard_regno_mode_ok( j, ( machine_mode)m) ) 
cost = ix86_register_move_cost( ( machine_mode)m, ( reg_class)i, ( reg_class)j); 
cost = ix86_register_move_cost( ( machine_mode)m, ( reg_class)i, ( reg_class)j); 
for ( p2 = ( reg_class *)( 100LL * j + 11029504); *p2 != LIM_REG_CLASSES; ++p2 ) 
for ( p1 = ( reg_class *)( 100LL * i + 11029504); *p1 != LIM_REG_CLASSES; ++p1 ) 
top_of_stack[i] = gen_rtx_MEM( ( machine_mode)i, global_rtl[2]); 
ident_hash->alloc_node = ( hashnode ( *)(  struct hash_table *))alloc_node_0; 
in_named_htab = htab_create( 0x1FuLL, ( htab_hash)WebCore::MessagePortChannel::close, ( htab_eq)in_named_entry_eq, 0LL); 
copy = rtx_alloc( ( rtx_code)*( _WORD *)notes); 
tree var; // rdx 
tree v25; // rdx 
tree inc_0; // [rsp+40h] [rbp-50h] 
tree type; // [rsp+60h] [rbp-30h] 
tree p; // [rsp+68h] [rbp-28h] 
p = actparms; 
while ( p ) 
type = *( tree *)( p->int_cst.int_cst.low + 8); 
preal = gen_realpart( ( machine_mode)*( unsigned __int8 *)( p->fld[0].rtwint + 2), p); 
pimag = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)preal + 2), p); 
valuea = lang_hooks_0.expand_constant( value); 
|| mode_class_0[BYTE5( inner_0->common.type->block.abstract_origin) >> 1] != MODE_INT 
&& mode_class_0[BYTE5( inner_0->common.type->block.abstract_origin) >> 1] != MODE_PARTIAL_INT 
&& mode_class_0[BYTE5( inner_0->common.type->block.abstract_origin) >> 1] != MODE_COMPLEX_INT 
&& mode_class_0[BYTE5( inner_0->common.type->block.abstract_origin) >> 1] != MODE_VECTOR_INT ) 
|| mode_class_0[BYTE5( inner_1->common.type->block.abstract_origin) >> 1] != MODE_INT 
&& mode_class_0[BYTE5( inner_1->common.type->block.abstract_origin) >> 1] != MODE_PARTIAL_INT 
&& mode_class_0[BYTE5( inner_1->common.type->block.abstract_origin) >> 1] != MODE_COMPLEX_INT 
&& mode_class_0[BYTE5( inner_1->common.type->block.abstract_origin) >> 1] != MODE_VECTOR_INT ) 
if ( valid0 == ( tree_node *)*( &global_trees + 14) ) 
if ( valid1 == ( tree_node *)*( &global_trees + 14) ) 
&& ( lang_hooks_0.tree_inlining.disregard_inline_limits( fna) || 10 * fna->decl.u1.i <= compiler_params->value / 2) ) 
if ( !lang_hooks_0.tree_inlining.disregard_inline_limits( fna) ) 
if ( inlinable && lang_hooks_0.tree_inlining.cannot_inline_tree_fn( &fna) ) 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
x_ent->const_rtx = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)x + 2), p_1->exp); 
v4 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT; 
make_new_qty( regno, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
else if ( mode_class_0[save_mode[regno]] == MODE_COMPLEX_INT || mode_class_0[save_mode[regno]] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[save_mode[regno]] == MODE_COMPLEX_INT || mode_class_0[save_mode[regno]] == MODE_COMPLEX_FLOAT ) 
v10 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)mem + 2), regno); 
else if ( mode_class_0[save_mode[regno]] == MODE_COMPLEX_INT || mode_class_0[save_mode[regno]] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[save_mode[regno]] == MODE_COMPLEX_INT || mode_class_0[save_mode[regno]] == MODE_COMPLEX_FLOAT ) 
v11 = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)mem + 2), regno); 
fatal_insn_not_found( insn, "insn-attrtab.c", 29, "insn_current_length"); 
if ( std::allocator_traits<std::allocator<std::_Rb_tree_node<std::pair<std::string const, tcmalloc::MallocExtension::Property>>>>::allocate( 
else if ( mode_class_0[*( ( unsigned __int8 *)r + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)r + 2)] == MODE_COMPLEX_FLOAT ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 356, "insn_default_length"); 
if ( !register_operand( recog_data_0.operand[0], DImode) ) 
if ( !register_operand( recog_data_0.operand[0], SImode) ) 
if ( !register_operand( recog_data_0.operand[0], VOIDmode) ) 
memset( &recog_data_0, 0, 0xF0uLL); 
memset( recog_data_0.operand_loc, 0, sizeof( recog_data_0.operand_loc)); 
memset( recog_data_0.operand_loc, 0, sizeof( recog_data_0.operand_loc)); 
fatal_insn_not_found( insn, "insn-extract.c", 26, "insn_extract"); 
recog_data_0.operand_loc[0] = ( rtx *)pat[2]->fld; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand_loc[1] = ( rtx *)&pat[2][1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand_loc[0] = ( rtx *)( pat[2]->fld[0].rtwint + 8); 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand[0] = *recog_data_0.operand_loc[0]; 
recog_data_0.operand_loc[1] = ( rtx *)( pat[2]->fld[0].rtwint + 16); 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand[1] = *recog_data_0.operand_loc[1]; 
recog_data_0.operand_loc[0] = ( rtx *)pat[2]->fld; 
fatal_insn_not_found( insn, "insn-attrtab.c", 46, "insn_variable_length_p"); 
edge_info_0 *inf; // [rsp+18h] [rbp-28h] 
edge_info_0 *inf; // [rsp+18h] [rbp-28h] 
inf = ( edge_info_0 *)e->aux; 
inf = ( edge_info_0 *)e->aux; 
if ( ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
if ( ( *( _BYTE *)inf & 4) == 0 && ( *( _BYTE *)inf & 2) == 0 ) 
v2 = ( const char *)&unk_8007A7; 
return *( _OWORD *)&type->decl.abstract_origin->block.vars >= *( _OWORD *)&c->block.vars 
return *( _OWORD *)&type->decl.abstract_origin->block.vars >= *( _OWORD *)&c->block.vars 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars 
return *( _OWORD *)&type->decl.abstract_origin->block.vars >= *( _OWORD *)&c->block.vars 
return *( _OWORD *)&type->decl.abstract_origin->block.vars >= *( _OWORD *)&c->block.vars 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars 
&& *( _OWORD *)&c->block.vars >= *( _OWORD *)&type->decl.initial->block.vars 
return new_loc_descr( ( dwarf_location_atom)( i + 48), i, 0LL); 
v4 = canon_hash( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) & 0x1F; 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)p_0->exp + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)p_0->exp + 2)] == MODE_COMPLEX_FLOAT ) 
elt = lookup_for_remove( x, hash, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
else if ( mode_class_0[*( ( unsigned __int8 *)p->exp + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)p->exp + 2)] == MODE_COMPLEX_FLOAT ) 
invalidate( ref->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)ref + 2)); 
invalidate( ref_0->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)ref_0 + 2)); 
v1 = gen_rtx_fmt_ee( reversed_code, ( machine_mode)*( ( unsigned __int8 *)comp + 2), comp->fld[0].rtx, *( rtx *)&comp[1]); 
return build1( ( tree_code)*( ( unsigned __int8 *)&arg->block.common + 16), type, v22); 
result = expand_mult_add( b, reg, m, a, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
fwrite( &unk_77B7C0, 1uLL, 2uLL, file); 
for ( i = recog_data_0.n_operands - 1; i >= 0; --i ) 
if ( *( _WORD *)recog_data_0.operand[i] == 66 ) 
return memory_address_length( recog_data_0.operand[i]->fld[0].rtx); 
for ( i = recog_data_0.n_operands - 1; i >= 0; --i ) 
if ( *( _WORD *)recog_data_0.operand[i] == 67 
|| *( _WORD *)recog_data_0.operand[i] == 68 
|| *( _WORD *)recog_data_0.operand[i] == 54 
|| *( _WORD *)recog_data_0.operand[i] == 55 
|| *( _WORD *)recog_data_0.operand[i] == 58 
|| *( _WORD *)recog_data_0.operand[i] == 134 
|| *( _WORD *)recog_data_0.operand[i] == 56 
|| *( _WORD *)recog_data_0.operand[i] == 140 ) 
&& *( _WORD *)recog_data_0.operand[i] == 54 
&& recog_data_0.operand[i]->fld[0].rtwint >= -128 
&& recog_data_0.operand[i]->fld[0].rtwint <= 127 ) 
fatal_insn( "unknown insn mode", insn, "i386.c", 9956, "ix86_attr_length_immediate_default"); 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_FLOAT ) 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_FLOAT ) 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
op0 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), op0); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
op0 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), op0); 
v3 = swap_condition( ( rtx_code)*( _WORD *)operands[1]); 
v6 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)operands[1]); 
tmp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
tmp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
v3 != mode || !symbolic_operand( operands[1], ( machine_mode)operands)) ) 
if ( push_operand( *operandsa, mode) && !general_no_elim_operand( operandsa[1], ( machine_mode)operandsa) ) 
if ( ( mode_class_0[mode] == MODE_FLOAT 
|| mode_class_0[mode] == MODE_COMPLEX_FLOAT 
|| mode_class_0[mode] == MODE_VECTOR_FLOAT) 
*( _WORD *)test = reverse_condition_maybe_unordered( ( rtx_code)*( unsigned __int16 *)bypass_test); 
v19 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)operanda + 2), v18); 
( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), 
return gen_rtx_REG( ( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), 0); 
if ( mode_class_0[BYTE5( valtype->block.abstract_origin) >> 1] == MODE_FLOAT && ( target_flags & 0x20) != 0 ) 
|| mode_class_0[BYTE5( valtype->block.abstract_origin) >> 1] == MODE_VECTOR_INT 
|| mode_class_0[BYTE5( valtype->block.abstract_origin) >> 1] == MODE_VECTOR_FLOAT ) 
return gen_rtx_REG( ( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), v2); 
if ( set_36 == -1 ) 
set_36 = new_alias_set( ); 
return set_36; 
return mode_class_0[mode] == MODE_CC; 
if ( mode_class_0[mode] == MODE_CC || mode_class_0[mode] == MODE_RANDOM || mode_class_0[mode] == MODE_PARTIAL_INT ) 
if ( mode_class_0[mode] == MODE_CC || mode_class_0[mode] == MODE_RANDOM || mode_class_0[mode] == MODE_PARTIAL_INT ) 
if ( mode_class_0[mode] == MODE_CC || mode_class_0[mode] == MODE_RANDOM || mode_class_0[mode] == MODE_PARTIAL_INT ) 
if ( mode_class_0[mode] == MODE_FLOAT && ( target_flags & 0x20) != 0 ) 
else if ( mode == TImode || mode_class_0[mode] == MODE_VECTOR_INT || mode_class_0[mode] == MODE_VECTOR_FLOAT ) 
else if ( mode == TImode || mode_class_0[mode] == MODE_VECTOR_INT || mode_class_0[mode] == MODE_VECTOR_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
|| ( mode_class_0[BYTE5( type->block.abstract_origin) >> 1] == MODE_VECTOR_INT 
|| mode_class_0[BYTE5( type->block.abstract_origin) >> 1] == MODE_VECTOR_FLOAT) 
&& mode_class_0[BYTE5( type->block.abstract_origin) >> 1] != MODE_VECTOR_INT 
&& mode_class_0[BYTE5( type->block.abstract_origin) >> 1] != MODE_VECTOR_FLOAT; 
rtx v12; // rax 
rtx v17; // rax 
rtx v22; // rax 
rtx bypass; // [rsp+30h] [rbp-50h] BYREF 
rtx second; // [rsp+38h] [rbp-48h] BYREF 
rtx i; // [rsp+40h] [rbp-40h] 
rtx condition; // [rsp+48h] [rbp-38h] 
rtx tmp_0; // [rsp+50h] [rbp-30h] 
nparts = ix86_split_to_parts( operands[1], part[1], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, part[0], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
( machine_mode)*( ( unsigned __int8 *)part[1][1] + 2), 
( machine_mode)*( ( unsigned __int8 *)part[1][0] + 2), 
part[1][0] = change_address( part[1][0], ( machine_mode)v3, part[0][nparts - 1]); 
*( ( _OWORD *)operands + 1) = *( _OWORD *)&part[0][0]; 
*( ( _OWORD *)operands + 1) = *( _OWORD *)&part[0][0]; 
*( _OWORD *)( operands + 5) = *( _OWORD *)&part[1][0]; 
*( _OWORD *)( operands + 5) = *( _OWORD *)&part[1][0]; 
*( ( _OWORD *)operands + 1) = *( _OWORD *)&part[0][0]; 
*( ( _OWORD *)operands + 1) = *( _OWORD *)&part[0][0]; 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
intreg_45, 
examine_argument( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, &needed_intregs, &needed_sseregs); 
r = expand_expr( t, int_addr_rtx, ( machine_mode)v18, EXPAND_NORMAL); 
r = expand_expr( t, sse_addr_rtx, ( machine_mode)v19, EXPAND_NORMAL); 
tree valista; // [rsp+10h] [rbp-70h] 
tree sav; // [rsp+38h] [rbp-48h] 
tree ovf; // [rsp+40h] [rbp-40h] 
tree fpr; // [rsp+48h] [rbp-38h] 
tree gpr; // [rsp+50h] [rbp-30h] 
tree f_sav; // [rsp+58h] [rbp-28h] 
tree f_ovf; // [rsp+60h] [rbp-20h] 
tree f_fpr; // [rsp+68h] [rbp-18h] 
tree f_gpr; // [rsp+70h] [rbp-10h] 
if ( ix86_hard_regno_mode_ok( regno, ( machine_mode)v7) 
if ( mode_class_0[v8] == MODE_COMPLEX_INT 
|| ( ( target_flags & 0x2000000) == 0 ? ( v9 = 4) : ( v9 = 5), mode_class_0[v9] == MODE_COMPLEX_FLOAT) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
else if ( mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[vd->e[j].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[j].mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[vd->e[j].mode] == MODE_COMPLEX_INT || mode_class_0[vd->e[j].mode] == MODE_COMPLEX_FLOAT ) 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)val + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)val + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)val + 2)] != MODE_VECTOR_FLOAT ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
newa = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), r, inner_mode, *( _DWORD *)&x[1]); 
new_0 = simplify_unary_operation( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)x + 2), r_0, inner_mode_0); 
namea = lang_hooks_0.init( name); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
tree_code_length[1] = ( lang_hooks_0.identifier_size - 17) >> 3; 
v0 = debug_info_level_0 == DINFO_LEVEL_NORMAL 
|| debug_info_level_0 == DINFO_LEVEL_VERBOSE 
&& mode_class_0[BYTE5( type->block.abstract_origin) >> 1] == MODE_INT ) 
element_size = ( tree_node *)*( &global_trees + 12); 
if ( local_symbolic_operand( x, ( machine_mode)v1) ) 
newj = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)v24, v23, 7); 
floatflag = NOT_FLOAT; 
floatflag = NOT_FLOAT; 
else if ( *stra == 48 && ( sch_istable[*( ( unsigned __int8 *)stra + 1)] & 4) != 0 ) 
if ( floatflag == AFTER_POINT ) 
if ( floatflag == AFTER_POINT ) 
if ( floatflag == AFTER_EXPON ) 
if ( floatflag == AFTER_EXPON ) 
elim_reg_set |= 1LL << eliminables_7[i].from; 
if ( ( !avail_p || uid_limit <= *( ( _DWORD *)uid_cuid_1 + *( int *)( list_entry->fld[0].rtwint + 8))) 
&& ( avail_p || uid_limit >= *( ( _DWORD *)uid_cuid_1 + *( int *)( list_entry->fld[0].rtwint + 8))) ) 
if ( flag_float_store && written && mode_class_0[*( ( unsigned __int8 *)mem + 2)] == MODE_FLOAT ) 
reg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)mem + 2)); 
sprintf( pic_label_name, "*.%s%u", ( const char *)&off_77B7F4, 0LL); 
return mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtl + 2)); 
recorded_label_ref_0 = 0; 
qty_0 = (  struct qty *)xmalloc( 44LL * ( max_regno - 53)); 
next_qty_0 = max_qty; 
if ( next_qty_0 > 5 ) 
memset( qty_phys_copy_sugg, 0, 8LL * next_qty_0); 
memset( qty_phys_num_copy_sugg, 0, 2LL * next_qty_0); 
memset( qty_phys_sugg, 0, 8LL * next_qty_0); 
memset( qty_phys_num_sugg, 0, 2LL * next_qty_0); 
for ( ia = 0; ia < next_qty_0; ++ia ) 
next_qty_0 = 0; 
free( qty_0); 
return recorded_label_ref_0; 
hash = hash_expr( pat, ( machine_mode)*( ( unsigned __int8 *)pat + 2), &do_not_record_p, expr_hash_table_size); 
if ( file_table_0.last_lookup_index && !strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
if ( file_table_0.last_lookup_index && !strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
if ( file_table_0.last_lookup_index && !strcmp( file_name, file_table_0.table[file_table_0.last_lookup_index]) ) 
return file_table_0.last_lookup_index; 
for ( i = 1; i < file_table_0.in_use; ++i ) 
if ( !strcmp( file_name, file_table_0.table[i]) ) 
file_table_0.last_lookup_index = i; 
if ( i == file_table_0.allocated ) 
file_table_0.allocated = i + 64; 
file_table_0.table = ( char **)xrealloc( file_table_0.table, 8LL * ( i + 64)); 
file_table_0.table = ( char **)xrealloc( file_table_0.table, 8LL * ( i + 64)); 
v2 = &file_table_0.table[i]; 
file_table_0.in_use = i + 1; 
file_table_0.last_lookup_index = i; 
induction_1 *v; // [rsp+20h] [rbp-10h] 
induction_1 *v; // [rsp+20h] [rbp-10h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( *( ( _BYTE *)v + 100) & 1) == 0 && ( *( ( _BYTE *)v + 100) & 2) == 0 ) 
if ( ( *( ( _BYTE *)v + 100) & 1) == 0 && ( *( ( _BYTE *)v + 100) & 2) == 0 ) 
check_final_value( loop, v); 
induction_1 *v1; // [rsp+10h] [rbp-10h] 
induction_1 *v1; // [rsp+10h] [rbp-10h] 
induction_1 *v; // [rsp+18h] [rbp-8h] 
induction_1 *v; // [rsp+18h] [rbp-8h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 
&& ( !v->same || ( *( ( _BYTE *)v->same + 100) & 4) == 0) 
&& ( !v->same || ( *( ( _BYTE *)v->same + 100) & 4) == 0) 
&& v->giv_type == DEST_REG 
&& *( _DWORD *)reg_n_info->data.l[v->dest_reg->fld[0].rtuint] == v->insn->fld[0].rtint ) 
&& *( _DWORD *)reg_n_info->data.l[v->dest_reg->fld[0].rtuint] == v->insn->fld[0].rtint ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
for ( v1 = bl_0->giv; v1; v1 = v1->next_iv ) 
if ( *( _DWORD *)( reg_n_info->data.l[v->dest_reg->fld[0].rtuint] + 4) == v1->insn->fld[0].rtint ) 
induction_1 *tv; // [rsp+20h] [rbp-30h] 
induction_1 *tv; // [rsp+20h] [rbp-30h] 
induction_1 *v; // [rsp+28h] [rbp-28h] 
induction_1 *v; // [rsp+28h] [rbp-28h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 && !v->same ) 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 && !v->same ) 
if ( !v->new_reg ) 
v->new_reg = gen_reg_rtx( v->mode); 
v->new_reg = gen_reg_rtx( v->mode); 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
insert_before = tv->insn; 
if ( tv->mult_val == const_int_rtx[65] ) 
induction_1 *v; // [rsp+28h] [rbp-28h] 
induction_1 *v; // [rsp+28h] [rbp-28h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( v->same && ( *( ( _BYTE *)v->same + 100) & 4) != 0 ) 
if ( v->same && ( *( ( _BYTE *)v->same + 100) & 4) != 0 ) 
*( ( _BYTE *)v + 100) |= 4u; 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 ) 
if ( v->same ) 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
v->new_reg = replace_rtx( v->new_reg, v->same->dest_reg, v->same->new_reg); 
if ( *( _WORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( ( char *)v->dest_reg + 3) < 0 ) 
if ( *( _WORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( ( char *)v->dest_reg + 3) < 0 ) 
if ( *( _WORD *)v->new_reg == 61 && v->giv_type == DEST_REG && *( ( char *)v->dest_reg + 3) < 0 ) 
mark_reg_pointer( v->new_reg, cfun->emit->regno_pointer_align[v->dest_reg->fld[0].rtuint]); 
induction_1 *v; // [rsp+48h] [rbp-C8h] 
induction_1 *v; // [rsp+48h] [rbp-C8h] 
induction_1 *biv_inc; // [rsp+A0h] [rbp-70h] 
induction_1 *biv_inc; // [rsp+A0h] [rbp-70h] 
if ( mode_class_0[*( ( unsigned __int8 *)iteration_var + 2)] != MODE_INT ) 
v = ivs->regs[iteration_var->fld[0].rtuint].iv.info; 
if ( v->src_reg->fld[0].rtint >= loop_info->ivs.n_regs ) 
if ( ( *( ( _BYTE *)v + 100) & 0x10) == 0 || ( *( ( _BYTE *)v + 100) & 0x20) != 0 ) 
if ( ( *( ( _BYTE *)v + 100) & 0x10) == 0 || ( *( ( _BYTE *)v + 100) & 0x20) != 0 ) 
bl_0 = ivs->regs[v->src_reg->fld[0].rtuint].iv.class; 
mode = v->mode; 
induction_1 *next_induction; // [rsp+18h] [rbp-28h] 
induction_1 *next_induction; // [rsp+18h] [rbp-28h] 
induction_1 *next_inductiona; // [rsp+18h] [rbp-28h] 
induction_1 *next_inductiona; // [rsp+18h] [rbp-28h] 
induction_1 *induction; // [rsp+30h] [rbp-10h] 
induction_1 *induction; // [rsp+30h] [rbp-10h] 
induction_1 *inductiona; // [rsp+30h] [rbp-10h] 
induction_1 *inductiona; // [rsp+30h] [rbp-10h] 
/data/output_dir/patch/gcc/ida/gcc/O0/gcc-gcc-O0/loop_ivs_free/src/loop.c:5373:48: error: expected expression
next_induction = induction->next_iv; 
next_induction = induction->next_iv; 
free( induction); 
for ( inductiona = iv->giv; inductiona; inductiona = next_inductiona ) 
return gen_rtx_fmt_e( ( rtx_code)*( _WORD *)tem, mode, tem->fld[0].rtx); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( x->fld[0].rtwint + 8) + 2LL), 
v8 = gen_rtx_fmt_ee( ( rtx_code)*( unsigned __int16 *)x->fld[0].rtwint, mode, v7, v6); 
if ( !ix86_hard_regno_mode_ok( reg_number, ( machine_mode)( BYTE5( decla->common.type->block.abstract_origin) >> 1)) ) 
x = gen_rtx_MEM( ( machine_mode)LOBYTE( decla->block.supercontext), v13); 
decla->decl.rtl = gen_rtx_fmt_i0( REG, ( machine_mode)LOBYTE( decla->block.supercontext), reg_number); 
else if ( mode_class_0[LOBYTE( decla->block.supercontext)] == MODE_COMPLEX_INT 
|| mode_class_0[LOBYTE( decla->block.supercontext)] == MODE_COMPLEX_FLOAT ) 
&& ( nonzero_bits( pos_rtx, ( machine_mode)*( ( unsigned __int8 *)pos_rtx + 2)) & ~( mode_mask_array[*( ( unsigned __int8 *)pos_rtx + 2)] >> 1)) == 0 ) 
v2 = nonzero_bits( other, ( machine_mode)*( ( unsigned __int8 *)dest + 2)); 
v5 = simplify_shift_const( 0LL, LSHIFTRT, ( machine_mode)*( ( unsigned __int8 *)src + 2), other, pos); 
tema = adjust_address_1( v2, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
if ( !e->aux && ( ( transp_0[pb->index]->elms[( unsigned int)j >> 6] >> ( j & 0x3F)) & 1) != 0 ) 
transp_0[pb->index]->elms[( unsigned int)j >> 6] &= ~( 1LL << ( j & 0x3F)); 
n_low = range_binop( ( tree_code)v9, type, low, 0, arg1, 0); 
n_high = range_binop( ( tree_code)v10, type, high, 1, arg1, 0); 
equiv_type = type_for_mode( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 1); 
|| ( *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > cse_basic_block_end 
|| *( ( _DWORD *)uid_cuid_0 + *( int *)reg_n_info->data.l[a1]) < cse_basic_block_start) 
&& *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > *( ( _DWORD *)uid_cuid_0 
&& *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[a1] + 4)) > *( ( _DWORD *)uid_cuid_0 
tree v5; // rbx 
tree v6; // rax 
tree v8; // rbx 
tree v9; // rax 
tree v13; // rbx 
tree v14; // rax 
else if ( mode_class_0[*( ( unsigned __int8 *)desta + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)desta + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)flags + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)flags + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno] + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
diddle_return_value( ( void ( *)( rtx, void *))mark_reg_0, set); 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
rtx rega; // [rsp+18h] [rbp-68h] 
rtx y; // [rsp+48h] [rbp-38h] 
rega = reg; 
rega = rega->fld[0].rtx; 
rega = rega->fld[0].rtx; 
while ( *( _WORD *)rega == 63 ); 
while ( *( _WORD *)rega == 133 || *( _WORD *)rega == 132 || *( _WORD *)rega == 64 ); 
while ( *( _WORD *)rega == 133 || *( _WORD *)rega == 132 || *( _WORD *)rega == 64 ); 
while ( *( _WORD *)rega == 133 || *( _WORD *)rega == 132 || *( _WORD *)rega == 64 ); 
if ( *( _WORD *)rega == 66 ) 
not_dead = bitmap_bit_p( pbi->reg_live, rega->fld[0].rtint); 
rega = rega->fld[0].rtx; 
rega = rega->fld[0].rtx; 
( machine_mode)*( unsigned __int8 *)( reg->fld[0].rtwint + 2), 
else if ( mode_class_0[outer_mode] == MODE_COMPLEX_INT || mode_class_0[outer_mode] == MODE_COMPLEX_FLOAT ) 
rtx xa; // [rsp+10h] [rbp-40h] 
rtx sub; // [rsp+30h] [rbp-20h] 
xa = x; 
code = *( _WORD *)xa; 
mark_set_1( pbi, code, xa->fld[0].rtx, cond, insn, pbi->flags); 
cond = xa->fld[0].rtx; 
xa = ( rtx)xa[1]; 
for ( i = *( _DWORD *)xa->fld[0].rtwint - 1; ; --i ) 
sub = *( rtx *)( xa->fld[0].rtwint + 8LL * i + 8); 
v4 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT; 
if ( std::allocator_traits<std::allocator<std::_Rb_tree_node<std::pair<std::string const, tcmalloc::MallocExtension::Property>>>>::allocate( 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT ) 
if ( mode_class_0[*( unsigned __int8 *)( x->fld[0].rtwint + 2)] != MODE_FLOAT 
&& mode_class_0[*( unsigned __int8 *)( *( _QWORD *)&x[1] + 2LL)] != MODE_FLOAT ) 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT ) 
induction_1 *v; // [rsp+60h] [rbp-10h] 
induction_1 *v; // [rsp+60h] [rbp-10h] 
induction_1 *va; // [rsp+60h] [rbp-10h] 
induction_1 *va; // [rsp+60h] [rbp-10h] 
induction_1 *vb; // [rsp+60h] [rbp-10h] 
induction_1 *vb; // [rsp+60h] [rbp-10h] 
induction_1 *vc; // [rsp+60h] [rbp-10h] 
induction_1 *vc; // [rsp+60h] [rbp-10h] 
induction_1 *vd; // [rsp+60h] [rbp-10h] 
induction_1 *vd; // [rsp+60h] [rbp-10h] 
for ( vd = bl_0->giv; vd; vd = vd->next_iv ) 
for ( vd = bl_0->giv; vd; vd = vd->next_iv ) 
for ( vd = bl_0->giv; vd; vd = vd->next_iv ) 
for ( vd = bl_0->giv; vd; vd = vd->next_iv ) 
if ( vd->giv_type == DEST_ADDR && ( rtunion *)vd->location == x->fld ) 
if ( vd->giv_type == DEST_ADDR && ( rtunion *)vd->location == x->fld ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
decode_asm_operands( pat, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
decode_asm_operands( pat, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
if ( ( sch_istable[*( unsigned __int8 *)*format] & 4) != 0 ) 
while ( ( sch_istable[*( unsigned __int8 *)fcp] & 4) != 0 ) 
if ( ( sch_istable[( unsigned __int8)ca] & 0x100) == 0 ) 
mem_loc_result = mem_loc_descriptor( rtla->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtla + 2)); 
if ( !legitimate_address_p( ( machine_mode)xa, xa, v9) ) 
xa = legitimize_address( v2, oldx, ( machine_mode)xa); 
y = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)xa + 2), v6, v5), 
return *( _WORD *)addr == 70 || legitimate_address_p( ( machine_mode)addr, addr, v3) != 0; 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
remove_invalid_subreg_refs( i_1, *( _DWORD *)&x[1], ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
data = insn_data_0 + 44520; 
data = insn_data_0 + 44480; 
data = insn_data_0 + 44560; 
v4 = operand_sub*(short *)0xforce( x, i, mode); 
move_by_pieces_1( insn_data_0[icode].genfun, mode, &data); 
rtx oldnotes; // [rsp+38h] [rbp-88h] BYREF 
rtx note; // [rsp+50h] [rbp-70h] 
rtx where_dead; // [rsp+58h] [rbp-68h] 
rtx dest; // [rsp+80h] [rbp-40h] 
rtx after_dead; // [rsp+98h] [rbp-28h] 
rtx before_dead; // [rsp+A0h] [rbp-20h] 
where_dead = reg_last_death[regno]; 
for ( before_dead = where_dead; 
for ( before_dead = where_dead; 
before_dead && before_dead->fld[0].rtint > max_uid_cuid; 
before_dead && before_dead->fld[0].rtint > max_uid_cuid; 
before_dead = ( rtx)before_dead[1] ) 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
v10 = mode_class_0[*( ( unsigned __int8 *)m->set_dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)m->set_dest + 2)] == MODE_COMPLEX_FLOAT 
*v14 = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)m1a->set_dest + 2), m->set_dest); 
v15 = mode_class_0[*( ( unsigned __int8 *)m1a->set_dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)m1a->set_dest + 2)] == MODE_COMPLEX_FLOAT 
if ( in_section_0 != in_named || strcmp( name, in_named_name) ) 
in_section_0 = no_section; 
in_section_0 = in_named; 
return ++last_alias_set_5; 
result = ( _cpp_buff_0 *)&v1[lenb]; 
return ( _cpp_buff_0 *)&v1[lenb]; 
result = ( cpp_context_0 *)xmalloc( 0x38uLL); 
run->next = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v7 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)if_info->cond + 2), cmp_a, cmp_b); 
v8 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, vtrue, vfalse); 
if ( !general_operand( cmp_a, ( machine_mode)*( ( unsigned __int8 *)cmp_a + 2)) 
|| !general_operand( cmp_b, ( machine_mode)*( ( unsigned __int8 *)cmp_b + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)outer + 2), 
v5 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
result = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)cond + 2), op_a, op_b); 
if ( *( _WORD *)tmp == 61 && mode_class_0[*( ( unsigned __int8 *)tmp + 2)] == MODE_INT ) 
v6 = reverse_condition( ( rtx_code)*( _WORD *)cond); 
if ( *( _WORD *)tmpb == 61 && mode_class_0[*( ( unsigned __int8 *)tmpb + 2)] == MODE_INT ) 
|| mode_class_0[*( ( unsigned __int8 *)op + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)op + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)op + 2)] != MODE_VECTOR_FLOAT ) 
rtx note; // [rsp+70h] [rbp-60h] 
rtx orig_x; // [rsp+78h] [rbp-58h] 
rtx b; // [rsp+80h] [rbp-50h] 
rtx a; // [rsp+88h] [rbp-48h] 
rtx set_a; // [rsp+90h] [rbp-40h] 
rtx insn_a; // [rsp+98h] [rbp-38h] 
rtx cond; // [rsp+A0h] [rbp-30h] 
rtx jump; // [rsp+A8h] [rbp-28h] 
rtx insn; // [rsp+B0h] [rbp-20h] 
target = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), ABS, b, if_info->x, 0); 
target = expand_simple_unop( ( machine_mode)*( ( unsigned __int8 *)target + 2), NEG, target, if_info->x, 0); 
( rtx_code)*( _WORD *)if_info->cond, 
else if ( general_operand( b, ( machine_mode)*( ( unsigned __int8 *)b + 2)) ) 
if ( !general_operand( a, ( machine_mode)*( ( unsigned __int8 *)a + 2)) ) 
v3 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)a + 2)); 
a = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)a + 2)); 
if ( general_operand( b, ( machine_mode)*( ( unsigned __int8 *)b + 2)) ) 
v7 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)b + 2)); 
b = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)b + 2)); 
tmpd = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), target); 
if ( ( mode_class_0[*( ( unsigned __int8 *)if_info->x + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)if_info->x + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)if_info->x + 2)] == MODE_VECTOR_FLOAT) 
( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), 
targeta = expand_simple_binop( mode, ( rtx_code)v5, v4, target, x, 0, OPTAB_WIDEN); 
v1 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2)); 
target = expand_simple_binop( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), v3, x, target, x, 0, OPTAB_WIDEN); 
v2 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)if_info->x + 2)); 
( machine_mode)*( ( unsigned __int8 *)if_info->x + 2), 
name = ( const char *)&unk_779750; 
fprintf( fp, off_7798B6, name); 
|| mode_class_0[mode] == MODE_INT 
|| mode_class_0[mode] == MODE_PARTIAL_INT) 
rtx v8; // rax 
rtx v11; // rax 
rtx v14; // rax 
rtx v16; // rax 
rtx v18; // rax 
rtx rtly; // [rsp+20h] [rbp-70h] 
rtx rtlx; // [rsp+28h] [rbp-68h] 
rtx moffsety; // [rsp+60h] [rbp-30h] 
rtx moffsetx; // [rsp+68h] [rbp-28h] 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT 
|| mode_class_0[mode] == MODE_FLOAT 
|| mode_class_0[mode] == MODE_COMPLEX_FLOAT 
|| mode_class_0[mode] == MODE_VECTOR_FLOAT ) 
( machine_mode)*( ( unsigned __int8 *)x + 2)) & nonzero; 
|| mode_class_0[reg_last_set_mode[x->fld[0].rtuint]] == MODE_INT && mode_class_0[modea] == MODE_INT) 
|| mode_class_0[reg_last_set_mode[x->fld[0].rtuint]] == MODE_INT && mode_class_0[modea] == MODE_INT) 
nonzero = v14 & nonzero_bits( x->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
if ( mode_class_0[modea] == MODE_INT ) 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_INT 
&& mode_class_0[*( unsigned __int8 *)( x->fld[0].rtwint + 2)] == MODE_INT 
|| mode_class_0[modea] == MODE_FLOAT 
|| mode_class_0[modea] == MODE_COMPLEX_FLOAT 
|| mode_class_0[modea] == MODE_VECTOR_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT ) 
LODWORD( v2) = num_sign_bit_copies( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), newa) 
addra = force_reg( ( machine_mode)*( ( unsigned __int8 *)addr + 2), addr); 
v7 = *( tree_node **)( *( _QWORD *)&memref[1] + 8LL); 
*( _QWORD *)&newb[1] = get_mem_attrs( v8, v7, 0LL, 0LL, v6, ( machine_mode)*( ( unsigned __int8 *)newb + 2)); 
z = gen_rtx_fmt_ee( LO_SUM, ( machine_mode)*( ( unsigned __int8 *)y + 2), y->fld[0].rtx, v6); 
return *( _WORD *)op == 66 && offsettable_address_p( 1, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx); 
return *( _WORD *)op == 66 && offsettable_address_p( 0, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx); 
dump_hash_table( gcse_file, off_778935, set_hash_table, set_hash_table_size, n_sets); 
free_edge_list( edge_list_0); 
timevar_push( TV_DUMP_0); 
timevar_pop( TV_DUMP_0); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
( machine_mode)*( unsigned __int8 *)( y->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2)); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
info = &reg_avail_info_0[x->fld[0].rtuint]; 
result = info->last_set < *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
result = info->first_set >= *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
src = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)memrefa + 2), *( rtx *)&body[1]); 
&& mode_class_0[*( ( unsigned __int8 *)dest + 2)] == mode_class_0[*( unsigned __int8 *)( dest->fld[0].rtwint + 2)]; 
&& mode_class_0[*( ( unsigned __int8 *)dest + 2)] == mode_class_0[*( unsigned __int8 *)( dest->fld[0].rtwint + 2)]; 
newreg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)dest + 2)); 
prev_fn = lang_hooks_0.tree_inlining.add_pending_fn_decls( &id, prev_fn); 
bb_info_0 *bb_info[1]; // [rsp+30h] [rbp-E0h] 
bb_info_0 *bb_info[1]; // [rsp+30h] [rbp-E0h] 
bb_info_0 *info; // [rsp+50h] [rbp-C0h] 
bb_info_0 *info; // [rsp+50h] [rbp-C0h] 
bb_info_0 *info_0; // [rsp+60h] [rbp-B0h] 
bb_info_0 *info_0; // [rsp+60h] [rbp-B0h] 
if ( max_num_modes < num_modes_1[e] ) 
max_num_modes = num_modes_1[e]; 
transp_0 = sbitmap_vector_alloc( n_basic_blocks, n_entities); 
comp_0 = sbitmap_vector_alloc( n_basic_blocks, n_entities); 
sbitmap_vector_ones( transp_0, n_basic_blocks); 
no_mode = num_modes_1[e_0]; 
info = bb_info[j]; 
info = bb_info[j]; 
add_seginfo( &info[bb], ptr); 
transp_0[bb]->elms[( unsigned int)j >> 6] &= ~( 1LL << ( j & 0x3F)); 
v2 = sibcall_use_tail_recursion_0; 
v2 = sibcall_use_sibcall_0; 
v2 = sibcall_use_normal_0; 
edge edge_0; // [rsp+18h] [rbp-38h] 
edge_0 = bb->succ; 
if ( ( edge_0->flags & 1) != 0 ) 
expa = lang_hooks_0.expand_constant( exp); 
else if ( ( sch_istable[*( unsigned __int8 *)p] & 0x88) != 0 ) 
if ( ( sch_istable[*( unsigned __int8 *)p] & 4) != 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 4) == 0 ) 
else if ( ( sch_istable[*( unsigned __int8 *)p] & 4) != 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 4) == 0 ) 
fprintf( asm_out_file, "\t%s %d\t%s", "#", debug_insn->fld[0].rtuint, insn_data_0[num].name); 
if ( insn_data_0[num].n_alternatives > 1 ) 
v3 = ( const char *)&unk_774FF3; 
v4 = ( const char *)&unk_774FF3; 
expa = lang_hooks_0.expand_constant( exp); 
*( _OWORD *)v9.r = *( _OWORD *)&expa->block.vars; 
v7 = gen_rtx_MEM( ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), v6); 
mergeable_constant_section( ( machine_mode)LOBYTE( exp->block.supercontext), align, 0); 
fancy_abort( &off_76BD38[4], 737, "output_format"); 
fancy_abort( &off_76BD38[4], 723, "output_format"); 
fancy_abort( &off_76BD38[4], 725, "output_format"); 
if ( valueb == ( tree_node *)global_trees ) 
sprintf( buffer->digit_buffer, off_76BD38, i); 
sprintf( buffer->digit_buffer, off_76BD31, i); 
sprintf( buffer->digit_buffer, off_76BD2A, i); 
if ( ( sch_istable[( unsigned __int8)c] & 0x10) != 0 ) 
ix86_cpu_string = cpu_names_52[12]; 
else if ( !strcmp( ix86_asm_string, off_77AEB2) ) 
if ( !strcmp( ix86_arch_string, processor_alias_table_51[i].name) ) 
ix86_arch = processor_alias_table_51[i].processor; 
if ( ( processor_alias_table_51[i].flags & 4) != 0 && ( target_flags & 0x8000) == 0 ) 
if ( ( processor_alias_table_51[i].flags & 0x10) != 0 && ( target_flags & 0x200000) == 0 ) 
if ( ( processor_alias_table_51[i].flags & 0x40) != 0 && ( target_flags & 0x800000) == 0 ) 
if ( ( processor_alias_table_51[i].flags & 1) != 0 && ( target_flags & 0x20000) == 0 ) 
if ( ( processor_alias_table_51[i].flags & 2) != 0 && ( target_flags & 0x80000) == 0 ) 
if ( ( processor_alias_table_51[i].flags & 8) != 0 ) 
if ( !strcmp( ix86_cpu_string, processor_alias_table_51[ia].name) ) 
ix86_cpu = processor_alias_table_51[ia].processor; 
if ( ( processor_alias_table_51[ia].flags & 8) != 0 ) 
ix86_cost = processor_target_table_50[ix86_cpu].cost; 
target_flags |= processor_target_table_50[ix86_cpu].target_enable; 
target_flags &= ~processor_target_table_50[ix86_cpu].target_disable; 
align_loops = processor_target_table_50[ix86_cpu].align_loop; 
save_constant = ( args_size)0LL; 
result->val.node = ( cpp_hashnode_0 *)source; 
if ( !already_0 ) 
already_0 = 1; 
for ( cur = pfile->buffer->cur; ( sch_istable[*cur] & 0x204) != 0; ++cur ) 
result = ( cpp_hashnode_0 *)ht_lookup( 
while ( ( sch_istable[( unsigned __int8)c] & 0x204) != 0 || c == 36 && pfile->opts.dollars_in_ident ) 
while ( ( sch_istable[( unsigned __int8)c] & 0x204) != 0 || c == 36 && pfile->opts.dollars_in_ident ); 
return ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, value, len, HT_ALLOCED); 
if ( ( sch_istable[( unsigned __int8)constraint[j]] & 0x88) == 0 ) 
if ( ( sch_istable[( unsigned __int8)ca] & 0x204) == 0 
if ( ( sch_istable[( unsigned __int8)ca] & 0x204) == 0 
lang_hooks_0.init_options( ); 
set_target_switch( &sep); 
lang_processed = lang_hooks_0.decode_option( argc - ia, &argv[ia]); 
lang_hooks_0.post_options( ); 
if ( ( sch_istable[*( unsigned __int8 *)p] & 0x88) != 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 0x400) != 0 ) 
if ( !peep2_insn_data_0[froma].insn ) 
reg_set_to_hard_reg_set( &live, peep2_insn_data_0[froma].live_before); 
if ( !peep2_insn_data_0[froma].insn ) 
reg_set_to_hard_reg_set( &this_live, peep2_insn_data_0[froma].live_before); 
search_ofs_1 = 0; 
raw_regno = search_ofs_1 + i; 
if ( search_ofs_1 + i > 52 ) 
v6 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v6 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v10 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v10 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
search_ofs_1 = raw_regno; 
if ( peep2_insn_data_0[na].insn == global_rtl[0] ) 
return peep2_insn_data_0[na].insn; 
if ( !peep2_insn_data_0[ofsa].insn ) 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
if ( bitmap_bit_p( peep2_insn_data_0[ofsa].live_before, n + regno) ) 
if ( !peep2_insn_data_0[ofsa].insn ) 
return bitmap_bit_p( peep2_insn_data_0[ofsa].live_before, regno) == 0; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1; 
teml = gen_peephole2_1246( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
temm = gen_peephole2_1249( insn, recog_data_0.operand); 
recog_data_0.operand[1] = x1; 
|| ( *_pmatch_len = 0, ( temn = gen_peephole2_1252( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1; 
temi = gen_peephole2_1245( insn, recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
temj = gen_peephole2_1248( insn, recog_data_0.operand); 
recog_data_0.operand[1] = x1; 
|| ( *_pmatch_len = 0, ( temk = gen_peephole2_1251( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[6] = x4b; 
recog_data_0.operand[4] = x5; 
recog_data_0.operand[5] = x5a; 
recog_data_0.operand[3] = x2n; 
recog_data_0.operand[0] = x2q; 
recog_data_0.operand[1] = x2r; 
recog_data_0.operand[2] = x2s; 
recog_data_0.operand[7] = x2t; 
recog_data_0.operand[8] = x2v; 
recog_data_0.insn = 0LL; 
peep2_insn_data_0[i].live_before = v1; 
peep2_insn_data_0[i].insn = 0LL; 
peep2_insn_data_0[4].insn = global_rtl[0]; 
bitmap_copy( peep2_insn_data_0[4].live_before, live); 
peep2_insn_data_0[peep2_current].insn = insn; 
bitmap_copy( peep2_insn_data_0[peep2_current].live_before, live); 
old_insn = peep2_insn_data_0[j].insn; 
( machine_mode)*( ( unsigned __int8 *)note_0 + 2), 
old_insn = peep2_insn_data_0[j].insn; 
note = find_reg_note( peep2_insn_data_0[i].insn, REG_EH_REGION, 0LL); 
trya = emit_insn_after( trya, peep2_insn_data_0[i].insn); 
delete_insn_chain( insn, peep2_insn_data_0[i].insn); 
bitmap_copy( live, peep2_insn_data_0[i].live_before); 
peep2_insn_data_0[i].insn = x; 
tem = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)xa + 2), v5); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)tem + 2), tem->fld[0].rtx) ) 
ca = trunc_int_for_mode( ca, ( machine_mode)*( ( unsigned __int8 *)xa + 2)); 
restype = ( tree_node *)*( &global_trees + 30); 
con1 = ( tree_node *)v3; 
con1 = *( tree_node **)( v3 + 32); 
while ( constructor_stack_0->implicit ) 
if ( constructor_range_stack_0 ) 
p = constructor_stack_0; 
spelling_0 = &spelling_base[constructor_depth]; 
constructor_range_stack_0 = p->range_stack; 
spelling_0 = &spelling_base[constructor_depth]; 
constructor_stack_0 = p->next; 
if ( constructor_stack_0 ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
expr->reaching_reg = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v0->fld[0].rtwint + 2)); 
pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] |= 1LL << ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) & 0x3F); 
pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] |= 1LL << ( *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) & 0x3F); 
did_insert = pre_edge_insert( edge_list_0, index_map); 
&& ( ( pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * insn->fld[0].rtint) & 0x3F)) & 1) == 0 ) 
&& ( ( pre_redundant_insns->elms[*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint) >> 6] >> ( *( ( _BYTE *)uid_cuid_1 + 4 * insn->fld[0].rtint) & 0x3F)) & 1) == 0 ) 
args[i].value = convert_modes( args[i].mode, ( machine_mode)mode, args[i].value, args[i].unsignedp); 
( machine_mode)( BYTE5( args[i].tree_value->common.type->block.abstract_origin) >> 1), 
else if ( mode_class_0[*( ( unsigned __int8 *)loop_info->final_value + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)loop_info->initial_value + 2)] == MODE_FLOAT ) 
probability = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
probability = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
classa = mode_class_0[*( int *)pmode]; 
result_mode = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8)) ) 
( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8)) ) 
if ( !insn_data_0[icode].operand[opnum].predicate( 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8), xa); 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&insn_data_0[icode].operand[opnum] + 8), xa); 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
p = recog_data_0.constraints[i]; 
for ( j = 0; j < recog_data_0.n_alternatives; ++j ) 
sep = ( const char *)&unk_80AC55; 
st[2] = ( const char *)&off_80AC34; 
st[3] = ( _BYTE *)( &off_80AC34 + 2); 
st[1] = ( const char *)&off_80AB40; 
st[1] = ( _BYTE *)( &off_80AB40 + 2); 
st[1] = ( _BYTE *)( &off_80AB40 + 4); 
low = *( _OWORD *)&c->block.vars; 
fprintf( outfile, off_7FF723, expr->decl.name->int_cst.int_cst.low); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 0, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 0, file); 
fwrite( &unk_77BDA8, 1uLL, 2uLL, file); 
fwrite( &off_77BDB8, 1uLL, 3uLL, file); 
fwrite( ( char *)&off_77BDB8 + 4, 1uLL, 3uLL, file); 
fwrite( &unk_77BBEF, 1uLL, 2uLL, file); 
fwrite( &unk_77BDAB, 1uLL, 2uLL, file); 
fwrite( &off_77BDC0, 1uLL, 3uLL, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 1, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 1, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 1, 0, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 1, 0, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 1, 1, file); 
fwrite( &unk_77C2A0, 1uLL, 3uLL, a1); 
fprintf( a1, off_77C2AB, ( unsigned int)scale); 
sprintf( t1, off_80B253); 
sprintf( buf, off_80B24F, t1); 
in_bb_p = ( print_rtl_graph_with_bb::bb_state *)xmalloc( 4LL * max_uid); 
in_bb_p[i] = NOT_IN_BB_0; 
in_bb_p[i] = NOT_IN_BB_0; 
v5 = in_bb_p[x->fld[0].rtint] ? 2 : 1; 
in_bb_p[x->fld[0].rtint] = v5; 
free( in_bb_p); 
fprintf( outfile, "\n%s%*s", print_rtx_head, 2 * indent, ( const char *)&unk_7FF665); 
fprintf( outfile, &off_7FF7A0[4], *( _QWORD *)&in_rtx[2]); 
fprintf( outfile, off_7FF7A0, *( _DWORD *)&in_rtx[2]); 
fprintf( outfile, &off_7FF7A0[7], ( unsigned int)bb->index); 
fprintf( outfile, "\n%s%*s", print_rtx_head, 2 * indent, ( const char *)&unk_7FF665); 
fprintf( outfile, "\n%s%*s", print_rtx_head, 2 * indent, ( const char *)&unk_7FF665); 
fprintf( outfile, off_7FF7A0, *( _DWORD *)&in_rtx[3]); 
fputs( hi_name_2[in_rtx->fld[0].rtuint], outfile); 
fputs( hi_name_2[in_rtx->fld[0].rtuint], outfile); 
fputs( qi_name_1[in_rtx->fld[0].rtuint], outfile); 
fprintf( outfile, off_7FF7A0, ( unsigned int)value); 
fprintf( outfile, off_7FF7A0, in_rtx->fld[i].rtuint); 
fprintf( outfile, off_7FF723, note_insn_name[in_rtx->fld[i].rtint + 100]); 
for ( p = spelling_base; p < spelling_0; ++p ) 
if ( ( sch_istable[( unsigned __int8)c] & 4) != 0 ) 
v2 = &sep; 
lang_hooks_0.name, 
if ( constructor_stack_0->replacement_value ) 
constructor_stack_0->replacement_value = value; 
if ( constructor_stack_0->replacement_value ) 
while ( constructor_stack_0->implicit 
if ( constructor_range_stack_0 
spelling_0 = &spelling_base[constructor_depth]; 
spelling_0 = &spelling_base[constructor_depth]; 
spelling_0 = &spelling_base[constructor_depth]; 
constructor_range_stack_0 = 0LL; 
if ( !constructor_range_stack_0 ) 
if ( general_operand( exp, ( machine_mode)*( ( unsigned __int8 *)reg + 2)) ) 
user_label_prefix = &sep; 
v1 = &sep; 
v0 = &sep; 
print_version( stderr, &sep); 
print_switch_values( stderr, 0, 75, &sep, " ", "\n"); 
temp = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int8 *)loc + 2), copy); 
expand_mult( ( machine_mode)*( ( unsigned __int8 *)aa + 2), aa, ba, 0LL, 1); 
deps_0 *succ_deps; // [rsp+38h] [rbp-38h] 
deps_0 *succ_deps; // [rsp+38h] [rbp-38h] 
succ_deps = &bb_deps[bb_succ]; 
succ_rl = &succ_deps->reg_last[reg]; 
fatal_insn( "Attempt to delete prologue/epilogue insn:", insn, "flow.c", 1615, "propagate_one_insn"); 
x[1].fld[0].rtwint = ( __int64)gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
temp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
temp = allocno_0[( __int64)num].hard_reg_conflicts; 
if ( allocno_0[( __int64)num].calls_crossed ) 
tempb = ~reg_class_contents[reg_preferred_class( allocno_0[( __int64)num].reg)] | tempa; 
allocno_0[( __int64)num].hard_reg_preferences &= ~tempb; 
allocno_0[( __int64)num].hard_reg_copy_preferences &= ~tempb; 
allocno_0[( __int64)num].hard_reg_full_preferences &= ~tempb; 
if ( allocno_0[( __int64)allocno2].size > allocno_0[( __int64)numa].size ) 
if ( allocno_0[( __int64)allocno2].size > allocno_0[( __int64)numa].size ) 
temp2 |= allocno_0[( __int64)allocno2].hard_reg_full_preferences; 
temp_0 |= allocno_0[( __int64)allocno2].hard_reg_full_preferences; 
rtx v12; // rax 
rtx p; // [rsp+30h] [rbp-70h] 
rtx pa; // [rsp+30h] [rbp-70h] 
rtx p_0; // [rsp+40h] [rbp-60h] 
rtx sub_0; // [rsp+50h] [rbp-50h] 
rtx x; // [rsp+60h] [rbp-40h] 
rtx tem_0; // [rsp+68h] [rbp-38h] 
rtx z; // [rsp+78h] [rbp-28h] 
( machine_mode)*( unsigned __int8 *)( reg->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 3; 
spelling_0->u.i = bounds; 
++spelling_0; 
while ( constructor_stack_0->implicit 
p->next = constructor_stack_0; 
constructor_stack_0 = p; 
constructor_depth = spelling_0 - spelling_base; 
p->range_stack = constructor_range_stack_0; 
constructor_range_stack_0 = 0LL; 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 2; 
spelling_0->u.s = string; 
++spelling_0; 
p->prev = constructor_range_stack_0; 
p->stack = constructor_stack_0; 
if ( constructor_range_stack_0 ) 
constructor_range_stack_0->next = p; 
constructor_range_stack_0 = p; 
v16 = mode_class_0[*( unsigned __int8 *)( ina->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( ina->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
( machine_mode)*( unsigned __int8 *)( ina->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)ina + 2)); 
depth = spelling_0 - spelling_base; 
spelling_0 = &spelling_base[depth]; 
spelling_0->kind = 1; 
spelling_0->u.s = string; 
++spelling_0; 
*( _OWORD *)( ( char *)&x->block + 88) = *( _OWORD *)( ( char *)&oldglobal->block + 88); 
*( _OWORD *)( ( char *)&x->block + 88) = *( _OWORD *)( ( char *)&oldglobal->block + 88); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
v6 = ( const char *)&unk_77BBE9; 
v6 = ( const char *)&unk_77BBEC; 
v5 = ( const char *)&off_77BBD7; 
v5 = ( const char *)&unk_77BBDB; 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth))); 
/ ( double)( qty_0[q2].death - qty_0[q2].birth))); 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth))); 
/ ( double)( qty_0[q1].death - qty_0[q1].birth))); 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
* ( ( double)( qty_0[q2].freq * floor_log2_wide( qty_0[q2].n_refs) * qty_0[q2].size) 
/ ( double)( qty_0[q2].death - qty_0[q2].birth))); 
/ ( double)( qty_0[q2].death - qty_0[q2].birth))); 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
* ( ( double)( qty_0[q1].freq * floor_log2_wide( qty_0[q1].n_refs) * qty_0[q1].size) 
/ ( double)( qty_0[q1].death - qty_0[q1].birth))); 
/ ( double)( qty_0[q1].death - qty_0[q1].birth))); 
v11 = ( tree_node *)*( &global_trees + 12); 
v11 = ( tree_node *)*( &global_trees + 11); 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
if ( ch_0a == -1 || ( sch_istable[( unsigned __int8)ch_0a] & 0xC00) != 0 ) 
for ( endp = p; *endp && ( sch_istable[*( unsigned __int8 *)endp] & 4) != 0; ++endp ) 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
while ( ch_0 != -1 && ( sch_istable[( unsigned __int8)ch_0] & 1) != 0 ); 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)); 
constructor_stack_0 = p; 
constructor_depth = spelling_0 - spelling_base; 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = x1d; 
recog_data_0.operand[0] = x1b; 
recog_data_0.operand[0] = x1b; 
recog_data_0.operand[0] = x1i; 
recog_data_0.operand[1] = x1l; 
recog_data_0.operand[1] = x1j; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = ( rtx)x0[1]; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = ( rtx)x0[1]; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = ( rtx)x0[1]; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1e; 
recog_data_0.operand[1] = x1e; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3e; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3d; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[0] = x3d; 
recog_data_0.operand[1] = x3e; 
recog_data_0.operand[2] = x3f; 
&& recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint <= 63 
&& recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint <= 63 
&& ( recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint <= 32 
&& ( recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint <= 32 
|| recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint == 64 
|| recog_data_0.operand[1]->fld[0].rtwint + recog_data_0.operand[2]->fld[0].rtwint == 64 
&& recog_data_0.operand[1]->fld[0].rtwint > 32) 
&& ( *( ( _BYTE *)recog_data_0.operand[0] + 2) == 4 
|| *( ( _BYTE *)recog_data_0.operand[0] + 2) == 5 
|| *( ( _BYTE *)recog_data_0.operand[0] + 2) == 3 
|| *( ( _BYTE *)recog_data_0.operand[0] + 2) == 2) ) 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x3k; 
recog_data_0.operand[2] = x3m; 
recog_data_0.operand[2] = x3o; 
recog_data_0.operand[1] = x3j; 
recog_data_0.operand[2] = x2k; 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x3i; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2a; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[1] = x2u; 
recog_data_0.operand[2] = x2v; 
recog_data_0.operand[1] = x2s; 
recog_data_0.operand[2] = x2t; 
recog_data_0.operand[1] = x2o; 
recog_data_0.operand[1] = x2y; 
recog_data_0.operand[2] = x2z; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[2] = x2a; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x2l; 
recog_data_0.operand[2] = x2m; 
recog_data_0.operand[1] = x2bk; 
recog_data_0.operand[2] = x2bl; 
recog_data_0.operand[1] = x4c; 
recog_data_0.operand[2] = x4d; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1c; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3l; 
recog_data_0.operand[2] = x3m; 
recog_data_0.operand[2] = x2n; 
recog_data_0.operand[1] = x3g; 
recog_data_0.operand[2] = x3h; 
recog_data_0.operand[2] = x2i; 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x2j; 
recog_data_0.operand[1] = x3j; 
recog_data_0.operand[1] = x4; 
if ( rtx_equal_p( x3a->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[2] = x4c; 
if ( rtx_equal_p( x3c->fld[0].rtx, recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = x4f; 
if ( rtx_equal_p( x3e->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[2] = x4l; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x3d; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[2] = x3b; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1g; 
recog_data_0.operand[1] = x1g; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x3e; 
|| !ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x3d; 
|| !ix86_binary_operator_ok( PLUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3f; 
recog_data_0.operand[2] = x4c; 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[2] = x3g; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[0] = x3; 
recog_data_0.operand[1] = x4m; 
recog_data_0.operand[2] = x4p; 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[1] = x3e; 
recog_data_0.operand[2] = x3f; 
recog_data_0.operand[3] = x2g; 
if ( rtx_equal_p( x2h->fld[0].rtx, recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)&x2h[1], recog_data_0.operand[2]) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) ) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) ) 
recog_data_0.operand[1] = x4b; 
recog_data_0.operand[2] = x4c; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) ) 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3o; 
recog_data_0.operand[2] = x3r; 
recog_data_0.operand[1] = x3i; 
recog_data_0.operand[2] = x3l; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[1] = x4a; 
recog_data_0.operand[2] = x3f; 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3d; 
recog_data_0.operand[2] = x3e; 
recog_data_0.operand[2] = x3e; 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x3g; 
recog_data_0.operand[2] = x4c; 
|| !ix86_binary_operator_ok( MINUS, DImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x2; 
|| !rtx_equal_p( x1->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[0]) 
recog_data_0.operand[1] = x4w; 
recog_data_0.operand[2] = x4x; 
|| *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
|| *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = x4y; 
recog_data_0.operand[2] = x4z; 
|| *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
|| *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[2] = x3b; 
|| *( _WORD *)recog_data_0.operand[1] == 66 && *( _WORD *)recog_data_0.operand[2] == 66 ) 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2ba; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bb; 
|| !rtx_equal_p( x2bc->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bc[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2b->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2b[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( PLUS, DImode, recog_data_0.operand) 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2ce; 
&& ( unsigned int)recog_data_0.operand[2]->fld[0].rtwint != 0x80000000LL ) 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2cf; 
|| !rtx_equal_p( x2cg->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2cg[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[0] = x2cf; 
|| !rtx_equal_p( x3bz->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x3bz[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, SImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2ba; 
&& ( unsigned __int16)recog_data_0.operand[2]->fld[0].rtwint != 0x8000LL ) 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bb; 
|| !rtx_equal_p( x2bc->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bc[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, HImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2b->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2b[1], recog_data_0.operand[2]) 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2be; 
if ( ix86_match_ccmode( insn, CCGCmode) && ( unsigned __int8)recog_data_0.operand[2]->fld[0].rtwint != 128LL ) 
recog_data_0.operand[2] = x3a; 
recog_data_0.operand[0] = x2bf; 
|| !rtx_equal_p( x2bg->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2bg[1], recog_data_0.operand[2]) 
|| !ix86_binary_operator_ok( MINUS, QImode, recog_data_0.operand) ) 
recog_data_0.operand[1] = x4; 
recog_data_0.operand[2] = x4a; 
recog_data_0.operand[0] = x2a; 
|| !rtx_equal_p( x2b->fld[0].rtx, recog_data_0.operand[1]) 
|| !rtx_equal_p( *( rtx *)&x2b[1], recog_data_0.operand[2]) 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x2b; 
if ( !rtx_equal_p( x1a->fld[0].rtx, recog_data_0.operand[1]) ) 
if ( rtx_equal_p( *( rtx *)&x1a[1], recog_data_0.operand[0]) ) 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x3a; 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) ) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) ) 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[2] = x3c; 
recog_data_0.operand[1] = x3d; 
recog_data_0.operand[2] = x3e; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3f; 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x2m; 
recog_data_0.operand[0] = x2n; 
if ( rtx_equal_p( x2o->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[2] = x2h; 
recog_data_0.operand[0] = x2i; 
if ( !rtx_equal_p( x2j->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[5] = x4d; 
recog_data_0.operand[2] = x3n; 
recog_data_0.operand[3] = x3o; 
recog_data_0.operand[4] = x3p; 
recog_data_0.operand[1] = x2y; 
recog_data_0.operand[1] = x3q; 
recog_data_0.operand[2] = x3r; 
recog_data_0.operand[2] = x3b; 
recog_data_0.operand[3] = x3c; 
recog_data_0.operand[1] = x2i; 
if ( rtx_equal_p( x2j->fld[0].rtx, recog_data_0.operand[2]) ) 
if ( rtx_equal_p( *( rtx *)&x2j[1], recog_data_0.operand[3]) ) 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[2] = x3d; 
recog_data_0.operand[3] = x2l; 
recog_data_0.operand[1] = x3bd; 
recog_data_0.operand[2] = x2ca; 
recog_data_0.operand[0] = x2cb; 
if ( !rtx_equal_p( x2cc->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = x3bd; 
recog_data_0.operand[2] = x2ce; 
recog_data_0.operand[0] = x2cf; 
if ( !rtx_equal_p( x2cg->fld[0].rtx, recog_data_0.operand[1]) ) 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x2p; 
recog_data_0.operand[0] = x2q; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1b; 
if ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66 ) 
if ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66 ) 
recog_data_0.operand[0] = x2c; 
recog_data_0.operand[1] = x1f; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2g; 
recog_data_0.operand[1] = x2d; 
recog_data_0.operand[0] = x4b; 
recog_data_0.operand[4] = x4c; 
recog_data_0.operand[1] = x2di; 
recog_data_0.operand[2] = x2dj; 
recog_data_0.operand[3] = x2dk->fld[0].rtx; 
&& recog_data_0.operand[4]->fld[0].rtwint + 16 * ( ( target_flags >> 22) & 8) <= 143 
+ 16 * recog_data_0.operand[2]->fld[0].rtwint >= -128 ) 
&& recog_data_0.operand[4]->fld[0].rtwint 
recog_data_0.operand[2] = x3; 
recog_data_0.operand[3] = x3a; 
recog_data_0.operand[0] = x2e; 
if ( rtx_equal_p( x2f->fld[0].rtx, recog_data_0.operand[2]) ) 
recog_data_0.operand[1] = x2g; 
recog_data_0.operand[2] = x2; 
recog_data_0.operand[0] = x2c; 
recog_data_0.operand[5] = x4; 
recog_data_0.operand[3] = x3e; 
recog_data_0.operand[1] = x2j; 
if ( rtx_equal_p( x3f->fld[0].rtx, recog_data_0.operand[5]) ) 
recog_data_0.operand[4] = x3g; 
if ( rtx_equal_p( x2l->fld[0].rtx, recog_data_0.operand[3]) ) 
if ( rtx_equal_p( x2m->fld[0].rtx, recog_data_0.operand[4]) ) 
if ( rtx_equal_p( x1h->fld[0].rtx, recog_data_0.operand[5]) ) 
recog_data_0.operand[0] = x2e; 
recog_data_0.operand[0] = x2e; 
recog_data_0.operand[0] = x3; 
recog_data_0.operand[1] = ( rtx)x1[1]; 
recog_data_0.operand[2] = x3b; 
recog_data_0.operand[0] = x3; 
recog_data_0.operand[1] = ( rtx)x1[1]; 
recog_data_0.operand[2] = x3d; 
recog_data_0.operand[0] = x2f; 
if ( rtx_equal_p( *( rtx *)&x2h[1], recog_data_0.operand[0]) ) 
if ( rtx_equal_p( x1f->fld[0].rtx, recog_data_0.operand[0]) 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x3w; 
recog_data_0.operand[2] = x2f; 
recog_data_0.operand[1] = x3x; 
recog_data_0.operand[2] = x2h; 
|| !ix86_binary_operator_ok( XOR, SImode, recog_data_0.operand) 
recog_data_0.operand[1] = x4n; 
|| !ix86_unary_operator_ok( NEG, SImode, recog_data_0.operand) 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x2b; 
recog_data_0.operand[1] = x3g; 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x1b; 
recog_data_0.operand[1] = x1b; 
&& *( _WORD *)recog_data_0.operand[1] == 54 
&& recog_data_0.operand[1]->fld[0].rtwint == -1 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2b; 
&& ( mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_FLOAT 
&& ( mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_VECTOR_FLOAT) 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] == MODE_VECTOR_FLOAT) 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[1] = x2g; 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x3i; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) ) 
if ( rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x3j; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) ) 
if ( rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = x3h; 
recog_data_0.operand[2] = x3k; 
recog_data_0.operand[1] = x3c; 
recog_data_0.operand[1] = x2f; 
recog_data_0.operand[1] = x3d; 
recog_data_0.operand[1] = x2g; 
recog_data_0.operand[1] = x3m; 
recog_data_0.operand[2] = x3n; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) ) 
if ( rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
recog_data_0.operand[1] = x3m; 
recog_data_0.operand[2] = x3o; 
if ( rtx_equal_p( *( rtx *)&x1[1], recog_data_0.operand[1]) ) 
if ( rtx_equal_p( x1[1].fld[0].rtx, recog_data_0.operand[2]) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
&& ( *( _WORD *)recog_data_0.operand[1] != 66 || *( _WORD *)recog_data_0.operand[2] != 66) 
recog_data_0.operand[1] = x3m; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2c; 
&& ix86_unary_operator_ok( ABS, XFmode, recog_data_0.operand) 
recog_data_0.operand[1] = x2b; 
&& ix86_unary_operator_ok( NEG, XFmode, recog_data_0.operand) 
recog_data_0.operand[1] = x2a; 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2a; 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x2; 
recog_data_0.operand[1] = x1a; 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2c; 
if ( ( target_flags & 1) != 0 && ix86_unary_operator_ok( ABS, TFmode, recog_data_0.operand) && pnum_clobbers ) 
recog_data_0.operand[1] = x2b; 
if ( ( target_flags & 1) != 0 && ix86_unary_operator_ok( NEG, TFmode, recog_data_0.operand) && pnum_clobbers ) 
recog_data_0.operand[1] = x2a; 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
recog_data_0.operand[1] = x2a; 
&& ( *( _WORD *)recog_data_0.operand[0] != 66 || *( _WORD *)recog_data_0.operand[1] != 66) ) 
pp = &costs_0[x->fld[0].rtuint]; 
superset_entry = ( alias_set_entry_0)xmalloc( 0x18uLL); 
allocno_0[( __int64)allocno_vec[len]].hard_reg_conflicts |= hard_regs_live; 
newa = lang_hooks_0.expand_constant( exp); 
else if ( mode_class_0[*( unsigned __int8 *)( link->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( link->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT ) 
induction_1 *b; // [rsp+58h] [rbp-8h] 
induction_1 *b; // [rsp+58h] [rbp-8h] 
induction_1 *ba; // [rsp+58h] [rbp-8h] 
induction_1 *ba; // [rsp+58h] [rbp-8h] 
for ( b = bl_0->biv; b; b = b->next_iv ) 
for ( b = bl_0->biv; b; b = b->next_iv ) 
for ( b = bl_0->biv; b; b = b->next_iv ) 
for ( b = bl_0->biv; b; b = b->next_iv ) 
if ( b->insn->fld[0].rtint >= max_uid_for_loop ) 
if ( *( ( _DWORD *)uid_luid + b->insn->fld[0].rtint) >= *( ( _DWORD *)uid_luid 
if ( b->insn->fld[0].rtint >= max_uid_for_loop ) 
if ( *( ( _DWORD *)uid_luid + b->insn->fld[0].rtint) <= *( ( _DWORD *)uid_luid 
for ( ba = bl_0->biv; ba; ba = ba->next_iv ) 
for ( ba = bl_0->biv; ba; ba = ba->next_iv ) 
for ( ba = bl_0->biv; ba; ba = ba->next_iv ) 
|| mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_COMPLEX_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_VECTOR_FLOAT ) 
|| mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT) 
info = &reg_avail_info_0[regno]; 
cuid = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
allocno_0[( __int64)ialloc].hard_reg_conflicts |= hard_regs_live; 
allocno_0[( __int64)j].hard_reg_conflicts |= 1LL << regno; 
reg_set_table = ( reg_set_0 **)grealloc( ( char *)reg_set_table, 8 * ( regno + 100)); 
reg_set_table[regno] = ( reg_set_0 *)value; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
constraints[i] = recog_data_0.constraints[i]; 
modes[i] = recog_data_0.operand_mode[i]; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( *( _WORD *)recog_data_0.operand[i] == 63 ) 
inner = recog_data_0.operand[i]->fld[0].rtx; 
recog_data_0.operand[i] = inner; 
if ( *( _WORD *)recog_data_0.operand[i] == 66 ) 
record_address_regs( recog_data_0.operand[i]->fld[0].rtx, GENERAL_REGS, 2 * frequency); 
record_address_regs( recog_data_0.operand[i], GENERAL_REGS, 2 * frequency); 
for ( i = 0; i < recog_data_0.n_operands - 1; ++i ) 
for ( j = 0; j < recog_data_0.n_operands; ++j ) 
recog_data_0.n_alternatives, 
recog_data_0.n_operands, 
recog_data_0.operand, 
recog_data_0.n_alternatives, 
recog_data_0.n_operands, 
recog_data_0.operand, 
win = address_operand( op, ( machine_mode)*( ( unsigned __int8 *)op + 2)); 
if ( recog_data_0.operand_type[i] == OP_OUT ) 
if ( recog_data_0.operand_type[i] ) 
if ( recog_data_0.operand_type[i] ) 
if ( recog_data_0.operand_type[i] == OP_OUT ) 
( machine_mode)*( ( unsigned __int8 *)op + 2))) ) 
if ( recog_data_0.operand_type[i] != OP_OUT ) 
if ( recog_data_0.operand_type[i] ) 
if ( recog_data_0.operand_type[i] == OP_OUT ) 
if ( recog_data_0.operand_type[i] ) 
if ( recog_data_0.operand_type[i] ) 
else if ( mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)rega + 2)] == MODE_COMPLEX_FLOAT ) 
if ( mode_class_0[mode] == MODE_INT && mode_bitsize[mode] <= 0x40u ) 
v11 = num_sign_bit_copies( valuea, ( machine_mode)*( ( unsigned __int8 *)rega + 2)); 
v5 = mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT ) 
v5 = mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
if ( reg_pref_0 ) 
return reg_pref_0[regno].altclass; 
else if ( mode_class_0[*( ( unsigned __int8 *)target + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)target + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
v2 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT; 
v4 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
v4 = mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT; 
alloc_qty( regno, ( machine_mode)*( ( unsigned __int8 *)reg + 2), v3 / v4, birth); 
qty_0[*( ( int *)reg_qty + regno)].death = -1; 
mark_life( regno, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
post_mark_life( regno, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1, birth, 2 * this_insn_number); 
return new_loc_descr( ( dwarf_location_atom)( reg + 80), 0LL, 0LL); 
( machine_mode)*( unsigned __int8 *)( xa->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)xa + 2)); 
else if ( mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)xa + 2)] == MODE_COMPLEX_FLOAT ) 
if ( reg_pref_0 ) 
return reg_pref_0[regno].prefclass; 
costs_0 = (  struct costs *)xmalloc( 104LL * nregs); 
memset( costs_0, 0, 104LL * nregs); 
reg_pref_0 = reg_pref_buffer; 
p = &costs_0[i]; 
if ( dump && ( reg_pref_0[i].prefclass != best || reg_pref_0[i].altclass != alt) ) 
if ( dump && ( reg_pref_0[i].prefclass != best || reg_pref_0[i].altclass != alt) ) 
fprintf( dump, " pref %s\n", reg_class_names_0[best]); 
fprintf( dump, " pref %s, else %s\n", reg_class_names_0[best], reg_class_names_0[alt]); 
fprintf( dump, " pref %s, else %s\n", reg_class_names_0[best], reg_class_names_0[alt]); 
fprintf( dump, " pref %s or none\n", reg_class_names_0[best]); 
reg_pref_0[i].prefclass = best; 
reg_pref_0[i].altclass = alt; 
free( costs_0); 
|| reg_class_subset_p( ( reg_class)class0, ( reg_class)class1) 
|| reg_class_subset_p( ( reg_class)class1, ( reg_class)class0) 
reg_pref_0 = 0LL; 
if ( mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_FLOAT 
for ( op_no = 0; op_no < recog_data_0.n_operands; ++op_no ) 
src = recog_data_0.operand[op_no]; 
dst = recog_data_0.operand[match_no]; 
( machine_mode)*( unsigned __int8 *)( dst->fld[0].rtwint + 2), 
&& recog_data_0.operand[match_no] == set->fld[0].rtx 
|| ( comm = recog_data_0.operand[match.commutative[op_no]], !operands_match_p( comm, dst)) 
for ( op_no_0 = 0; op_no_0 < recog_data_0.n_operands; ++op_no_0 ) 
dst_0 = recog_data_0.operand[match_no_0]; 
src_0 = recog_data_0.operand[op_no_0]; 
|| ( comm_0 = recog_data_0.operand[match.commutative[op_no_0]], !operands_match_p( comm_0, dst_0)) ) 
&& recog_data_0.operand[match_no_0] == set_0->fld[0].rtx ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)*this->loc + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*this->loc + 2)] == MODE_COMPLEX_FLOAT ) 
tmp && ix86_hard_regno_mode_ok( new_reg, ( machine_mode)*( ( unsigned __int8 *)*tmp->loc + 2)); 
pp = ( page_entry_0 **)( &G + 2640); 
pp = ( page_entry_0 **)*pp; 
gp = ( page_group_0 **)( &G + 2648); 
gp = ( page_group_0 **)*gp; 
( machine_mode)*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2), 
if ( !verbose_warned_21 ) 
verbose_warned_21 = 1; 
*( _QWORD *)( v1 + 8) = eliminate_regs( *( rtx *)( v1 + 8), ( machine_mode)*( unsigned __int8 *)( v1 + 2), 0LL); 
v1 = mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] != MODE_COMPLEX_INT 
&& mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] != MODE_COMPLEX_FLOAT; 
v6 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] != MODE_COMPLEX_INT 
&& mode_class_0[*( ( unsigned __int8 *)reg + 2)] != MODE_COMPLEX_FLOAT; 
index_reg = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)reg + 2), i); 
reg_sum = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)reg + 2), index_reg, base); 
else if ( mode_class_0[*( ( unsigned __int8 *)usage_rtx + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)usage_rtx + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
v1 = sext_for_mode( ( machine_mode)*( ( unsigned __int8 *)reg + 2), src->fld[0].rtwint - reg_offset_0[regno]); 
v1 = sext_for_mode( ( machine_mode)*( ( unsigned __int8 *)reg + 2), src->fld[0].rtwint - reg_offset_0[regno]); 
reg_offset_0[regno] = src->fld[0].rtwint; 
base_offset = reg_offset_0[src->fld[0].rtuint]; 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
added_offset + base_offset - reg_offset_0[regno]); 
reg_offset_0[regno] = sext_for_mode( ( machine_mode)*( ( unsigned __int8 *)reg + 2), base_offset + added_offset); 
reg_offset_0[regno] = sext_for_mode( ( machine_mode)*( ( unsigned __int8 *)reg + 2), base_offset + added_offset); 
if ( !recog_data_0.n_alternatives || !recog_data_0.n_operands ) 
if ( !recog_data_0.n_alternatives || !recog_data_0.n_operands ) 
fatal_insn_not_found( insna, "reload1.c", 8371, "reload_cse_simplify_operands"); 
v2 = alloca( 16 * ( ( 4LL * recog_data_0.n_alternatives + 23) / 0x10uLL)); 
v3 = alloca( 16 * ( ( 4LL * recog_data_0.n_alternatives + 23) / 0x10uLL)); 
v4 = alloca( 16 * ( ( 4LL * recog_data_0.n_alternatives + 23) / 0x10uLL)); 
memset( &v13, 0, 4LL * recog_data_0.n_alternatives); 
memset( alternative_nregs, 0, 4LL * recog_data_0.n_alternatives); 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( *( _WORD *)recog_data_0.operand[i] != 36 
&& ( *( _WORD *)recog_data_0.operand[i] != 67 
&& *( _WORD *)recog_data_0.operand[i] != 68 
&& *( _WORD *)recog_data_0.operand[i] != 54 
&& *( _WORD *)recog_data_0.operand[i] != 55 
&& *( _WORD *)recog_data_0.operand[i] != 58 
old_cost = ix86_memory_move_cost( ( machine_mode)*( ( unsigned __int8 *)src + 2), dclass, 1); 
( machine_mode)*( ( unsigned __int8 *)src + 2), 
val = cselib_lookup( src, ( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)this_rtx + 2), 
v8 = mode_class_0[*( ( unsigned __int8 *)inner + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)inner + 2)] == MODE_COMPLEX_FLOAT 
v13 = mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)reg + 2)] == MODE_COMPLEX_FLOAT; 
htab_traverse_noresize( hash_table_0, ( htab_trav)discard_useless_locs, 0LL); 
htab_traverse_noresize( hash_table_0, ( htab_trav)discard_useless_values, 0LL); 
if ( use == sibcall_use_tail_recursion_0 ) 
else if ( use == sibcall_use_sibcall_0 ) 
if ( use != sibcall_use_normal_0 ) 
return replace_oldest_value_addr( ( rtx *)x->fld, GENERAL_REGS, ( machine_mode)*( ( unsigned __int8 *)x + 2), insn, vd); 
*loc = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)xa + 2), reg_equiv_address[regno]); 
replace_pseudos_in_call_usage( ( rtx *)x->fld, ( machine_mode)*( ( unsigned __int8 *)x + 2), usage); 
v2 = mode_class_0[*( ( unsigned __int8 *)*reg + 2)]; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
while ( ( sch_istable[*( unsigned __int8 *)p] & 4) != 0 ) 
if ( ( sch_istable[( unsigned __int8)pb[1]] & 0x88) != 0 && pb[2] == 91 ) 
prefix = prefixes_21[sec][( BYTE2( decla->block.supercontext) & 8) != 0]; 
timevar_push( TV_REST_OF_COMPILATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_TO_SSA_0); 
timevar_pop( TV_TO_SSA_0); 
timevar_push( TV_SSA_CCP_0); 
timevar_pop( TV_SSA_CCP_0); 
timevar_push( TV_SSA_DCE_0); 
timevar_pop( TV_SSA_DCE_0); 
timevar_push( TV_FROM_SSA_0); 
timevar_pop( TV_FROM_SSA_0); 
timevar_push( TV_VARCONST_0); 
timevar_pop( TV_VARCONST_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
fatal_insn_not_found( insn, "insn-attrtab.c", 1990, "result_ready_cost"); 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && memory_operand( recog_data_0.operand[1], VOIDmode) 
|| ix86_cpu == PROCESSOR_PENTIUM && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
if ( ix86_cpu == PROCESSOR_PENTIUMPRO && !which_alternative && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
|| !symbolic_operand( ( unsigned __int16 *)recog_data_0.operand[1]) ) 
&& memory_operand( recog_data_0.operand[1], VOIDmode) ) 
&& ( which_alternative == 2 || ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2])) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& ( which_alternative == 2 || ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2])) 
&& ( which_alternative || ( unsigned int)pic_symbolic_operand( ( __int64)recog_data_0.operand[2])) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& !incdec_operand( recog_data_0.operand[2]) 
&& !incdec_operand( recog_data_0.operand[2]) 
( rtx_code)*( _WORD *)comparison, 
if ( mode_class_0[mode] == MODE_CC ) 
if ( mode_class_0[mode] != MODE_CC ) 
&& mode_class_0[mode] != MODE_CC 
&& mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
if ( mode_class_0[BYTE5( enttype->block.abstract_origin) >> 1] == MODE_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_INT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_PARTIAL_INT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_COMPLEX_INT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_INT ) 
e = cselib_lookup( x, ( machine_mode)*( ( unsigned __int8 *)x + 2), 0); 
e_0 = cselib_lookup( y, ( machine_mode)*( ( unsigned __int8 *)y + 2), 0); 
v3 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( y->fld[0].rtwint + 2), x); 
v4 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), y); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
( machine_mode)*( unsigned __int8 *)( y->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2)); 
save_expr_list_4 = 0LL; 
for ( t = save_expr_list_4; t; t = t->common.chain ) 
save_expr_list_4 = tree_cons( exp, 0LL, save_expr_list_4); 
save_expr_list_4 = tree_cons( exp, 0LL, save_expr_list_4); 
nops = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&expa->block.common + 16)); 
if ( *( ( _BYTE *)&expa->block.common + 16) > 0x92u && !lang_hooks_0.safe_from_p( xa, expa) ) 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno_0] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[regno_0] + 2)] == MODE_COMPLEX_FLOAT ) 
if ( ( sch_istable[*( ( unsigned __int8 *)pfile->buffer->cur - 1)] & 0x400) != 0 ) 
( save_level)( thisblock->next == 0LL), 
v20 = mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
v6 = mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
v12 = mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( unsigned __int8 *)( set->fld[0].rtwint + 2)] == MODE_COMPLEX_FLOAT 
costs_0[*( unsigned int *)( set->fld[0].rtwint + 8)].mem_cost -= frequency 
( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 
&& recog_data_0.n_operands > 2 
&& *recog_data_0.constraints[1] == 48 
&& !*( ( _BYTE *)recog_data_0.constraints[1] + 1) 
&& ( *( _WORD *)recog_data_0.operand[1] == 67 
|| *( _WORD *)recog_data_0.operand[1] == 68 
|| *( _WORD *)recog_data_0.operand[1] == 54 
|| *( _WORD *)recog_data_0.operand[1] == 55 
|| *( _WORD *)recog_data_0.operand[1] == 58 
|| *( _WORD *)recog_data_0.operand[1] == 134 
|| *( _WORD *)recog_data_0.operand[1] == 56 
|| *( _WORD *)recog_data_0.operand[1] == 140) 
&& !rtx_equal_p( recog_data_0.operand[0], recog_data_0.operand[1]) 
scan_rtx_address( insn, ( rtx *)x->fld, GENERAL_REGS, action, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
scan_rtx_address( insn, ( rtx *)x->fld, GENERAL_REGS, action, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
else if ( mode_class_0[*( ( unsigned __int8 *)*loc + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*loc + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)*this_0->loc + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*this_0->loc + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)dest + 2)] == MODE_COMPLEX_FLOAT ) 
if ( std::allocator_traits<std::allocator<std::_Rb_tree_node<std::pair<std::string const, tcmalloc::MallocExtension::Property>>>>::allocate( 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
add_dependence( insn, pendinga->fld[0].rtx, ( reg_note)0); 
print_block_visualization( byte_779C53); 
bb_deps = ( deps_0 *)xmalloc( 104LL * ( int)current_nr_blocks); 
sched_rgn_n_insns += sched_n_insns_0; 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE && ( *( ( _BYTE *)&containing_scope[1] + 1) & 0x40) == 0 ) 
if ( constructor_range_stack_0 ) 
while ( constructor_stack_0->implicit ) 
memset( dc, 0, sizeof( diagnostic_context_0)); 
if ( constructor_range_stack_0 || lasta ) 
if ( constructor_range_stack_0 ) 
v6 = *( tree_node **)( *( _QWORD *)&mem[1] + 8LL); 
v5 = *( tree_node **)( *( _QWORD *)&mem[1] + 8LL); 
v3 = *( tree_node **)( *( _QWORD *)&ref[1] + 8LL); 
v10 = lang_hooks_0.honor_readonly 
off_tree = ( tree_node *)*( &global_trees + 15); 
v5 = *( tree_node **)( *( _QWORD *)&mem[1] + 8LL); 
G.lookup[BYTE3( p)] = ( page_entry_0 **)xcalloc( 1LL << ( 24 - LOBYTE( G.lg_pagesize)), 8uLL); 
|| rld[r].out && !ix86_hard_regno_mode_ok( regno, ( machine_mode)*( ( unsigned __int8 *)rld[r].out + 2)) ) 
add_dependence( insn, link->fld[0].rtx, ( reg_note)*( ( unsigned __int8 *)link + 2)); 
insn[3].fld[0].rtwint = ( __int64)gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, datum, insn[3].fld[0].rtx); 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[mode] == MODE_COMPLEX_INT || mode_class_0[mode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2)] == MODE_COMPLEX_FLOAT ) 
( machine_mode)*( ( _DWORD *)&regno_save_mode + 5 * ia + j), 
( machine_mode)*( ( _DWORD *)&regno_save_mode + 5 * ia + 5 * kb + 1), 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x, c); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, v3); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v7, rtx); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v5, v4); 
min_gt = *( _OWORD *)&primop1->block.vars < *( _OWORD *)&minval->block.vars; 
min_gt = *( _OWORD *)&primop1->block.vars < *( _OWORD *)&minval->block.vars; 
max_gt = *( _OWORD *)&primop1->block.vars < *( _OWORD *)&maxval->block.vars; 
max_gt = *( _OWORD *)&primop1->block.vars < *( _OWORD *)&maxval->block.vars; 
min_lt = *( _OWORD *)&minval->block.vars < *( _OWORD *)&primop1->block.vars; 
min_lt = *( _OWORD *)&minval->block.vars < *( _OWORD *)&primop1->block.vars; 
if ( type1 == ( tree_node *)*( &global_trees + 10) ) 
if ( type1 == ( tree_node *)*( &global_trees + 9) ) 
if ( type1 == ( tree_node *)*( &global_trees + 8) ) 
if ( type1 == ( tree_node *)*( &global_trees + 7) ) 
if ( type1 == ( tree_node *)*( &global_trees + 6) ) 
v6 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)varopa + 2), *( rtx *)&varopa[1], constopb); 
v7 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)varopa + 2), varopa->fld[0].rtx, constopb); 
v8 = gen_binary( ( rtx_code)*( _WORD *)varopa, ( machine_mode)*( ( unsigned __int8 *)varopa + 2), v7, v6); 
v8 = gen_binary( ( rtx_code)*( _WORD *)varopa, ( machine_mode)*( ( unsigned __int8 *)varopa + 2), v7, v6); 
if ( mode_class_0[mode] == MODE_FLOAT 
else if ( mode_class_0[mode] == MODE_INT 
|| mode_class_0[*( ( unsigned __int8 *)xop00 + 2)] != MODE_CC 
|| mode_class_0[*( ( unsigned __int8 *)xop10 + 2)] != MODE_CC ) 
if ( ( mode_class_0[mode] == MODE_FLOAT 
|| mode_class_0[mode] == MODE_COMPLEX_FLOAT 
|| mode_class_0[mode] == MODE_VECTOR_FLOAT) 
if ( ( mode_class_0[mode] == MODE_INT 
|| mode_class_0[mode] == MODE_PARTIAL_INT 
|| mode_class_0[mode] == MODE_COMPLEX_INT 
|| mode_class_0[mode] == MODE_VECTOR_INT) 
if ( mode_class_0[mode] != MODE_FLOAT 
induction_1 *v; // [rsp+38h] [rbp-58h] 
induction_1 *v; // [rsp+38h] [rbp-58h] 
&& ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_INT || mode_bitsize[*( ( unsigned __int8 *)x + 2)] > 0x40u) ) 
v = ivs->regs[x->fld[0].rtuint].iv.info; 
*benefit += v->benefit; 
if ( ( *( ( _BYTE *)v + 100) & 0x40) != 0 ) 
add_val = v->add_val; 
v28 = gen_rtx_fmt_ee( MULT, mode, v->src_reg, v->mult_val); 
v28 = gen_rtx_fmt_ee( MULT, mode, v->src_reg, v->mult_val); 
if ( v->derive_adjustment ) 
tema = gen_rtx_fmt_ee( MINUS, mode, tema, v->derive_adjustment); 
if ( v->ext_dependent ) 
*ext_val = v->ext_dependent; 
*ext_val = gen_rtx_fmt_e( ( rtx_code)*( _WORD *)x, mode, arg0b); 
&& ( nzb = nonzero_bits( from, ( machine_mode)*( ( unsigned __int8 *)from + 2)), exact_log2_wide( nzb) >= 0) ) 
&& num_sign_bit_copies( from, ( machine_mode)*( ( unsigned __int8 *)from + 2)) == mode_bitsize[*( ( unsigned __int8 *)from + 2)] ) 
v12 = reversed_comparison( cond, ( machine_mode)*( ( unsigned __int8 *)cond + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT 
if ( mode_class_0[mode] == MODE_INT 
v11 = gen_binary( ( rtx_code)*( _WORD *)op0, mode, v10, v9); 
v15 = gen_binary( ( rtx_code)*( _WORD *)op1, mode, v14, v13); 
if ( mode_class_0[*( ( unsigned __int8 *)op0a + 2)] == MODE_CC ) 
if ( ( mode_class_0[mode] == MODE_INT 
|| mode_class_0[mode] == MODE_PARTIAL_INT 
|| mode_class_0[mode] == MODE_COMPLEX_INT 
|| mode_class_0[mode] == MODE_VECTOR_INT) 
&& ( mode_class_0[*( ( unsigned __int8 *)trueop0 + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)trueop0 + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)trueop0 + 2)] != MODE_VECTOR_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)trueop0 + 2)] == MODE_FLOAT ) 
if ( ( mode_class_0[mode] == MODE_INT || mode == VOIDmode) 
|| mode_class_0[mode] != MODE_INT 
&& mode_class_0[mode] != MODE_PARTIAL_INT 
exp = simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), v15, v14, v13); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
rtx note; // [rsp+18h] [rbp-98h] BYREF 
rtx pat; // [rsp+20h] [rbp-90h] BYREF 
rtx op1; // [rsp+28h] [rbp-88h] BYREF 
rtx op0; // [rsp+30h] [rbp-80h] BYREF 
rtx other_insn; // [rsp+38h] [rbp-78h] BYREF 
rtx term3; // [rsp+40h] [rbp-70h] 
rtx term2; // [rsp+48h] [rbp-68h] 
rtx new_dest; // [rsp+58h] [rbp-58h] 
( machine_mode)*( ( unsigned __int8 *)varop + 2), 
varop = gen_binary( ASHIFT, ( machine_mode)*( ( unsigned __int8 *)varop + 2), varop->fld[0].rtx, v21); 
varop = gen_binary( LSHIFTRT, ( machine_mode)*( ( unsigned __int8 *)varop + 2), varop->fld[0].rtx, v23); 
( machine_mode)*( ( unsigned __int8 *)varop + 2), 
varop = gen_rtx_fmt_e( NEG, ( machine_mode)*( ( unsigned __int8 *)varop + 2), varop); 
if ( v6 < mode_size[innermode] && mode_class_0[outermode] == MODE_INT ) 
if ( mode_class_0[outermode] != MODE_INT ) 
result = simplify_subreg( outermode, op->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( op->fld[0].rtwint + 2), 0); 
( machine_mode)*( unsigned __int8 *)( op->fld[0].rtwint + 2), 
res = simplify_subreg( outermode, v11.rtx, ( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), final_offset_0); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, &val0); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), *( rtx *)&x[1], &val1); 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[mode] != MODE_FLOAT 
&& mode_class_0[mode] != MODE_COMPLEX_FLOAT 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT 
temp = simplify_relational_operation( ( rtx_code)*( _WORD *)op0a, cmp_mode, op0a->fld[0].rtx, *( rtx *)&op0a[1]); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)op0a, mode, op0a->fld[0].rtx, *( rtx *)&op0a[1]); 
else if ( *( _WORD *)trueop == 55 && mode_class_0[modea] == MODE_FLOAT ) 
&& mode_class_0[*( ( unsigned __int8 *)trueop + 2)] == MODE_FLOAT 
&& mode_class_0[modea] == MODE_INT 
if ( !size_htab_9 ) 
size_htab_9 = htab_create( 0x400uLL, ( htab_hash)size_htab_hash, ( htab_eq)size_htab_eq, 0LL); 
ggc_add_deletable_htab( size_htab_9, 0LL, 0LL); 
new_const_8 = make_node( INTEGER_CST); 
ggc_add_tree_root( &new_const_8, 1); 
new_const_8->int_cst.int_cst.low = number; 
new_const_8->int_cst.int_cst.high = v2; 
new_const_8->common.type = type; 
v3 = force_fit_type( new_const_8, 0); 
v4 = new_const_8; 
*( ( _BYTE *)&new_const_8->block.common + 18) = ( 4 * ( v3 & 1)) | *( ( _BYTE *)&new_const_8->block.common + 18) & 0xFB; 
*( ( _BYTE *)&new_const_8->block.common + 18) = ( 4 * ( v3 & 1)) | *( ( _BYTE *)&new_const_8->block.common + 18) & 0xFB; 
*( ( _BYTE *)&new_const_8->block.common + 18) = ( 8 * ( ( *( ( _BYTE *)&v4->block.common + 18) & 4) != 0)) | *( ( _BYTE *)&new_const_8->block.common + 18) & 0xF7; 
*( ( _BYTE *)&new_const_8->block.common + 18) = ( 8 * ( ( *( ( _BYTE *)&v4->block.common + 18) & 4) != 0)) | *( ( _BYTE *)&new_const_8->block.common + 18) & 0xF7; 
slot = htab_find_slot( size_htab_9, new_const_8, INSERT); 
slot = htab_find_slot( size_htab_9, new_const_8, INSERT); 
t = new_const_8; 
*slot = new_const_8; 
else if ( ( sch_istable[BYTE4( prevc)] & 0x400) != 0 ) 
next = cpp_trigraph_map[*( ( unsigned __int8 *)buffer->cur + 1)]; 
while ( ( sch_istable[*v1] & 0x800) != 0 && buffer->cur < buffer->rlimit ); 
if ( ( sch_istable[*v1] & 0x400) == 0 ) 
if ( ( sch_istable[( unsigned __int8)c] & 0x400) != 0 ) 
while ( ( sch_istable[( unsigned __int8)c] & 0x800) != 0 ); 
for ( p = spelling_base; p < spelling_0; ++p ) 
error( "unable to find a register to spill in class `%s'", reg_class_names_18[a2]); 
fatal_insn( "this is the insn:", insn, "reload1.c", 1910, "spill_failure"); 
error_for_asm( insn, "can't find a register in class `%s' while reloading `asm'", reg_class_names_18[a2]); 
else if ( mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[i] + 2)] == MODE_COMPLEX_FLOAT ) 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2j; 
return gen_split_1133( recog_data_0.operand); 
recog_data_0.operand[1] = x2l; 
return gen_split_1135( recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2i; 
return gen_split_943( recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
recog_data_0.operand[1] = x2h; 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] != MODE_FLOAT 
|| mode_class_0[*( ( unsigned __int8 *)recog_data_0.operand[1] + 2)] != MODE_FLOAT 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3b; 
recog_data_0.operand[1] = x3b; 
|| ( v16 = true_regnum( recog_data_0.operand[0]), v16 != true_regnum( recog_data_0.operand[1])) ) 
|| ( v16 = true_regnum( recog_data_0.operand[0]), v16 != true_regnum( recog_data_0.operand[1])) ) 
return gen_split_883( recog_data_0.operand); 
if ( *( _WORD *)recog_data_0.operand[1] != 61 ) 
return gen_split_881( recog_data_0.operand); 
if ( *( _WORD *)recog_data_0.operand[1] != 61 
|| recog_data_0.operand[1]->fld[0].rtint > 7u 
&& ( recog_data_0.operand[1]->fld[0].rtint <= 0x24u || recog_data_0.operand[1]->fld[0].rtint > 0x2Cu) ) 
&& ( recog_data_0.operand[1]->fld[0].rtint <= 0x24u || recog_data_0.operand[1]->fld[0].rtint > 0x2Cu) ) 
v15 = *( _WORD *)recog_data_0.operand[0] == 61 
&& ( recog_data_0.operand[0]->fld[0].rtint <= 7u 
|| recog_data_0.operand[0]->fld[0].rtint > 0x24u && recog_data_0.operand[0]->fld[0].rtint <= 0x2Cu); 
|| recog_data_0.operand[0]->fld[0].rtint > 0x24u && recog_data_0.operand[0]->fld[0].rtint <= 0x2Cu); 
v15 = *( _WORD *)recog_data_0.operand[0] == 61 && recog_data_0.operand[0]->fld[0].rtint <= 3u; 
v15 = *( _WORD *)recog_data_0.operand[0] == 61 && recog_data_0.operand[0]->fld[0].rtint <= 3u; 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3u; 
recog_data_0.operand[2] = x1bc->fld[0].rtx; 
return gen_split_1040( recog_data_0.operand); 
recog_data_0.operand[1] = x3v; 
recog_data_0.operand[2] = x1be->fld[0].rtx; 
return gen_split_1060( recog_data_0.operand); 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3w; 
recog_data_0.operand[2] = x1bg->fld[0].rtx; 
&& ( *( _WORD *)recog_data_0.operand[0] != 61 
|| ( recog_data_0.operand[0]->fld[0].rtint <= 0x14u 
|| recog_data_0.operand[0]->fld[0].rtint > 0x1Cu) 
&& ( recog_data_0.operand[0]->fld[0].rtint <= 0x2Cu 
|| recog_data_0.operand[0]->fld[0].rtint > 0x34u)) 
|| *( _WORD *)recog_data_0.operand[0] == 61 
&& recog_data_0.operand[0]->fld[0].rtint > 7u 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3; 
recog_data_0.operand[2] = x2c; 
recog_data_0.operand[3] = x2d; 
recog_data_0.operand[4] = x2e; 
recog_data_0.operand[5] = x2f; 
return gen_split_930( recog_data_0.operand); 
recog_data_0.operand[0] = x2; 
recog_data_0.operand[1] = x3a; 
recog_data_0.operand[2] = x2g; 
recog_data_0.operand[3] = x2h; 
recog_data_0.operand[4] = x2i; 
recog_data_0.operand[5] = x2j; 
return gen_split_931( recog_data_0.operand); 
recog_data_0.operand[0] = x2k; 
recog_data_0.operand[1] = x3d; 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = x1; 
return gen_split_1178( recog_data_0.operand); 
recog_data_0.operand[0] = x1; 
return gen_split_1179( recog_data_0.operand); 
edge_info_0 = ( edge *)xmalloc( 8LL * edges->num_edges); 
edge_info_0[index] = curredge->succ_next; 
free( edge_info_0); 
edge_info_0 = 0LL; 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_COMPLEX_FLOAT 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT ) 
|| ( section_name = decl1->decl.name, section_name == ( tree_node *)*( &global_trees + 50)) ) 
|| ( section_name = decl1->decl.name, section_name == ( tree_node *)*( &global_trees + 50)) ) 
p->constructor_stack = constructor_stack_0; 
p->constructor_range_stack = constructor_range_stack_0; 
p->spelling = spelling_0; 
p->next = initializer_stack_0; 
initializer_stack_0 = p; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
result = lang_hooks_0.staticp( arg); 
rounded_size = ( tree_node *)*( &global_trees + 15); 
tree t; // [rsp+28h] [rbp-18h] 
t = build( MODIFY_EXPR, valist->common.type, valist, tree); 
*( ( _BYTE *)&t->block.common + 17) |= 1u; 
expand_expr( t, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
&& mode_class_0[fieldmode] != MODE_INT 
&& mode_class_0[fieldmode] != MODE_PARTIAL_INT ) 
imode = int_mode_for_mode( ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
if ( !insn_data_0[icode].operand[1].predicate( valueb, fieldmode) ) 
&& mode_class_0[fieldmode] != MODE_INT 
&& mode_class_0[fieldmode] != MODE_PARTIAL_INT ) 
genfun = insn_data_0[icode].genfun; 
if ( mode_class_0[*( ( unsigned __int8 *)valueb + 2)] != MODE_INT 
&& mode_class_0[*( ( unsigned __int8 *)valueb + 2)] != MODE_PARTIAL_INT ) 
store_by_pieces_2( insn_data_0[icode].genfun, mode, data); 
tree expa; // [rsp+18h] [rbp-248h] 
tree value; // [rsp+30h] [rbp-230h] 
if ( *( ( _BYTE *)target + 2) == 51 || bitpos % get_mode_alignment( ( machine_mode)*( ( unsigned __int8 *)target + 2)) ) 
tree expa; // [rsp+18h] [rbp-68h] 
expa = exp; 
temp = expand_expr( exp, 0LL, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
v5 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
temp = expand_expr( exp, v5, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
( machine_mode)*( ( unsigned __int8 *)sizea + 2), 
temp = convert_to_mode( ( machine_mode)*( ( unsigned __int8 *)targeta + 2), temp, unsignedp); 
temp = expand_expr( exp, target, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
temp = expand_expr( exp, target, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
expa = convert( v6, exp); 
|| mode_class_0[mode] == MODE_COMPLEX_INT 
|| mode_class_0[mode] == MODE_COMPLEX_FLOAT) 
temp = convert_modes( mode, ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), temp, 1); 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
*(short *)0x0 = operand_sub*(short *)0xforce( 
*(short *)0x0a = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
*(short *)0x0a = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
induction_1 *tv; // [rsp+58h] [rbp-28h] 
induction_1 *tv; // [rsp+58h] [rbp-28h] 
induction_1 *v; // [rsp+60h] [rbp-20h] 
induction_1 *v; // [rsp+60h] [rbp-20h] 
induction_1 *va; // [rsp+60h] [rbp-20h] 
induction_1 *va; // [rsp+60h] [rbp-20h] 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
for ( v = bl_0->giv; v; v = v->next_iv ) 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 && !v->same ) 
if ( ( *( ( _BYTE *)v + 100) & 4) == 0 && !v->same ) 
benefit = loop_giv_reduce_benefit( loop, bl_0, v, test_reg); 
|| insn_count <= benefit * threshold * v->lifetime 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
for ( tv = bl_0->biv; tv; tv = tv->next_iv ) 
return legitimate_address_p( ( machine_mode)addr, addr, v3) != 0; 
if ( check_mode && !ix86_hard_regno_mode_ok( base_regno, ( machine_mode)*( ( unsigned __int8 *)reg + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)) == x[1]; 
( machine_mode)*( ( unsigned __int8 *)subreg + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
else if ( mode_class_0[xmode] == MODE_COMPLEX_INT || mode_class_0[xmode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[xmode] == MODE_COMPLEX_INT || mode_class_0[xmode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[ymode] == MODE_COMPLEX_INT || mode_class_0[ymode] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[ymode] == MODE_COMPLEX_INT || mode_class_0[ymode] == MODE_COMPLEX_FLOAT ) 
return gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)x + 2), const_int_rtx[64]); 
( machine_mode)*( unsigned __int8 *)( xa->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)xa + 2), 
( machine_mode)*( unsigned __int8 *)( xa->fld[0].rtwint + 2)); 
n_outputs = recog_data_0.n_operands - n_inputs; 
for ( i = 0; i < recog_data_0.n_operands; ++i ) 
if ( *( _WORD *)recog_data_0.operand[i] == 63 && *( _WORD *)recog_data_0.operand[i]->fld[0].rtwint == 61 ) 
if ( *( _WORD *)recog_data_0.operand[i] == 63 && *( _WORD *)recog_data_0.operand[i]->fld[0].rtwint == 61 ) 
recog_data_0.operand_loc[i] = ( rtx *)recog_data_0.operand[i]->fld; 
recog_data_0.operand_loc[i] = ( rtx *)recog_data_0.operand[i]->fld; 
recog_data_0.operand[i] = recog_data_0.operand[i]->fld[0].rtx; 
recog_data_0.operand[i] = recog_data_0.operand[i]->fld[0].rtx; 
note_kind = ( reg_note *)&regstacka; 
if ( *( _WORD *)recog_data_0.operand[i] == 61 
&& recog_data_0.operand[i]->fld[0].rtint > 7u 
&& recog_data_0.operand[i]->fld[0].rtint <= 0xFu 
regno = get_hard_regnum( &temp_stack, recog_data_0.operand[i]); 
if ( mode_class_0[*( ( unsigned __int8 *)src + 2)] == MODE_CC ) 
tem = gen_lowpart_if_possible( ( machine_mode)*( unsigned __int8 *)( dest->fld[0].rtwint + 2), src); 
&& mode_class_0[*( ( unsigned __int8 *)src + 2)] == MODE_CC 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
&& !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx) ) 
( rtx_code)*( _WORD *)op0, 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
newa = simplify_unary_operation( code, ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, op0_mode); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
&& ( mode_class_0[*( ( unsigned __int8 *)*dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*dest + 2)] == MODE_COMPLEX_FLOAT) 
else if ( mode_class_0[*( ( unsigned __int8 *)*dest + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)*dest + 2)] == MODE_COMPLEX_FLOAT ) 
*( _WORD *)pat = swap_condition( ( rtx_code)*( _WORD *)pat); 
if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
popped = stack_0; 
if ( &timevars[timevar] != stack_0->timevar ) 
stack_0 = stack_0->next; 
stack_0 = stack_0->next; 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, &now); 
if ( stack_0 ) 
timevar_accumulate( &stack_0->timevar->elapsed, &start_time, &now); 
context->next = stack_0; 
stack_0 = context; 
result = truth_value_p( ( tree_code)*( ( unsigned __int8 *)&t->block.common + 16)) != 0; 
return *( _OWORD *)&t1->block.vars < *( _OWORD *)&t2->block.vars; 
return *( _OWORD *)&t1->block.vars < *( _OWORD *)&t2->block.vars; 
return *( _OWORD *)&t1->block.vars < *( _OWORD *)&t2->block.vars; 
return *( _OWORD *)&t1->block.vars < *( _OWORD *)&t2->block.vars; 
if ( !cpp_trigraph_map[*( ( unsigned __int8 *)pfile->buffer->cur + 1)] ) 
cpp_trigraph_map[from_char]); 
if ( !base_alias_check( x_addr, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), mem_modea) ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
undobuf_0.other_insn = 0LL; 
&& mode_class_0[*( unsigned __int8 *)( temp->fld[0].rtwint + 2)] == MODE_INT ) 
&& mode_class_0[*( unsigned __int8 *)( *( _QWORD *)( *( _QWORD *)&i3[2] + 8LL) + 2LL)] == MODE_INT ) 
v19 = immed_double_const( lo, hi, ( machine_mode)*( unsigned __int8 *)( temp->fld[0].rtwint + 2)); 
&& mode_class_0[*( unsigned __int8 *)( *( _QWORD *)( *( _QWORD *)( *( _QWORD *)( *( _QWORD *)&i2a[2] + 8LL) + 8LL) + 8LL) 
if ( !undobuf_0.other_insn ) 
cc_use = find_single_use( newpat->fld[0].rtx, i3, &undobuf_0.other_insn); 
compare_mode = ix86_cc_mode( ( rtx_code)*( _WORD *)*cc_use, i2src, const_int_rtx[64]); 
undobuf_0.other_insn = 0LL; 
rtx insn; // [rsp+20h] [rbp-70h] 
rtx insn_0; // [rsp+28h] [rbp-68h] 
rtx insn_1; // [rsp+30h] [rbp-60h] 
rtx insn_2; // [rsp+38h] [rbp-58h] 
rtx seq; // [rsp+40h] [rbp-50h] 
rtx before; // [rsp+50h] [rbp-40h] 
rtx note; // [rsp+60h] [rbp-30h] 
rtx notea; // [rsp+60h] [rbp-30h] 
rtx tema; // [rsp+68h] [rbp-28h] 
( machine_mode)( BYTE5( index_type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( range->common.type->block.abstract_origin) >> 1), 
do_tablejump( indexa, ( machine_mode)( BYTE5( index_type->block.abstract_origin) >> 1), v10, table_label, default_label); 
rtx old_stack_level; // [rsp+38h] [rbp-48h] BYREF 
rtx seq; // [rsp+40h] [rbp-40h] 
rtx first_insn; // [rsp+50h] [rbp-30h] 
rtx temp; // [rsp+58h] [rbp-28h] 
rtx before_call; // [rsp+60h] [rbp-20h] 
rtx insn; // [rsp+70h] [rbp-10h] 
old_stack_level = 0LL; 
before_call = get_last_insn( ); 
timevar_push( TV_INTEGRATION_0); 
temp = expand_inline_function( fndecl, actparms, target, ignore, type, structure_value_addr); 
timevar_pop( TV_INTEGRATION_0); 
if ( temp == ( rtx)-1LL ) 
if ( before_call ) 
undo->next = undobuf_0.frees; 
undobuf_0.frees = undo; 
undobuf_0.undos = 0LL; 
undo->next = undobuf_0.frees; 
undobuf_0.frees = undo; 
undobuf_0.undos = 0LL; 
if ( type1 == ( tree_node *)*( &global_trees + 5) ) 
if ( type1 == ( tree_node *)*( &global_trees + 4) ) 
if ( type1 == ( tree_node *)*( &global_trees + 3) ) 
if ( type1 == ( tree_node *)*( &global_trees + 2) ) 
if ( type1 == ( tree_node *)*( &global_trees + 1) ) 
recorded_label_ref_0 = 1; 
induction_1 *giv; // [rsp+38h] [rbp-18h] 
induction_1 *giv; // [rsp+38h] [rbp-18h] 
induction_1 *biv; // [rsp+40h] [rbp-10h] 
induction_1 *biv; // [rsp+40h] [rbp-10h] 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
for ( biv = bl_0->biv; biv; biv = biv->next_iv ) 
if ( *( _WORD *)p == 36 || *( _WORD *)p == 33 || p == biv->insn ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
for ( giv = bl_0->giv; giv; giv = giv->next_iv ) 
if ( ( *( ( _BYTE *)giv + 100) & 0x40) == 0 ) 
if ( *( _WORD *)p != 36 || ( *( ( _BYTE *)giv + 100) & 8) != 0 ) 
if ( giv->mult_val != const_int_rtx[64] && ( *( ( _BYTE *)giv + 100) & 1) == 0 ) 
if ( giv->mult_val != const_int_rtx[64] && ( *( ( _BYTE *)giv + 100) & 1) == 0 ) 
if ( p == biv->insn ) 
if ( biv->mult_val == const_int_rtx[65] ) 
v3 = TV_LIFE_0; 
v3 = TV_LIFE_UPDATE_0; 
if ( reg_class_subset_p( rclass, qty_0[qtyno].min_class) ) 
qty_0[qtyno].min_class = rclass; 
if ( reg_class_subset_p( rclassa, qty_0[qtyno].alternate_class) ) 
qty_0[qtyno].alternate_class = rclassa; 
qty_0[qtyno].changes_mode = 1; 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
else if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_INT 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_COMPLEX_FLOAT ) 
overflow_arg_area = ( tree_code *)ap[0].overflow_arg_area; 
overflow_arg_area = ( tree_code *)( ( char *)ap[0].reg_save_area + ap[0].gp_offset); 
changes = ( change_t_0 *)xrealloc( changes, 32LL * changes_allocated); 
rtx x; // [rsp+60h] [rbp-30h] 
x = *loc; 
code = *( _WORD *)x; 
fmt = rtx_format[*( _WORD *)x]; 
op0_mode = *( unsigned __int8 *)( x->fld[0].rtwint + 2); 
if ( x == from 
|| *( _WORD *)x == 61 
&& *( ( _BYTE *)x + 2) == *( ( _BYTE *)from + 2) 
&& x->fld[0].rtint == from->fld[0].rtint 
|| *( _WORD *)x == *( _WORD *)from && *( ( _BYTE *)x + 2) == *( ( _BYTE *)from + 2) && rtx_equal_p( x, from) ) 
|| !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)ref + 2), ref->fld[0].rtx) ) 
mergeable_constant_section( ( machine_mode)LOBYTE( decl->block.supercontext), decl->type.uid & 0xFFFFFF, 0); 
fatal_insn( "wrong insn in the fallthru edge", insn, "cfgrtl.c", 1717, "verify_flow_info"); 
fatal_insn( "flow control insn inside a basic block", xc, "cfgrtl.c", 1829, "verify_flow_info"); 
fatal_insn( "insn outside basic block", xd, "cfgrtl.c", 1887, "verify_flow_info"); 
fatal_insn( "return not followed by barrier", xd, "cfgrtl.c", 1895, "verify_flow_info"); 
max = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&xa->block.common + 16)); 
rtx dest; // [rsp+48h] [rbp-A8h] 
rtx src; // [rsp+50h] [rbp-A0h] 
rtx src2; // [rsp+68h] [rbp-88h] 
rtx src1_1; // [rsp+70h] [rbp-80h] 
rtx src0_2; // [rsp+78h] [rbp-78h] 
rtx src1_0; // [rsp+80h] [rbp-70h] 
rtx src0_1; // [rsp+88h] [rbp-68h] 
rtx src0_0; // [rsp+90h] [rbp-60h] 
strcpy( pa, prefix_0); 
p = &pa[strlen( prefix_0)]; 
v3 = v2 - strlen( prefix_0); 
v5 = v4 - strlen( prefix_0); 
if ( !statement_code_p( code) && code != TREE_LIST && !lang_hooks_0.tree_inlining.tree_chain_matters_p( *tp) ) 
result = lang_hooks_0.tree_inlining.walk_subtrees( tp, &walk_subtrees, func, data, htab); 
if ( general_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
if ( !test_insn_14 ) 
test_insn_14 = make_insn_raw( v5); 
v6 = ( rtunion *)test_insn_14; 
*( _QWORD *)&test_insn_14[1] = 0LL; 
test_insn_14[1].fld[0] = v6[2]; 
ggc_add_rtx_root( &test_insn_14, 1); 
*( _BYTE *)( *( _QWORD *)( *( _QWORD *)&test_insn_14[2] + 8LL) + 2LL) = *( ( _BYTE *)x + 2); 
*( _QWORD *)( *( _QWORD *)&test_insn_14[2] + 16LL) = x; 
icode = recog( *( rtx *)&test_insn_14[2], test_insn_14, &num_clobbers); 
icode = recog( *( rtx *)&test_insn_14[2], test_insn_14, &num_clobbers); 
v9 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)op + 2), result); 
v7 = force_reg( ( machine_mode)*( ( unsigned __int8 *)op + 2), op); 
if ( **( _WORD **)&this_insn_0[2] == 39 && multiple_sets( this_insn_0) ) 
if ( **( _WORD **)&this_insn_0[2] == 39 && multiple_sets( this_insn_0) ) 
for ( i = **( _DWORD **)( *( _QWORD *)&this_insn_0[2] + 8LL) - 1; i >= 0; --i ) 
output_p = find_regno_note( this_insn_0, REG_INC, regno) != 0LL; 
qty_0[*( ( int *)reg_qty + regno)].death = 2 * this_insn_number + output_p; 
mark_life( regno, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)mem + 2)) ) 
&& mode_class_0[BYTE5( inner_array_type->block.abstract_origin) >> 1] != MODE_INT 
&& mode_class_0[BYTE5( inner_array_type->block.abstract_origin) >> 1] != MODE_COMPLEX_INT ) 
if ( xexit_cleanup ) 
v1 = ( const char *)&unk_819A41; 
v1 = ( const char *)&unk_819A40; 
v1 = ( const char *)&unk_761657; 
if ( val <= 0xFF && ( sch_istable[( unsigned __int8)val] & 0xAC) != 0 ) 
timevar_push( TV_LEX_0); 
timevar_pop( TV_LEX_0); 
fprintf( file, off_76192C, mode_name[*( _BYTE *)( *( _QWORD *)( yyl.itype + 8) + 61LL) >> 1]); 
