p_free_buffs = ( _cpp_buff_0 *)&pfile->free_buffs; 
result = ( _cpp_buff_0 *)&v6[( min_size + 7) & 0xFFFFFFFFFFFFFFF8LL]; 
v9 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v11 = ( cpp_token_0 *)xmalloc( 0x1770uLL); 
v5 = ( tokenrun_0 *)xmalloc( 0x20uLL); 
v7 = ( cpp_token_0 *)xmalloc( 0x1770uLL); 
v1 = cpp_type2name( ( cpp_ttype)v0); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
v25 = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v25 + 2), fixed); 
tree_node *elements; // rdi 
fancy_abort( ( const char *)&a, 9320, "add_byte_size_attribute"); 
elements = result->vector.elements; 
if ( elements ) 
if ( host_integerp( elements, 1) ) 
rtx *v19; // rax 
rtx *v23; // rdx 
v23 = ( rtx *)next_label[1]; 
*( _QWORD *)( v18.rtwint + 16) = v23; 
if ( v23 ) 
if ( *v23 == next_label ) 
*v23 = ( rtx)v18.rtwint; 
v23[1] = ( rtx)v18.rtwint; 
v23 = ( rtx *)next_label[1]; 
*( _QWORD *)( v18.rtwint + 16) = v23; 
if ( v23 ) 
if ( next_label == *v23 ) 
fancy_abort( ( const char *)&a, 8430, "field_byte_offset"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 8599, "add_data_member_location_attribute"); 
if ( v10 == reverse_condition( ( rtx_code)*( _WORD *)v8) 
*hv = ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64; 
return ( ( ( ( __PAIR128__( h2, l2) + *( _OWORD *)&l1) >> 64) ^ v6) & ~( v6 ^ h2)) >> 63; 
v19 = gen_rtx_fmt_e( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v20); 
v19 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)target + 2), v18, v17); 
compiler_params = ( param_info_0 *)xrealloc( compiler_params, 24 * ( n + num_compiler_params)); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)addr + 2), addr->fld[0].rtx, v6); 
rtx v10; // r13 
rtx v13; // r12 
rtx v16; // rcx 
rtx v23; // rax 
rtx addra; // [rsp+8h] [rbp-40h] 
v10 = *( rtx *)( v8 + 16); 
v10 = 0LL; 
v13 = change_address_1( memref, mode, v12, validate); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v7 = ( ( unsigned int)( mode_class_0[( BYTE5( type->block.abstract_origin) >> 1) & 0x7F] - 5) < 2) + 1; 
if ( initialized_6 ) 
initialized_6 = 1; 
if ( initialized_2 ) 
initialized_2 = 1; 
return gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, val, next); 
rtx *v18; // rbp 
uid_cuid_1 = xmalloc( v3); 
v5 = memset( uid_cuid_1, 0, v4); 
v18 = ( rtx *)xmalloc( v17); 
canon_modify_mem_list = v18; 
memset( v18, 0, 8LL * ( int)n_basic_blocks); 
v6 = convert_to_mode( ( machine_mode)v8, v6, 1); 
v3 = gen_reg_rtx( ( machine_mode)v11); 
v15 = *( ( unsigned __int16 *)&insn_data_0[1234].operand[1] + 8); 
predicate = insn_data_0[1234].operand[1].predicate; 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
emit_cmp_and_jump_insns( v25, v6, GEU, 0LL, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 1, v24); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v21 = expand_divmod( 0, TRUNC_DIV_EXPR, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v19, v20, 0LL, 1); 
v3 = expand_mult( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v21, v22, 0LL, 1); 
free( reg_pref_0); 
if ( reg_pref_0 ) 
reg_pref_0 = reg_pref_buffer; 
v12 = assign_stack_local( ( machine_mode)v8, v10, -( v7 > v9)); 
v12 = assign_stack_local( ( machine_mode)v8, v10, -( v10 != v9)); 
v18 = adjust_address_1( v12, ( machine_mode)v8, 0LL, 0, 1); 
result = simplify_subreg( v5, v3.rtx, ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2), v4); 
verbatim( off_670ADF, v1); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
result = size_11; 
if ( size_11 < 0 ) 
size_11 = v1; 
size_11 = 2 * v1; 
return size_11; 
else if ( ( unsigned int)( mode_class_0[v3] - 5) >= 2 ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v12) ) 
if ( have_insn_for( SET, ( machine_mode)v12) ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v13) ) 
if ( have_insn_for( SET, ( machine_mode)v13) ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v14) ) 
if ( have_insn_for( SET, ( machine_mode)v14) ) 
v10 = size_11; 
rtx v18; // rax 
v18 = gen_rtx_fmt_E( PARALLEL, VOIDmode, v17); 
rtwint = ( int *)v18->fld[0].rtwint; 
v16 = v18; 
if ( !legitimate_address_p( ( machine_mode)*( ( unsigned __int8 *)object + 2), rtx, 0) ) 
old_reg = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)old_reg + 2)); 
rtx v5; // rbx 
rtx v6; // r13 
rtx result; // rax 
if ( ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) == 2 ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT ) 
v5 = expand_compound_operation( rtx); 
v6 = expand_compound_operation( v4); 
v7 = *( _WORD *)v5; 
if ( ( _WORD)v7 != *( _WORD *)v6 ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) != *( _BYTE *)( v6->fld[0].rtwint + 2) ) 
if ( *( _BYTE *)( v5->fld[0].rtwint + 2) != *( _BYTE *)( v6->fld[0].rtwint + 2) ) 
if ( v5[1] != v6[1] ) 
if ( v5[1] != v6[1] ) 
result = size_5; 
if ( size_5 < 0 ) 
size_5 = 0; 
if ( ix86_hard_regno_mode_ok( i, ( machine_mode)v2) ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v6) ) 
if ( have_insn_for( SET, ( machine_mode)v6) ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v7) ) 
if ( have_insn_for( SET, ( machine_mode)v7) ) 
while ( !ix86_hard_regno_mode_ok( i, ( machine_mode)v8) ) 
if ( have_insn_for( SET, ( machine_mode)v8) ) 
v5 = size_5; 
if ( size_5 % ( int)( mode_alignment >> 3) ) 
v5 = ( mode_alignment >> 3) * ( ( int)( size_5 + ( mode_alignment >> 3) - 1) / ( int)( mode_alignment >> 3)); 
size_5 = mode_size[v3] + v5; 
v16 = hex_value[( unsigned __int8)v10]; 
v17 = hex_value[( unsigned __int8)v10]; 
v20 = sch_istable[v18]; 
while ( ( sch_istable[( unsigned __int8)v25] & 4) != 0 ) 
if ( ( sch_istable[v6] & 4) == 0 ) 
while ( ( sch_istable[v8] & 4) != 0 ); 
sprintf( label, "*.%s%u", ( const char *)&off_709022, ( unsigned int)++labelno_17); 
sprintf( label, "*.%s%u", ( const char *)&off_709022, ( unsigned int)++labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_709022, ( unsigned int)labelno_17); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_709022, ( unsigned int)labelno_17); 
v2 = after_function_constants; 
after_function_constants = 0LL; 
fprintf( asm_out_file, off_70902E, 6567950LL); 
v9 = byte_709338[v8]; 
v12 = byte_709338[v11]; 
if ( v26 != ( tree_node *)global_trees ) 
if ( !v12 || v12 == ( tree_node *)global_trees ) 
if ( in_section_0 != in_bss ) 
in_section_0 = in_bss; 
fprintf( v31, off_70902E, "object"); 
if ( ( tree_node *)global_trees == v12 ) 
if ( in_section_0 == in_text ) 
fprintf( asm_out_file, off_70902E, "object"); 
if ( in_section_0 == in_text ) 
v30 = ( tree_node *)*( ( _QWORD *)v9 + 5); 
rtx start; // rbp 
rtx nonnote_insn; // rax 
rtx v9; // rax 
start = loop->start; 
nonnote_insn = prev_nonnote_insn( end); 
v6 = nonnote_insn; 
if ( *( _WORD *)nonnote_insn == 35 ) 
v6 = (  struct rtx_def *)nonnote_insn[1]; 
if ( start != rtx ) 
if ( start == v8 ) 
v9 = start; 
v9 = start; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
if ( v9 == rtx ) 
return mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_FLOAT; 
return mode_class_0[*( ( unsigned __int8 *)op + 2)] == MODE_FLOAT; 
v1 = off_671DF2; 
v2 = ( tree_node *)*( &global_trees + 19); 
if ( *( _OWORD *)v6->bits != 0LL ) 
*( _OWORD *)( object_base + 24) = 0LL; 
*( _OWORD *)( object_base + 24) = 0LL; 
*( _OWORD *)( object_base + 24) = 0LL; 
induction_1 *biv; // rbx 
induction_1 *biv; // rbx 
biv = bl_0->biv; 
if ( biv ) 
v5 = *( ( _BYTE *)biv + 100); 
if ( ( v5 & 8) == 0 || biv->mult_val != const_int_rtx[65] || ( v5 & 0x20) != 0 ) 
v4 = fold_rtx_mult_add( v2, const_int_rtx[65], biv->add_val, biv->mode); 
v4 = fold_rtx_mult_add( v2, const_int_rtx[65], biv->add_val, biv->mode); 
biv = biv->next_iv; 
biv = biv->next_iv; 
if ( !biv ) 
rtx v198; // rbx 
if ( !ignore_next_note_3 ) 
ignore_next_note_3 = 0; 
ignore_next_note_3 = 1; 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6, v7); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)x, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6, v7); 
*( _OWORD *)&result->common.chain = 0LL; 
v8 = ( const char *)&unk_7059BA; 
v8 = ( const char *)&unk_7059CE; 
v8 = ( const char *)&unk_7059E4; 
v8 = ( const char *)&unk_7059F6; 
v11 = *( tree_node **)( low + 8); 
if ( v11 == ( tree_node *)global_trees ) 
v6 = ( tree_node *)global_trees; 
sprintf( v11, "%s.%d", "__compound_literal", ( unsigned int)var_labelno); 
++var_labelno; 
v4->int_cst.int_cst = *( $A887AD9C3C6C8CC7716950D571F57C9D *)&v7->block.vars; 
reg_dies( *( _DWORD *)( v15 + 8), ( machine_mode)*( unsigned __int8 *)( v15 + 2), v7); 
reg_dies( *( _DWORD *)( v11 + 8), ( machine_mode)*( unsigned __int8 *)( v11 + 2), v7); 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
p_int_cst = &node->int_cst.int_cst; 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst[-1].high = *( _QWORD *)&v16[v13]; 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v12 ) 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v12 ) 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst[-1].high = *( _QWORD *)v14; 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
p_int_cst = &node->int_cst.int_cst; 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst[-1].high = *( _QWORD *)&v16[v13]; 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v12 ) 
if ( p_int_cst == ( $A887AD9C3C6C8CC7716950D571F57C9D *)v12 ) 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst[-1].high = *( _QWORD *)v14; 
if ( debug_no_type_hash ) 
if ( !debug_no_type_hash ) 
v30 = ( tree_node *)*( &global_trees + 12); 
v42 = build( ( tree_code)( 59 - ( ( ( ( v5 - 130) & 0xFFFFFFFD) == 0) - 1)), v28, v41, v31); 
v13 = ( tree_node *)global_trees; 
v20 = ( tree_node *)splay_tree_lookup( cases, ( splay_tree_key)low_value); 
attributes = *( tree_node **)( v15->value + 48); 
v23 = *( tree_node **)( v21->value + 40); 
v2 = ( tree_node *)*( &global_trees + 16); 
v2 = ( tree_node *)*( &global_trees + 15); 
v11 = ( tree_node *)*( &global_trees + 16); 
v4 = *( tree_node **)( *( _QWORD *)( low + 8) + 8LL); 
v4 = *( tree_node **)( *( _QWORD *)( v3 + 8) + 8LL); 
v0 = &if_stack_0[--if_stack_pointer]; 
if ( ( tree_node *)global_trees != v3 ) 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * ( v3 + 10)); 
if_stack_0 = ( if_elt *)xrealloc( if_stack_0, 32LL * ( v3 + 10)); 
if_stack_0 = ( if_elt *)xmalloc( 0x140uLL); 
v6 = &if_stack_0[if_stack_pointer]; 
v1 = &if_stack_0[v0 - 1]; 
if ( warn_parentheses && if_stack_pointer > 1 && ( v3 = &if_stack_0[v0 - 2], v3->compstmt_count == compstmt_count) ) 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
if_stmt = if_stack_0[if_stack_pointer - 1].if_stmt; 
timevar_push( TV_CPP_0); 
timevar_pop( TV_CPP_0); 
if ( ( sch_istable[c] & 0xAC) != 0 ) 
v3 = ( tree_node *)*( &global_trees + 16); 
v3 = ( tree_node *)*( &global_trees + 15); 
*( _OWORD *)&result->insns = 0LL; 
*( _OWORD *)&result->pred_next = 0LL; 
*( _OWORD *)&result->src = 0LL; 
*( _OWORD *)&result->flags = 0LL; 
if ( *( _OWORD *)&idom != 0LL ) 
rtx last_value; // rax 
rtx v21; // rbp 
rtx v25; // rax 
rtx v27; // rax 
rtx pinsn[8]; // [rsp+8h] [rbp-40h] BYREF 
pinsn[0] = a2; 
v8 = ( unsigned __int16 *)pinsn[0][1]; 
pinsn[0] = ( rtx)v8; 
return general_operand( op, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
return general_operand( op, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v9 = ( tree_node *)i[13]; 
while ( v1 != ( change_t_0 *)v2 ); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v19[2 * v22 + 2] + 2LL)); 
&& ( global_regs[rtuint] || !fixed_regs[rtuint] && mode_class_0[*( ( unsigned __int8 *)v2 + 2)] != MODE_CC) ) 
|| insn_data_0[rtint].n_dups > 0) ) 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), v5, v6); 
if ( !base_alias_check( rtx, mem_addr, ( machine_mode)*( ( unsigned __int8 *)x + 2), mem_mode) ) 
rtx v8; // r12 
rtx nonnote_insn; // rax 
rtx v17; // rax 
rtx x; // [rsp+8h] [rbp-50h] 
rtx xa; // [rsp+8h] [rbp-50h] 
v8 = ( rtx)cond[1]; 
if ( rtx_class[v9] == 60 && const_tiny_rtx[0][*( ( unsigned __int8 *)rtx + 2)] == v8 && rtx != want_reg ) 
v8 = ( rtx)rtx[1]; 
if ( rtx_class[v10] != 60 || const_tiny_rtx[0][*( ( unsigned __int8 *)rtx + 2)] != v8 || want_reg == rtx ) 
nonnote_insn = prev_nonnote_insn( v5); 
v5 = nonnote_insn; 
if ( reg_note ) 
if ( *( __int64 *)( reg_note->fld[0].rtwint + 8) <= 4999 ) 
mode_alignment = get_mode_alignment( ( machine_mode)*( ( unsigned __int8 *)v3 + 2)); 
v7 = gen_rtx_CONST_INT_0( ( machine_mode)mode_size[v4], *( __int64 *)&mode); 
rtx v6; // r8 
rtx v7; // rax 
if ( !rtx_equal_p( rtx, memref->fld[0].rtx) || ( v6 = memref, *( ( unsigned __int8 *)memref + 2) != v4) ) 
v7 = gen_rtx_fmt_e0( MEM, v4, rtx); 
*( _QWORD *)&v7[1] = 0LL; 
v6 = v7; 
v6 = v7; 
LOBYTE( v7) = *( ( _BYTE *)memref + 3) & 8 | *( ( _BYTE *)v7 + 3) & 0xF7; 
LOBYTE( v7) = *( ( _BYTE *)memref + 3) & 8 | *( ( _BYTE *)v7 + 3) & 0xF7; 
*( ( _BYTE *)v6 + 3) = ( _BYTE)v7; 
*( ( _BYTE *)v6 + 3) = ( _BYTE)v7; 
LOBYTE( v7) = *( ( _BYTE *)memref + 3) & 0x10 | ( unsigned __int8)v7 & 0xEF; 
LOBYTE( v7) = *( ( _BYTE *)memref + 3) & 0x10 | ( unsigned __int8)v7 & 0xEF; 
*( ( _BYTE *)v6 + 3) = ( _BYTE)v7; 
*( ( _BYTE *)v6 + 3) = ( _BYTE)v7; 
if ( ( sch_istable[( unsigned __int8)v11] & 4) != 0 && !v10[1] ) 
rtx v12; // rax 
rtx v20; // rsi 
rtx v22; // rax 
rtx insna; // [rsp+10h] [rbp-C0h] 
n_operands = recog_data_0.n_operands; 
n_outputs = recog_data_0.n_operands - asm_operand_n_inputs; 
if ( recog_data_0.n_operands > 0 ) 
v7 = recog_data_0.operand[v6]; 
recog_data_0.operand[v6++] = rtx; 
v12 = recog_data_0.operand[v10]; 
v12 = recog_data_0.operand[v10]; 
if ( *( _WORD *)v12 != 61 ) 
rtuint = v12->fld[0].rtuint; 
v12 = recog_data_0.operand[v10]; 
*( function_format_info_0 **)( chain->int_cst.int_cst.low + 32), 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
induction_1 *v24; // r15 
induction_1 *v24; // r15 
rtx src_reg; // [rsp+18h] [rbp-60h] BYREF 
rtx add_val; // [rsp+20h] [rbp-58h] BYREF 
rtx mult_val; // [rsp+28h] [rbp-50h] BYREF 
rtx ext_val; // [rsp+30h] [rbp-48h] BYREF 
rtx last_consec_insn[8]; // [rsp+38h] [rbp-40h] BYREF 
if ( general_induction_var( loop, *( rtx *)&v19[1], &src_reg, &add_val, &mult_val, &ext_val, 0, &benefit, VOIDmode) 
if ( general_induction_var( loop, *( rtx *)&v19[1], &src_reg, &add_val, &mult_val, &ext_val, 0, &benefit, VOIDmode) 
v32 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
v33 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v34 = ( ( unsigned int)( mode_class_0[v17] - 5) < 2) + 1; 
v35 = ( ( unsigned int)( mode_class_0[v23] - 5) < 2) + 1; 
else if ( ( ( unsigned int)( mode_class_0[v29] - 5) < 2) + 1 == nregs ) 
if ( ix86_hard_regno_mode_ok( regno, ( machine_mode)v29) ) 
v62 = subreg_regno_offset( byte_0d, ( machine_mode)*( ( unsigned __int8 *)v61 + 2), v60, v59); 
v66 = smallest_mode_for_size( v63 + passa, mode_class_0[v59]); 
v92 = ix86_hard_regno_mode_ok( byte_0, *( ( machine_mode *)&rld + 26 * v15 + 7)); 
regnoi = ix86_register_move_cost( v59, class1a, ( reg_class)ra), 
regnoi >= ix86_memory_move_cost( v59, ( reg_class)ra, 1)) 
|| ( v149 = ix86_secondary_memory_needed( class1a, ( reg_class)ra, v59, 1), v93 = v227, v149)) ) 
*( reload_type *)( v7 + 64), 
*( machine_mode *)v7); 
( machine_mode)( BYTE5( v39->block.abstract_origin) >> 1), 
( machine_mode)( *( _BYTE *)( rtl->fld[0].rtwint + 61) >> 1), 
( machine_mode)( BYTE5( v18->block.abstract_origin) >> 1), 
( machine_mode)( *( _BYTE *)( j->fld[0].rtwint + 61) >> 1), 
rtx v2; // rbp 
rtx nonnote_insn; // rax 
v2 = rtx; 
if ( *( _WORD *)v2 != 35 ) 
nonnote_insn = prev_nonnote_insn( v2); 
nonnote_insn = prev_nonnote_insn( v2); 
if ( *( _WORD *)nonnote_insn == 35 ) 
if ( *( _WORD *)v2 != 35 ) 
delete_insn( v2); 
reorder_insns( v2, v2, nonnote_insn); 
reorder_insns( v2, v2, nonnote_insn); 
reorder_insns( v2, v2, nonnote_insn); 
timevar_push( TV_CLEANUP_CFG_0); 
timevar_pop( TV_CLEANUP_CFG_0); 
if ( recog_data_0.n_operands > 0 ) 
v3 = recog_data_0.operand_loc[v2]; 
recog_data_0.operand[v2++] = alter_subreg( v3); 
if ( recog_data_0.n_operands <= ( int)v2 ) 
if ( ( unsigned __int16)( *( _WORD *)recog_data_0.operand[v2] - 66) <= 0xCu 
&& _bittest64( &v1, ( unsigned int)*( _WORD *)recog_data_0.operand[v2] - 66) ) 
recog_data_0.operand[v2] = walk_alter_subreg( v3); 
while ( recog_data_0.n_operands > ( int)v2 ); 
for ( i = 4609LL; recog_data_0.n_dups > ( int)v4; ++v4 ) 
v6 = recog_data_0.dup_loc[v4]; 
*v6 = alter_subreg( recog_data_0.dup_loc[v4]); 
*v6 = walk_alter_subreg( recog_data_0.dup_loc[v4]); 
if ( ( unsigned int)( mode_class_0[v11] - 5) <= 1 ) 
for ( i = *( _QWORD *)( v1 + 40); i; *( _OWORD *)( v3 + 48) = 0LL ) 
*( _OWORD *)v3 = 0LL; 
*( _OWORD *)( v3 + 16) = 0LL; 
*( _OWORD *)( v3 + 32) = 0LL; 
for ( j = entry_exit_blocks[0].succ; j; *( _OWORD *)&v7->flags = 0LL ) 
*( _OWORD *)&v7->pred_next = 0LL; 
*( _OWORD *)&v7->src = 0LL; 
*( _OWORD *)&v7->insns = 0LL; 
v27 = ( tree_node *)i6[5]; 
v10 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v23 = ( ( unsigned int)( mode_class_0[v20] - 5) < 2) + 1; 
tree v21; // r12 
tree v27; // rax 
tree v28; // rax 
tree v37; // rdi 
mode_alignment = get_mode_alignment( ( machine_mode)*( ( unsigned __int8 *)object + 2)); 
htab_empty( hash_table_0); 
|| ix86_hard_regno_mode_ok( rtuint, ( machine_mode)*( ( unsigned __int8 *)v18 + 2)) ) 
rtx v9; // rbx 
rtx v13; // rbx 
rtx v21; // rax 
reg_last_set_mode = ( machine_mode *)xmalloc( v3); 
v9 = f; 
v11 = v9->fld[0].rtint; 
subst_insn = v9; 
v12 = *( _WORD *)v9; 
if ( rtx_class[*( _WORD *)v9] == 105 ) 
rtx v12; // rcx 
rtx v20; // rdx 
v12 = rtx; 
v14 = ( unsigned int)v12[1]; 
( machine_mode)*( ( unsigned __int8 *)rtx + 2), 
( machine_mode)*( ( unsigned __int8 *)v12 + 2)); 
( machine_mode)*( ( unsigned __int8 *)v12 + 2)); 
v18 = ( ( unsigned int)( mode_class_0[v16] - 5) < 2) + 1; 
v20 = v9; 
v22 = ( unsigned int)v20[1]; 
( machine_mode)*( ( unsigned __int8 *)v9 + 2), 
( machine_mode)*( ( unsigned __int8 *)v20 + 2)); 
&& ( v3.rtwint = ( __int64)exp->fld[0], mode_class_0[*( unsigned __int8 *)( v3.rtwint + 2)] == MODE_CC) 
return reversed_comparison_code_parts( ( rtx_code)*( _WORD *)exp, last_value->fld[0].rtx, *( rtx *)&last_value[1], 0LL); 
rtx v133; // r14 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), global_rtl[2]) ) 
v22 = ( tree_node *)high[4]; 
v11 = lang_hooks_0.expand_constant( elements); 
rtx *v21; // rax 
v21 = get_true_reg( ( rtx *)&pat_src[1]); 
v7 = v21; 
remove_regno_note( insn, ( reg_note)v16, v15); 
v2 = *( _OWORD *)&t->block.vars; 
change_stack( v21, &tmpstack, v6, ( emit_where)v22); 
v12 = ( tree_node *)high[3]; 
rtx nonnote_insn; // rax 
rtx v4; // rbp 
rtx v6; // rax 
rtx v7; // rbx 
rtx v8; // rax 
nonnote_insn = head; 
while ( rtx_class[*( _WORD *)nonnote_insn] != 105 ) 
nonnote_insn = nonnote_insn[1].fld[0].rtx; 
nonnote_insn = nonnote_insn[1].fld[0].rtx; 
if ( rtx == nonnote_insn ) 
v4 = nonnote_insn; 
v4 = nonnote_insn; 
nonnote_insn = next_nonnote_insn( nonnote_insn); 
nonnote_insn = next_nonnote_insn( nonnote_insn); 
reg_avail_info_0 = v3; 
v4 = reg_avail_info_0; 
reg_avail_info_0 = 0LL; 
rtx insn; // [rsp+8h] [rbp-40h] BYREF 
insn = insns; 
for_each_rtx( &insn, insns_for_mem_walk, &ifmwi); 
rtx = insn[1].fld[0].rtx; 
insn = rtx; 
rtx v18; // rax 
reg_set_0 *v29; // rdx 
reg_set_0 *v29; // rdx 
rtx insn; // rcx 
reg_set_0 *v33; // rdx 
reg_set_0 *v33; // rdx 
rtx v35; // rcx 
v29 = reg_set_table[rtuint]; 
if ( v29 ) 
insn = v29->insn; 
insn = v29->insn; 
v29 = v29->next; 
v29 = v29->next; 
v32 = bmap[*( int *)( v30->data.l[insn->fld[0].rtint] + 88)]; 
while ( v29 ); 
v33 = reg_set_table[rtuint]; 
if ( ( unsigned int)( mode_class_0[v14] - 5) > 1 ) 
rtx v29; // rax 
rtx v32; // [rsp+32h] [rbp-D0h] 
rtx v33; // [rsp+3Ah] [rbp-C8h] 
rtx *add_vala; // [rsp+B2h] [rbp-50h] 
rtx src_rega[2]; // [rsp+BAh] [rbp-48h] BYREF 
src_rega[0] = src_reg; 
add_vala = add_val; 
v32 = v15; 
v33 = v16; 
src_rega, 
add_vala, 
v20 = ( tree_node *)j[4]; 
v4 = ( unsigned int)mode_class_0[mode]; 
*( _OWORD *)v20.r = *( _OWORD *)v23; 
*( _OWORD *)v19.r = *( _OWORD *)v23; 
rtx v21; // rsi 
rtx v22; // rdi 
n_operands = recog_data_0.n_operands; 
if ( !n_operands || !recog_data_0.n_alternatives || n_operands <= 0 ) 
*( const char **)( ( char *)&constraints[-1] + ( unsigned int)( 8 * n_operands)) = *( const char **)( ( char *)&recog_data_0.constraints[-1] 
qmemcpy( constraints, recog_data_0.constraints, 8LL * ( ( unsigned int)( 8 * n_operands - 1) >> 3)); 
rtx = recog_data_0.operand[v6]; 
( machine_mode)*( unsigned __int8 *)( v29.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)); 
v21 = recog_data_0.operand[v6]; 
v21 = recog_data_0.operand[v6]; 
v22 = recog_data_0.operand[v19]; 
fprintf( stderr, off_670ADF, x86_64_reg_class_name[v13]); 
v27 = ( tree_node *)low; 
rtx v18; // rax 
rtx v27; // r12 
rtx resume; // rdi 
rtx label; // rdi 
rtx continue_label; // rdx 
rtx insns; // [rsp+8h] [rbp-30h] BYREF 
insns = get_insns( ); 
convert_from_eh_region_ranges_1( &insns, v11, 0); 
v14 = reg_note; 
rtx v7; // rbp 
v7 = rtx; 
v8 = *( _WORD *)v7; 
if ( *( _WORD *)v7 == 37 ) 
rtint = v7[2].fld[0].rtint; 
v5 = ( __int64)v7[2]; 
if ( *pinsns == v7 ) 
remove_insn( v7); 
if ( !find_reg_note( v7, REG_EH_REGION, 0LL) ) 
if ( *( _WORD *)v7 == 34 ) 
v14 = (  struct rtx_def *)v7[2]; 
v17 = v7[3].fld[0].rtx; 
v7[3].fld[0].rtwint = ( __int64)alloc_EXPR_LIST( 23, v15, v17); 
if ( *( _WORD *)v7 == 34 ) 
v10 = ( __int64)v7[2]; 
rtx k; // rdi 
rtx data[2]; // [rsp+30h] [rbp-58h] BYREF 
data[0] = *( rtx *)( v39 + 16); 
if ( *( _WORD *)data[0] == 61 ) 
bitmap_set_bit( &head, data[0]->fld[0].rtint); 
if ( *( _WORD *)data[0] == 152 ) 
for_each_rtx( data, mark_reg_in_phi, &head); 
data[0] = ( rtx)v1; 
data[1] = ( rtx)v10; 
for_each_successor_phi( v13, coalesce_reg_in_phi, data); 
for ( k = ( rtx)**( ( _QWORD **)&basic_block_info->num_elements + v33); ; k = k[1].fld[0].rtx ) 
if ( mode_class_0[mode] != MODE_INT ) 
if ( mode_class_0[mode] != MODE_INT ) 
if ( mode_class_0[oldmode] == MODE_INT 
v85 = mode_class_0[v87]; 
frome = mode_class_0[( unsigned __int8)v6] == MODE_FLOAT; 
v83 = mode_class_0[( unsigned __int8)v6]; 
v8 = gen_lowpart( ( machine_mode)v87, ( rtx)v7); 
v8 = simplify_gen_subreg( ( machine_mode)v87, v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2), 0); 
v8 = simplify_gen_subreg( ( machine_mode)v87, v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2), 0); 
to = simplify_gen_subreg( ( machine_mode)v6, to, ( machine_mode)*( ( unsigned __int8 *)to + 2), 0); 
to = simplify_gen_subreg( ( machine_mode)v6, to, ( machine_mode)*( ( unsigned __int8 *)to + 2), 0); 
v36 = can_extend_p( ( machine_mode)v87, ( machine_mode)v6, unsignedp); 
rtx end; // r15 
rtx *v22; // rbp 
rtx *v27; // rax 
fprintf( file, off_646752, ( unsigned int)v17); 
end = v2->end; 
if ( *( _WORD *)end == 33 ) 
end = ( rtx)end[1]; 
v22 = ( rtx *)( FP_mode_reg + 120); 
v24 = gen_rtx_fmt_ee( SET, VOIDmode, *v22, nan); 
end = emit_insn_after( v24, end); 
end = emit_insn_after( v24, end); 
subst_stack_regs( end, &regstack); 
v22 += 59; 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
return build1( ( tree_code)( ( flag_float_store == 0) + 114), type, expr); 
return copy_to_mode_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), x); 
v8 = operand_sub*(short *)0xforce( srcreg, v10 / v11, ( machine_mode)*( ( unsigned __int8 *)srcreg + 2)); 
v8 = operand_sub*(short *)0xforce( srcreg, v10 / v11, ( machine_mode)*( ( unsigned __int8 *)srcreg + 2)); 
return build( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v7, v6); 
return build1( ( tree_code)*( ( unsigned __int8 *)&exp->block.common + 16), exp->common.type, v5); 
rtx v4; // rbp 
if ( reg_note ) 
v4 = reg_note; 
v4 = reg_note; 
rtx[3].fld[0].rtwint = ( __int64)gen_rtx_fmt_ee( EXPR_LIST, XCmode, v4->fld[0].rtx, rtx[3].fld[0].rtx); 
rtvec v12; // rax 
rtx result; // rax 
v4 = rtx_alloc( ( rtx_code)*( _WORD *)orig); 
v12 = rtvec_alloc( rtvec->num_elem); 
v4->fld[v8].rtwint = ( __int64)v12; 
p_num_elem = &v12->num_elem; 
if ( v12->num_elem > 0 ) 
return result; 
rtx v20; // r15 
rtx v33; // rax 
rtx v35; // rax 
rtx v49; // r15 
rtx v52; // rax 
rtx sequence[3]; // [rsp+10h] [rbp-58h] 
v20 = 0LL; 
v20 = ( rtx)v3[2]; 
if ( ( *( _DWORD *)v20->fld[0].rtwint & 0x4000FFFF) != 1073741885 ) 
if ( volatile_refs_p( *( rtx *)&v20[1]) ) 
|| ( v49 = ( rtx)rtx[2], *( _WORD *)v49 != 47) && ( v49 = single_set_2( rtx, *( rtx *)&rtx[2])) == 0LL ) 
rtx v12; // rbp 
rtx v13; // r14 
rtx v16; // rax 
rtx note; // [rsp+18h] [rbp-40h] BYREF 
note = copy_rtx_and_substitute( rtx, map, 0); 
subst_constants( &note, 0LL, map, 0); 
v12 = note; 
v12 = note; 
v7[3].fld[0].rtwint = ( __int64)note; 
if ( !v12 ) 
v13 = v12; 
v13 = v12; 
v12 = ( rtx)v12[1]; 
v14 = *( ( _BYTE *)v13 + 2); 
rtx last_insn; // r12 
rtx v16; // rax 
rtx *insn_map; // rdx 
rtx v18; // r12 
rtx v19; // r15 
rtx v20; // rax 
rtx v24; // rcx 
rtx v26; // rax 
rtx label_from_map; // rax 
rtx nonnote_insn; // rax 
rtx *v13; // r13 
rtx v15; // rsi 
rtx v16; // rdx 
rtx *v20; // r14 
rtx v22; // r14 
rtx v26; // rax 
rtx v28; // r10 
rtx v33; // rax 
rtx v35; // rax 
v4 = ( tree_node *)memcpy( v3, node, v2); 
rtx v33; // r12 
rtx v34; // rax 
rtx v40; // rax 
rtx v42; // r12 
rtx v43; // rax 
rtx v61; // rax 
rtx *v65; // rbp 
v18 = rtx_alloc( ( rtx_code)v2); 
v2 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
n_operands = recog_data_0.n_operands; 
v15 = ( reg_class *)( 32LL * v8 + 9947208); 
if ( recog_data_0.operand_type[v14] != OP_OUT ) 
recog_data_0.operand_type[v14] = OP_INOUT; 
v18 = recog_data_0.operand[v17++]; 
v21 = recog_data_0.operand[v19++]; 
v26 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
oldest_value_reg = find_oldest_value_reg( ( reg_class)regclass_map[rtuint], reg, v1); 
v39 = ( reg_class *)( v35 + 9947208); 
if ( warning_message_3 ) 
warning_message_3 = 1; 
v14 = ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
count += ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[v4] - 5) > 1 ) 
v9 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
while ( ( int *)( ( char *)&unk_9F825C + 4 * ( v14 - v13)) != v15 ); 
name = ( const unsigned __int8 *)off_6C8A01; 
if ( i == ( const  struct named_op *)&unk_65C530 ) 
return ( cpp_hashnode_0 *)ht_lookup( pfile->hash_table, str, len, HT_ALLOC); 
if ( ( sch_istable[v21] & 0x100) == 0 ) 
v23 = hex_value[*v10]; 
if ( ( sch_istable[**a2] & 0xAC) != 0 ) 
if ( ( sch_istable[v11] & 0x100) == 0 ) 
v27 = hex_value[v28]; 
object_base = ( cpp_buffer_0 *)pfile->buffer_ob.object_base; 
v11 = ( cpp_buffer_0 *)( next_free + 144); 
if ( ( sch_istable[v6] & 0x10) != 0 ) 
rtx v16; // rdx 
v16 = head; 
v16 = ( rtx)head[1]; 
if ( v16 != bb_note && v16[1].fld[0].rtx != bb_note ) 
if ( v16 != bb_note && v16[1].fld[0].rtx != bb_note ) 
reorder_insns( bb_note, bb_note, v16); 
rtx v21; // rax 
rtx v25; // rax 
rtx nonnote_insn; // rax 
if ( !v31.rtwint || ( nonnote_insn = prev_nonnote_insn( rtx)) != 0LL && *( _WORD *)nonnote_insn == 35 ) 
rtx real_insn; // rax 
rtx v36; // r9 
rtx v39; // rax 
rtx *p_branch; // rdx 
rtx v42; // rax 
rtx v45; // rax 
rtx *v46; // rdx 
rtx qd; // [rsp+8h] [rbp-60h] 
rtx q; // [rsp+8h] [rbp-60h] 
rtx nonnote_insn; // rax 
rtx v301; // r14 
rtx v310; // rax 
rtx v312; // rbx 
rtx last; // rax 
rtx v19; // rdx 
uid_cuid_0 = v8; 
last = val.last; 
if ( !last ) 
v6 = last[1].fld[0].rtx; 
v19 = cse_basic_block( v6, v13, val.path, after_loop == 0); 
v6 = v19; 
free( uid_cuid_0); 
|| ( result = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)x + 2), const_rtx)) == 0LL ) 
invalidate( *( rtx *)( v6.rtwint + 8), ( machine_mode)*( unsigned __int8 *)( v6.rtwint + 2)); 
htab_delete( hash_table_0); 
hash_table_0 = htab_create( 0x1FuLL, get_value_hash, entry_and_rtx_equal_p, 0LL); 
v6 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v20 = ( unsigned int)( mode_class_0[v19] - 5) <= 1; 
cselib_invalidate_regno( dest->fld[0].rtuint, ( machine_mode)*( ( unsigned __int8 *)dest + 2)); 
if ( !push_operand( dest, ( machine_mode)*( ( unsigned __int8 *)dest + 2)) ) 
htab_traverse_noresize( hash_table_0, cselib_invalidate_mem_1, dest); 
if ( push_operand( dest, ( machine_mode)*( ( unsigned __int8 *)dest + 2)) ) 
v21 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
v12 = new_cselib_val( ++next_unknown_value, ( machine_mode)v6); 
*( _QWORD *)htab_find_slot_with_hash( ( __int64)hash_table_0, ( __int64)x, value, 1) = v12; 
slot_with_hash = htab_find_slot_with_hash( ( __int64)hash_table_0, ( __int64)v9, v8, create != 0); 
if ( ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) == 2 
|| mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_VECTOR_FLOAT ) 
*( _QWORD *)htab_find_slot_with_hash( ( __int64)hash_table_0, ( __int64)v3, value, 1) = elt; 
htab_traverse_noresize( hash_table_0, cselib_invalidate_mem_1, callmem); 
htab_traverse_noresize( hash_table_0, discard_useless_locs, 0LL); 
htab_traverse_noresize( hash_table_0, discard_useless_values, 0LL); 
rtvec v19; // rax 
rtvec jc; // [rsp+0h] [rbp-58h] 
v19 = rtvec_alloc( *rtwint); 
rtvec = v19; 
v3->fld[v25].rtwint = ( __int64)v19; 
jc = v19; 
jc = v19; 
memmove( v19->elem, rtwint + 2, 8 * v14); 
rtvec = jc; 
if ( in_section_0 != in_data ) 
in_section_0 = in_data; 
fprintf( asmfile, &off_646752[1], ( unsigned int)current_sym_value); 
sprintf( temp, "*.%s%u", "LM", ( unsigned int)sym_lineno_4); 
fprintf( asmfile, ".%s%u:\n", "LM", ( unsigned int)sym_lineno_4); 
++sym_lineno_4; 
v20 = ( tree_node *)*( &global_trees + 27); 
rtx xp; // [rsp+8h] [rbp-30h] BYREF 
xp = home; 
rtx = alter_subreg( &xp); 
xp = rtx; 
if ( !initial || !strcmp( lang_hooks_0.name, "GNU C++") && initial == ( tree)global_trees ) 
v21 = (  struct rtx_def *)xp[1]; 
v3 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + ( _DWORD)rtuint; 
clear_reload_reg_in_use( v4, *( ( _DWORD *)v2 + 18), *( ( reload_type *)v2 + 23), *( ( machine_mode *)v2 + 7)); 
clear_reload_reg_in_use( v4, *( ( _DWORD *)v2 + 18), *( ( reload_type *)v2 + 23), *( ( machine_mode *)v2 + 7)); 
fprintf( v1, "%ssecondary_in_icode = %s", "\n\t", insn_data_0[v8].name); 
fprintf( v1, "%ssecondary_out_icode = %s", v9, insn_data_0[v10].name); 
bitmap_element *v7; // r15 
bitmap_element *v7; // r15 
v7 = ( bitmap_element *)attribute_tables; 
v7 = ( bitmap_element *)attribute_tables; 
next = ( const char *)v7->next->next; 
next = *( const char **)( ( char *)&v7->next->next + v9); 
while ( ( sch_istable[( unsigned __int8)v2[v3]] & 4) != 0 ) 
for ( i = "eax"; ; i = table_21[v8].name ) 
return table_21[( int)v8].number; 
v12 = mode_class_0[v3]; 
rtx v9; // r13 
rtx v28; // rax 
rtx v39; // rax 
rtx v43; // rax 
v37 = mode_class_0[*( ( unsigned __int8 *)x + 2)]; 
v37 = mode_class_0[v44]; 
v9 = *( rtx *)( v7.rtwint + 8); 
v11 = *( _WORD *)v9; 
rtx v10; // rsi 
v10 = ( rtx)dead_insn[2]; 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( dead_insn, v10)) != 0LL ) 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( dead_insn, v10)) != 0LL ) 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( dead_insn, v10)) != 0LL ) 
v11.rtwint = ( __int64)v10->fld[0]; 
if ( reg_note && ( v4.rtwint = ( __int64)reg_note->fld[0], *( _WORD *)v4.rtwint == 36) ) 
if ( reg_note && ( v4.rtwint = ( __int64)reg_note->fld[0], *( _WORD *)v4.rtwint == 36) ) 
rtx v29; // rsi 
rtx v33; // rsi 
rtx output_reload_insn; // [rsp+0h] [rbp-58h] 
for ( output_reload_insn = spill_reg_store[last_reload_reg]; *( _WORD *)rtx == 63; rtx = rtx->fld[0].rtx ) 
v14.rtwint = ( __int64)output_reload_insn[1].fld[0]; 
if ( ( unsigned int)( mode_class_0[v16] - 5) > 1 ) 
delete_address_reloads( output_reload_insn, insn); 
delete_insn( output_reload_insn); 
rtx nonnote_insn; // rax 
nonnote_insn = next_nonnote_insn( ( rtx)v12); 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
if ( nonnote_insn && *( _WORD *)nonnote_insn == 33 && ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) <= 1u ) 
delete_related_insns( nonnote_insn); 
v17 = ( ( unsigned int)( mode_class_0[v14] - 5) < 2) + 1; 
if ( ( sch_istable[v23] & 0x88) != 0 ) 
rtx v10; // rdi 
v10 = added_links_insn; 
if ( v10 ) 
rtint = v10->fld[0].rtint; 
v13 = ( int)rtint > max_uid_cuid ? insn_cuid( v10) : *( ( _DWORD *)uid_cuid + rtint); 
rtx real_insn; // rax 
rtx v27; // rax 
rtx v30; // rdx 
rtx *v41; // r9 
rtx v43; // rax 
rtx v48; // rax 
rtx v57; // rbp 
rtx v70; // rsi 
v37 = __CFADD__( *v13, ( _QWORD)lnum_origa); 
v2 = ( tree_node *)switch_stack; 
if ( ( tree_node *)global_trees == v3 ) 
if ( mode_class_0[mode] != MODE_INT || can_compare_p( op, mode, ccp_jump) ) 
if ( !if_true_label && ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
if ( !if_true_label && ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
v8 = operand_sub*(short *)0xforce( v4, i, ( machine_mode)v5); 
v8 = operand_sub*(short *)0xforce( v4, i, ( machine_mode)v5); 
v9 = operand_sub*(short *)0xforce( v3, v7, ( machine_mode)v5); 
v9 = operand_sub*(short *)0xforce( v3, v7, ( machine_mode)v5); 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v6 = operand_sub*(short *)0xforce( op0, 0, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v9 = operand_sub*(short *)0xforce( op0, v8, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v9 = operand_sub*(short *)0xforce( op0, v8, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v14 = operand_sub*(short *)0xforce( op0, v12, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v14 = operand_sub*(short *)0xforce( op0, v12, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
( machine_mode)( *( _BYTE *)( *( _QWORD *)( exp->int_cst.int_cst.low + 8) + 61LL) >> 1), 
v10 = operand_sub*(short *)0xforce( op0, v9, mode); 
v11 = operand_sub*(short *)0xforce( op1, v9, mode); 
if ( !can_compare_p( v14, ( machine_mode)v44, ccp_store_flag) ) 
&& *( ( unsigned __int16 *)insn_data_0[v15].operand + 8) != mode 
v11 = emit_store_flag( v4, v14, v19, v18, ( machine_mode)v44, unsignedp, 1); 
v23 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v4 + 2)); 
v25 = compare_from_rtx( v16, v17, v14, unsignedp, ( machine_mode)v44, 0LL); 
v11 = expand_shift( RSHIFT_EXPR, ( machine_mode)v44, op0b, v37, v4, 1); 
if ( mode_class_0[*( ( unsigned __int8 *)v2 + 2)] == MODE_INT && *( _WORD *)newval == 54 ) 
if ( rtwint != trunc_int_for_mode( rtwint, ( machine_mode)*( ( unsigned __int8 *)v2 + 2)) ) 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
undos = undobuf_0.undos; 
undobuf_0.undos = frees; 
if ( !warned_11 && do_warn ) 
warned_11 = 1; 
( machine_mode)*( unsigned __int8 *)( v12.rtwint + 2), 
v18 = swap_condition( ( rtx_code)aux[22]); 
v66 = expand_simple_binop( ( machine_mode)*( ( unsigned __int8 *)v56 + 2), LSHIFTRT, v56, v65, 0LL, 1, OPTAB_LIB_WIDEN); 
( machine_mode)*( ( unsigned __int8 *)doloop_regb + 2), 
emit_cmp_and_jump_insns( v68, v70, ( rtx_code)( v69 == 0 ? EQ : LEU), 0LL, v88, 0, op1a); 
( machine_mode)*( ( unsigned __int8 *)doloop_regb + 2), 
fwrite( &unk_64697D, 1uLL, 0x11uLL, outf); 
fprintf( file, off_646752, ( unsigned int)dest->index); 
fprintf( file, &off_646752[1], ( unsigned int)v7++); 
v10 = bitnames_8[v7++]; 
v20 = reg_class_names_9[v14]; 
fprintf( file, "; pref %s, else %s", v20, reg_class_names_9[v15]); 
fwrite( &unk_645FA1, 1uLL, 9uLL, file); 
fprintf( file, off_646752, ( unsigned int)v4++); 
fprintf( di_0->stream, asc_707673, 25LL, 6551391LL); 
fprintf( di_0->stream, off_707674, 15 - v2, 6551391LL); 
predictor_info_0[predictor].name, 
fprintf( outf, off_646752, ( unsigned int)v5); 
fprintf( file, &off_646752[1], ( bmap->elms[v6] >> v7) & 1); 
lang_hooks_0.print_statistics( ); 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), label); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), lab2); 
v6 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), lab1); 
v7 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6, v5); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
v8 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v4, global_rtl[0]); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
v11 = byte_664720[v10]; 
v16 = byte_664720[( unsigned int)v15]; 
if ( ( sch_istable[( unsigned __int8)v14] & 0x10) == 0 ) 
fprintf( asm_out_file, "\\0\"\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), label); 
fprintf( asm_out_file, "\t%s ", ( const char *)&stru_6F109F._IO_save_end + 7); 
value = ( tree_node *)v2->value; 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
sprintf( v8, "*.%s%u", ( const char *)&off_665E02, current_funcdef_number); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&off_665E02, current_funcdef_number); 
args_size_0 = 0LL; 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
v0 = label_num_59++; 
sprintf( label_58, "*.%s%u", "LCFI", v0); 
assemble_name( asm_out_file, label_58); 
return label_58; 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
&& ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
sprintf( label, "*.%s%u", ( const char *)&a.dw_attr_next + 4, current_funcdef_number); 
rtx *v7; // rdx 
fancy_abort( ( const char *)&a, 1626, "dwarf2out_frame_debug"); 
fancy_abort( ( const char *)&a, 1009, "dwarf2out_stack_adjust"); 
v11 = -args_size_0; 
v7 = ( rtx *)insn[2]; 
v8 = *( _WORD *)v7; 
if ( *( _WORD *)v7 == 47 ) 
v11 = stack_adjust_offset( v7[1]); 
v9 = v7[1]; 
v13 = args_size_0 + v11; 
args_size_0 = v13; 
v15 = args_size_0; 
if ( args_size_0 != old_args_size ) 
old_args_size = args_size_0; 
fancy_abort( ( const char *)&a, 1309, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1603, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1479, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1549, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1513, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1555, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1490, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1495, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1561, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1528, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1538, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1588, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1457, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 1386, "dwarf2out_frame_debug_expr"); 
fancy_abort( ( const char *)&a, 900, "initial_return_save"); 
fancy_abort( ( const char *)&a, 906, "initial_return_save"); 
fancy_abort( ( const char *)&a, 911, "initial_return_save"); 
fancy_abort( ( const char *)&a, 894, "initial_return_save"); 
fancy_abort( ( const char *)&a, 921, "initial_return_save"); 
fancy_abort( ( const char *)&a, 926, "initial_return_save"); 
*( _OWORD *)&yy[1] = 0LL; 
*( _OWORD *)&yy[1] = 0LL; 
while ( &unk_97C802 != ( _UNKNOWN *)v6 ); 
if ( ( unsigned int)format > 0xFF || ( result = format_names_3[format]) == 0LL ) 
*( _OWORD *)equot = 0LL; 
v62 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v61 + 2)); 
rtx v42; // rdi 
rtx v45; // rax 
rtx v47; // rax 
rtx v49; // rax 
rtx v50; // rsi 
rtx v55; // rax 
rtx v58; // rax 
rtvec v60; // rax 
rtx v14; // rax 
rtx v16; // r14 
rtx *v20; // rdx 
rtx *v23; // rdx 
rtx *v28; // rdx 
rtx *v35; // rdx 
rtx *v40; // rdx 
rtx v50; // rax 
rtx to_rtx; // r14 
rtx nonnote_insn; // rax 
rtx v23; // rdx 
rtx v27; // rax 
rtx v31; // rcx 
v31 = global_rtl[4]; 
if ( rtx == v30->to_rtx && rtx != v31 ) 
v23 = v3; 
v23 = v3->fld[0].rtx; 
v4 = *( _WORD *)v23; 
if ( *( _WORD *)v23 == 61 ) 
if ( mode_size[*( ( unsigned __int8 *)v3 + 2)] <= mode_size[*( ( unsigned __int8 *)v23 + 2)] 
&& reg_equiv_memory_loc[v23->fld[0].rtuint] ) 
rtint = v23->fld[0].rtint; 
while ( v38->from_rtx != v23 || !v38->can_eliminate ) 
*( _OWORD *)( s + 1) = 0LL; 
*( _OWORD *)rbit = 0LL; 
tree v25; // r12 
tree v32; // rax 
tree v33; // rax 
tree v42; // rdi 
v41 = convert_modes( v7, ( machine_mode)v9, v40, v8); 
v43 = convert_modes( v7, ( machine_mode)v9, v42, v8); 
v14 = convert_modes( v7, ( machine_mode)v9, v13, v8); 
v16 = convert_modes( v7, ( machine_mode)v9, v15, v8); 
v58 = convert_modes( v7, ( machine_mode)v9, v57, v8); 
v34 = convert_modes( v7, ( machine_mode)v9, v33, v8); 
v56 = convert_modes( v7, ( machine_mode)v9, v55, v8); 
v60 = convert_modes( v7, ( machine_mode)v9, v59, v8); 
v39 = convert_modes( v7, ( machine_mode)v9, v38, v8); 
v10 = mode_class_0[mode]; 
mode = *( ( unsigned __int16 *)insn_data_0[1203].operand + 8); 
operand = insn_data_0[icode].operand; 
if ( !operand->predicate( v14, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) ) 
subtarget = gen_reg_rtx( ( machine_mode)*( ( unsigned __int16 *)operand + 8)); 
if ( !operand[2].predicate( v15, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8), v15); 
if ( !operand[3].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8)) ) 
copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)&operand[3] + 8), x); 
v18 = insn_data_0[icode].genfun( subtarget, v17); 
v27 = assign_stack_temp( ( machine_mode)v26, mode_size[v26], 0); 
v13 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( v12 + 2)); 
v34 = assign_stack_temp( ( machine_mode)*( ( unsigned __int8 *)dst + 2), ssizea, 0); 
v14 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)dst + 2)); 
if ( !insn_data_0[1159].operand->predicate( loc, ( ( BYTE3( target_flags) & 2) != 0) + 4) ) 
v1 = copy_to_mode_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), loc); 
rtx v10; // rax 
rtx i; // r15 
rtx v14; // rcx 
rtx v16; // rbp 
rtx last_insn; // rbp 
rtx v23; // rbx 
rtx v25; // r12 
rtx v30; // rbp 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v3->fld[0].rtx) 
&& !push_operand( v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)) 
if ( memory_address_p( ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v5->fld[0].rtx) ) 
v3 = mode_class_0[v2]; 
v63 = insn_data_0[insn_code].genfun( v4, y); 
if ( push_operand( v4, ( machine_mode)*( ( unsigned __int8 *)v4 + 2)) ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v41 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v40); 
v45 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v44); 
genfun = (  struct rtx_def *(  *)( rtx, rtx))insn_data_0[optab_table[30]->handlers[submode].insn_code].genfun; 
v16 = (  struct rtx_def *(  *)( rtx, rtx))insn_data_0[optab_table[30]->handlers[submode].insn_code].genfun; 
v26 = insn_data_0[optab_table[30]->handlers[submode].insn_code].genfun( v22, v23); 
v27 = insn_data_0[optab_table[30]->handlers[submode].insn_code].genfun( v24, v25); 
if ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)reg + 2)] - 5) <= 1 ) 
induction_1 *biv; // rbp 
induction_1 *biv; // rbp 
induction_1 *v5; // rax 
induction_1 *v5; // rax 
induction_1 **p_giv; // rbx 
induction_1 **p_giv; // rbx 
induction_1 *v34; // rbp 
induction_1 *v34; // rbp 
induction_1 *v51; // rbx 
induction_1 *v51; // rbx 
induction_1 *giv; // r14 
induction_1 *giv; // r14 
biv = v2->biv; 
if ( !biv ) 
v5 = v2->biv; 
if ( *( _WORD *)biv->add_val == 54 ) 
while ( ( *( ( _BYTE *)biv + 100) & 0x20) == 0 ) 
add_val = v5->add_val; 
v5 = v5->next_iv; 
v41 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), args_addr, args_so_far); 
operand = insn_data_0[v54].operand; 
v52 = insn_data_0[v54].genfun( v47, xinnera); 
convert_modes( ( machine_mode)( BYTE5( v55->block.abstract_origin) >> 1), VOIDmode, size, ( v56 & 0x20) != 0); 
( machine_mode)*( ( unsigned __int8 *)size + 2), 
if ( *( _WORD *)v17 == 61 && v17->fld[0].rtint <= 0x34u && mode_class_0[*( ( unsigned __int8 *)v17 + 2)] != MODE_INT ) 
v26 = operand_sub*(short *)0xforce( v17, v23, mode); 
v29 = operand_sub*(short *)0xforce( v17, v27, mode); 
v34 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), args_addr, args_so_far); 
v12 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( 4 - ( ( v6 == 0) - 1)), global_rtl[2]); 
v16 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v15); 
v12 = gen_rtx_fmt_ee( PRE_MODIFY, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v16); 
predicate = insn_data_0[insn_code].operand->predicate; 
v11 = insn_data_0[v9].genfun( x, ( rtx)v7); 
v10 = assign_stack_local( ( machine_mode)v6, mode_size[v6], 0); 
v10 = gen_reg_rtx( ( machine_mode)v6); 
if ( v14 != ( ( ( unsigned int)target_flags & 0x2000000) == 0 ? 64 : 128) || mode_class_0[mode] != MODE_INT ) 
operand = insn_data_0[icode].operand; 
v29 = insn_data_0[v24].genfun( v28, v19); 
if ( !ix86_branch_cost || mode_class_0[v18] != MODE_INT || op1 != const_int_rtx[64] ) 
if ( mode_class_0[v18] != MODE_INT ) 
v11 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
operand = insn_data_0[icode].operand; 
if ( !operand->predicate( v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)) ) 
if ( !operand->predicate( v8, ( machine_mode)*( ( unsigned __int8 *)v8 + 2)) ) 
v12 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v8 + 2)); 
v11 = insn_data_0[icode].genfun( v12, v10); 
v11 = insn_data_0[icode].genfun( v8, v10); 
( machine_mode)*( ( unsigned __int8 *)dest_reg + 2), 
v4 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), name); 
v5 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), name); 
v1 = gen_lowpart_if_possible( ( machine_mode)*( ( unsigned __int8 *)v1 + 2), const_rtx); 
if ( mode_class_0[mode] != MODE_FLOAT ) 
if ( mode_class_0[mode] != MODE_FLOAT ) 
v2 = spelling_0; 
if ( spelling_base >= spelling_0 ) 
rtx v111; // [rsp+10h] [rbp-78h] 
rtx earliest; // [rsp+48h] [rbp-40h] BYREF 
v111 = ( rtx)v87; 
v87 = ( __int64)v111; 
v87 = ( __int64)v111; 
condition = get_condition( v14, &earliest); 
if ( ( mode_class_0[*( unsigned __int8 *)( v102.rtwint + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( unsigned __int8 *)( v102.rtwint + 2)] != MODE_VECTOR_FLOAT 
if ( ( mode_class_0[*( unsigned __int8 *)( v101.rtwint + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( unsigned __int8 *)( v101.rtwint + 2)] != MODE_VECTOR_FLOAT 
for ( i = 0; ; i = XFlittlenan[v6] ) 
*( _OWORD *)&v12.r[1] = *( unsigned int *)&einv[4]; 
v22 = mode_class_0[mode]; 
*( _QWORD *)( low + 144) = adjust_address_1( rtl, ( machine_mode)v11, 0LL, 0, 1); 
*( _QWORD *)( low + 144) = gen_lowpart_SUBREG( ( machine_mode)v11, rtl); 
v37 = expand_expr( from, 0LL, ( machine_mode)*( ( unsigned __int8 *)v17 + 2), EXPAND_NORMAL); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
type = ( tree_node *)v15[1]; 
v25 = store_field( v15, bitsize, bitpos, mode1, from, ( machine_mode)v24, unsignedp, v7->common.type, alias_set); 
( machine_mode)( BYTE5( to->common.type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( from->common.type->block.abstract_origin) >> 1), 
rtx old_stack_level; // [rsp+10h] [rbp-48h] BYREF 
rtx call_fusage[8]; // [rsp+18h] [rbp-40h] BYREF 
old_stack_level = 0LL; 
call_fusage[0] = 0LL; 
v6 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), arguments); 
emit_stack_save( SAVE_BLOCK, &old_stack_level, 0LL); 
v15 = get_mode_alignment( ( machine_mode)v14) >> 3; 
v17 = gen_rtx_REG( ( machine_mode)v14, v16); 
v18 = adjust_address_1( v11, ( machine_mode)v14, v12, 1, 1); 
use_reg( call_fusage, v17); 
v22 = adjust_address_1( v11, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v19, 1, 1); 
use_reg( call_fusage, struct_value_rtx); 
v24 = prepare_call_address( function, 0LL, call_fusage, 0, 0); 
v5 = get_mode_alignment( ( machine_mode)v4) >> 3; 
v7 = gen_rtx_REG( ( machine_mode)v4, v6); 
v8 = adjust_address_1( v1, ( machine_mode)v4, v2, 1, 1); 
v10 = adjust_address_1( v1, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 0LL, 1, 1); 
v13 = adjust_address_1( v1, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v11, 1, 1); 
v4 = *( tree_node **)( *high + 32LL); 
v7 = ( tree_node *)high[4]; 
return expand_expr( addr_tree, 0LL, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), EXPAND_NORMAL); 
v10 = adjust_address_1( v5, ( machine_mode)v4, v8, 1, 1); 
v5 = force_reg( ( machine_mode)v4, buf_addr); 
v6 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v5); 
v8 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v7); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v4 = *( tree_node **)( v2 + 32); 
v8 = expand_expr( v4, 0LL, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), EXPAND_NORMAL); 
if ( !insn_data_0[1316].operand->predicate( v8, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
if ( !insn_data_0[1316].operand->predicate( v8, *( ( unsigned __int16 *)insn_data_0[1316].operand + 8)) ) 
v8 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8); 
v10 = memory_address( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), tem); 
v11 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v10); 
return gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v7); 
v2 = gen_reg_rtx( ( machine_mode)( BYTE5( integer_types[5]->block.abstract_origin) >> 1)); 
v4 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
v5 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v4); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6); 
v8 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), receiver_label); 
v9 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8); 
stack_save = gen_rtx_MEM( ( machine_mode)v2, v11); 
if ( !gave_help_9 ) 
gave_help_9 = 1; 
v6 = gen_rtx_MEM( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), v5); 
v5 = mode_class_0[mode]; 
operand = insn_data_0[insn_code].operand; 
v46 = insn_data_0[insn_code].operand; 
v15 = insn_data_0[insn_code].genfun( v11, v13); 
v18 = gen_rtx_fmt_e( USE, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v1->fld[0].rtx); 
v12 = nonzero_bits( v1->fld[0].rtx, ( machine_mode)*( unsigned __int8 *)( v1->fld[0].rtwint + 2)); 
v1 = gen_rtx_fmt_e( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v13.rtx); 
v28 = nonzero_bits( *( rtx *)( v23.rtwint + 8), ( machine_mode)( unsigned __int8)v9); 
v25 = simplify_shift_const( 0LL, ASHIFT, ( machine_mode)v11, v1->fld[0].rtx, v10 - ( v7 + v8)); 
v21 = simplify_shift_const( 0LL, ( rtx_code)( i + 89), ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v25, v24); 
rtx v20; // rbx 
rtx v28; // rax 
rtx v30; // rax 
rtx v35; // rax 
v35 = decl->decl.rtl; 
if ( !v35 ) 
v35 = decl->decl.rtl; 
regno_decl[*( unsigned int *)( *( _QWORD *)&v35[1] + 8LL)] = decl; 
v30 = type->int_cst.rtl; 
v5 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
exc_ptr = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v0 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 2); 
v7 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
emit_stack_restore( ( save_level)( x_block_stack->next == 0LL), next_label, 0LL); 
rtx v46; // r12 
rtx v47; // r12 
rtx v51; // rbx 
rtx v75; // rax 
rtx v77; // r14 
rtx v78; // r15 
v10 = mode_class_0[v9]; 
rtx = gen_rtx_fmt_e( USE, ( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), *( rtx *)( v2.rtwint + 8)); 
v29 = gen_lowpart_for_combine( ( machine_mode)v25, *( rtx *)&x[1]); 
emit_cmp_and_jump_insns( v27, v22, GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v27 + 2), 0, v23); 
( machine_mode)*( ( unsigned __int8 *)v27 + 2), 
v30 = trunc_int_for_mode( 1LL << tob, ( machine_mode)*( ( unsigned __int8 *)v25 + 2)); 
( machine_mode)*( ( unsigned __int8 *)v25 + 2), 
v35 = gen_rtx_fmt_e( UNSIGNED_FIX, ( machine_mode)*( ( unsigned __int8 *)v25 + 2), v34); 
( machine_mode)*( ( unsigned __int8 *)v38 + 2), 
( rtx_code)( unsignedp == 0 ? FIX : UNSIGNED_FIX), 
( machine_mode)*( ( unsigned __int8 *)v38 + 2), 
v17 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v16 + 2)); 
v18 = expand_unop( ( machine_mode)*( ( unsigned __int8 *)froma + 2), optab_table[17], froma, v17, 0); 
emit_unop_insn( v13, v3, v18, ( rtx_code)( v15 == 0 ? FIX : UNSIGNED_FIX)); 
emit_unop_insn( v11, v3, v13, ( rtx_code)( v12 == 0 ? FLOAT : UNSIGNED_FLOAT)); 
emit_cmp_and_jump_insns( v17, const_int_rtx[64], GE, 0LL, ( machine_mode)*( ( unsigned __int8 *)v17 + 2), 0, v14); 
( machine_mode)*( ( unsigned __int8 *)v15 + 2), 
v31 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)v15 + 2), v25); 
v8 = ( tree_node *)i[3]; 
v19 = ( tree_node *)p_chain[4]; 
v16 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v17 = gen_rtx_MEM( ( machine_mode)LOBYTE( subr->decl.result->block.supercontext), v16); 
v41->decl.rtl = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)v40 + 2)); 
v35 = memory_address( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v34); 
v36 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v35); 
rtx v10; // rax 
rtx v15; // rax 
rtx last_insn; // rbx 
v4 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
v10 = copy_to_reg( v9); 
v12 = v10; 
v15 = copy_to_reg( v14); 
v17 = v15; 
last_insn = get_last_insn( ); 
if ( last_insn ) 
while ( *( _WORD *)last_insn != 33 ) 
if ( *( _WORD *)last_insn != 34 ) 
last_insn = ( rtx)last_insn[1]; 
if ( last_insn ) 
( machine_mode)*( ( unsigned __int8 *)target + 2), 
operand = insn_data_0[insn_code].operand; 
v24 = operand->predicate( v8, ( machine_mode)v6); 
v25 = operand[1].predicate( v8, ( machine_mode)v6); 
if ( !operand[2].predicate( ignoreb, ( machine_mode)v6) ) 
force_reg( ( machine_mode)v6, ignoreb); 
v26 = insn_data_0[insn_code].genfun( v8, v8); 
if ( general_operand( v8->fld[0].rtx, ( machine_mode)v6) ) 
v33 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8->fld[0].rtx); 
v8 = force_reg( ( machine_mode)*( ( unsigned __int8 *)v34 + 2), v34); 
if ( !operand[2].predicate( ignorec, ( machine_mode)v6) ) 
force_reg( ( machine_mode)v6, ignorec); 
( machine_mode)*( ( unsigned __int8 *)v34 + 2), 
v37 = insn_data_0[insn_code].genfun( v8, v8); 
rtx v34; // r15 
rtx v39; // rax 
rtx v41; // rax 
rtx *v43; // rax 
rtx *v45; // rax 
rtx last_insn; // rax 
rtx v53; // r14 
rtx v54; // r13 
rtx v55; // r12 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v4 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), const_int_rtx[64]); 
if ( mode_class_0[*( ( unsigned __int8 *)op1 + 2)] != MODE_INT ) 
if ( mode_class_0[v10] == MODE_INT ) 
variant = basic_variant; 
variant = basic_variant; 
variant = basic_variant; 
variant = basic_variant; 
variant = negate_variant; 
tree v14; // r13 
tree v15; // rax 
tree v17; // rax 
v12 = type_for_mode( ( machine_mode)v11, unsignedp); 
v14 = make_tree( v10, mult); 
v15 = make_tree( v10, x); 
v16 = build( MULT_EXPR, v10, v15, v14); 
v16 = build( MULT_EXPR, v10, v15, v14); 
v17 = fold( v16); 
v18 = build( PLUS_EXPR, v10, v17, tree); 
v13 = gen_rtx_fmt_ee( ( rtx_code)v8, mode, adj_operand, v12); 
v18 = gen_rtx_fmt_ee( ( rtx_code)v8, mode, v14, v17); 
v4 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
v27 = expand_expr( ( tree)high, v26, ( machine_mode)*( ( unsigned __int8 *)v26 + 2), EXPAND_NORMAL); 
v13 = operand_sub*(short *)0xforce( result_val, v14 / v35, BLKmode); 
v41 = gen_reg_rtx( ( machine_mode)v39); 
tree v29; // rax 
v29 = convert( type, v28); 
v30 = build( MINUS_EXPR, type, v29, amount); 
classa = mode_class_0[v11]; 
operand = insn_data_0[insn_code].operand; 
v24 = insn_data_0[icode].genfun( targ0a, cop0); 
v67 = mode_class_0[mode]; 
operand = insn_data_0[( int)insn_code].operand; 
operand = insn_data_0[( int)insn_code].operand; 
v17 = insn_data_0[insn_code].genfun( libfunc, v13); 
v39 = operand_sub*(short *)0xforce( op0, v36, mode); 
rtx v5; // rax 
rtx v6; // rax 
v5 = pc_set( rtx); 
v6 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v5[1] + 8LL), 0, 0LL, v2); 
v6 = canonicalize_condition( rtx, *( rtx *)( *( _QWORD *)&v5[1] + 8LL), 0, 0LL, v2); 
if ( v6 ) 
if ( v6->fld[0].rtx == v2 ) 
v7 = (  struct rtx_def *)v6[1]; 
v8 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v6, VOIDmode, *( rtx *)( v3 + 16), v7); 
v8 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v6, VOIDmode, *( rtx *)( v3 + 16), v7); 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), 
return expand_expr( size_unit, 0LL, ( machine_mode)( BYTE5( sizetype_tab[0]->block.abstract_origin) >> 1), EXPAND_NORMAL); 
rtx g1_add_val; // [rsp+8h] [rbp-30h] 
g1_add_val = g1->add_val; 
v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)g1_add_val + 2), g1_add_val->fld[0].rtx, v22); 
v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)g1_add_val + 2), g1_add_val->fld[0].rtx, v22); 
v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)g1_add_val + 2), g1_add_val->fld[0].rtx, v22); 
v14 = gen_rtx_fmt_ee( MULT, ( machine_mode)*( ( unsigned __int8 *)v12 + 2), v12, v6); 
( rtx_code)*( _WORD *)ext_dependent, 
( machine_mode)*( ( unsigned __int8 *)ext_dependent + 2), 
rtx v17; // rax 
rtx fixed_bit_field; // r12 
rtx v60; // rax 
if ( insn != recog_data_0.insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
fatal_insn_not_found( insn, "recog.c", 2063, "extract_constrain_insn_cached"); 
v19 = immed_double_const( v17, v18, ( machine_mode)*( ( unsigned __int8 *)v10 + 2)); 
( machine_mode)*( ( unsigned __int8 *)v10 + 2), 
v29 = force_reg( ( machine_mode)v15, v10); 
*( _WORD *)&recog_data_0.n_operands = 0; 
recog_data_0.n_alternatives = 0; 
recog_data_0.insn = 0LL; 
recog_data_0.n_operands = v15; 
fatal_insn_not_found( insn, "recog.c", 2139, "extract_insn"); 
recog_data_0.operand, 
recog_data_0.operand_loc, 
recog_data_0.constraints, 
recog_data_0.operand_mode); 
v17 = recog_data_0.constraints[0]; 
recog_data_0.n_alternatives = 1; 
for ( i = *recog_data_0.constraints[0]; *v17; i = *v17 ) 
recog_data_0.n_alternatives = n_alternatives; 
if ( recog_data_0.n_alternatives <= 30 ) 
fatal_insn_not_found( insn, "recog.c", 2148, "extract_insn"); 
if ( recog_data_0.insn != insn || insn[2].fld[0].rtint < 0 ) 
recog_data_0.insn = insn; 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
v25 = operand_sub*(short *)0xforce( 
v30 = operand_sub*(short *)0xforce( op0, v21, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v30 = operand_sub*(short *)0xforce( op0, v21, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
rtx v11; // rax 
rtx i; // rdi 
v11 = first; 
if ( *( _WORD *)v11 == 37 ) 
v12 = v11[2].fld[0].rtint; 
v11 = v11[1].fld[0].rtx; 
v11 = v11[1].fld[0].rtx; 
if ( !v11 ) 
v11 = v11[1].fld[0].rtx; 
v11 = v11[1].fld[0].rtx; 
while ( v11 ); 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
for ( i = first[1].fld[0].rtx; i; i = final_scan_insn( i, file, optimize, prescan, 0) ) 
rtuint = i->fld[0].rtuint; 
induction_1 *biv; // rax 
induction_1 *biv; // rax 
biv = bl_0->biv; 
if ( mode_class_0[biv->mode] != MODE_INT ) 
if ( mode_class_0[biv->mode] != MODE_INT ) 
src_reg = biv->src_reg; 
biv = bl_0->biv; 
biv = bl_0->biv; 
src_reg = biv->src_reg; 
v9 = gen_reg_rtx( biv->mode); 
( machine_mode)*( ( unsigned __int8 *)v8 + 2), 
rtx v48; // [rsp+0h] [rbp-40h] BYREF 
rtx *i; // [rsp+8h] [rbp-38h] 
if ( ( unsigned int)( debug_info_level_0 - 2) <= 1 
if ( ( unsigned int)( debug_info_level_0 - 2) <= 1 
( const char *)&stru_6F109F._IO_save_end + 7, 
i = &v48; 
i = &v48; 
mode_alignment = get_mode_alignment( ( machine_mode)( v2 >> 1)); 
rtx v6; // rax 
v6 = find_base_term( x); 
if ( !v6 ) 
base_term = v6; 
if ( ( unsigned __int16)( *( _WORD *)v6 - 67) > 1u && ( *( _WORD *)v6 != 25 || !*( ( _BYTE *)v6 + 2)) ) 
if ( ( unsigned __int16)( *( _WORD *)v6 - 67) > 1u && ( *( _WORD *)v6 != 25 || !*( ( _BYTE *)v6 + 2)) ) 
if ( ( unsigned __int16)( *( _WORD *)v6 - 67) > 1u && ( *( _WORD *)v6 != 25 || !*( ( _BYTE *)v6 + 2)) ) 
rtx base_value; // rax 
rtx v11; // rax 
base_value = find_base_value( rtx->fld[0].rtx); 
if ( base_value ) 
v1 = base_value; 
v11 = find_base_value( v3); 
if ( v11 ) 
v3 = v11; 
rtx nonnote_insn; // rax 
timevar_push( TV_CFG_0); 
nonnote_insn = next_nonnote_insn( v25); 
|| *( _WORD *)nonnote_insn != 33 
if ( ( !nonnote_insn 
|| ( unsigned __int16)( **( _WORD **)&nonnote_insn[2] - 44) > 1u) 
timevar_pop( TV_CFG_0); 
rtx v7; // r13 
v7 = *parg2; 
if ( ( _WORD)v9 == COMPARE && const_int_rtx[64] == v7 ) 
v7 = ( rtx)exp[1]; 
if ( const_tiny_rtx[0][v8] != v7 ) 
v13 = canon_hash( rtx, ( machine_mode)v8); 
v14 = lookup( rtx, v13 & 0x1F, ( machine_mode)v8); 
rtx v21; // rbx 
rtx v22; // r8 
rtx v27; // r8 
rtx v39; // rax 
rtx v56; // rax 
rtx datumb; // [rsp+20h] [rbp-68h] 
rtx datumc; // [rsp+20h] [rbp-68h] 
rtx datumd; // [rsp+20h] [rbp-68h] 
|| flag_float_store && mode_class_0[*( ( unsigned __int8 *)in + 2)] == MODE_FLOAT 
if ( mode_class_0[*( unsigned __int8 *)( v22.rtwint + 2)] != MODE_FLOAT ) 
datumc = v23; 
v27 = datumc; 
if ( ( *( ( _BYTE *)cfun + 425) & 1) != 0 && qty_0[v26].n_calls_crossed > 0 ) 
if ( !qty_0[v26].n_calls_crossed ) 
if ( ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
if ( &unk_952B74 == ( _UNKNOWN *)++v13 ) 
while ( &unk_952B74 != ( _UNKNOWN *)v13 ); 
n_calls_crossed = qty_0[v26].n_calls_crossed; 
if ( !n_calls_crossed || 4 * n_calls_crossed >= qty_0[v26].n_refs ) 
induction_1 *v12; // rbp 
induction_1 *v12; // rbp 
( machine_mode)*( ( unsigned __int8 *)x + 2)) ) 
v12 = ( induction_1 *)xmalloc( 0xA8uLL); 
v12 = ( induction_1 *)xmalloc( 0xA8uLL); 
v12, 
v12->mem = x; 
if ( ( unsigned int)( mode_class_0[v5] - 5) <= 1 && ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[v5] - 5) <= 1 && ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
v11 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
fancy_abort( ( const char *)&va, 273, "find_pdom"); 
fancy_abort( ( const char *)&va, 275, "find_pdom"); 
&& *( tree_node **)( *( _QWORD *)( v8.rtwint + 8) + 128LL) == section_name ) 
v6 = *( int *)( ( char *)&allocno_0->reg + v5); 
v8 = ( char *)allocno_0 + v5; 
v9 = *( ( unsigned __int8 *)cfun->emit->x_regno_reg_rtx[*( int *)( ( char *)&allocno_0->reg + v5)] + 2); 
if ( ix86_hard_regno_mode_ok( v15, ( machine_mode)v9) ) 
if ( ( unsigned int)( mode_class_0[( int)v9] - 5) > 1 ) 
v21 = allocno_0; 
v22 = ( char *)allocno_0 + v89; 
v24 = *( HARD_REG_ELT_TYPE *)( ( _BYTE *)&allocno_0->hard_reg_copy_preferences + v89) & ~v13; 
*( HARD_REG_ELT_TYPE *)( ( char *)&allocno_0->hard_reg_copy_preferences + v89) = v24; 
v10 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
if ( ( ( unsigned int)( mode_class_0[v12] - 5) < 2) + 1 + ( unsigned int)v10 > regno ) 
rtx v76; // rdi 
rtx dummy_reload; // rax 
rtx *v149; // rdx 
rtx memloc; // rax 
rtx v32; // rdi 
rtx v33; // rax 
rtx v35; // r12 
rtx v42; // rax 
rtx v48; // rax 
rtx v49; // r12 
rtx tem; // [rsp+8h] [rbp-40h] BYREF 
tem = force_const_mem( mode, x); 
rtx = tem->fld[0].rtx; 
v11 = tem; 
fld = tem->fld; 
find_reloads_address( mode, &tem, rtx, ( rtx *)fld, opnum, type, ind_levels, 0LL); 
v20 = force_const_mem( ( machine_mode)*( ( unsigned __int8 *)v11 + 2), *( rtx *)&v11[1]); 
tem = v20; 
rtx = tem->fld[0].rtx; 
fld = tem->fld; 
rtx v14; // r15 
rtx v15; // rax 
rtx v17; // rax 
rtx result; // rax 
rtx tem; // [rsp+18h] [rbp-40h] BYREF 
tem = make_memloc( rtx, v13); 
v14 = tem; 
v14 = tem; 
tem = make_memloc( x->fld[0].rtx, v13); 
v20 = rtx_equal_p( tem, reg_equiv_mem[v21]); 
result = x; 
return result; 
if ( replace_reloads && recog_data_0.operand[opnum] != arg0 ) 
( machine_mode)*( ( unsigned __int8 *)v33 + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v43); 
( machine_mode)*( unsigned __int8 *)( arg0->fld[0].rtwint + 2)); 
v45 = legitimate_address_p( ( machine_mode)*( ( unsigned __int8 *)result + 2), v44->fld[0].rtx, 1); 
result = gen_lowpart_common( ( machine_mode)*( ( unsigned __int8 *)arg0 + 2), v41); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), replacement, v10); 
return gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)v3, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), replacement, v10); 
( machine_mode)*( unsigned __int8 *)( v7->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)v7 + 2)); 
return gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*loc + 2), rtint + v12); 
( machine_mode)( unsigned __int8)v8, 
rtx *single_use; // rax 
rtx v37; // rcx 
rtx v82; // rax 
rtx v83; // r13 
rtx v93; // rsi 
rtx v96; // rax 
rtx desta; // [rsp+0h] [rbp-58h] 
v10 = ix86_register_move_cost( m1, ( reg_class)v3, v5); 
best_cost = ix86_register_move_cost( m1, ( reg_class)v3, v5); 
v60 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v43 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v41); 
v45 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 0); 
rtx rtl; // rbx 
v6 = ( tree_node *)*( &global_trees + 11); 
elements = ( tree_node *)*( &global_trees + 11); 
rtl = i->int_cst.rtl; 
rttree = rtl[6].fld[0].rttree; 
rtl->fld[0].rtwint = ( __int64)enumtypea; 
rtl[2].fld[0].rtwint = low; 
*( _QWORD *)&rtl[4] = v23->int_cst.int_cst.high; 
rtl[3].fld[0].rtint = v23->type.align & 0xFFFFFF | rtl[3].fld[0].rtint & 0xFF000000; 
rtl[3].fld[0].rtint = v23->type.align & 0xFFFFFF | rtl[3].fld[0].rtint & 0xFF000000; 
v0 = initializer_stack_0; 
v1 = constructor_stack_0; 
if ( !constructor_stack_0 ) 
constructor_stack_0 = constructor_stack_0->next; 
constructor_stack_0 = constructor_stack_0->next; 
if ( constructor_range_stack_0 ) 
constructor_stack_0 = v0->constructor_stack; 
constructor_range_stack_0 = v0->constructor_range_stack; 
spelling_0 = v0->spelling; 
initializer_stack_0 = v0->next; 
v44 = ( tree_node ***)values; 
v44 = ( tree_node ***)v43; 
v14 = memory_address( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), fixed); 
v15 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v14); 
error( "can't use '%s' as a %s register", name, what_option_2[fixed][call_used]); 
if ( **( _WORD **)( v7.rtwint + 16) != 54 || memory_address_p( ( machine_mode)*( ( unsigned __int8 *)x + 2), v7.rtx) ) 
rtx *v24; // r12 
rtx v28; // rbp 
rtx v35; // rax 
rtx v38; // rbx 
rtx v45; // rbp 
rtx v48; // r15 
rtx v50; // rdx 
rtx v60; // rax 
*( _QWORD *)( v11.rtwint + 8) = walk_fixup_memory_subreg( *( rtx *)( v11.rtwint + 8), insn, ( machine_mode)v13, v14); 
rtx seq; // [rsp+8h] [rbp-50h] 
seq = ( rtx)*( ( _QWORD *)v11 + 4); 
seq->fld[v16].rtwint = ( __int64)get_insns( ); 
*( _OWORD *)&loops->num = 0LL; 
*( _OWORD *)&loops->tree_root = 0LL; 
*( _OWORD *)&loops->cfg.dfs_order = 0LL; 
add_dependence( insn, v7->fld[0].rtx, ( reg_note)v6); 
add_dependence( insn, v9->fld[0].rtx, ( reg_note)v6); 
rtx v53; // rax 
rtx v59; // rax 
rtx *v60; // rbp 
rtx v80; // r12 
rtx v95; // rdx 
rtx v106; // rax 
rtx v117; // rax 
rtx v10; // rax 
rtx v12; // r14 
rtx exit_labels; // rax 
rtx top; // rbx 
rtx v20; // r11 
rtx v23; // [rsp+0h] [rbp-48h] 
v10 = fncall( loop, rtx, v8, v3); 
v11 = *( _WORD *)v10; 
v12 = v10; 
v12 = v10; 
if ( *( _WORD *)v10 != 36 ) 
top = v10[1].fld[0].rtx; 
top = v10[1].fld[0].rtx; 
sprintf( label, "*.%s%u", ( const char *)&a.dw_attr_val, v16); 
v22 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v21); 
rtx v30; // rdi 
edge succ; // rax 
edge v39; // rdx 
succ = entry_exit_blocks[0].succ; 
if ( succ ) 
if ( e == succ ) 
v39 = succ; 
v39 = succ; 
succ = succ->succ_next; 
succ = succ->succ_next; 
if ( !succ ) 
if ( e == succ ) 
p_succ_next = &v39->succ_next; 
v30 = src->end; 
v30 = src->end; 
rtx v27; // rax 
v4 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2)); 
return expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v6, v19, v20, target, 0, OPTAB_LIB_WIDEN); 
v27 = negate_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2), *( rtx *)&value[1]); 
v27 = negate_rtx( ( machine_mode)*( ( unsigned __int8 *)value + 2), *( rtx *)&value[1]); 
v7 = v27; 
v11 = expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v6, v10, v7, v4, 0, OPTAB_LIB_WIDEN); 
return expand_binop( ( machine_mode)*( ( unsigned __int8 *)value + 2), v6, v11, v12, target, 0, OPTAB_LIB_WIDEN); 
v18 = force_reg( ( machine_mode)*( unsigned __int8 *)( value->fld[0].rtwint + 2), v17); 
return simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)value + 2), v18, ( machine_mode)v15, v16); 
return simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)value + 2), v18, ( machine_mode)v15, v16); 
return expand_mult( ( machine_mode)*( ( unsigned __int8 *)value + 2), v24, v25, target, 1); 
rtx v27; // rax 
rtx v33; // rax 
rtx v36; // rax 
rtx v57; // rax 
rtx v75; // rax 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, y, x); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, y, x); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, y, x); 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, y, x); 
v18 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v4, y, x); 
v37 = ( unsigned int)( mode_class_0[a2] - 5) <= 1; 
v25 = ( unsigned int)( mode_class_0[v22] - 5) <= 1; 
free( uid_cuid_1); 
else if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
immediate_operand( recog_data_0.operand[1], VOIDmode); 
v16 = immediate_operand( recog_data_0.operand[1], VOIDmode); 
v21 = general_operand( recog_data_0.operand[0], QImode); 
rtx v252; // r15 
rtx v271; // [rsp+8h] [rbp-D0h] 
if ( mode_class_0[v202] != MODE_CC 
|| ( v203 = gen_rtx_REG( ( machine_mode)v202, 58), 
reg_set_table = ( reg_set_0 **)xmalloc( v3); 
gcc_obstack_init( &reg_set_obstack); 
if ( *( ( _DWORD *)uid_cuid_1 + v91->fld[0].rtint) >= *( ( _DWORD *)uid_cuid_1 + rtint) ) 
v2 = &insn_data_0[optab_table[0]->handlers[*( ( unsigned __int8 *)x + 2)].insn_code]; 
if ( !operand->predicate( x, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
|| !operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
|| !operand[2].predicate( y, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
v4 = &insn_data_0[insn_code]; 
if ( operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
fancy_abort( ( const char *)&a, 5026, "add_child_die"); 
v21 = ( tree_node *)rtl[7]; 
if ( compiled_from_record_1++ ) 
rtx result; // rax 
result = simplify_binary_operation( code, mode, v5, rtx); 
if ( result ) 
return result; 
result = simplify_binary_operation( code, mode, rtx, v5); 
if ( result ) 
return result; 
result = simplify_binary_operation( code, mode, op0, op1); 
if ( result ) 
return result; 
result = simplify_relational_operation( code, v8, rtx, v5); 
if ( !result ) 
return result; 
rtx v11; // rax 
if ( !call_insn_operand( rtx, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v11 = emit_call_insn( v10); 
use_reg( ( rtx *)&v11[4], v9); 
rtx v10; // r13 
rtx v11; // rax 
if ( !call_insn_operand( rtx, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v10 = gen_rtx_fmt_ee( SET, VOIDmode, v9, v8); 
v11 = gen_rtx_fmt_ee( CALL, VOIDmode, operand0, operand1); 
v12 = gen_rtvec( 2, v11, v10); 
v12 = gen_rtvec( 2, v11, v10); 
rtx v15; // rax 
if ( !call_insn_operand( rtx, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v15 = emit_call_insn( v14); 
use_reg( ( rtx *)&v15[4], v12); 
rtx v12; // r13 
rtx v14; // rax 
if ( !call_insn_operand( rtx, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v12 = gen_rtx_fmt_ee( SET, VOIDmode, v11, v10); 
v14 = gen_rtx_fmt_ee( SET, VOIDmode, operand0, v13); 
v15 = gen_rtvec( 2, v14, v12); 
v15 = gen_rtvec( 2, v14, v12); 
v8 = copy_to_mode_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operand1->fld[0].rtx); 
v9 = copy_to_mode_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operand2->fld[0].rtx); 
v10 = insn_data_0[optab_table[41]->handlers[v6].insn_code].genfun( op1, op2); 
v2 = ix86_expand_compare( ( rtx_code)*( _WORD *)operand0, 0LL, 0LL); 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 10568, "gen_label_die"); 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 11221, "gen_tagged_type_instantiation_die"); 
v2 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[5], operand0); 
v4 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
return concat( " ( ", v5, ( char *)&stru_6F109F._IO_write_ptr + 7, 0LL); 
return concat( " ( ", v5, ( char *)&stru_6F109F._IO_write_ptr + 7, 0LL); 
return concat( " ( ", v5, ( char *)&stru_6F109F._IO_write_ptr + 7, 0LL); 
fancy_abort( ( const char *)&a, 10025, "gen_formal_parameter_die"); 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
fancy_abort( ( const char *)&a, 8989, "add_location_or_const_value_attribute"); 
x = force_reg( ( machine_mode)*( ( unsigned __int8 *)x + 2), x); 
rtx result; // rax 
v15 = mode_class_0[v2]; 
v15 = mode_class_0[v2]; 
result = 0LL; 
return gen_rtx_fmt_e( ( rtx_code)v16, mode, rtx); 
return result; 
return simplify_gen_subreg( mode, rtx, ( machine_mode)v5, 0); 
result = rtx; 
return result; 
return gen_rtx_CONST_INT_0( ( machine_mode)rtwint, v19); 
return gen_rtx_CONST_INT_0( ( machine_mode)rtwint, v19); 
rtx result; // rax 
result = rtx->fld[0].rtx; 
if ( *( _WORD *)result == 66 ) 
if ( *( ( unsigned __int8 *)result + 2) == mode ) 
return result; 
result = gen_lowpart_common( mode, rtx); 
if ( result ) 
return result; 
return gen_rtx_fmt_ee( ( rtx_code)( unsigned __int16)v6, mode, rtx->fld[0].rtx, *( rtx *)&rtx[1]); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v8); 
result = simplify_gen_subreg( mode, rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v8); 
if ( !result ) 
return result; 
v3 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)reg + 2)); 
v4 = gen_rtx_fmt_eit( ADDRESSOF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3, rtint, decl); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
if ( mode_class_0[v3] == MODE_CC && optab_table[30]->handlers[v3].insn_code == CODE_FOR_nothing ) 
return insn_data_0[optab_table[30]->handlers[v6].insn_code].genfun( v8, v9); 
operands[4] = gen_rtx_REG( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), 17); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v5, ( machine_mode)*( ( unsigned __int8 *)v5 + 2), v10, v9); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v10, v5); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v10, v5); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v5, v10); 
v11 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v5, v10); 
v3 = gen_rtx_REG( ( machine_mode)( ( *( ( _BYTE *)*operands + 2) == 5) + 4), v2); 
v3 = gen_rtx_REG( ( machine_mode)( ( *( ( _BYTE *)*operands + 2) == 5) + 4), v2); 
v1 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2]); 
v2 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v1); 
if ( generating_concat_p && ( v9 = mode_class_0[mode], ( unsigned int)( v9 - 5) <= 1) ) 
rtx last_insn; // rbx 
rtx v15; // rax 
rtx v20; // r15 
rtx v23; // rax 
rtx v29; // r9 
rtx v31; // r12 
rtx v37; // rax 
rtx secondary_mem; // rax 
rtx v40; // r14 
return gen_rtx_CONST_INT_0( ( machine_mode)v23, *( __int64 *)&mode); 
if ( MEMORY[0x1009868DF] ) 
rtx v5; // r8 
rtx v6; // rax 
rtx *v7; // rdx 
v5 = gen_rtx_fmt_E( SEQUENCE, VOIDmode, v4); 
v6 = cfun->emit->x_first_insn; 
if ( v6 ) 
v7 = ( rtx *)( v5->fld[0].rtwint + 8); 
v7 = ( rtx *)( v5->fld[0].rtwint + 8); 
*v7 = v6; 
*v7 = v6; 
v6 = v6[1].fld[0].rtx; 
v6 = v6[1].fld[0].rtx; 
++v7; 
while ( v6 ); 
return v5; 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v5 = trunc_int_for_mode( 1 << operands[2]->fld[0].rtwint, ( machine_mode)( !v2 + 4)); 
v8 = gen_rtx_fmt_ee( MULT, ( machine_mode)( !v2 + 4), v7, v6); 
v1 = gen_lowpart( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operands[1]); 
v3 = trunc_int_for_mode( 1 << operands[2]->fld[0].rtwint, ( machine_mode)( !v2 + 4)); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], 0LL); 
ix86_split_fp_branch( ( rtx_code)*( _WORD *)*operands, operands[1], operands[2], operands[3], operands[4], operands[5]); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
v4 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)operands[3], ( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), v2, v3); 
v4 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)operands[3], ( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), v2, v3); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2), operands[2]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
v4 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)operands[3], ( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), v3, v2); 
v4 = gen_rtx_fmt_ee( ( rtx_code)*( _WORD *)operands[3], ( machine_mode)*( ( unsigned __int8 *)operands[3] + 2), v3, v2); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[2] + 2)); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)v1, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v2, const_int_rtx[64]); 
v7 = gen_rtx( ( rtx_code)*( _WORD *)v1, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v2, const_int_rtx[64]); 
v12 = gen_rtx( ( rtx_code)*( _WORD *)v1, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v11, v10); 
v12 = gen_rtx( ( rtx_code)*( _WORD *)v1, ( machine_mode)*( ( unsigned __int8 *)v1 + 2), v11, v10); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v7, v6); 
v8 = gen_rtx( ( rtx_code)*( _WORD *)operand1, ( machine_mode)*( ( unsigned __int8 *)operand1 + 2), v7, v6); 
*( _WORD *)operands[1] = swap_condition( ( rtx_code)*( _WORD *)v21); 
if ( const0_operand( operands[2], ( machine_mode)*( ( unsigned __int8 *)*operands + 2)) ) 
v10 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v9, v7); 
v10 = gen_rtx( ( rtx_code)*( _WORD *)v6, ( machine_mode)*( ( unsigned __int8 *)v6 + 2), v9, v7); 
v10 = gen_rtx( ( rtx_code)*( _WORD *)v7, ( machine_mode)*( ( unsigned __int8 *)v7 + 2), v5, v6); 
v10 = gen_rtx( ( rtx_code)*( _WORD *)v7, ( machine_mode)*( ( unsigned __int8 *)v7 + 2), v5, v6); 
v1 = ix86_force_to_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2), operands[1]); 
v2 = gen_rtx_fmt_e( FLOAT, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v1); 
ix86_free_from_memory( ( machine_mode)*( ( unsigned __int8 *)operands[1] + 2)); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v6 = gen_lowpart( ( machine_mode)( !v2 + 4), v5); 
v8 = gen_lowpart( ( machine_mode)( !v2 + 4), v7); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( !v2 + 4), v10, v9); 
v13 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v12, v11); 
v1 = gen_lowpart( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operands[1]); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v6 = gen_lowpart( ( machine_mode)( !v2 + 4), v5); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v6 = gen_lowpart( ( machine_mode)( !v2 + 4), v5); 
v10 = gen_rtx_fmt_ee( MULT, ( machine_mode)( !v2 + 4), v8, v7); 
v11 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v10, v9); 
v1 = gen_lowpart( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operands[1]); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v6 = gen_lowpart( ( machine_mode)( !v2 + 4), v5); 
v8 = gen_lowpart( ( machine_mode)( !v2 + 4), v7); 
v13 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v10, v9); 
v14 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v13, v11); 
v15 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v14, v12); 
v1 = gen_lowpart( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operands[1]); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v6 = gen_lowpart( ( machine_mode)( !v2 + 4), v5); 
v5 = gen_lowpart( ( machine_mode)v4, operands[1]); 
v8 = gen_lowpart( ( machine_mode)( !v6 + 4), v7); 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( !v6 + 4), v11, v10); 
v1 = gen_lowpart( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), operands[1]); 
v4 = gen_lowpart( ( machine_mode)( !v2 + 4), v3); 
v13 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v13 = gen_rtx( ( rtx_code)*( _WORD *)operand1, VOIDmode, operand4, operand5); 
v4 = &insn_data_0[insn_code]; 
if ( operand->predicate( r0, ( machine_mode)*( ( unsigned __int16 *)operand + 8)) 
&& operand[1].predicate( r1, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) 
&& operand[2].predicate( c, ( machine_mode)*( ( unsigned __int16 *)&operand[2] + 8)) ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 10210, "gen_subprogram_die"); 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
if ( ( unsigned int)debug_info_level_0 <= DINFO_LEVEL_TERSE ) 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
ret_val = concat( "( ", ret_val, ( char *)&stru_6F109F._IO_write_ptr + 7, 0LL); 
sprintf( buff, ( const char *)&stru_6F109F._IO_save_end + 1, ( unsigned int)( v41 / v42)); 
v16 = ( tree_node *)v12[2]; 
if ( v16 == ( tree_node *)*( &global_trees + 27) ) 
v16 = ( tree_node *)v12[2]; 
v11 = concat( " ( ", v14, ( char *)&stru_6F109F._IO_write_ptr + 7, 0LL); 
fancy_abort( ( const char *)&a, 10121, "gen_type_die_for_member"); 
fancy_abort( ( const char *)&a, 9459, "add_abstract_origin_attribute"); 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 4387, "AT_flag"); 
fancy_abort( ( const char *)&a, 8989, "add_location_or_const_value_attribute"); 
if ( !( _BYTE)v5 && ( mode_class_0[mode] & 0xFFFFFFFD) != 1 ) 
if ( trunc_int_for_mode( op->fld[0].rtwint, ( machine_mode)v3) != op->fld[0].rtwint ) 
if ( mode_class_0[v5] == MODE_FLOAT && mode_size[v5] > mode_size[*( ( unsigned __int8 *)rtwint + 2)] ) 
if ( *( _WORD *)v10 != 70 && !legitimate_address_p( ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10, 0) ) 
if ( !explained_1 ) 
explained_1 = 1; 
for ( i = *( tree_node **)( low + 32); i; i = i->common.chain ) 
result = lang_hooks_0.get_alias_set( i); 
v18 = ++last_alias_set_5; 
result = lang_hooks_0.get_alias_set( section_name); 
result = ++last_alias_set_5; 
fatal_insn_not_found( insn, "insn-attrtab.c", 12189, "get_attr_athlon_decode"); 
LODWORD( v3) = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
fatal_insn_not_found( insn, "insn-attrtab.c", 11973, "get_attr_athlon_fpunits"); 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) || immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( !mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( !mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( mult_operator( recog_data_0.operand[3], TFmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 13438, "get_attr_i387"); 
if ( mult_operator( recog_data_0.operand[3], SFmode) ) 
if ( mult_operator( recog_data_0.operand[3], DFmode) ) 
if ( get_attr_type( insn) != TYPE_FOP && !mult_operator( recog_data_0.operand[3], XFmode) ) 
if ( get_attr_type( insn) != TYPE_FOP && !mult_operator( recog_data_0.operand[3], TFmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 13072, "get_attr_imm_disp"); 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( !memory_displacement_operand( recog_data_0.operand[0], VOIDmode) ) 
return immediate_operand( recog_data_0.operand[1], VOIDmode) != 0; 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
v3 = incdec_operand( recog_data_0.operand[2], DImode); 
if ( !incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
if ( const1_operand( recog_data_0.operand[2], VOIDmode) 
|| !const1_operand( recog_data_0.operand[2], VOIDmode) ) 
if ( const0_operand( recog_data_0.operand[2], SImode) 
&& memory_displacement_operand( recog_data_0.operand[0], VOIDmode) 
&& immediate_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !const0_operand( recog_data_0.operand[2], DImode) 
fatal_insn_not_found( insn, "insn-attrtab.c", 13642, "get_attr_length_address"); 
if ( !constant_call_address_operand( recog_data_0.operand[1], VOIDmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 14632, "get_attr_length_immediate"); 
if ( symbolic_operand( recog_data_0.operand[1], SImode) || ( unsigned int)( ( _DWORD)which_alternative - 4) <= 5 ) 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( !symbolic_operand( recog_data_0.operand[1], DImode) && ( unsigned int)( ( _DWORD)which_alternative - 4) > 4 ) 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
|| pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) && ( _DWORD)which_alternative != 2 ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) && ( _DWORD)which_alternative != 3 ) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
v5 = recog_data_0.operand[1]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 15861, "get_attr_memory"); 
if ( !memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
&& symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) && memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 17669, "get_attr_mode"); 
v18 = aligned_operand( recog_data_0.operand[1], HImode) == 0; 
if ( !aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 16766, "get_attr_modrm"); 
LODWORD( v3) = memory_operand( recog_data_0.operand[0], VOIDmode) != 0; 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( !register_operand( recog_data_0.operand[0], VOIDmode) ) 
LODWORD( v3) = immediate_operand( recog_data_0.operand[1], VOIDmode) == 0; 
if ( q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], DImode) ) 
LODWORD( v3) = memory_operand( recog_data_0.operand[1], VOIDmode) != 0; 
if ( incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
if ( register_operand( recog_data_0.operand[1], SImode) ) 
LODWORD( v3) = register_operand( recog_data_0.operand[1], HImode) == 0; 
if ( ( _DWORD)which_alternative == 1 && const0_operand( recog_data_0.operand[2], SImode) ) 
if ( ( _DWORD)which_alternative == 1 && const0_operand( recog_data_0.operand[2], DImode) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 19258, "get_attr_pent_pair"); 
if ( memory_operand( recog_data_0.operand[0], VOIDmode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( !memory_operand( recog_data_0.operand[1], VOIDmode) ) 
if ( !pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
v9 = incdec_operand( recog_data_0.operand[2], HImode) == 0; 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
|| !incdec_operand( recog_data_0.operand[2], QImode) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
rtx v10; // rdx 
fatal_insn_not_found( insn, "insn-attrtab.c", 20323, "get_attr_prefix_0f"); 
if ( !aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
rtx = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
rtx = recog_data_0.operand[0]->fld[0].rtx; 
v10 = recog_data_0.operand[0]; 
v10 = recog_data_0.operand[0]; 
if ( *( _WORD *)recog_data_0.operand[0] == 67 ) 
v10 = recog_data_0.operand[0]->fld[0].rtx; 
v10 = recog_data_0.operand[0]->fld[0].rtx; 
v9 = insn_addresses_->data.i[v10->fld[0].rtint]; 
fatal_insn_not_found( insn, "insn-attrtab.c", 20460, "get_attr_prefix_data16"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 20358, "get_attr_prefix_rep"); 
rtx v9; // rdx 
fatal_insn_not_found( insn, "insn-attrtab.c", 21978, "get_attr_type"); 
if ( flag_pic && symbolic_operand( recog_data_0.operand[1], SImode) ) 
if ( aligned_operand( recog_data_0.operand[1], HImode) ) 
if ( register_operand( recog_data_0.operand[0], QImode) ) 
if ( !q_regs_operand( recog_data_0.operand[0], QImode) ) 
if ( !flag_pic || !symbolic_operand( recog_data_0.operand[1], DImode) ) 
if ( ( _DWORD)which_alternative == 2 || pic_symbolic_operand( recog_data_0.operand[2], DImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], DImode) ) 
if ( pic_symbolic_operand( recog_data_0.operand[2], SImode) ) 
if ( incdec_operand( recog_data_0.operand[2], SImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], HImode) ) 
if ( !incdec_operand( recog_data_0.operand[2], QImode) ) 
if ( !register_operand( recog_data_0.operand[0], VOIDmode) ) 
v5 = CSWTCH_607[v4]; 
v7 = swap_condition( ( rtx_code)*v3); 
result = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v12 = value_2; 
if ( value_2 ) 
v13 = value_2 % 0x3EuLL; 
v14 = ( 0x8421084210842109LL * ( unsigned __int128)( value_2 / 0x7CuLL)) >> 64; 
v12 = value_2 / 0x3EuLL - 62 * ( v14 >> 4); 
value_2 = v30; 
LOBYTE( v25) = letters_1[v38]; 
v27[1] = letters_1[v12]; 
v27[2] = letters_1[v26]; 
v27[3] = letters_1[v28]; 
v27[4] = letters_1[v29]; 
v27[5] = letters_1[v24]; 
if ( ( sch_istable[v5] & 0x8C) == 0 && v5 != 46 ) 
result = set_2; 
if ( set_2 == -1 ) 
result = ++last_alias_set_5; 
set_2 = result; 
v14 = ( initial_value_pair_0 *)xmalloc( 0x50uLL); 
v13 = ( initial_value_pair_0 *)xrealloc( entries, 16LL * v12); 
v9 = ( tree_node *)*( &global_trees + 15); 
v10 = ( tree_node *)*( &global_trees + 17); 
imag = *( tree_node **)( high + 40); 
return insn_data_0[code].name; 
v2 = &insn_data_0[code]; 
return ( const char *)output( &recog_data_0); 
return gen_lowpart_for_combine( ( machine_mode)*( ( unsigned __int8 *)x + 2), last_value); 
v17 = ( ( unsigned int)( mode_class_0[v23] - 5) < 2) + 1; 
*v4 = gen_rtx_fmt_e( CLOBBER, ( machine_mode)*( ( unsigned __int8 *)v7 + 2), const_int_rtx[64]); 
if ( ( unsigned int)( mode_class_0[mode] - 5) <= 1 ) 
v8 = mode_class_0[mode]; 
if ( ( mode_class_0[v6] & 0xFFFFFFF9) == 1 ) 
find_reloads_address( v7, 0LL, v10->fld[0].rtx, ( rtx *)v10->fld, opnum, ( reload_type)v13, 0, 0LL); 
rtunion v4; // rdx 
if ( ( *( _DWORD *)( v4.rtwint + 16) & 0x800FF) != 25 ) 
v5 = *( _QWORD *)( v4.rtwint + 40); 
v6 = *( _QWORD *)( v4.rtwint + 32); 
if ( v6 >= 0 || ( *( _BYTE *)( *( _QWORD *)( v4.rtwint + 8) + 17LL) & 0x20) != 0 ) 
v6 = *( _QWORD *)( v4.rtwint + 32); 
*( _OWORD *)( v9 + 8) = 0LL; 
v8 = ( tree_node *)v9; 
rtx v6; // r12 
v6 = rtx; 
v6 = rtx; 
( machine_mode)*( unsigned __int8 *)( v5.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2))] 
result = set_3; 
if ( set_3 == -1 ) 
result = ++last_alias_set_5; 
set_3 = result; 
v0 = pwd_1; 
if ( !pwd_1 ) 
v3 = failure_errno_0; 
*v2 = failure_errno_0; 
failure_errno_0 = v6; 
pwd_1 = v0; 
page_group_0 *v47; // r12 
page_group_0 *v47; // r12 
v23 = ( page_entry_0 *)( &G + 2640); 
v25 = ( page_group_0 *)entrya; 
if ( length == 1 && ( sch_istable[*( unsigned __int8 *)contents] & 4) != 0 ) 
timevar_push( TV_GC_0); 
timevar_pop( TV_GC_0); 
v2 = ( tree_node *)*( ( _QWORD *)&v0->name + elements_used); 
rtl_op = first_rtl_op( ( tree_code)*( ( unsigned __int8 *)&v2->block.common + 16)); 
v0 = ( page_entry_0 **)( &G + 16); 
rtx v214; // [rsp+10h] [rbp-58h] 
v5 = 1LL << eliminables_2[v4].from; 
*( _OWORD *)v14 = -1LL; 
*( ( _OWORD *)v14 + 1) = -1LL; 
*( ( _OWORD *)v14 + 2) = -1LL; 
*( ( _OWORD *)v14 + 3) = -1LL; 
*( ( _OWORD *)v14 + 4) = -1LL; 
*( ( _OWORD *)v14 + 5) = -1LL; 
*( ( _OWORD *)v14 + 6) = -1LL; 
v7 = ( tree_node *)( ( unsigned __int64)width | ( unsigned __int64)declarator); 
v7 = grokdeclarator( declarator, declspecs, ( decl_context)v10, 0); 
reg_set_0 *v3; // rax 
reg_set_0 *v3; // rax 
v3 = reg_set_table[regno]; 
if ( v3 ) 
v8 = uid_cuid_1; 
rtint = v3->insn->fld[0].rtint; 
v3 = v3->next; 
v3 = v3->next; 
while ( v3 ); 
v12 = ( ( unsigned int)( mode_class_0[v10] - 5) < 2) + 1; 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&v12[2 * v15 + 2] + 2LL), 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)&rtwint[2 * v18 + 2] + 2LL), 
v13 = cselib_lookup( x, ( machine_mode)*( ( unsigned __int8 *)x + 2), create); 
&& ( operand = insn_data_0[insn_code].operand, operand->predicate( 
( machine_mode)*( ( unsigned __int16 *)operand + 8))) 
&& operand[1].predicate( x, ( machine_mode)*( ( unsigned __int16 *)&operand[1] + 8)) ) 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)( 5 - ( ( ( unsigned int)target_flags & 0x2000000) == 0)), v8, result); 
rtx v62; // rax 
rtx v63; // rsi 
rtx nonnote_insn; // rax 
rtx v70; // r13 
rtx v76; // rax 
rtx a; // r8 
rtx v93; // rdx 
rtx v95; // rax 
rtx last_value; // rax 
rtx expa; // [rsp+20h] [rbp-68h] 
rtx true0; // [rsp+30h] [rbp-58h] BYREF 
rtx true1; // [rsp+38h] [rbp-50h] BYREF 
rtx false0; // [rsp+40h] [rbp-48h] BYREF 
rtx false1; // [rsp+48h] [rbp-40h] BYREF 
if ( ( mode_class_0[mode] & 0xFFFFFFFD) == 1 ) 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
*( _OWORD *)&v2.r[1] = *( _OWORD *)&exp->block.subblocks; 
return immed_real_const_1( ( machine_mode)( BYTE5( exp->common.type->block.abstract_origin) >> 1), v2); 
if ( !target_isnan( d) && *( _OWORD *)d.r == *( _OWORD *)dconst0.r && dconst0.r[2] == d.r[2] ) 
while ( *( _OWORD *)u.d.r != *( _OWORD *)&result[1] || result[2] != u.d.r[2] ) 
result[1] = ( rtx_def)v3; 
if ( !*( ( _BYTE *)op + 2) && mode && ( mode_class_0[mode] & 0xFFFFFFFD) != 1 ) 
rtx *v37; // rdx 
rtx *v41; // rsi 
rtx v45; // rdx 
rtx *v47; // rax 
rtx *v52; // r13 
rtx note; // [rsp+8h] [rbp-40h] 
v47 = ( rtx *)xrealloc( alias_invariant, 8LL * ( unsigned int)reg_base_value_size); 
alias_invariant = v47; 
memset( v47, 0, 8LL * ( unsigned int)reg_base_value_size); 
v9 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v7); 
v12 = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2]); 
v15 = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( !v13 + 4), global_rtl[5]); 
v17 = gen_rtx_fmt_e( ADDRESS, ( machine_mode)( !v13 + 4), global_rtl[3]); 
&& ix86_hard_regno_mode_ok( i, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
profiler_label = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8); 
profiler_label = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8); 
ggc_add_rtx_root( &profiler_label, 1); 
*( _OWORD *)total_hist_br_prob = 0LL; 
*( _OWORD *)&total_hist_br_prob[4] = 0LL; 
*( _OWORD *)&total_hist_br_prob[8] = 0LL; 
*( _OWORD *)&total_hist_br_prob[12] = 0LL; 
*( _OWORD *)&total_hist_br_prob[16] = 0LL; 
if ( v3 == ( const  struct builtin *)&unk_65C690 ) 
if ( v3 != ( const  struct builtin *)&unk_65C690 ) 
v9 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6); 
address = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v9, v11); 
while ( !*v10 || strict_memory_address_p( ( machine_mode)*v10, address) ) 
if ( v10 == &stack_arg_under_construction ) 
si128 = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
v17 = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
*( __m128i *)&cum->words = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
v11 = _mm_load_si128( ( const __m128i *)&zero_cum_47); 
*( _QWORD *)&cum->sse_nregs = *( _QWORD *)&zero_cum_47.sse_nregs; 
cum->maybe_vaarg = zero_cum_47.maybe_vaarg; 
v12 = mode_class_0[5]; 
v12 = mode_class_0[4]; 
v14 = gen_rtx_fmt_i0( REG, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 7); 
v15 = gen_rtx_fmt_i0( REG, ( machine_mode)( !v8 + 4), 20); 
v43 = gen_rtx_fmt_i0( REG, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 6); 
v42 = gen_rtx_fmt_i0( REG, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 16); 
v17 = gen_rtx_fmt_i0( REG, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 53); 
v18 = gen_rtx_fmt_i0( REG, ( machine_mode)( !v8 + 4), 54); 
v44 = gen_rtx_fmt_e( TRUNCATE, ( machine_mode)v38, v43); 
if ( ix86_hard_regno_mode_ok( v5, ( machine_mode)v4) ) 
v6 = gen_rtx_REG( ( machine_mode)v4, v5); 
if ( initialized_12 ) 
initialized_12 = 1; 
*( v13 - 1) = sch_tolower[v15]; 
v18 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v17); 
$B50C8071A5A789E219D5EDC319094081 *handlers; // rax 
$B50C8071A5A789E219D5EDC319094081 *handlers; // rax 
$B50C8071A5A789E219D5EDC319094081 *v13; // rax 
$B50C8071A5A789E219D5EDC319094081 *v13; // rax 
$B50C8071A5A789E219D5EDC319094081 *v15; // rax 
$B50C8071A5A789E219D5EDC319094081 *v15; // rax 
$B50C8071A5A789E219D5EDC319094081 *v17; // rax 
$B50C8071A5A789E219D5EDC319094081 *v17; // rax 
$B50C8071A5A789E219D5EDC319094081 *v19; // rax 
$B50C8071A5A789E219D5EDC319094081 *v19; // rax 
$B50C8071A5A789E219D5EDC319094081 *v21; // rax 
$B50C8071A5A789E219D5EDC319094081 *v21; // rax 
$B50C8071A5A789E219D5EDC319094081 *v23; // rax 
$B50C8071A5A789E219D5EDC319094081 *v23; // rax 
$B50C8071A5A789E219D5EDC319094081 *v25; // rax 
$B50C8071A5A789E219D5EDC319094081 *v25; // rax 
$B50C8071A5A789E219D5EDC319094081 *v27; // rax 
rtx v19; // rax 
v19 = canon_rtx( rtx); 
v20 = v19; 
if ( ( *( ( _BYTE *)v19 + 3) & 4) == 0 ) 
v21.rtwint = ( __int64)v19->fld[0]; 
*( _OWORD *)global_regs = 0LL; 
*( _OWORD *)&global_regs[16] = 0LL; 
*( _OWORD *)&global_regs[32] = 0LL; 
reg_class ( *v16)[25]; // rbx 
reg_class ( *v19)[25]; // rdx 
reg_class ( *v69)[25]; // r15 
reg_class ( *v71)[25]; // rdx 
reg_class ( *v75)[25]; // rdx 
reg_class ( *v89)[25]; // [rsp+18h] [rbp-B0h] 
v16 = reg_class_subunion; 
v19 = v16; 
v19 = v16; 
if ( ( v21 & v23) == 0 && ( v23 & ~reg_class_contents[*( _DWORD *)v19]) != 0 ) 
*( _DWORD *)v19 = m; 
v1 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 58); 
v2 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v1, v0); 
v3 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v2); 
for ( i = v3; ; i = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), i) ) 
v6 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), off_6F6CAA); 
v6 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), off_6F6CAA); 
v7 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6); 
v8 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v5); 
v9 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 6); 
v10 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v9, v8); 
while ( v0 != ( _QWORD *)&unk_95AE90 ); 
v0->alloc_node = alloc_node_0; 
timevars[14].name = ( const char *)&off_6FF33C; 
timevars[15].name = ( const char *)&unk_6FF335; 
v2 = rtx_alloc( ( rtx_code)*( _WORD *)notes); 
v3 = lang_hooks_0.expand_constant( value); 
if ( ( mode_class_0[v28] & 0xFFFFFFF9) != 1 
if ( ( mode_class_0[v31] & 0xFFFFFFF9) != 1 
v7 = ( tree_node *)*( &global_trees + 14); 
if ( ( tree_node *)*( &global_trees + 14) != v7 ) 
v3 = lang_hooks_0.expand_constant( v3->vector.elements); 
v7 = ( tree_node *)*( &global_trees + 14); 
if ( ( tree_node *)*( &global_trees + 14) == v7 ) 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // rax 
&& ( ( v11 = lang_hooks_0.tree_inlining.disregard_inline_limits( fn), fn = fnp, v11) 
if ( lang_hooks_0.tree_inlining.disregard_inline_limits( fn) ) 
v3 = lang_hooks_0.tree_inlining.disregard_inline_limits( fn); 
if ( lang_hooks_0.tree_inlining.cannot_inline_tree_fn( &fnp) 
p_int_cst = &inlined_fns->int_cst.int_cst; 
while ( p_int_cst->low != fns->data.l[0] ) 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
if ( &inlined_fns->block.subblocks + ( unsigned int)( length - 1) == ( tree *)p_int_cst ) 
v42 = ( ( unsigned int)( mode_class_0[v39] - 5) < 2) + 1; 
v44[v45->reg_qty].const_insn = this_insn_0; 
v34->const_insn = this_insn_0; 
v15 = ( unsigned int)( mode_class_0[v11] - 5) <= 1; 
reg_eqv_table[v8] = ( reg_eqv_elem)-1LL; 
v36 = *( ( _DWORD *)uid_cuid_0 + v35[1]); 
if ( v36 > cse_basic_block_end || *( ( _DWORD *)uid_cuid_0 + *v35) < cse_basic_block_start ) 
if ( v36 > *( ( _DWORD *)uid_cuid_0 + *( int *)( reg_n_info->data.l[first_reg] + 4)) ) 
fatal_insn_not_found( insn, "insn-attrtab.c", 29, "insn_current_length"); 
fatal_insn_not_found( insn, "insn-attrtab.c", 356, "insn_default_length"); 
if ( !register_operand( recog_data_0.operand[0], DImode) ) 
if ( !register_operand( recog_data_0.operand[0], SImode) ) 
if ( !register_operand( recog_data_0.operand[0], VOIDmode) ) 
rtx *v537; // rdx 
rtx *v542; // rcx 
rtx *v545; // rdx 
rtx *v550; // rcx 
rtx *v552; // rdx 
rtx *v557; // rcx 
rtx *v560; // rdx 
rtx *v565; // rcx 
rtx v569; // rdx 
rtx *v573; // rdx 
rtx *v579; // rcx 
rtx v581; // rax 
rtx *v584; // rsi 
rtx *v586; // rcx 
rtx *v591; // rdx 
rtx v593; // rax 
fatal_insn_not_found( insn, "insn-attrtab.c", 46, "insn_variable_length_p"); 
rtx v13; // r8 
rtx v14; // r9 
rtx v15; // rax 
rtx s1a; // [rsp+0h] [rbp-48h] 
rtx s1; // [rsp+0h] [rbp-48h] 
rtx s2; // [rsp+8h] [rbp-40h] 
v13 = 0LL; 
rtx addr[4]; // [rsp+0h] [rbp-20h] BYREF 
addr[0] = rtx; 
addr[0] = copy_rtx( rtx); 
instantiate_virtual_regs_1( addr, 0LL, 0); 
v8 = addr[0]; 
if ( !memory_address_p( v9, addr[0]) ) 
v8 = addr[0]; 
v8 = addr[0]; 
instantiate_virtual_regs_1( addr, 0LL, 0); 
v8 = addr[0]; 
rtx *v7; // rdi 
v7 = &v5->x_parm_reg_stack_loc[v6]; 
if ( *v7 ) 
instantiate_virtual_regs_1( v7, 0LL, 0); 
rtx *fld; // r14 
rtx *v14; // rbp 
rtx v20; // rdx 
rtx v23; // rax 
rtx v24; // r14 
rtx v31; // rdx 
rtx v46; // rax 
rtx old; // [rsp+0h] [rbp-58h] 
rtx src; // [rsp+18h] [rbp-40h] BYREF 
fld = loc; 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( *( _OWORD *)&c->block.vars >= *( _OWORD *)&initial->block.vars ) 
if ( !strchr( off_70A4D6, v13) ) 
v6 = *( _OWORD *)&expr->block.vars; 
p_vars = ( tree_node *)&v5->block.vars; 
rtx v12; // rax 
v7 = canon_hash( rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2)) & 0x1F; 
v27 = ( ( unsigned int)( mode_class_0[v23] - 5) < 2) + 1; 
v44 = ( ( unsigned int)( mode_class_0[v41] - 5) < 2) + 1; 
v12 = canon_rtx( rtx); 
v13 = v12; 
full_mode = *( ( unsigned __int8 *)v12 + 2); 
v15 = ( ( unsigned int)( mode_class_0[v12] - 5) < 2) + 1; 
invalidate( *( rtx *)( v8.rtwint + 8), ( machine_mode)*( unsigned __int8 *)( v8.rtwint + 2)); 
invalidate( v6->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)v6 + 2)); 
( v8 = reversed_comparison_code_parts_0( ( rtx_code)*v4, ( rtx)*( _WORD *)v6, ( rtx)*( ( unsigned __int8 *)v6 + 2), v7)) != 0) ) 
v9 = gen_rtx_fmt_ee( ( rtx_code)v8, ( machine_mode)*( ( unsigned __int8 *)v4 + 2), v6, v7); 
return build1( ( tree_code)*( ( unsigned __int8 *)&elements->block.common + 16), type, v6); 
return build( ( tree_code)CSWTCH_547[v28], type, elements->int_cst.int_cst.low, elements->int_cst.int_cst.high); 
v6 = *( _OWORD *)dconst0.r != *( _OWORD *)&exp->block.vars || exp->real_cst.real_cst.r[2] != dconst0.r[2]; 
output_asm_insn( off_6720DB, xops); 
LODWORD( v1) = recog_data_0.n_operands - 1; 
v2 = recog_data_0.operand[v1]; 
LODWORD( v3) = recog_data_0.n_operands - 1; 
v6 = recog_data_0.operand[v3]; 
fatal_insn( "unknown insn mode", insn, "i386.c", 9956, "ix86_attr_length_immediate_default"); 
v4 = CSWTCH_1591[v5]; 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_FLOAT ) 
rtx v6; // rsi 
rtx v13; // rsi 
rtx v18; // rdx 
rtx v20; // rsi 
rtx v32; // rsi 
rtx v33; // rsi 
rtx v34; // rdx 
rtx v36; // rsi 
rtx v37; // rsi 
v7 = gen_rtx_MEM( ( machine_mode)v6, pointer); 
v8 = adjust_address_1( v7, ( machine_mode)v6, offset, 1, 1); 
v9 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), i); 
v4 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), i); 
v6 = gen_rtx_MEM( ( machine_mode)v5, pointer); 
v7 = adjust_address_1( v6, ( machine_mode)v5, offset, 1, 1); 
if ( mode_class_0[*( ( unsigned __int8 *)v4 + 2)] == MODE_FLOAT ) 
v26 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 2); 
v28 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v27, global_rtl[4], v26); 
v31 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[4]); 
v34 = gen_rtx_fmt_ee( PLUS, ( machine_mode)v27, global_rtl[2], v26); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v15 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v15); 
*operands = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), *operands); 
v15 = force_reg( ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v15); 
v28 = reverse_condition_maybe_unordered( ( rtx_code)*( _WORD *)v24); 
v34 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
tmp = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v8 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)*operands + 2), v5, v7, operands[3]); 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
( machine_mode)*( ( unsigned __int8 *)*operands + 2), 
if ( ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
if ( ( ( mode_class_0[mode] & 0xFFFFFFFB) == 2 || mode_class_0[mode] == MODE_VECTOR_FLOAT) 
if ( !symbolic_operand_0( v15->fld[0].rtx, ( machine_mode)operands) ) 
v24 = force_reg( ( machine_mode)v6, v15); 
v19 = gen_reg_rtx( ( machine_mode)v6); 
v4 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
v14 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), "_alloca"); 
v8 = reverse_condition_maybe_unordered( ( rtx_code)( unsigned __int16)**( ( _WORD **)&test + 1)); 
v9 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v8); 
v17 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2]); 
v12 = gen_rtx_fmt_e( PRE_DEC, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2]); 
v3 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v2); 
( machine_mode)v3, 
return gen_rtx_REG( ( machine_mode)( BYTE5( valtype->block.abstract_origin) >> 1), 0); 
v5 = mode_class_0[v1 >> 1]; 
return gen_rtx_REG( ( machine_mode)v3, v4); 
v2 = mode_class_0[mode]; 
v3 = mode_class_0[mode]; 
v6 = CSWTCH_1605[v4]; 
v11 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v14 = CSWTCH_1605[v13]; 
v14 = CSWTCH_1605[v20]; 
else if ( ( unsigned int)( mode_class_0[mode] - 5) <= 1 ) 
( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), 
|| ( unsigned int)( mode_class_0[BYTE5( type->block.abstract_origin) >> 1] - 7) <= 1 && int_size_in_bytes( type) == 8 ) 
return ( unsigned int)( mode_class_0[BYTE5( type->block.abstract_origin) >> 1] - 7) > 1; 
v18 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v17); 
v20 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v19); 
v23 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v22); 
v24 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v25 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v29 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v25, v28); 
v32 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
rtx v38; // r15 
rtx v40; // r13 
rtx i; // [rsp+8h] [rbp-50h] 
rtx second; // [rsp+10h] [rbp-48h] BYREF 
rtx bypass; // [rsp+18h] [rbp-40h] BYREF 
v11 = ix86_expand_fp_compare( code, op1, op2, tmp, &second, &bypass); 
v11 = ix86_expand_fp_compare( code, op1, op2, tmp, &second, &bypass); 
v13 = bypass; 
if ( !bypass ) 
v40 = global_rtl[0]; 
v42 = v40; 
v43 = gen_rtx_fmt_eee( IF_THEN_ELSE, VOIDmode, bypass, v41, v42); 
if ( !bypass ) 
rtx tmp; // [rsp+0h] [rbp-58h] BYREF 
rtx x; // [rsp+8h] [rbp-50h] 
rtx v38; // [rsp+10h] [rbp-48h] 
rtx parts; // [rsp+18h] [rbp-40h] BYREF 
rtx y; // [rsp+20h] [rbp-38h] 
rtx v41; // [rsp+28h] [rbp-30h] 
v6 = ix86_split_to_parts( operands[1], &parts, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v6 = ix86_split_to_parts( operands[1], &parts, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, &tmp, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
ix86_split_to_parts( *operands, &tmp, ( machine_mode)*( ( unsigned __int8 *)*operands + 2)); 
v25 = y; 
y = change_address( y, ( machine_mode)*( ( unsigned __int8 *)y + 2), v41->fld[0].rtx); 
y = change_address( y, ( machine_mode)*( ( unsigned __int8 *)y + 2), v41->fld[0].rtx); 
rtx v16; // rax 
rtx pool_constant; // rax 
rtx op; // [rsp+8h] [rbp-60h] BYREF 
if ( !push_operand( op, VOIDmode) ) 
v16 = copy_rtx( op); 
v16 = copy_rtx( op); 
*( ( _BYTE *)v16 + 2) = ( ( BYTE3( target_flags) & 2) != 0) + 4; 
parts[2] = v16; 
parts[1] = v16; 
*parts = v16; 
split_ti( &op, 1, parts, parts + 1); 
rtx container; // [rsp+20h] [rbp-88h] 
rtx addr_rtx; // [rsp+50h] [rbp-58h] 
v16 = construct_container( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, v14, v15, intreg_43, 0); 
v16 = construct_container( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, v14, v15, intreg_43, 0); 
rtx = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
examine_argument( ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1), type, 0, &needed_intregs, needed_sseregs); 
int_addr_rtx = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
src_addr = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v23 = expand_expr( v22, src_addr, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), EXPAND_NORMAL); 
container = v16; 
addr_rtx = rtx; 
tree v20; // rax 
tree v21; // rax 
tree v22; // rax 
tree v23; // rax 
v20 = build_int_2_wide( 
tree = build( PLUS_EXPR, v10->common.type, tree, v20); 
v21 = build( MODIFY_EXPR, v10->common.type, v10, tree); 
*( ( _BYTE *)&v21->block.common + 17) |= 1u; 
expand_expr( v21, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
v22 = make_tree( v11->common.type, global_rtl[3]); 
v23 = build( MODIFY_EXPR, v11->common.type, v11, v22); 
return force_reg( ( machine_mode)( 4 - ( ( v3 == 0) - 1)), exp); 
v5 = gen_reg_rtx( ( machine_mode)v4); 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
if ( ( unsigned int)( mode_class_0[v4] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[mode] - 5) <= 1 ) 
&& ( mode_class_0[*( ( unsigned __int8 *)x + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[*( ( unsigned __int8 *)val + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)val + 2)] != MODE_VECTOR_FLOAT ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
if ( comparison_dominates_p( v5, ( rtx_code)v8) ) 
result = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), v27, ( machine_mode)v26, *( _DWORD *)&x[1]); 
result = simplify_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), v27, ( machine_mode)v26, *( _DWORD *)&x[1]); 
result = simplify_unary_operation( ZERO_EXTEND, ( machine_mode)*( ( unsigned __int8 *)x + 2), v20, ( machine_mode)v19); 
if ( v5 && mode_class_0[v18 >> 1] == MODE_INT ) 
rtx v19; // rax 
rtx v26; // rax 
rtx v44; // rax 
v30 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), x->fld[0].rtx); 
v4 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v30, v29); 
v25 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), *( rtx *)( v4->fld[0].rtwint + 8)); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v43 = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), *( rtx *)( *( _QWORD *)&v4[1] + 8LL)); 
v44 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v43, v42); 
rtx v12; // r12 
rtx v21; // rax 
rtx v30; // rax 
rtx v36; // rax 
v5 = local_symbolic_operand( orig, ( machine_mode)reg); 
v19 = gen_rtx_fmt_Ei( UNSPEC, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v18, 15); 
v20 = gen_rtx_fmt_e( CONST, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v19); 
v21 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v20); 
v21 = gen_rtx_MEM( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v20); 
v22 = set_31; 
*( ( _BYTE *)v21 + 3) |= 4u; 
v23 = v21; 
set_31 = new_alias_set( ); 
v22 = set_31; 
v3 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
v24 = ( tree_node *)*( &global_trees + 12); 
if ( ( sch_istable[( unsigned __int8)v2] & 4) != 0 ) 
v12 = sch_istable[( unsigned __int8)v11]; 
v13 = hex_value[( unsigned __int8)v3]; 
v8 = hex_value[( unsigned __int8)v3]; 
floatflag = NOT_FLOAT; 
rtx insns; // rax 
rtx rtwint; // rbp 
v19 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 2); 
diddle_return_value( mark_reg_0, global_live_at_start); 
*( _OWORD *)regs_ever_live = 0LL; 
*( _OWORD *)&regs_ever_live[16] = 0LL; 
*( _OWORD *)&regs_ever_live[32] = 0LL; 
insns = get_insns( ); 
rtwint = insns; 
rtwint = insns; 
if ( insns ) 
v16 = *( _WORD *)insns; 
v17.rtwint = ( __int64)rtwint[1].fld[0]; 
sprintf( pic_label_name, "*.%s%u", ( const char *)&off_6720F5, 0LL); 
v3 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), pic_label_name); 
fancy_abort( ( const char *)&a, 7976, "loc_descriptor"); 
return mem_loc_descriptor( rtl->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtl + 2)); 
fancy_abort( ( const char *)&a, 8292, "loc_descriptor_from_tree"); 
rtx v19; // rax 
rtx v34; // rax 
rtx init_insns; // rax 
rtx v136; // rax 
rtx v137; // rbx 
rtx v145; // rax 
rtx v156; // rbp 
rtx hard_reg_initial_reg; // rax 
rtx v5; // rax 
v5 = insn; 
rtint = v5->fld[0].rtint; 
v8 = *( _WORD *)v5; 
v5 = v5[1].fld[0].rtx; 
v5 = v5[1].fld[0].rtx; 
if ( !v5 ) 
if ( v5 == reference || !rtx ) 
rtx v43; // rax 
rtx v44; // r12 
rtx v46; // rax 
rtx v59; // rax 
rtx increment; // [rsp+8h] [rbp-60h] 
induction_1 *biv_inc; // [rsp+18h] [rbp-50h] 
induction_1 *biv_inc; // [rsp+18h] [rbp-50h] 
if ( mode_class_0[v17] != MODE_INT ) 
v12 = expand_mult_add( v11, reg, mult, add, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
v10 = expand_mult_add( v9, reg, v8, v7, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
v9 = expand_mult_add( v8, reg, mult, add, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
rtx v5; // rbp 
rtx v17; // rbx 
rtx i; // rdx 
rtx v20; // r15 
rtx real_insn; // rax 
rtx v29; // rax 
rtx v50; // r8 
rtx v53; // rdx 
v18 = gen_rtx_REG( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), i); 
return gen_rtx_fmt_e( ( rtx_code)*v32, v8, ( rtx)v64); 
( machine_mode)*( unsigned __int8 *)( *( _QWORD *)( v3->fld[0].rtwint + 8) + 2LL), 
v70 = gen_rtx_fmt_ee( ( rtx_code)*( unsigned __int16 *)v3->fld[0].rtwint, v8, v69, v68); 
if ( ix86_hard_regno_mode_ok( v11, ( machine_mode)( BYTE5( type->block.abstract_origin) >> 1)) ) 
v22 = gen_rtx_fmt_i0( REG, ( machine_mode)LOBYTE( decl->block.supercontext), v11); 
if ( ( unsigned int)( mode_class_0[v23] - 5) > 1 ) 
v15 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), low); 
v16 = gen_rtx_MEM( ( machine_mode)LOBYTE( decl->block.supercontext), v15); 
rtx v14; // r14 
rtx v20; // rax 
rtx v30; // rax 
rtx v41; // rcx 
rtx result; // rax 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
result = adjust_address_1( v3, ( machine_mode)*( ( unsigned __int8 *)ad + 2), 0LL, 0, 1); 
if ( reg_equiv_memory_loc[regno] == result ) 
return copy_rtx( result); 
return result; 
v3 = ( tree_node *)ggc_alloc( v2); 
abstract_origin = type_for_mode( ( machine_mode)( *( _BYTE *)( v7 + 61) >> 1), 1)->decl.abstract_origin; 
tree v14; // r12 
tree v15; // rax 
tree v16; // r12 
tree v17; // rax 
tree v18; // rax 
tree v20; // r13 
rtx v5; // rbp 
rtx v6; // r12 
rtx v9; // rbp 
v9 = gen_rtx_fmt_u00( LABEL_REF, VOIDmode, v8); 
mark_jump_label( v9, rtx, 0); 
*( _QWORD *)( *( _QWORD *)&rtx[2] + 32LL) = v9->fld[0].rtwint; 
v5 = reg_note; 
v5 = reg_note; 
if ( reg_note ) 
if ( ( unsigned int)( mode_class_0[v7] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[v12] - 5) <= 1 ) 
v4 = ( ( unsigned int)( mode_class_0[v2] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[mode] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[v11] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[v3] - 5) > 1 ) 
v7 = ( ( unsigned int)( mode_class_0[v5] - 5) < 2) + 1; 
v8 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
rtx y; // [rsp+30h] [rbp-48h] 
( machine_mode)( unsigned __int8)v29, 
( machine_mode)( unsigned __int8)v28); 
v51 = ( ( unsigned int)( mode_class_0[v47] - 5) < 2) + 1; 
v14 = ( unsigned int)( mode_class_0[v11] - 5) <= 1; 
y = *v46; 
&& y 
rtx v22; // r11 
rtx mem_set_list; // r13 
rtx *listp; // [rsp+10h] [rbp-48h] 
rtx prev; // [rsp+18h] [rbp-40h] 
listp = &pbi->mem_set_list; 
free_INSN_LIST_list( listp); 
free_INSN_LIST_list( listp); 
v22 = insn; 
+ mode_size[*( ( unsigned __int8 *)v22 
v9 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT 
|| mode_class_0[*( unsigned __int8 *)( x->fld[0].rtwint + 2)] == MODE_FLOAT 
|| mode_class_0[*( unsigned __int8 *)( *( _QWORD *)&x[1] + 2LL)] == MODE_FLOAT ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] == MODE_FLOAT || v9 == 54 && !*( ( _QWORD *)v7 + 1) ) 
if ( mode_class_0[*( ( unsigned __int8 *)x + 2)] != MODE_FLOAT ) 
v19 = ( const char *)&off_6F019E; 
decode_asm_operands( v4, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
decode_asm_operands( v4, recog_data_0.operand, recog_data_0.operand_loc, constraints, operand_mode); 
if ( ( sch_istable[*( unsigned __int8 *)*format] & 4) != 0 ) 
if ( ( sch_istable[v13] & 4) == 0 ) 
rtx v8; // rax 
rtx pool_constant_mark; // rax 
pool_constant_mark = get_pool_constant_mark( v3, marked); 
if ( *( _WORD *)pool_constant_mark != 68 ) 
rtx = pool_constant_mark; 
if ( ( *( ( _BYTE *)pool_constant_mark + 3) & 4) != 0 ) 
get_pool_constant_mark( pool_constant_mark, marked); 
v10 = mem_loc_descriptor( v3->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)v3 + 2)); 
v8 = gen_rtx_fmt_ee( PLUS, *(short *)0xmode, rtx->fld[0].rtx, v7); 
v4 = *( _WORD *)v8; 
rtx = v8; 
rtx constant_term; // [rsp+8h] [rbp-30h] BYREF 
v3 = force_reg_0( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), x); 
constant_term = const_int_rtx[64]; 
v9 = eliminate_constant_term_0( v3, &constant_term); 
if ( const_int_rtx[64] != constant_term ) 
v10 = constant_term; 
v12 = gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)v3 + 2), v11, v10); 
if ( general_operand( v3, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)) ) 
v3 = force_reg_0( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3); 
rtx v9; // rbp 
rtx v15; // rbx 
rtx addr_0; // rax 
rtx v22; // rax 
rtx v30; // rax 
rtx x1a; // [rsp+8h] [rbp-50h] 
rtx y1a; // [rsp+10h] [rbp-48h] 
rtx x0; // [rsp+18h] [rbp-40h] 
rtx x0a; // [rsp+18h] [rbp-40h] 
v9 = y; 
v25 = ( ( unsigned int)( mode_class_0[v27] - 5) < 2) + 1; 
rtx head; // r12 
rtx end; // r14 
rtx v6; // rbp 
rtx v13; // rax 
head = b->head; 
end = b->end; 
v6 = a->end; 
b_empty = head == end; 
b_empty = head == end; 
v7 = *( _WORD *)head[1].fld[0].rtwint; 
head = head[1].fld[0].rtx; 
head = head[1].fld[0].rtx; 
if ( v7 == 37 && head[2].fld[0].rtint == -80 ) 
if ( head != end ) 
if ( head != end ) 
else if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
result = *( unsigned __int16 *)( *( ( _QWORD *)*( &CSWTCH_517 + ( unsigned int)pattern) + 3) + 24LL * opno + 16); 
fancy_abort( ( const char *)&a, 7381, "base_type_die"); 
fancy_abort( ( const char *)&a, 7573, "modified_type_die"); 
fancy_abort( ( const char *)&a, 7461, "is_base_type"); 
v8 = operand_sub*(short *)0xforce( x, v7, mode); 
rtx v17; // r13 
genfun = insn_data_0[insn_code].genfun; 
v17 = 0LL; 
v17 = adjust_automodify_address_1( to, v9, to_addr, v8, 1); 
v17 = adjust_address_1( to, v9, v8, 1, 1); 
v19 = genfun( v17, v18); 
rtx *v49; // r8 
rtx *v50; // r14 
rtx v57; // rax 
rtx *v66; // rax 
rtx *v68; // r14 
rtx *v90; // [rsp+8h] [rbp-70h] 
rtx *v91; // [rsp+8h] [rbp-70h] 
rtx note; // [rsp+10h] [rbp-68h] 
rtx v96; // [rsp+18h] [rbp-60h] 
rtx *after_dead; // [rsp+20h] [rbp-58h] 
rtx after_deada; // [rsp+20h] [rbp-58h] 
rtx after_deadb; // [rsp+20h] [rbp-58h] 
rtx v36; // rbx 
rtx v44; // rax 
rtx v46; // rbp 
rtx v48; // rax 
rtx v56; // rax 
rtx v57; // rax 
rtx v59; // r12 
rtx v60; // rax 
rtx set_dest; // r12 
if ( !strcmp( name, aE) ) 
v2 = ( const char *)&unk_6F22A4; 
if ( in_section_0 != in_named || strcmp( name, in_named_name) ) 
in_section_0 = no_section; 
in_section_0 = in_named; 
return ++last_alias_set_5; 
v12 = gen_rtx_fmt_ee( code, ( machine_mode)*( ( unsigned __int8 *)if_info->cond + 2), cmp_a, cmp_b); 
v13 = gen_rtx_fmt_eee( IF_THEN_ELSE, ( machine_mode)*( ( unsigned __int8 *)x + 2), v12, vtrue, vfalse); 
if ( general_operand( cmp_a, ( machine_mode)*( ( unsigned __int8 *)cmp_a + 2)) 
&& general_operand( cmp_b, ( machine_mode)*( ( unsigned __int8 *)cmp_b + 2)) ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
v13 = gen_rtx_fmt_ee( v10, ( machine_mode)*( ( unsigned __int8 *)x + 2), cond->fld[0].rtx, *( rtx *)&cond[1]); 
rtx v10; // rbx 
if ( *( _WORD *)v9.rtwint == 61 && mode_class_0[*( unsigned __int8 *)( v9.rtwint + 2)] == MODE_INT ) 
v10 = *earliest; 
while ( rtx_class[*( _WORD *)v10] != 105 || !modified_in_p( v7, v10) ) 
while ( rtx_class[*( _WORD *)v10] != 105 || !modified_in_p( v7, v10) ) 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
if ( jump == v10 ) 
if ( mode_class_0[*( unsigned __int8 *)( v6 + 2)] != MODE_INT ) 
v14 = reverse_condition( ( rtx_code)*v5); 
if ( ( mode_class_0[mode] & 0xFFFFFFFD) != 1 ) 
rtx v21; // rdx 
rtx v25; // rax 
rtx v27; // rax 
rtx v34; // rax 
rtx v35; // rax 
rtx v48; // rax 
rtx v52; // rax 
rtx v55; // rax 
rtx v60; // rax 
if ( ( mode_class_0[( unsigned __int8)v3] & 0xFFFFFFFB) != 2 
&& mode_class_0[( unsigned __int8)v3] != MODE_VECTOR_FLOAT 
&& ( mode_class_0[mode] & 0xFFFFFFFB) != 2 
&& mode_class_0[mode] != MODE_VECTOR_FLOAT ) 
if ( ( _DWORD)v28 != ( _DWORD)v6 && ( mode_class_0[v28] != MODE_INT || mode_class_0[( int)v6] != MODE_INT) ) 
if ( ( _DWORD)v28 != ( _DWORD)v6 && ( mode_class_0[v28] != MODE_INT || mode_class_0[( int)v6] != MODE_INT) ) 
v4 &= nonzero_bits( last_value, ( machine_mode)v6); 
v36 = nonzero_bits( v34.rtx, ( machine_mode)v6); 
v33 = nonzero_bits( *( rtx *)&x[1], ( machine_mode)v6); 
v4 &= nonzero_bits( x[1].fld[0].rtx, ( machine_mode)v6) | v33; 
v12 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v6); 
v13 = nonzero_bits( *( rtx *)&x[1], ( machine_mode)v6); 
v32 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v6); 
v4 &= nonzero_bits( *( rtx *)&x[1], ( machine_mode)v6) & v32; 
v17 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v6); 
v4 &= nonzero_bits( *( rtx *)&x[1], ( machine_mode)v6) | v17; 
&& ( v4 = *( ( unsigned __int8 *)x + 2), mode_class_0[v4] == MODE_INT) 
&& ( v5 = *( unsigned __int8 *)( v2.rtwint + 2), mode_class_0[v5] == MODE_INT) 
if ( ( mode_class_0[( int)v4] & 0xFFFFFFFB) == 2 
|| mode_class_0[( int)v4] == MODE_VECTOR_FLOAT 
|| ( v8 = *( ( _BYTE *)x + 2), ( mode_class_0[v8] & 0xFFFFFFFB) == 2) 
|| mode_class_0[v8] == MODE_VECTOR_FLOAT ) 
v17 = nonzero_bits( x, ( machine_mode)v4); 
LODWORD( rtuint) = num_sign_bit_copies( v39.rtx, ( machine_mode)v4); 
LODWORD( rtuint) = num_sign_bit_copies( *( rtx *)&x[1], ( machine_mode)v4); 
v40 = num_sign_bit_copies( x[1].fld[0].rtx, ( machine_mode)v4); 
v27 = num_sign_bit_copies( x->fld[0].rtx, ( machine_mode)v4); 
v28 = num_sign_bit_copies( *( rtx *)&x[1], ( machine_mode)v4); 
v41 = num_sign_bit_copies( x->fld[0].rtx, ( machine_mode)v4); 
v48 = nonzero_bits( x->fld[0].rtx, ( machine_mode)v4); 
if ( *( _OWORD *)&t1 == 0LL ) 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v3.rtx, offset); 
if ( !memory_address_p( ( machine_mode)*( ( unsigned __int8 *)memref + 2), v5) 
v14 = force_reg( ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2), v3.rtx); 
v5 = simplify_gen_binary( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v14, offset); 
v11 = *( tree_node **)( v10 + 8); 
v7 = gen_rtx_fmt_ee( LO_SUM, ( machine_mode)*( ( unsigned __int8 *)y + 2), y->fld[0].rtx, v13); 
return *( _WORD *)op == 66 && offsettable_address_p( 1, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx) != 0; 
return *( _WORD *)op == 66 && offsettable_address_p( 0, ( machine_mode)*( ( unsigned __int8 *)op + 2), op->fld[0].rtx) != 0; 
&& *( _OWORD *)&v5->block.vars == *( _OWORD *)&elements->block.vars 
&& *( _OWORD *)&v5->block.vars == *( _OWORD *)&elements->block.vars 
( machine_mode)*( unsigned __int8 *)( v23.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)) 
( machine_mode)*( unsigned __int8 *)( v8.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)y + 2)) 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
v10 = &reg_avail_info_0[rtx->fld[0].rtuint]; 
v11 = *( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint); 
*( ( _DWORD *)uid_cuid_1 + insn->fld[0].rtint), 
lang_hooks_0.tree_inlining.add_pending_fn_decls( &id, v6); 
v13 = *( tree_node **)( low + 40); 
v22 = ( tree_node *)*( &global_trees + 12); 
v22 = ( tree_node *)*( &global_trees + 11); 
transp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
comp_0 = sbitmap_vector_alloc( n_basic_blocks, 1u); 
sbitmap_vector_ones( transp_0, n_basic_blocks); 
transp_0[v55]->elms[0] &= ~1uLL; 
note_stores( *( ( rtx *)v8 + 4), reg_becomes_live_0, live_at_edge); 
sbitmap_vector_zero( comp_0, n_basic_blocks); 
v17 = comp_0; 
v21 = transp_0[v20]; 
v23 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
v23 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
v23 = pre_edge_lcm( file, 1, transp_0, comp_0, antic, kill, &insert_0, &delete); 
v30 = insert_0; 
transp_0[index]->elms[0] &= ~1uLL; 
free( transp_0); 
free( comp_0); 
free( insert_0); 
rtx v42; // rax 
rtx v43; // r10 
rtx v48; // rax 
rtx v49; // rdx 
rtx v50; // rsi 
rtx v51; // rax 
rtx v53; // rax 
rtx v54; // rsi 
rtx v55; // rdx 
elements = lang_hooks_0.expand_constant( exp); 
v8 = ( tree_node *)high[4]; 
( const char *)&stru_6F109F._IO_save_end + 7, 
insn_data_0[rtint].name); 
fprintf( asm_out_file, off_66C5A4, ( unsigned int)( ( _DWORD)which_alternative + 1)); 
v7 = ( char *)&stru_6F109F._IO_save_end + 7; 
v14 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v13->dw_fde_begin); 
v18 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), l1); 
v6 = CSWTCH_604[dw_cfi_opc]; 
v16 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( 4 - ( ( v15 == 0) - 1)), cfi->dw_cfi_oprnd1.dw_cfi_addr); 
v13 = CSWTCH_607[v14]; 
fancy_abort( ( const char *)&a, 1772, "output_cfi"); 
v5 = lang_hooks_0.expand_constant( exp); 
if ( in_section_0 == in_const ) 
if ( in_section_0 == in_data ) 
in_section_0 = in_data; 
if ( in_section_0 == in_data ) 
mergeable_constant_section( ( machine_mode)LOBYTE( v4->block.supercontext), v5, 0); 
if ( in_section_0 == in_const ) 
in_section_0 = in_const; 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&a.dw_attr_val, ( unsigned int)labelno); 
fprintf( asm_out_file, ".%s%u:\n", ( const char *)&a.dw_attr_val, ( unsigned int)v7->labelno); 
assemble_real( ( machine_mode)mode, v7->align, v27); 
sprintf( digit_buffer, off_663A61, *v39); 
sprintf( digit_buffer, off_663A65, *v48); 
sprintf( digit_buffer, &off_646752[1], *v11); 
v13 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v12); 
table_address = force_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v13); 
v14 = gen_rtx_fmt_s( SYMBOL_REF, ( machine_mode)fnname, "__bb_init_func"); 
v22 = ( tree_node *)*( &global_trees + 11); 
v22 = *( tree_node **)( *( _QWORD *)htab_find_slot_with_hash( 
v11 = ( tree_node *)digest_init( type, v5, require_constant_value, pending); 
if ( ( tree_node *)global_trees == v11 ) 
fancy_abort( ( const char *)&a, 2778, "output_loc_operands"); 
fancy_abort( ( const char *)&a, 2789, "output_loc_operands"); 
if ( ( sch_istable[( unsigned __int8)v2] & 0x10) != 0 ) 
else if ( !strcmp( v0, ( const char *)&off_672010) ) 
for ( i = "i386"; strcmp( v3, i); i = processor_alias_table_49[v4].name ) 
flags = processor_alias_table_49[( int)v4].flags; 
flags = processor_alias_table_49[( int)v4].flags; 
ix86_arch = processor_alias_table_49[( int)v4].processor; 
if ( ( flags & 4) != 0 ) 
if ( ( flags & 0x10) != 0 && ( ( unsigned int)target_flags & 0x200000) == 0 ) 
if ( ( flags & 0x40) != 0 && ( ( unsigned int)target_flags & 0x800000) == 0 ) 
if ( !already_0 ) 
if ( already_0 ) 
already_0 = 1; 
if ( ( sch_istable[v14] & 0x88) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v4] & 0x204) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v4] & 0x204) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v15] & 0x88) == 0 ) 
if ( ( sch_istable[( unsigned __int8)v9] & 0x400) == 0 ) 
v2 = spelling_0; 
if ( spelling_base >= spelling_0 ) 
v10 = &peep2_insn_data_0[v7]; 
v13 = &peep2_insn_data_0[v7]; 
v18 = v17 + search_ofs_1; 
if ( v17 + search_ofs_1 > 52 ) 
v18 = v17 + search_ofs_1 - 53; 
v25 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
search_ofs_1 = 0; 
v28 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
search_ofs_1 = v38; 
result = peep2_insn_data_0[v1].insn; 
if ( !peep2_insn_data_0[v2].insn ) 
v6 = ( ( unsigned int)( mode_class_0[v4] - 5) < 2) + 1; 
while ( !bitmap_bit_p( peep2_insn_data_0[v2].live_before, v9) ); 
v3 = &peep2_insn_data_0[v2]; 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = v7.rtx; 
recog_data_0.operand[1] = v7.rtx; 
|| ( *_pmatch_len = 0, ( result = gen_peephole2_1246( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = v7.rtx; 
|| ( *_pmatch_len = 0, ( result = gen_peephole2_1249( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[1] = v7.rtx; 
result = gen_peephole2_1252( insn, recog_data_0.operand); 
recog_data_0.operand[0] = v7.rtx; 
recog_data_0.operand[1] = v7.rtx; 
|| ( *_pmatch_len = 0, ( result = gen_peephole2_1245( insn, recog_data_0.operand)) == 0LL) ) 
recog_data_0.operand[0] = v7.rtx; 
edge v44; // rdx 
edge nehea; // [rsp+8h] [rbp-110h] 
peep2_insn_data_0[0].insn = 0LL; 
peep2_insn_data_0[1].insn = 0LL; 
peep2_insn_data_0[2].insn = 0LL; 
peep2_insn_data_0[4].insn = global_rtl[0]; 
peep2_insn_data_0[3].insn = 0LL; 
bitmap_copy( peep2_insn_data_0[4].live_before, live); 
peep2_insn_data_0[v9].insn = ( rtx)v8; 
bitmap_copy( peep2_insn_data_0[peep2_current].live_before, live); 
v16 = peep2_insn_data_0[v15].insn; 
if ( *( _WORD *)peep2_insn_data_0[v35].insn == 34 ) 
note = find_reg_note( peep2_insn_data_0[v17].insn, REG_EH_REGION, 0LL); 
v1 = constructor_stack_0; 
for ( ; constructor_stack_0->implicit; v1 = constructor_stack_0 ) 
for ( ; constructor_stack_0->implicit; v1 = constructor_stack_0 ) 
if ( constructor_range_stack_0 ) 
spelling_0 = &spelling_base[constructor_depth]; 
replacement_value = ( tree_node *)global_trees; 
constructor_range_stack_0 = v1->range_stack; 
spelling_0 = &spelling_base[depth]; 
constructor_stack_0 = v1->next; 
if ( !constructor_stack_0 ) 
if ( mode_class_0[*( unsigned __int8 *)( *( ( _QWORD *)aux + 6) + 2LL)] == MODE_FLOAT 
|| ( v14 = *( ( _QWORD *)aux + 4), mode_class_0[*( unsigned __int8 *)( v14 + 2)] == MODE_FLOAT) ) 
hitrate = predictor_info_0[predictor].hitrate; 
if ( taken != TAKEN_0 ) 
v12 = &insn_data_0[icode].operand[opnum]; 
if ( v12->predicate( v11, ( machine_mode)*( ( unsigned __int16 *)v12 + 8)) ) 
return copy_to_mode_reg( ( machine_mode)*( ( unsigned __int16 *)v12 + 8), v11); 
if ( recog_data_0.n_operands > 0 ) 
for ( i = ( char *)recog_data_0.constraints[v1]; 
recog_data_0.n_alternatives > v2; 
while ( recog_data_0.n_operands > ( int)v1 ); 
fprintf( outfile, off_670ADF, name->int_cst.int_cst.low); 
fwrite( &stru_6F109F, 1uLL, 0xCuLL, outfile); 
fwrite( &off_672E3A, 1uLL, 3uLL, file); 
fwrite( &off_6CCDC1, 1uLL, 3uLL, file); 
fwrite( &off_6CCDBB, 1uLL, 3uLL, file); 
fwrite( &unk_672230, 1uLL, 5uLL, file); 
fwrite( &off_672232, 1uLL, 3uLL, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 1, file); 
put_condition_code( ( rtx_code)*( _WORD *)x, ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 0, 1, file); 
if ( mode_class_0[v20] == MODE_INT ) 
*( _OWORD *)v30.r = *( _OWORD *)u.d.r; 
v2 = *( _OWORD *)&scale.base; 
if ( *( _OWORD *)&scale.base == 0LL ) 
fprintf( file, off_67227A, v4); 
fprintf( file, off_67227E, v4); 
fprintf( file, off_672207, v9); 
v31 = ( const char *)&unk_6708BE; 
fprintf( v9, off_670ADF, v33, dest, v14); 
( const char *)&stru_6F109F._IO_read_end + 7, 
result = fprintf( outfile, ( const char *)&stru_6F109F._IO_read_base + 6); 
fwrite( ( char *)&stru_6F109F._IO_write_end + 1, 1uLL, 2uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_write_end + 4, 1uLL, 2uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_write_end + 7, 1uLL, 2uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_buf_base + 2, 1uLL, 2uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_buf_base + 5, 1uLL, 2uLL, outfile); 
fwrite( &stru_6F109F._IO_buf_end, 1uLL, 2uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_buf_end + 3, 1uLL, 2uLL, outfile); 
fprintf( outfile, ( const char *)&stru_6F109F._IO_save_end, v37); 
fprintf( outfile, ( const char *)&stru_6F109F._IO_backup_base); 
fwrite( ( char *)&stru_6F109F._IO_read_end + 3, 1uLL, 3uLL, outfile); 
fwrite( ( char *)&stru_6F109F._IO_save_end + 6, 1uLL, 2uLL, outfile); 
fprintf( outfile, off_646752, *( ( unsigned int *)a1 + 8)); 
fprintf( outfile, ( const char *)&stru_6F109F._markers + 1, *( unsigned int *)( v39 + 88)); 
fprintf( outfile, ( const char *)&stru_6F109F._IO_buf_end + 6); 
fprintf( outfile, ( const char *)&stru_6F109F._IO_backup_base); 
for ( i = buffer; spelling_0 > v1; ++v1 ) 
sprintf( i, ( const char *)&stru_6F109F._IO_save_end + 1, v7); 
if ( spelling_0 <= v1 ) 
fwrite( ( char *)&stru_6F109F._chain + 2, 1uLL, 2uLL, file); 
v2 = convert_to_mode( ( machine_mode)v5, size, 1); 
v6 = gen_rtx( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v2); 
v11 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v10); 
v13 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v2); 
v16 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v15); 
v18 = gen_rtx_fmt_ee( MINUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), global_rtl[2], v2); 
v17 = force_reg_0( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v17); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
emit_cmp_and_jump_insns( v17, v19, GTU, 0LL, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 1, v21); 
if ( !constructor_stack_0->replacement_value ) 
v3 = constructor_stack_0; 
if ( !constructor_stack_0->replacement_value ) 
v4 = copy_to_mode_reg( ( machine_mode)*( ( unsigned __int8 *)loc + 2), copy); 
*( _OWORD *)aux = 0x3FF0000000000000uLL; 
fatal_insn( "Attempt to delete prologue/epilogue insn:", insn, "flow.c", 1615, "propagate_one_insn"); 
rtx result; // rax 
rtx v6; // rbx 
rtx v7; // rax 
rtx v12; // r13 
rtx v13; // rax 
rtx v14; // rbx 
rtx v15; // rax 
v8 = gen_reg_rtx( ( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
v6 = protect_from_queue( x->fld[0].rtx, 0); 
rtx note; // [rsp+8h] [rbp-90h] BYREF 
for ( note = ( rtx)v3.rtwint; v3.rtwint; note = ( rtx)v3.rtwint ) 
for ( note = ( rtx)v3.rtwint; v3.rtwint; note = ( rtx)v3.rtwint ) 
if ( for_each_rtx( &note, is_addressof, 0LL) ) 
remove_note( rtx, note); 
v3.rtwint = ( __int64)note[1]; 
rtx v18; // rax 
rtx *fld; // rbp 
rtx v29; // rdx 
rtx v34; // r14 
rtx v40; // rax 
rtx v41; // rbx 
rtx v43; // rbx 
rtx p; // [rsp+18h] [rbp-40h] 
( machine_mode)*( unsigned __int8 *)( v7 + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2)); 
v1 = spelling_0; 
v3 = spelling_0 - spelling_base; 
spelling_0 = v6; 
v4 = convert_modes( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), ptr_mode, size, 1); 
v11 = copy_to_mode_reg( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
while ( constructor_stack_0->implicit ) 
v15 = constructor_stack_0; 
constructor_stack_0 = v6; 
constructor_depth = spelling_0 - spelling_base; 
v16 = constructor_range_stack_0; 
constructor_range_stack_0 = 0LL; 
v21 = ( tree_node *)*( &global_trees + 17); 
v27 = ( tree_node *)*( &global_trees + 17); 
v3 = constructor_range_stack_0; 
v5 = constructor_stack_0; 
constructor_range_stack_0 = v1; 
rtx rtwint; // r13 
rtx *v31; // r10 
rtx v36; // rsi 
rtx v47; // rax 
rtx *v52; // r15 
rtx v59; // rdi 
rtx *v62; // r10 
result = ( tree_node *)p_first[2]; 
v5 = *( tree_node **)( v3.rtwint + 8); 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
( machine_mode)*( unsigned __int8 *)( v2.rtwint + 2), 
v9 = ( const char *)&unk_671F90; 
v9 = ( const char *)&unk_671F8D; 
v9 = ( const char *)&unk_671F8A; 
v9 = ( const char *)&off_671F86; 
put_reg_into_stack( v9, rtl, decl->common.type, v8, ( machine_mode)supercontext_low, v3, 0, v2, 0LL); 
v3 = ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)); 
v3 = ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)); 
v3 = ( double)( qty_0[v2].size * qty_0[v2].freq * floor_log2_wide( qty_0[v2].n_refs)); 
v4 = ( double)( qty_0[v2].death - qty_0[v2].birth); 
v4 = ( double)( qty_0[v2].death - qty_0[v2].birth); 
- ( int)( ( double)( qty_0[v5].size * qty_0[v5].freq * floor_log2_wide( qty_0[v5].n_refs)) 
- ( int)( ( double)( qty_0[v5].size * qty_0[v5].freq * floor_log2_wide( qty_0[v5].n_refs)) 
- ( int)( ( double)( qty_0[v5].size * qty_0[v5].freq * floor_log2_wide( qty_0[v5].n_refs)) 
/ ( double)( qty_0[v5].death - qty_0[v5].birth) 
/ ( double)( qty_0[v5].death - qty_0[v5].birth) 
LODWORD( v5) = ( int)( ( double)( *( int *)( ( char *)&qty_0->size + v5) 
* *( int *)( ( char *)&qty_0->freq + v5) 
* floor_log2_wide( *( int *)( ( char *)&qty_0->n_refs + v5))) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
/ ( double)( *( int *)( ( char *)&qty_0->death + v5) - *( int *)( ( char *)&qty_0->birth + v5)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
- ( int)( ( double)( qty_0[v6].size * qty_0[v6].freq * floor_log2_wide( qty_0[v6].n_refs)) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
/ ( double)( qty_0[v6].death - qty_0[v6].birth) 
v13 = ( tree_node *)*( &global_trees + 12); 
v13 = ( tree_node *)*( &global_trees + 11); 
aka = ( tree_node *)prev_try->aka; 
v11 = ( tree_node *)prev_try->aka; 
if ( ( sch_istable[( unsigned __int8)ch_0] & 0xC00) == 0 ) 
if ( v6 == -1 || ( sch_istable[( unsigned __int8)v6] & 0xC00) != 0 ) 
while ( ( sch_istable[v3] & 4) != 0 ) 
while ( ( sch_istable[( unsigned __int8)v9] & 0xC00) == 0 ) 
while ( v10 != -1 && ( sch_istable[( unsigned __int8)v10] & 1) != 0 ); 
if ( in_section_0 != in_const ) 
in_section_0 = in_const; 
ereal_from_uint( &d, low, high, ( machine_mode)v7); 
ereal_from_int( &d, low, high, ( machine_mode)v7); 
constructor_stack_0 = v2; 
constructor_depth = spelling_0 - spelling_base; 
v9 = ( tree_node *)*( &global_trees + 17); 
rtx i; // rax 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
for ( i = cfun->expr->x_forced_labels; i; i = ( rtx)i[1] ) 
v4.rtwint = ( __int64)i->fld[0]; 
rtx v170; // rax 
rtx v172; // rax 
rtx v189; // rdx 
rtx v277; // rax 
rtx v279; // rax 
rtx v412; // rdx 
rtx v481; // rdx 
rtx v755; // rdx 
recog_data_0.insn = 0LL; 
rtx x6; // [rsp+0h] [rbp-48h] 
rtx x6n; // [rsp+0h] [rbp-48h] 
rtx x6ct; // [rsp+0h] [rbp-48h] 
rtx x6cw; // [rsp+0h] [rbp-48h] 
rtx x6cx; // [rsp+0h] [rbp-48h] 
rtx x6dc; // [rsp+0h] [rbp-48h] 
rtx x6dg; // [rsp+0h] [rbp-48h] 
recog_data_0.operand[0] = v7; 
recog_data_0.operand[1] = ( rtx)v40; 
recog_data_0.operand[0] = ( rtx)v254; 
recog_data_0.operand[1] = v255; 
recog_data_0.operand[2] = v343; 
recog_data_0.operand[0] = ( rtx)v254; 
recog_data_0.operand[1] = v258; 
recog_data_0.operand[2] = v263; 
recog_data_0.operand[0] = v252; 
recog_data_0.operand[0] = v252; 
recog_data_0.operand[0] = v168; 
v176 = rtx_equal_p( *( rtx *)( v175 + 8), recog_data_0.operand[0]); 
recog_data_0.operand[0] = v48; 
frees = undobuf_0.frees; 
if ( undobuf_0.frees ) 
undobuf_0.frees = undobuf_0.frees->next; 
undobuf_0.frees = undobuf_0.frees->next; 
undos = undobuf_0.undos; 
undobuf_0.undos = frees; 
reg_dead_regno = v20; 
reg_dead_flag = 0; 
reg_dead_endregno = v20 + 1; 
v25 = ( ( unsigned int)( mode_class_0[v21] - 5) < 2) + 1; 
reg_dead_flag = 0; 
reg_dead_endregno = v20 + v25; 
if ( ( unsigned int)v20 >= reg_dead_endregno ) 
v29 = reg_dead_flag; 
if ( reg_dead_flag ) 
if ( reg_dead_flag != 1 ) 
if ( find_regno_note( nonnote_insn, REG_DEAD, reg_dead_regno) ) 
v27 = reg_dead_endregno; 
LODWORD( v20) = reg_dead_regno; 
v7 = &costs_0[rtx->fld[0].rtuint]; 
v8 = ix86_memory_move_cost( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), ( reg_class)v3, 1); 
v8 = ix86_memory_move_cost( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), ( reg_class)v3, 1); 
record_address_regs( rtx->fld[v12].rtx, ( reg_class)v3, scale); 
v10 = lang_hooks_0.expand_constant( exp); 
v34 = ( tree_node *)v33[4]; 
v34 = ( tree_node *)v33[4]; 
v7 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
rtx v19; // rax 
rtx v20; // rbx 
rtx rtwint; // rax 
rtx v53; // rax 
rtx dest_rega; // [rsp+28h] [rbp-50h] 
rtx v65; // [rsp+30h] [rbp-48h] 
allocno_0[v10].hard_reg_conflicts |= hard_regs_live; 
v6 = allocno_0; 
reg_set_0 **v7; // rax 
reg_set_0 **v7; // rax 
reg_set_table = ( reg_set_0 **)xrealloc( reg_set_table, ( unsigned int)( 8 * ( regno + 100))); 
v7 = &reg_set_table[regno]; 
*( _QWORD *)object_base = *v7; 
*v7 = ( reg_set_0 *)object_base; 
*v7 = ( reg_set_0 *)object_base; 
rtx valuea[8]; // [rsp+18h] [rbp-40h] BYREF 
valuea[0] = value; 
v3 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
if ( !valuea[0] 
|| !reg_overlap_mentioned_p( reg, valuea[0]) 
v20 = valuea[0]; 
if ( valuea[0] ) 
update_table_tick( valuea[0]); 
v20 = valuea[0]; 
v20 = valuea[0]; 
v20 = valuea[0]; 
v24 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v18); 
rtx v21; // rax 
v31 = ( ( unsigned int)( mode_class_0[v28] - 5) < 2) + 1; 
v15 = ( ( unsigned int)( mode_class_0[v16] - 5) < 2) + 1; 
if ( v10 != 69 || ( v21 = *v9, LODWORD( v22) = *( _DWORD *)*v9 - 1, ( int)v22 < 0) ) 
if ( loc != ( rtx *)&v21->fld[v22] ) 
v23 = refers_to_regno_for_reload_p( regno, endregno, v21->fld[( int)v22].rtx, loc); 
v21 = *v9; 
v27 = ( ( unsigned int)( mode_class_0[v29] - 5) < 2) + 1; 
v18 = subreg_regno_offset( v15, ( machine_mode)*( unsigned __int8 *)( v14.rtwint + 2), *( _DWORD *)&v5[1], v16) + v15; 
v19 = ( ( unsigned int)( mode_class_0[v16] - 5) < 2) + 1; 
if ( reg_pref_0 ) 
return reg_pref_0[regno].altclass; 
v13 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v17 = ( ( unsigned int)( mode_class_0[v16] - 5) < 2) + 1; 
v5 = ( unsigned int)( mode_class_0[mode] - 5) <= 1; 
v11 = ( unsigned int)( mode_class_0[v4] - 5) <= 1; 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 1); 
post_mark_life( ( unsigned int)rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), birth, 2 * this_insn_number, v6); 
v8 = qty_0; 
v10 = next_qty_0; 
*v4 = next_qty_0; 
next_qty_0 = v10 + 1; 
reg_offset_0[rtint] = 0; 
v14 = &qty_0[v12]; 
v16 = &qty_0[v12]; 
qty_0[v5].death = -1; 
( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)) 
v12 = ( ( unsigned int)( mode_class_0[v15] - 5) < 2) + 1; 
( machine_mode)*( unsigned __int8 *)( v11.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)rtx + 2)) 
v12 = ( ( unsigned int)( mode_class_0[v19] - 5) < 2) + 1; 
if ( reg_pref_0 ) 
return reg_pref_0[regno].prefclass; 
if ( reg_note ) 
v37 = *( _WORD *)reg_note->fld[0].rtwint; 
v35 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v32 + 2)] - 5) < 2) + rtint + 1; 
v36 = ( ( unsigned int)( mode_class_0[*( ( unsigned __int8 *)v32 + 2)] - 5) < 2) + rtint; 
costs_0 = v4; 
memset( costs_0, 0, n); 
reg_pref_0 = reg_pref_buffer; 
v15 = reg_class_names_1[v12++]; 
fprintf( dump, " %s:%i", v15, ( unsigned int)costs_0[v11].cost[v14]); 
fprintf( dump, " MEM:%i\n", ( unsigned int)costs_0[v13].mem_cost); 
v22 = &costs_0[v18]; 
v26 = &reg_pref_0[v19]; 
v30 = reg_class_names_1[( int)v20]; 
v26 = &reg_pref_0[v34]; 
fprintf( v16, " pref %s, else %s\n", v30, reg_class_names_1[v28]); 
v26 = &reg_pref_0[v34]; 
free( costs_0); 
reg_pref_0 = 0LL; 
if ( mode_class_0[v2] == MODE_FLOAT ) 
rtx regno_note; // r9 
rtx v122; // rax 
rtx v123; // r13 
rtx v125; // rbx 
rtx real_insn; // r14 
rtx v127; // rax 
rtx v130; // rsi 
rtx v140; // r8 
rtx v143; // rsi 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
closed_chains = 0LL; 
open_chains = 0LL; 
n_operands = recog_data_0.n_operands; 
if ( recog_data_0.n_operands > 0 ) 
v8 = ( reg_class *)( 32LL * ( int)which_alternative + 9947208); 
if ( recog_data_0.operand_type[v7] == OP_OUT ) 
recog_data_0.operand_type[v7] = OP_INOUT; 
v11 = recog_data_0.operand_loc[v10]; 
v12 = recog_data_0.operand_type[v10++]; 
to[v13] = ( HARD_REG_ELT_TYPE)recog_data_0.operand[v13]; 
if ( *recog_data_0.constraints[v13] ) 
*recog_data_0.operand_loc[v13] = global_rtl[1]; 
n_dups = recog_data_0.n_dups; 
page_group_0 *v3; // rbx 
page_group_0 *v3; // rbx 
v1 = ( page_entry_0 *)( &G + 2640); 
v3 = ( page_group_0 *)( &G + 2648); 
v3 = ( page_group_0 *)( &G + 2648); 
v3 = page_groups; 
v3->next = page_groups->next; 
page_groups = v3->next; 
while ( v3->next ); 
rtx *v29; // rbp 
rtx v31; // r13 
rtx *v35; // r14 
rtx v38; // rax 
rtx v44; // rbx 
rtx n; // rbx 
rtx v59; // r12 
rtx v72; // rax 
rtx *v149; // rbx 
rtx v161; // rax 
rtx v40; // rax 
rtx v43; // rax 
rtx v45; // rbp 
rtx v46; // r13 
rtx v49; // r9 
rtx v50; // rbp 
rtx v53; // rax 
rtx v54; // rsi 
rtx *v70; // rdx 
rtx *v11; // rbp 
$46E27178171750CEF28E8B43DEBEAD96 *v16; // r13 
$46E27178171750CEF28E8B43DEBEAD96 *v16; // r13 
rtx v24; // rdi 
v35 = ( unsigned int)( mode_class_0[v31] - 5) <= 1; 
if ( ( unsigned int)( mode_class_0[v14] - 5) <= 1 ) 
v16 = &reg_state[( int)rtuint]; 
v17 = v16->use_index - 1; 
v16->use_index = v17; 
v16->offset = v4; 
v16->use_ruid = v28; 
if ( rtx_equal_p( v4, v16->offset) ) 
rtx last_insn; // rax 
rtx v21; // rbp 
$46E27178171750CEF28E8B43DEBEAD96 *v29; // rdx 
$46E27178171750CEF28E8B43DEBEAD96 *v29; // rdx 
rtx v40; // rax 
rtx v41; // rbx 
rtx v42; // r8 
rtx nonnote_insn; // rax 
rtx v64; // r10 
rtx v66; // r9 
v9 = ix86_memory_move_cost( ( machine_mode)*( ( unsigned __int8 *)v4 + 2), dclass, 1); 
( machine_mode)*( ( unsigned __int8 *)v4 + 2), 
v10 = cselib_lookup( v4, ( machine_mode)*( unsigned __int8 *)( set->fld[0].rtwint + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)loc + 2), 
*( _OWORD *)&e->pred_next = 0LL; 
*( _OWORD *)&e->src = 0LL; 
*( _OWORD *)&e->insns = 0LL; 
*( _OWORD *)&e->flags = 0LL; 
v10 = ( tree_node *)v9[5]; 
v22 = *( tree_node **)( v15 + 64); 
v22 = ( tree_node *)v15; 
if ( use == sibcall_use_tail_recursion_0 ) 
else if ( use == sibcall_use_sibcall_0 ) 
if ( use != sibcall_use_normal_0 ) 
rtx v4; // r8 
rtx v5; // rax 
if ( !rtx_equal_p( rtx, memref->fld[0].rtx) || ( v4 = memref, v3 != *( ( unsigned __int8 *)memref + 2)) ) 
v5 = gen_rtx_fmt_e0( MEM, v3, rtx); 
*( _QWORD *)&v5[1] = 0LL; 
v4 = v5; 
v4 = v5; 
LOBYTE( v5) = *( ( _BYTE *)memref + 3) & 8 | *( ( _BYTE *)v5 + 3) & 0xF7; 
LOBYTE( v5) = *( ( _BYTE *)memref + 3) & 8 | *( ( _BYTE *)v5 + 3) & 0xF7; 
*( ( _BYTE *)v4 + 3) = ( _BYTE)v5; 
*( ( _BYTE *)v4 + 3) = ( _BYTE)v5; 
LOBYTE( v5) = *( ( _BYTE *)memref + 3) & 0x10 | ( unsigned __int8)v5 & 0xEF; 
LOBYTE( v5) = *( ( _BYTE *)memref + 3) & 0x10 | ( unsigned __int8)v5 & 0xEF; 
*( ( _BYTE *)v4 + 3) = ( _BYTE)v5; 
*( ( _BYTE *)v4 + 3) = ( _BYTE)v5; 
LOBYTE( v5) = *( ( _BYTE *)memref + 3) & 0x80 | ( unsigned __int8)v5 & 0x7F; 
rtx v9; // rax 
rtx *v12; // rbx 
rtx v15; // rdx 
rtx v16; // rdx 
rtx v20; // rax 
v9 = eliminate_regs( rtx, mem_mode, usage); 
rtx = v9; 
if ( *fld == v9 ) 
v15 = reg_equiv_constant[rtuint]; 
if ( v15 || ( v15 = reg_equiv_mem[rtuint]) != 0LL ) 
if ( v15 || ( v15 = reg_equiv_mem[rtuint]) != 0LL ) 
*fld = v15; 
*fld = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v9 + 2), v19); 
*fld = gen_rtx_MEM( ( machine_mode)*( ( unsigned __int8 *)v9 + 2), v19); 
if ( ( mode_class_0[v4] & 0xFFFFFFFB) != 2 ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( v9.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
rtx last_insn; // r10 
rtx j; // r11 
rtx v12; // rbp 
last_insn = get_last_insn( ); 
if ( last_insn ) 
j = 0LL; 
v12 = 0LL; 
while ( *( _WORD *)last_insn == 37 ) 
if ( last_insn[2].fld[0].rtint == -89 ) 
j = last_insn; 
j = last_insn; 
last_insn = ( rtx)last_insn[1]; 
if ( !last_insn ) 
if ( contains( last_insn, v10) ) 
v12 = last_insn; 
v12 = last_insn; 
if ( ( sch_istable[v6] & 4) != 0 ) 
while ( ( sch_istable[v7] & 4) != 0 ); 
v26 = ( tree_node *)i5[5]; 
sprintf( p, &off_646752[1], v5); 
v7 = prefixes_18[v3][( BYTE2( decl->block.supercontext) & 8) != 0]; 
timevar_push( TV_REST_OF_COMPILATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_INTEGRATION_0); 
timevar_pop( TV_INTEGRATION_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_JUMP_0); 
timevar_pop( TV_JUMP_0); 
timevar_push( TV_TO_SSA_0); 
timevar_pop( TV_TO_SSA_0); 
timevar_push( TV_SSA_CCP_0); 
timevar_pop( TV_SSA_CCP_0); 
timevar_push( TV_SSA_DCE_0); 
timevar_push( TV_VARCONST_0); 
timevar_pop( TV_VARCONST_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_push( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
timevar_pop( TV_SYMOUT_0); 
rtx v4; // rax 
rtx line_note; // rbp 
rtx v10; // rax 
v4 = head; 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
if ( *( _WORD *)v4 == 37 && v4[2].fld[0].rtint > 0 ) 
v4 = ( rtx)v4[1]; 
while ( v4 ); 
v4 = 0LL; 
v4 = v2; 
line_note = h_i_d[rtint].line_note; 
if ( line_note != v4 
if ( line_note != v4 
&& line_note 
&& ( !v4 || line_note[2].fld[0].rtint != v4[2].fld[0].rtint || line_note[2] != v4[2]) ) 
&& ( !v4 || line_note[2].fld[0].rtint != v4[2].fld[0].rtint || line_note[2] != v4[2]) ) 
reverse_condition_0( ( rtx_code)v1); 
return CSWTCH_103[v1]; 
( rtx_code)*( _WORD *)comparison, 
rtx v7; // rdx 
rtx v9; // rax 
v7 = head; 
while ( *( _WORD *)v7 != 37 ) 
v7 = v7[1].fld[0].rtx; 
v7 = v7[1].fld[0].rtx; 
if ( rtx == v7 ) 
v8 = (  struct rtx_def *)v7[1]; 
v9 = v7; 
v9 = v7; 
v10 = v9; 
v9 = v9[1].fld[0].rtx; 
v9 = v9[1].fld[0].rtx; 
if ( rtx == v9 ) 
if ( *( _WORD *)v9 != 37 ) 
v8[1].fld[0].rtwint = ( __int64)v9; 
rtx v5; // rcx 
rtx v10; // rax 
v5 = head; 
while ( *( _WORD *)v5 != 37 ) 
v5 = v5[1].fld[0].rtx; 
v5 = v5[1].fld[0].rtx; 
if ( rtx == v5 ) 
v9 = ( __int64)v5[1]; 
v10 = v5; 
v10 = v5; 
v11.rtwint = ( __int64)v10; 
v10 = v10[1].fld[0].rtx; 
v10 = v10[1].fld[0].rtx; 
*( _QWORD *)( v9 + 24) = v10; 
if ( v10 ) 
*( _QWORD *)&v10[1] = v9; 
if ( rtx == v10 ) 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
v8 = expand_divmod( 0, TRUNC_DIV_EXPR, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v6, v7, 0LL, 1); 
return expand_mult( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v8, v9, 0LL, 1); 
v1 = gen_reg_rtx( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4)); 
( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 
return expand_simple_binop( ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), AND, v4, v3, v4, 0, OPTAB_LIB_WIDEN); 
fancy_abort( ( const char *)&a, 8957, "rtl_for_decl_location"); 
if ( mode_class_0[v18] == MODE_INT ) 
if ( _bittest( &v27, ix86_cpu) || ( v28 = *( ( unsigned __int8 *)v2 + 2), ( mode_class_0[v28] & 0xFFFFFFF9) != 1) ) 
v18 = cselib_lookup( x, ( machine_mode)*( ( unsigned __int8 *)x + 2), 0); 
v17 = cselib_lookup( y, ( machine_mode)*( ( unsigned __int8 *)y + 2), 0); 
v6 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( v5.rtwint + 2), x); 
v4 = gen_lowpart_for_combine( ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2), y); 
if ( *( _OWORD *)&x == 0LL ) 
rtx real_insn; // rbx 
rtx *v24; // r12 
rtx *i; // rbp 
rtx v27; // rdx 
rtx v28; // rcx 
real_insn = next_real_insn( rtx); 
result = real_insn == next_real_insn( v4->fld[0].rtx); 
v37 = subreg_regno_offset( v36, ( machine_mode)*( unsigned __int8 *)( v34.rtwint + 2), v35, v13); 
( machine_mode)*( unsigned __int8 *)( v32.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)v4 + 2)); 
return CSWTCH_156[v1]; 
rtx *v12; // r14 
v12 = ( rtx *)( rtwint + 2); 
while ( !rtx_varies_p( *v12, for_alias) ) 
if ( ++v12 == ( rtx *)v13 ) 
rtx v16; // rax 
save_expr_list_5 = 0LL; 
for ( i = save_expr_list_5; i; i = i->common.chain ) 
v16 = elements->decl.rtl; 
if ( !v16 || *( _WORD *)v16 != 66 ) 
if ( !v16 || *( _WORD *)v16 != 66 ) 
rtl = v16->fld[0].rtx; 
save_expr_list_5 = tree_cons( elements, 0LL, save_expr_list_5); 
save_expr_list_5 = tree_cons( elements, 0LL, save_expr_list_5); 
return lang_hooks_0.safe_from_p( rtx, elements) != 0; 
v12 = ( machine_mode *)( regno_save_mode + 4); 
v31 = ( ( unsigned int)( mode_class_0[v27] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[v44] - 5) > 1 ) 
v17 = gen_realpart( ( machine_mode)*( unsigned __int8 *)( rtl->fld[0].rtwint + 2), rtl); 
v18 = gen_imagpart( ( machine_mode)*( ( unsigned __int8 *)v17 + 2), rtl); 
rtx v4; // rcx 
v4 = line_note_head[b]; 
v5[rtint].line_note = v4; 
v4 = head; 
( save_level)( x_block_stack->next == 0LL), 
rtx v10; // rbp 
rtx nonnote_insn; // rax 
rtx v13; // r12 
rtx v14; // rax 
rtx v17; // r8 
rtx v22; // rax 
rtx v29; // rax 
rtx cont; // rax 
rtx v37; // rax 
v14 = ( ( unsigned int)( mode_class_0[v11] - 5) < 2) + 1; 
v21 = ( ( unsigned int)( mode_class_0[v26] - 5) < 2) + 1; 
cselib_lookup( rtwint->fld[0].rtx, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), 1); 
if ( ( unsigned int)( mode_class_0[v10] - 5) > 1 ) 
rtx v16; // r15 
rtx pending_read_insns; // rbx 
rtx pending_read_mems; // r14 
rtx pending_write_insns; // rbx 
rtx i; // r14 
rtx last_pending_memory_flush; // rbx 
rtx v25; // rax 
rtx v32; // rax 
rtx *mem_list; // [rsp+0h] [rbp-40h] 
rtx v27; // [rsp+0h] [rbp-38h] BYREF 
rtx tailp; // [rsp+8h] [rbp-30h] BYREF 
get_block_head_tail( v7, &v27, &tailp); 
get_block_head_tail( v7, &v27, &tailp); 
v11 = v27; 
v12 = tailp[1].fld[0].rtx; 
if ( v12 != v27 ) 
rtx v14; // rbp 
rtx *vec; // rcx 
rtx *v18; // rbp 
rtx v23; // rbp 
rtx v37; // r14 
rtx v45; // rbx 
rtx v46; // r12 
deps_0 *v5; // rdx 
deps_0 *v5; // rdx 
deps_0 *v9; // rdi 
deps_0 *v9; // rdi 
deps_0 *v39; // rdi 
deps_0 *v39; // rdi 
deps_0 *v52; // rdi 
deps_0 *v52; // rdi 
deps_0 *v81; // rax 
deps_0 *v81; // rax 
rtx headp; // [rsp+A0h] [rbp-B8h] BYREF 
rtx tail; // [rsp+A8h] [rbp-B0h] BYREF 
deps_0 v315; // [rsp+B0h] [rbp-A8h] BYREF 
deps_0 v315; // [rsp+B0h] [rbp-A8h] BYREF 
LODWORD( tail) = 1; 
LODWORD( v315.pending_read_insns) = h_i_d[*( int *)( v242 + 8)].luid - h_i_d[*( int *)( v243 + 8)].luid; 
fancy_abort( ( const char *)&a, 9575, "scope_die_for"); 
if ( ( unsigned int)debug_info_level_0 > DINFO_LEVEL_TERSE && ( *( ( _BYTE *)&rtl[1] + 1) & 0x40) == 0 ) 
fancy_abort( ( const char *)&a, 9604, "scope_die_for"); 
rtx v4; // rbp 
v4 = rtx; 
if ( active_insn_p( v4) ) 
if ( ( unsigned __int16)( **( _WORD **)&v4[2] - 44) > 1u ) 
if ( *( _WORD *)v4 != 37 ) 
rtint = v4[2].fld[0].rtint; 
v3 = ( __int64)v4[2]; 
delete_insn( v4); 
delete_insn( v4); 
insn_scopes->data.l[v4->fld[0].rtint] = v3; 
v2 = *( tree_node **)( low + 128); 
if ( v2 == ( tree_node *)*( &global_trees + 24) ) 
v7 = *( tree_node **)( low + 104); 
if ( v7 != ( tree_node *)global_trees ) 
v5 = *( tree_node **)( low + 104); 
if ( v5 && v5 != ( tree_node *)global_trees ) 
if ( initial != ( tree_node *)global_trees ) 
if ( initial != ( tree_node *)global_trees ) 
if ( constructor_range_stack_0 ) 
while ( constructor_stack_0->implicit ) 
if ( !constructor_range_stack_0 ) 
if ( !( ( unsigned __int64)constructor_range_stack_0 | ( unsigned __int64)v8) ) 
if ( !constructor_range_stack_0 ) 
if ( constructor_range_stack_0 ) 
v8 = gen_rtx_CONST_INT_0( ( machine_mode)mode_size[*( ( unsigned __int8 *)mem + 2)], 0LL); 
v6 = *( tree_node **)( v5 + 8); 
v6 = ( tree_node *)ref[1]; 
honor_readonly = lang_hooks_0.honor_readonly; 
if ( !lang_hooks_0.honor_readonly || ( v14 & 0x10) == 0 && ( *( ( _BYTE *)&elements->block.common + 17) & 0x10) == 0 ) 
mem_attrs = get_mem_attrs( alias, v31, const_int_rtx[64], v7, align, ( machine_mode)*( ( unsigned __int8 *)ref + 2)); 
mem_attrs = get_mem_attrs( alias, v6, offset, v7, align, ( machine_mode)*( ( unsigned __int8 *)ref + 2)); 
v4 = ( page_entry_0 **)xcalloc( 1LL << ( 24 - LOBYTE( G.lg_pagesize)), 8uLL); 
if ( !ix86_hard_regno_mode_ok( v7, *( ( machine_mode *)&rld + 26 * r + 7)) ) 
if ( *( _BYTE *)( v8 + 2) && !ix86_hard_regno_mode_ok( v7, ( machine_mode)*( unsigned __int8 *)( v8 + 2)) ) 
if ( !ix86_hard_regno_mode_ok( v7, ( machine_mode)*( unsigned __int8 *)( v9 + 2)) ) 
mark_reload_reg_in_use( v11, *( ( _DWORD *)v12 + 18), *( ( reload_type *)v12 + 23), *( ( machine_mode *)v12 + 7)); 
mark_reload_reg_in_use( v11, *( ( _DWORD *)v12 + 18), *( ( reload_type *)v12 + 23), *( ( machine_mode *)v12 + 7)); 
result = gen_rtx_fmt_ee( EXPR_LIST, ( machine_mode)kind, datum, insn[3].fld[0].rtx); 
v7 = ( ( unsigned int)( mode_class_0[mode] - 5) < 2) + 1; 
v9 = ( ( unsigned int)( mode_class_0[v8] - 5) < 2) + 1; 
rtx v9; // rax 
rtx v10; // rax 
return gen_rtx_fmt_ee( PLUS, ( machine_mode)*( ( unsigned __int8 *)x + 2), x, c); 
v10 = gen_rtx_CONST_INT( VOIDmode, v2->fld[0].rtwint + c->fld[0].rtwint); 
v6 = v10; 
v9 = sge_plus_constant( *( rtx *)&x[1], c); 
rtx = v9; 
rtx v43; // rbx 
rtx align_tab[16]; // [rsp+20h] [rbp-B8h] BYREF 
memset( align_tab, 0, sizeof( align_tab)); 
memset( align_tab, 0, sizeof( align_tab)); 
*v23 = align_tab[0]; 
*v23 = align_tab[0]; 
*v23 = align_tab[v24]; 
align_tab[v25--] = i; 
if ( ( tree_node *)*( &global_trees + 10) == section_name ) 
if ( ( tree_node *)*( &global_trees + 9) == section_name ) 
if ( ( tree_node *)*( &global_trees + 8) == section_name ) 
if ( ( tree_node *)*( &global_trees + 7) == section_name ) 
if ( ( tree_node *)*( &global_trees + 6) == section_name ) 
v13 = *( _OWORD *)&imag->block.vars != *( _OWORD *)&elements->block.vars 
v13 = *( _OWORD *)&imag->block.vars != *( _OWORD *)&elements->block.vars 
v2 = ( tree_node *)*( &global_trees + 25); 
if ( section_name == ( tree_node *)*( &global_trees + 24) ) 
v17 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), *( rtx *)&rtx[1], v8); 
v18 = simplify_and_const_int( 0LL, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), rtx->fld[0].rtx, v8); 
v19 = gen_binary( ( rtx_code)*( _WORD *)rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v18, v17); 
v19 = gen_binary( ( rtx_code)*( _WORD *)rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v18, v17); 
rtx compound_operation; // r14 
rtx v58; // rbp 
rtx v78; // rax 
rtx v83; // rax 
rtx v15; // r8 
rtx result; // rax 
rtx v21; // rax 
rtx v28; // rax 
rtx v29; // r9 
rtx v56; // rax 
rtx v62; // rax 
rtx v12; // r10 
rtx *v18; // rdi 
rtx compound_operation; // rax 
rtx v21; // rdx 
rtx v34; // rdx 
_OWORD *v10; // rbx 
_OWORD *v10; // rbx 
_OWORD *v27; // rax 
_OWORD *v27; // rax 
_OWORD *v29; // r14 
_OWORD *v29; // r14 
_OWORD *v30; // rbx 
_OWORD *v30; // rbx 
_OWORD *v31; // r15 
_OWORD *v31; // r15 
rtx v48; // rax 
_OWORD *v55; // rbp 
_OWORD *v55; // rbp 
_OWORD *v61; // rax 
_OWORD *v61; // rax 
if ( mode_class_0[*( ( unsigned __int8 *)op0 + 2)] == MODE_CC ) 
v10 = mode_class_0[mode]; 
v43 = mode_class_0[mode]; 
&& ( ( mode_class_0[*( ( unsigned __int8 *)v8 + 2)] & 0xFFFFFFFB) != 2 
&& mode_class_0[*( ( unsigned __int8 *)v8 + 2)] != MODE_VECTOR_FLOAT 
if ( *( _WORD *)v9 == 55 && mode_class_0[*( ( unsigned __int8 *)v8 + 2)] == MODE_FLOAT ) 
result = simplify_gen_subreg( ( machine_mode)*( ( unsigned __int8 *)x + 2), v28, v27, v25); 
return simplify_relational_operation( ( rtx_code)*( _WORD *)x, v9, v7.rtx, ( rtx)v8); 
( rtx_code)*( _WORD *)x, 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2)); 
( rtx_code)*( _WORD *)x, 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
return simplify_binary_operation( ( rtx_code)v2, v1, v6, rtx); 
v63 = gen_rtx_fmt_e( ( rtx_code)( ( v13 != ASHIFTRT) + 120), mode, v61); 
if ( v8 == ( ( ( unsigned int)target_flags & 0x2000000) == 0 ? 4 : 8) && v16 > v8 && mode_class_0[v15] == MODE_INT ) 
rtx = simplify_subreg( outermode, op->fld[0].rtx, ( machine_mode)*( ( unsigned __int8 *)rtx + 2), v10); 
rtx = simplify_subreg( outermode, v29.rtx, ( machine_mode)*( unsigned __int8 *)( v29.rtwint + 2), v30); 
if ( mode_class_0[v15] != MODE_INT ) 
if ( mode_class_0[v40] != MODE_INT ) 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)x + 2), x->fld[0].rtx, &val0); 
decode_rtx_const( ( machine_mode)*( ( unsigned __int8 *)v1 + 2), *( rtx *)&v1[1], &val1); 
&& ( ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT 
&& ( ( mode_class_0[mode] & 0xFFFFFFFB) != 2 && mode_class_0[mode] != MODE_VECTOR_FLOAT 
v19 = simplify_relational_operation( ( rtx_code)*( _WORD *)op0, op0_mode, v16.rtx, ( rtx)v17); 
*( _OWORD *)v32.r = *( _OWORD *)&args.operand; 
*( _OWORD *)v31.r = *( _OWORD *)&args.operand; 
*( _OWORD *)v33.r = *( _OWORD *)&args.operand; 
v14 = mode_class_0[v4]; 
if ( mode_class_0[v13] == MODE_FLOAT && v14 == MODE_INT && v11 - 1 <= 0x3F ) 
v12 = ( tree_node *)*( &global_trees + 11); 
v7 = ( tree_node *)*( &global_trees + 11); 
v2 = size_htab_11; 
if ( !size_htab_11 ) 
size_htab_11 = htab_create( 0x400uLL, size_htab_hash, size_htab_eq, 0LL); 
ggc_add_deletable_htab( size_htab_11, 0LL, 0LL); 
new_const_10 = make_node( INTEGER_CST); 
ggc_add_tree_root( &new_const_10, 1); 
v2 = size_htab_11; 
v3 = new_const_10; 
new_const_10->int_cst.int_cst.low = number; 
v3 = new_const_10; 
v9 = new_const_10; 
*slot = new_const_10; 
new_const_10 = make_node( INTEGER_CST); 
v9 = sch_istable[*( v7 - 1)]; 
v13 = cpp_trigraph_map[*( ( unsigned __int8 *)buffer->cur + 1)]; 
v4 = cpp_trigraph_map[v17]; 
fancy_abort( ( const char *)&a, 4588, "AT_ref"); 
fancy_abort( ( const char *)&a, 5055, "splice_child_die"); 
recog_data_0.operand[0] = v3.rtx; 
recog_data_0.operand[1] = ( rtx)v147; 
return gen_split_1133( recog_data_0.operand); 
recog_data_0.operand[1] = ( rtx)v46; 
return gen_split_1135( recog_data_0.operand); 
recog_data_0.operand[0] = v3.rtx; 
recog_data_0.operand[1] = v113; 
return gen_split_943( recog_data_0.operand); 
recog_data_0.operand[0] = v3.rtx; 
recog_data_0.operand[1] = ( rtx)v51; 
rtx v6; // rax 
v6 = split_insn( v4); 
if ( v6 ) 
while ( *( _WORD *)v6 == 35 ) 
v6 = ( rtx)v6[1]; 
v4 = v6; 
recog_data_0.insn = 0LL; 
recog_data_0.operand[0] = ( rtx)v5; 
return gen_split_1178( recog_data_0.operand); 
recog_data_0.operand[0] = ( rtx)v5; 
return ( rtx)gen_split_1179( &recog_data_0); 
recog_data_0.operand[0] = ( rtx)v40; 
recog_data_0.operand[1] = v184; 
recog_data_0.operand[2] = v186; 
recog_data_0.operand[3] = v188; 
recog_data_0.operand[4] = v190; 
return gen_split_938( recog_data_0.operand); 
recog_data_0.operand[1] = v170; 
recog_data_0.operand[0] = *( rtx *)( v44 + 16); 
if ( !rtx_equal_p( *( rtx *)( v446 + 8), recog_data_0.operand[1]) ) 
recog_data_0.operand[2] = v453; 
&& recog_data_0.operand[1]->fld[0].rtint != 2 ) 
rtx v7; // rdi 
rtx v8; // rdx 
v7 = rtx; 
v8 = rtx; 
if ( *( _WORD *)v8 == 37 && ( unsigned int)( v8[2].fld[0].rtint + 98) <= 5 ) 
if ( *( _WORD *)v8 == 37 && ( unsigned int)( v8[2].fld[0].rtint + 98) <= 5 ) 
v5 = v8; 
if ( v7 == v8 ) 
if ( v7 == v8 ) 
v7 = rtx; 
v9 = ( __int64)v7[1]; 
v10 = ( __int64)v8[1]; 
v8[1].fld[0].rtwint = ( __int64)v7; 
v8[1].fld[0].rtwint = ( __int64)v7; 
*( _QWORD *)&v8[1] = v9; 
*( _QWORD *)( v9 + 24) = v8; 
rtx m; // rbp 
edge_info_0 = v7; 
edge_info_0[edge_index] = succ->succ_next; 
v11 = edge_info_0; 
v36 = edge_info_0; 
for ( m = first_insn_after_basic_block_note( v62); m; m = m[1].fld[0].rtx ) 
for ( m = first_insn_after_basic_block_note( v62); m; m = m[1].fld[0].rtx ) 
for ( m = first_insn_after_basic_block_note( v62); m; m = m[1].fld[0].rtx ) 
$7E965715368205AFDBD59B4566E36A4D *v3; // rax 
$7E965715368205AFDBD59B4566E36A4D *v3; // rax 
unprocessed_instructions = varray_init( 0x40uLL, 8uLL, ( const char *)&va.elements_used + 2); 
v3 = ( $7E965715368205AFDBD59B4566E36A4D *)xmalloc( 0x10uLL); 
v3 = ( $7E965715368205AFDBD59B4566E36A4D *)xmalloc( 0x10uLL); 
v3->length = v2; 
p_data = &v3->data; 
cdbte = v3; 
fancy_abort( ( const char *)&va, 247, "find_control_dependence"); 
fancy_abort( ( const char *)&va, 185, "set_control_dependent_block_to_edge_map_bit"); 
fancy_abort( ( const char *)&va, 399, "find_inherently_necessary"); 
fancy_abort( ( const char *)&va, 737, "ssa_eliminate_dead_code"); 
v4 = build_nt( ( tree_code)v1, v3); 
if ( ( mode_class_0[v1] & 0xFFFFFFFB) != 2 && mode_class_0[v1] != MODE_VECTOR_FLOAT ) 
if ( ( mode_class_0[v1] & 0xFFFFFFFB) != 2 && mode_class_0[v1] != MODE_VECTOR_FLOAT ) 
v5->constructor_stack = constructor_stack_0; 
v5->constructor_range_stack = constructor_range_stack_0; 
v5->spelling = spelling_0; 
v8 = initializer_stack_0; 
initializer_stack_0 = v5; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
spelling_0 = v13 + 1; 
constructor_stack_0 = 0LL; 
constructor_range_stack_0 = 0LL; 
spelling_0 = 0LL; 
v3 = ( tree_node *)*( &global_trees + 15); 
v4 = ( tree_node *)*( &global_trees + 17); 
return lang_hooks_0.staticp( arg); 
return lang_hooks_0.staticp( arg); 
v5 = ( tree_node *)*( &global_trees + 15); 
v6 = expand_expr( valist, 0LL, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), EXPAND_NORMAL); 
tree v8; // rax 
v8 = build( MODIFY_EXPR, valist->common.type, valist, tree); 
*( ( _BYTE *)&v8->block.common + 17) |= 1u; 
expand_expr( v8, const_int_rtx[64], VOIDmode, EXPAND_NORMAL); 
rtx v14; // r12 
rtx last_insn; // rax 
rtx v46; // rax 
rtx v49; // rcx 
tree set_constructor_bits; // rax 
tree v62; // r15 
get_mode_alignment( ( machine_mode)v18); 
rtx v48; // rax 
rtx v54; // rbp 
rtx v55; // r14 
v10 = gen_reg_rtx( ( machine_mode)*( ( unsigned __int8 *)target + 2)); 
v12 = expand_expr( imag, v10, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
v12 = expand_expr( imag, target, ( machine_mode)*( ( unsigned __int8 *)target + 2), EXPAND_NORMAL); 
( machine_mode)v29, 
( machine_mode)v30, 
v7 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)v8 + 2), v7); 
v7 = convert_to_mode( ( machine_mode)*( ( unsigned __int8 *)v8 + 2), v7, 1); 
v8 = *( tree_node **)( v7->int_cst.int_cst.low + 32); 
v23 = ( tree_node *)p_chain[4]; 
v47 = ( tree_node *)*( &global_trees + 25); 
v20 = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
v20 = operand_sub*(short *)0xforce( op0, offset, ( machine_mode)*( ( unsigned __int8 *)op0 + 2)); 
( machine_mode)*( unsigned __int8 *)( op0->fld[0].rtwint + 2)); 
v19 = operand_sub*(short *)0xforce( 
rtx v51; // r12 
rtx v55; // rax 
rtx v62; // rsi 
rtx v71; // rax 
rtx v78; // rax 
rtx *v80; // rax 
rtx v86; // rax 
rtx v96; // rdx 
rtx n; // rbx 
rtx v110; // rsi 
if ( check_mode && !ix86_hard_regno_mode_ok( v5, ( machine_mode)*( unsigned __int8 *)( v3.rtwint + 2)) ) 
( machine_mode)*( unsigned __int8 *)( v1.rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v8 = ( ( unsigned int)( mode_class_0[( int)v4] - 5) < 2) + 1; 
if ( ( unsigned int)( mode_class_0[( int)v4] - 5) <= 1 ) 
if ( ( unsigned int)( mode_class_0[v13] - 5) > 1 ) 
if ( ( unsigned int)( mode_class_0[( int)v4] - 5) <= 1 ) 
if ( ( unsigned int)( mode_class_0[ymode] - 5) > 1 ) 
rtx v24; // r11 
rtx v28; // rsi 
rtx *v29; // rdi 
rtx v38; // rax 
rtx v39; // rax 
rtx v40; // rax 
rtx v41; // rax 
rtx *v17; // r12 
rtx *v23; // r13 
rtx v30; // rax 
rtx v37; // rsi 
rtx *v39; // rdi 
rtx *v44; // rdi 
rtx **v45; // r12 
rtx *v50; // rbx 
rtx v53; // rsi 
rtx *v55; // r12 
rtx v64; // rdx 
rtx v70; // rdx 
rtx v46; // rax 
rtx op0c; // [rsp+8h] [rbp-70h] 
rtx op0d; // [rsp+8h] [rbp-70h] 
rtx x; // [rsp+10h] [rbp-68h] 
rtx *v63; // [rsp+18h] [rbp-60h] 
rtx inner; // [rsp+38h] [rbp-40h] BYREF 
if ( *( _WORD *)v36 == 74 && mode_class_0[*( unsigned __int8 *)( v36 + 2)] == MODE_CC ) 
rtx *v39; // r12 
rtx v40; // r14 
rtx v44; // rsi 
rtx v45; // rsi 
rtx *v46; // rbx 
rtx *v49; // r12 
rtx regno_note; // rbx 
rtx v51; // rax 
rtx v67; // rbx 
rtx v76; // rax 
rtx flags_user; // rax 
rtx v12; // rax 
flags_user = next_flags_user( insn); 
rtx = flags_user; 
if ( !flags_user ) 
v2 = ( __int64)flags_user[2]; 
v12 = next_flags_user( rtx); 
rtx = v12; 
if ( !v12 ) 
v2 = ( __int64)v12[2]; 
*( _WORD *)pat = swap_condition( ( rtx_code)*( _WORD *)pat); 
if ( in_section_0 != in_text ) 
in_section_0 = in_text; 
rtx end; // r13 
rtx last_insn; // r15 
rtx v24; // r14 
rtx v25; // r15 
rtx active_insn; // rax 
rtx v37; // r14 
rtx v48; // rdi 
rtx v49; // rsi 
rtx *v64; // r9 
rtx *v65; // rax 
v1 = stack_0; 
if ( stack_0->timevar != &timevars[timevar] ) 
stack_0 = next; 
if ( stack_0 ) 
timevar = stack_0->timevar; 
v3 = stack_0; 
if ( stack_0 ) 
v5 = stack_0->timevar; 
v5->elapsed.user = ( float)( v4 - start_time.user) + stack_0->timevar->elapsed.user; 
v3 = stack_0; 
stack_0 = v9; 
for ( i = 0; ; i = XFlittlenan[v13] ) 
lang_hooks_0.init_options( ); 
v10 = lang_hooks_0.decode_option( HIDWORD( v154) - v9, ( char **)v12); 
while ( &unk_7058B8 != ( _UNKNOWN *)v48 ) 
if ( &unk_7058B8 == ( _UNKNOWN *)v48 ) 
variable = ( const char *)&unk_6FF6E3; 
if ( !displayed_4 ) 
if ( !displayed_4 ) 
lang_hooks_0.name, 
v16 = __CFADD__( &v153, 32LL); 
while ( ( sch_istable[v36] & 4) != 0 ) 
if ( ( sch_istable[v90] & 4) == 0 ) 
while ( ( sch_istable[v92] & 4) != 0 ) 
while ( &unk_952F0A != ( _UNKNOWN *)v139 ); 
rtx v10; // r12 
v10 = assign_stack_local_1( BLKmode, 24LL, 0, cfun); 
v10 = assign_stack_local_1( BLKmode, 11LL, 0, cfun); 
node->int_cst.int_cst.high = ( __int64)v10; 
v10 = assign_stack_local_1( BLKmode, 24LL, 0, v9); 
v10 = assign_stack_local_1( BLKmode, 11LL, 0, v9); 
v11->int_cst.int_cst.high = ( __int64)v10; 
rtx = v10->fld[0].rtx; 
*( _OWORD *)&result->decl.common.type = 0LL; 
if ( *( _OWORD *)&t1->block.vars == 0LL ) 
rtx base_term; // rax 
rtx addr_0; // rax 
addr_0 = get_addr_0( x->fld[0].rtx); 
rtx = addr_0; 
base_term = find_base_term( rtx); 
if ( base_term ) 
if ( *( _WORD *)base_term == 67 || ( *( _DWORD *)base_term & 0x400FFFF) == 67108932 ) 
if ( *( _WORD *)base_term == 67 || ( *( _DWORD *)base_term & 0x400FFFF) == 67108932 ) 
if ( base_alias_check( rtx, v8, ( machine_mode)*( ( unsigned __int8 *)x + 2), v4) ) 
base_term = find_base_term( rtx); 
if ( base_term ) 
( machine_mode)*( unsigned __int8 *)( x->fld[0].rtwint + 2), 
( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v8 = *( tree_node **)( elements->int_cst.int_cst.low + 8); 
( tree_code)( ( *( ( _BYTE *)&elements->block.common + 17) & 1) == 0 ? TRUTH_ORIF_EXPR : TRUTH_OR_EXPR), 
imag = ( tree_node *)*( &global_trees + 11); 
rtx v244; // rax 
rtx v247; // r15 
rtx v274; // r14 
rtx elim_i2b; // [rsp+20h] [rbp-F8h] 
rtx elim_i2e; // [rsp+20h] [rbp-F8h] 
rtx new_destc; // [rsp+30h] [rbp-E8h] 
rtx new_destb; // [rsp+30h] [rbp-E8h] 
rtx v10; // rsi 
rtx v17; // rax 
rtx reg_rtx; // [rsp+10h] [rbp-78h] 
rtx x; // [rsp+28h] [rbp-60h] BYREF 
rtx v26; // [rsp+40h] [rbp-48h] 
reg_rtx = cfun->emit->x_regno_reg_rtx[regno]; 
v10 = ( rtx)rtx[2]; 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( rtx, v10)) != 0LL ) 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( rtx, v10)) != 0LL ) 
if ( *( _WORD *)v10 == 47 || ( v10 = single_set_2( rtx, v10)) != 0LL ) 
v14.rtwint = ( __int64)v10->fld[0]; 
x = rtx; 
rtx v11; // rax 
v11 = set_unique_reg_note( insn, REG_EQUAL, v10); 
reg_equal_equiv_note = v11; 
if ( !v11 ) 
rtx = v11->fld[0].rtx; 
rtx v37; // rdi 
rtx before; // [rsp+10h] [rbp-58h] 
before = ( rtx)trial[1]; 
( machine_mode)*( unsigned __int8 *)( v18.rtwint + 2), 
( machine_mode)( BYTE5( index_type->block.abstract_origin) >> 1), 
( machine_mode)( BYTE5( range->common.type->block.abstract_origin) >> 1), 
emit_cmp_and_jump_insns( v14, v17, GTU, 0LL, ( machine_mode)( unsigned __int8)v18, 1, default_label); 
v19 = gen_rtx_fmt_u00( LABEL_REF, ( machine_mode)v18, table_label); 
v22 = gen_rtx_fmt_ee( MULT, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v14, v21); 
v24 = gen_rtx_fmt_ee( PLUS, ( machine_mode)( ( ( BYTE3( target_flags) & 2) != 0) + 4), v22, v19); 
v25 = memory_address_noforce( ( machine_mode)v23, v24); 
v28 = gen_reg_rtx( ( machine_mode)v26); 
v31 = gen_rtx_MEM( ( machine_mode)v29, v27); 
if ( *( _OWORD *)&args1 == 0LL ) 
undos = undobuf_0.undos; 
if ( undobuf_0.undos ) 
frees = undobuf_0.frees; 
undobuf_0.frees = undos; 
undobuf_0.undos = 0LL; 
rtx v12; // rdx 
rtx v17; // rax 
rtx v18; // rdx 
rtx v32; // rax 
rtx i; // r13 
rtx v44; // rax 
rtx v46; // rax 
rtx *v49; // rax 
rtx *x_regno_reg_rtx; // rax 
*( _OWORD *)&result->common.chain = 0LL; 
v4 = ( tree_node *)*( ( _QWORD *)&chain->vector.elements + v3--); 
v25 = ( tree_node *)i5[5]; 
rtx v13; // rax 
v13 = copy_rtx_if_shared( rtx); 
i[3].fld[0].rtwint = ( __int64)v13; 
if ( ( tree_node *)*( &global_trees + 5) == section_name ) 
if ( ( tree_node *)*( &global_trees + 4) == section_name ) 
if ( ( tree_node *)*( &global_trees + 3) == section_name ) 
if ( ( tree_node *)*( &global_trees + 2) == section_name ) 
if ( ( tree_node *)*( &global_trees + 1) == section_name ) 
timevar_push( TV_LIFE_0); 
if ( ( prop_flags & 2) == 0 || ( timevar = TV_LIFE_0, ( insns = get_insns( )) == 0LL) ) 
timevar = TV_LIFE_0; 
timevar = TV_LIFE_0; 
timevar_push( TV_LIFE_UPDATE_0); 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
timevar = TV_LIFE_UPDATE_0; 
v4 = ( ( unsigned int)( mode_class_0[v6] - 5) < 2) + 1; 
rtx v7; // rax 
v7 = gen_rtx_fmt_ee( EXPR_LIST, VOIDmode, temp_slot_from_address->address, 0LL); 
v5->address = v7; 
address = v7; 
v25 = ( ( unsigned int)( mode_class_0[v22] - 5) < 2) + 1; 
v14 = ( change_t_0 *)xrealloc( changes, v13); 
rtx v33; // rcx 
rtx x; // [rsp+18h] [rbp-60h] 
rtx froma; // [rsp+20h] [rbp-58h] 
x = v4; 
froma = v7; 
v33 = *v12; 
validate_replace_rtx_1( ( rtx *)( ( char *)v33 + i), v36, v35, object); 
v33 = *v12; 
if ( in_section_0 == in_const ) 
if ( in_section_0 == in_data ) 
in_section_0 = in_data; 
if ( in_section_0 == in_data ) 
if ( in_section_0 == in_const ) 
in_section_0 = in_const; 
mergeable_constant_section( ( machine_mode)LOBYTE( decl->block.supercontext), v4, 0); 
rtx v46; // r14 
rtx x; // [rsp+10h] [rbp-48h] 
x = get_insns( ); 
fatal_insn( "wrong insn in the fallthru edge", rtx, "cfgrtl.c", 1717, "verify_flow_info"); 
fatal_insn( "flow control insn inside a basic block", ( rtx)v31, "cfgrtl.c", 1829, "verify_flow_info"); 
if ( x ) 
v41 = *( _WORD *)x; 
if ( x[2].fld[0].rtint == -80 ) 
if ( *( _DWORD *)( *( _QWORD *)&x[2] + 88LL) != ++v43 ) 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // r15 
$A887AD9C3C6C8CC7716950D571F57C9D *p_int_cst; // r15 
p_int_cst = &writer->int_cst.int_cst; 
v57 = ( tree_node *)p_int_cst->low; 
p_int_cst = ( $A887AD9C3C6C8CC7716950D571F57C9D *)( ( char *)p_int_cst + 8); 
rtx v12; // rdx 
rtx v14; // rax 
rtx v35; // rdx 
rtx v36; // r10 
rtx v40; // rax 
rtx v49; // rdx 
rtx v50; // rcx 
edge_info_0[( int)v18] = v21; 
if ( statement_code_p( ( tree_code)*( ( unsigned __int8 *)*v6 + 16)) && ( *( ( _BYTE *)*v6 + 19) & 4) == 0 ) 
result = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v6, walk_subtrees, func, data, htab_); 
result = lang_hooks_0.tree_inlining.walk_subtrees( ( tree_node **)v6, walk_subtrees, func, data, htab_); 
&& !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v6) ) 
&& !lang_hooks_0.tree_inlining.tree_chain_matters_p( ( tree_node *)*v6) ) 
v4 = general_operand( x, ( machine_mode)*( ( unsigned __int8 *)x + 2)); 
v6 = test_insn_13; 
if ( !test_insn_13 ) 
test_insn_13 = insn_raw; 
ggc_add_rtx_root( &test_insn_13, 1); 
v6 = test_insn_13; 
v2 = spelling_0; 
if ( spelling_base >= spelling_0 ) 
v10 = gen_lowpart( ( machine_mode)*( ( unsigned __int8 *)op + 2), v8); 
if ( **( _WORD **)&this_insn_1[2] == 39 ) 
if ( multiple_sets( this_insn_1) ) 
v6 = *( _DWORD **)( *( _QWORD *)&this_insn_1[2] + 8LL); 
v6 = *( _DWORD **)( *( _QWORD *)&this_insn_1[2] + 8LL); 
if ( output_p || find_regno_note( this_insn_1, REG_INC, rtint) ) 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
( machine_mode)*( ( unsigned __int8 *)reg + 2), 
mark_life( rtint, ( machine_mode)*( ( unsigned __int8 *)reg + 2), 0); 
qty_0[v4].death = output_p + 2 * this_insn_number; 
rtx base_term; // rax 
base_term = find_base_term( addr_0); 
if ( base_term ) 
if ( *( _WORD *)base_term == 67 || ( *( _DWORD *)base_term & 0x400FFFF) == 67108932 ) 
if ( *( _WORD *)base_term == 67 || ( *( _DWORD *)base_term & 0x400FFFF) == 67108932 ) 
( machine_mode)*( ( unsigned __int8 *)x + 2), 
( machine_mode)*( ( unsigned __int8 *)mem + 2)) ) 
if ( ( _DWORD)v5 == 16 || ( _DWORD)v5 == 22 || ( mode_class_0[v5] & 0xFFFFFFFB) == 1 ) 
if ( ( _DWORD)v3 != 16 && ( _DWORD)v3 != 22 && ( mode_class_0[v3] & 0xFFFFFFFB) != 1 ) 
if ( xexit_cleanup ) 
sprintf( xstrerror_buf, aUndocumentedEr, ( unsigned int)errnum); 
if ( ( unsigned int)v3 <= 0xFF && ( sch_istable[( unsigned int)v3] & 0xAC) != 0 ) 
timevar_push( TV_LEX_0); 
timevar_pop( TV_LEX_0); 
